{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>","tags":["test"]},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>","tags":["test"]},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>","tags":["test"]},{"location":"#some-tests","title":"Some tests","text":"<p>test equation \\(y = a + b\\)</p> \\[ \\sum_a^b \\] <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre> <pre><code>import numpy as np\n</code></pre> CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <p>Test</p> CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> Note <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> Tip <p>note that</p> Question <p>How does it work?</p>","tags":["test"]},{"location":"tags/","title":"Tags","text":"<p>Here is a list of tags used in this site:</p>"},{"location":"tags/#tag:abstract-data-type","title":"Abstract Data Type","text":"<ul> <li>            Priority Queue          </li> </ul>"},{"location":"tags/#tag:array","title":"Array","text":"<ul> <li>            1 Two sum          </li> <li>            1004 Max consecutive ones iii          </li> <li>            119 Pascal's triangle ii          </li> <li>            15 3sum          </li> <li>            18 4sum          </li> <li>            189 Rotate array          </li> <li>            209 Minimum size subarray sum          </li> <li>            26 Remove duplicates from sorted array          </li> <li>            27 Remove element          </li> <li>            325 Maximum size subarray sum equals k          </li> <li>            448 Find all numbers disappeared in an array          </li> <li>            485 Max consecutive ones          </li> <li>            487 Max consecutive ones ii          </li> <li>            560 Subarray sum equals k          </li> <li>            713 Subarray product less than k          </li> <li>            75 Sort colors          </li> <li>            80 Remove duplicates from sorted array ii          </li> <li>            862 Shortest subarray with sum at least k          </li> <li>            88 Merge sorted array          </li> <li>            896 Monotonic array          </li> <li>            904 Fruit into baskets          </li> <li>            974 Subarray sums divisible by k          </li> </ul>"},{"location":"tags/#tag:backtracking","title":"Backtracking","text":"<ul> <li>            17 Letter combinations of a phone number          </li> <li>            22 Generate parentheses          </li> <li>            37 Sudoku solver          </li> <li>            46 Permutations          </li> <li>            489 Robot room cleaner          </li> <li>            51 N-Queens          </li> <li>            52 N-Queens ii          </li> <li>            77 Combinations          </li> </ul>"},{"location":"tags/#tag:binary-search","title":"Binary Search","text":"<ul> <li>            1011 Capacity to ship packages within D days          </li> <li>            1099 Two sum less than k          </li> <li>            1146 Snapshot array          </li> <li>            1231 Divide chocolate          </li> <li>            1235 Maximum profit in job scheduling          </li> <li>            1283 Find the smallest divisor given a threshold          </li> <li>            1351 Count negative numbers in a sorted matrix          </li> <li>            153 Find minimum in rotated sorted array          </li> <li>            1533 Find the index of the large integer          </li> <li>            1539 Kth missing positive number          </li> <li>            154 Find minimum in rotated sorted array ii          </li> <li>            1631 Path with minimum effort          </li> <li>            1802 Maximum value at a given index in a bounded array          </li> <li>            1870 Minimum speed to arrive on time          </li> <li>            2300 Successful pairs of spells and portions          </li> <li>            240 Search a 2D matrix ii          </li> <li>            275 H-index ii          </li> <li>            278 First bad version          </li> <li>            300 Longest increasing subsequence          </li> <li>            33 Search in rotated sorted array          </li> <li>            34 Find first and last position of element in sorted array          </li> <li>            35 Search insert position          </li> <li>            354 Russian doll envelopes          </li> <li>            367 Valid perfect square          </li> <li>            374 Guess number higher or lower          </li> <li>            378 Kth smallest element in a sorted matrix          </li> <li>            4 Median of two sorted arrays          </li> <li>            410 Split array largest sum          </li> <li>            436 Find right interval          </li> <li>            441 Arranging coins          </li> <li>            528 Random pick with weight          </li> <li>            540 Single element in a sorted array          </li> <li>            658 Find k closest elements          </li> <li>            69 Sqrt(x)          </li> <li>            702 Search in a sorted array of unknown size          </li> <li>            704 Binary search          </li> <li>            74 Search a 2D matrix          </li> <li>            744 Find smallest letter greater than target          </li> <li>            81 Search in rotated sorted array ii          </li> <li>            852 Peak index in a mountain array          </li> <li>            875 Koko eating bananas          </li> <li>            981 Time Based Key-Value Store          </li> </ul>"},{"location":"tags/#tag:binary-search-tree","title":"Binary Search Tree","text":"<ul> <li>            426 Convert binary search tree to sorted doubly linked list          </li> <li>            700 Search in a binary search tree          </li> <li>            95 Unique binary search trees ii          </li> <li>            96 Unique binary search trees          </li> <li>            98 Validate binary search tree          </li> </ul>"},{"location":"tags/#tag:binary-tree","title":"Binary Tree","text":"<ul> <li>            100 Same tree          </li> <li>            101 Symmetric tree          </li> <li>            102 Binary tree level order traversal          </li> <li>            104 Maximum depth of binary tree          </li> <li>            105 Construct binary tree from preorder and inorder traversal          </li> <li>            106 Construct binary tree from inorder and postorder traversal          </li> <li>            112 Path sum          </li> <li>            116 Populating next right pointers in each node          </li> <li>            117 Populating next right pointers in each node ii          </li> <li>            144 Binary tree preorder traversal          </li> <li>            145 Binary tree postorder traversal          </li> <li>            236 Lowest common ancestor of a binary tree          </li> <li>            250 Count univalue subtrees          </li> <li>            297 Serialize and deserialize binary tree          </li> <li>            779 k-th Symbol in grammar          </li> <li>            94 Binary tree inorder traversal          </li> </ul>"},{"location":"tags/#tag:bit-manipulation","title":"Bit Manipulation","text":"<ul> <li>            779 k-th Symbol in grammar          </li> </ul>"},{"location":"tags/#tag:breadth-first-search","title":"Breadth-First Search","text":"<ul> <li>            1091 Shortest path in binary matrix          </li> <li>            1129 Shortest path with alternating colors          </li> <li>            116 Populating next right pointers in each node          </li> <li>            117 Populating next right pointers in each node ii          </li> <li>            1202 Smallest string with swaps          </li> <li>            133 Clone graph          </li> <li>            139 Word break          </li> <li>            1631 Path with minimum effort          </li> <li>            1971 Find if Path Exists in Graph          </li> <li>            200 Number of islands          </li> <li>            261 Graph valid tree          </li> <li>            279 Perfect square          </li> <li>            286 Walls and gates          </li> <li>            399 Evaluate divisions          </li> <li>            429 N-ary tree level order traversal          </li> <li>            494 Target sum          </li> <li>            542 01 matrix          </li> <li>            547 Number of provinces          </li> <li>            733 Flood fill          </li> <li>            752 Open the lock          </li> <li>            841 Keys and rooms          </li> <li>            994 Rotting oranges          </li> <li>            LCxxx. Title          </li> </ul>"},{"location":"tags/#tag:count","title":"Count","text":"<ul> <li>            611 Valid triangle number          </li> </ul>"},{"location":"tags/#tag:data-structure","title":"Data Structure","text":"<ul> <li>            Heap          </li> </ul>"},{"location":"tags/#tag:depth-first-search","title":"Depth-First Search","text":"<ul> <li>            1059 All paths from source lead to destination          </li> <li>            1202 Smallest string with swaps          </li> <li>            133 Clone graph          </li> <li>            1971 Find if Path Exists in Graph          </li> <li>            200 Number of islands          </li> <li>            261 Graph valid tree          </li> <li>            399 Evaluate divisions          </li> <li>            547 Number of provinces          </li> <li>            733 Flood fill          </li> <li>            797 All paths from source to target          </li> <li>            802 Find eventual safe states          </li> </ul>"},{"location":"tags/#tag:dequeue","title":"Dequeue","text":"<ul> <li>            862 Shortest subarray with sum at least k          </li> </ul>"},{"location":"tags/#tag:divide-and-conquer","title":"Divide and Conquer","text":"<ul> <li>            105 Construct binary tree from preorder and inorder traversal          </li> <li>            106 Construct binary tree from inorder and postorder traversal          </li> <li>            218 The skyline problem          </li> <li>            240 Search a 2D matrix ii          </li> </ul>"},{"location":"tags/#tag:doubly-linked-list","title":"Doubly-Linked List","text":"<ul> <li>            426 Convert binary search tree to sorted doubly linked list          </li> </ul>"},{"location":"tags/#tag:dynamic-programming","title":"Dynamic Programming","text":"<ul> <li>            1137 N-th Tribonacci number          </li> <li>            118 Pascal's triangle          </li> <li>            119 Pascal's triangle ii          </li> <li>            1235 Maximum profit in job scheduling          </li> <li>            1335 Minimum difficulty of a job schedule          </li> <li>            139 Word break          </li> <li>            1770 Maximum score from performing multiplication operations          </li> <li>            198 House robber          </li> <li>            221 Maximal square          </li> <li>            276 Paint fence          </li> <li>            300 Longest increasing subsequence          </li> <li>            509 Fibonacci number          </li> <li>            518 Coin change ii          </li> <li>            542 01 matrix          </li> <li>            70 Climbing stairs          </li> <li>            740 Delete and earn          </li> <li>            746 Min cost climbing stairs          </li> <li>            91 Decode ways          </li> <li>            95 Unique binary search trees ii          </li> <li>            96 Unique binary search trees          </li> </ul>"},{"location":"tags/#tag:graph","title":"Graph","text":"<ul> <li>            261 Graph valid tree          </li> </ul>"},{"location":"tags/#tag:hash-table","title":"Hash Table","text":"<ul> <li>            1 Two sum          </li> <li>            325 Maximum size subarray sum equals k          </li> <li>            448 Find all numbers disappeared in an array          </li> <li>            560 Subarray sum equals k          </li> <li>            904 Fruit into baskets          </li> <li>            974 Subarray sums divisible by k          </li> </ul>"},{"location":"tags/#tag:heap","title":"Heap","text":"<ul> <li>            1046 Last stone weight          </li> <li>            1167 Minimum cost to connect sticks          </li> <li>            1337 The k weakest rows in a matrix          </li> <li>            1642 Furthest building you can reach          </li> <li>            215 Kth largest element in an array          </li> <li>            218 The skyline problem          </li> <li>            253 Meeting rooms ii          </li> <li>            295 Find median from data stream          </li> <li>            347 Top k frequent elements          </li> <li>            378 Kth smallest element in a sorted matrix          </li> <li>            703 Kth largest element in a stream          </li> <li>            973 K closest points to origin          </li> </ul>"},{"location":"tags/#tag:line-sweep","title":"Line Sweep","text":"<ul> <li>            218 The skyline problem          </li> </ul>"},{"location":"tags/#tag:linked-list","title":"Linked List","text":"<ul> <li>            141 Linked list cycle          </li> <li>            142 Linked list cycle ii          </li> <li>            143 Reorder list          </li> <li>            1721 Swapping nodes in a linked list          </li> <li>            2 Add two numbers          </li> <li>            203 Remove linked list elements          </li> <li>            206 Reverse linked list          </li> <li>            2095 Delete the middle node of a linked list          </li> <li>            21 Merge two sorted list          </li> <li>            23 Merge k sorted list          </li> <li>            234 Palindrome linked list          </li> <li>            237 Delete node in a linked list          </li> <li>            24 Swap nodes in pairs          </li> <li>            445 Add two numbers ii          </li> <li>            876 Middle of the linked list          </li> <li>            92 Reverse linked list ii          </li> </ul>"},{"location":"tags/#tag:math","title":"Math","text":"<ul> <li>            119 Pascal's triangle ii          </li> <li>            50 Pow(x, n)          </li> <li>            509 Fibonacci number          </li> <li>            95 Unique binary search trees ii          </li> <li>            96 Unique binary search trees          </li> </ul>"},{"location":"tags/#tag:matrix","title":"Matrix","text":"<ul> <li>            1351 Count negative numbers in a sorted matrix          </li> <li>            240 Search a 2D matrix ii          </li> </ul>"},{"location":"tags/#tag:minimum-spanning-tree","title":"Minimum Spanning Tree","text":"<ul> <li>            1168 Optimize water distribution in a village          </li> <li>            1584 Min cost to connect all points          </li> </ul>"},{"location":"tags/#tag:monotonic-stack","title":"Monotonic Stack","text":"<ul> <li>            84 Largest rectangle in histogram          </li> </ul>"},{"location":"tags/#tag:prefix-sum","title":"Prefix Sum","text":"<ul> <li>            209 Minimum size subarray sum          </li> <li>            325 Maximum size subarray sum equals k          </li> <li>            528 Random pick with weight          </li> <li>            560 Subarray sum equals k          </li> <li>            862 Shortest subarray with sum at least k          </li> <li>            974 Subarray sums divisible by k          </li> </ul>"},{"location":"tags/#tag:queue","title":"Queue","text":"<ul> <li>            225 Implement stack using queues          </li> <li>            346 Moving average from data stream          </li> <li>            622 Design circular queue          </li> </ul>"},{"location":"tags/#tag:quickselect","title":"Quickselect","text":"<ul> <li>            215 Kth largest element in an array          </li> <li>            347 Top k frequent elements          </li> <li>            973 K closest points to origin          </li> </ul>"},{"location":"tags/#tag:recursion","title":"Recursion","text":"<ul> <li>            50 Pow(x, n)          </li> <li>            779 k-th Symbol in grammar          </li> </ul>"},{"location":"tags/#tag:shortest-path","title":"Shortest Path","text":"<ul> <li>            1631 Path with minimum effort          </li> <li>            743 Network delay time          </li> <li>            787 Cheapest flights within k stops          </li> </ul>"},{"location":"tags/#tag:sliding-window","title":"Sliding Window","text":"<ul> <li>            1004 Max consecutive ones iii          </li> <li>            485 Max consecutive ones          </li> <li>            487 Max consecutive ones ii          </li> <li>            713 Subarray product less than k          </li> <li>            80 Remove duplicates from sorted array ii          </li> <li>            904 Fruit into baskets          </li> </ul>"},{"location":"tags/#tag:slowfast-pointers","title":"Slow/Fast Pointers","text":"<ul> <li>            141 Linked list cycle          </li> <li>            142 Linked list cycle ii          </li> <li>            2095 Delete the middle node of a linked list          </li> <li>            876 Middle of the linked list          </li> </ul>"},{"location":"tags/#tag:sorting","title":"Sorting","text":"<ul> <li>            1099 Two sum less than k          </li> <li>            1498 Number of subsequences that satisfy the given sum condition          </li> <li>            2300 Successful pairs of spells and portions          </li> <li>            274 H-index          </li> <li>            354 Russian doll envelopes          </li> <li>            611 Valid triangle number          </li> <li>            75 Sort colors          </li> <li>            912 Sort an array          </li> </ul>"},{"location":"tags/#tag:stack","title":"Stack","text":"<ul> <li>            150 Evaluate reverse polish notation          </li> <li>            155 Min stack          </li> <li>            20 Valid parentheses          </li> <li>            206 Reverse linked list          </li> <li>            232 Implement queue using stacks          </li> <li>            394 Decode string          </li> <li>            739 Daily temperatures          </li> <li>            92 Reverse linked list ii          </li> </ul>"},{"location":"tags/#tag:string","title":"String","text":"<ul> <li>            344 Reverse string          </li> </ul>"},{"location":"tags/#tag:topological-sort","title":"Topological Sort","text":"<ul> <li>            1136 Parallel courses          </li> <li>            207 Course schedule          </li> <li>            210 Course schedule ii          </li> <li>            269 Alien dictionary          </li> <li>            310 Minimum height trees          </li> </ul>"},{"location":"tags/#tag:two-pointers","title":"Two Pointers","text":"<ul> <li>            1099 Two sum less than k          </li> <li>            1498 Number of subsequences that satisfy the given sum condition          </li> <li>            15 3sum          </li> <li>            18 4sum          </li> <li>            209 Minimum size subarray sum          </li> <li>            26 Remove duplicates from sorted array          </li> <li>            27 Remove element          </li> <li>            325 Maximum size subarray sum equals k          </li> <li>            344 Reverse string          </li> <li>            485 Max consecutive ones          </li> <li>            487 Max consecutive ones ii          </li> <li>            713 Subarray product less than k          </li> <li>            75 Sort colors          </li> <li>            80 Remove duplicates from sorted array ii          </li> <li>            88 Merge sorted array          </li> </ul>"},{"location":"tags/#tag:union-find","title":"Union Find","text":"<ul> <li>            1101 The earliest moment when everyone become friends          </li> <li>            1168 Optimize water distribution in a village          </li> <li>            1202 Smallest string with swaps          </li> <li>            1584 Min cost to connect all points          </li> <li>            1971 Find if Path Exists in Graph          </li> <li>            261 Graph valid tree          </li> <li>            323 Number of connected components in an undirected graph          </li> <li>            399 Evaluate divisions          </li> </ul>"},{"location":"tags/#tag:test","title":"test","text":"<ul> <li>            Home          </li> </ul>"},{"location":"abstract-data-type/","title":"Abstract Data Type","text":"<ul> <li>Priority Queue</li> <li>Tree</li> </ul>"},{"location":"abstract-data-type/priority-queue/","title":"Priority Queue","text":"","tags":["Abstract Data Type"]},{"location":"abstract-data-type/priority-queue/#introduction","title":"Introduction","text":"<p>A priority queue is an abstract data type similar to a regular queue or stack abstract data type. Each element in a priority queue has an associate priority. In a priority queue, elements with high priority are served before elements with low priority.</p>","tags":["Abstract Data Type"]},{"location":"abstract-data-type/priority-queue/#priority-queue-vs-heaps","title":"Priority Queue vs. Heaps","text":"<ul> <li>A priority queue is an abstract data type like a list or a map.</li> <li>Heaps are data structure that can be used to implement priority queue.</li> </ul> <p>Just as list (an abstract data type) can be implemented with a linked list or with an array (data structure). A priority queue can be implemented with a heap or another method such as an ordered array.</p>","tags":["Abstract Data Type"]},{"location":"abstract-data-type/priority-queue/#references","title":"References","text":"<ul> <li>Wiki - Priority Queue</li> </ul>","tags":["Abstract Data Type"]},{"location":"abstract-data-type/tree/","title":"Tree","text":"<p>A tree is a abstract data type that represents a hierarchical tree structure with a set of connected nodes. Each node has a parent (except the root) and zero or more children.</p> <p>The tree defines how trees are structured and manipulated but does not dictate a specific implementation. For example, the tree can be represented in a number of ways, including a list of parents with pointers to children, a list of children with pointers to parents, or a list of nodes and a separate list of parent-child relations.</p>"},{"location":"abstract-data-type/tree/#operations-and-properties","title":"Operations and Properties","text":"<p>Operations:</p> <ul> <li>Insert nodes</li> <li>Delete nodes</li> <li>Traversal (preorder, inorder, postorder, level-order)</li> <li>Search for a node</li> </ul> <p>Properties:</p> <ul> <li>There are no cycles (no node can be its own ancestor).</li> <li>Each child can be treated like the root node of its own subtree.</li> </ul>"},{"location":"abstract-data-type/tree/#traverse-the-tree","title":"Traverse the Tree","text":"<ul> <li>Depth First Search (DFS)<ul> <li>preorder: root -&gt; left -&gt; right</li> <li>in-order: left -&gt; root -&gt; right</li> <li>post-order: left -&gt; right -&gt; root</li> </ul> </li> <li>Breadth First Search (BFS) - Level Order     Scan through the tree level by level based on the height.</li> </ul>"},{"location":"abstract-data-type/tree/#common-tree-based-data-structure","title":"Common Tree-Based Data Structure","text":"<ul> <li>Binary Tree (each node has at most two children)</li> <li>Binary Search Tree (BST) (Ordered binary tree for efficient searching)</li> <li>Heap Tree (used for priority queues)</li> <li>Trie (Prefix Tree) (used for string storage)</li> </ul>"},{"location":"abstract-data-type/tree/#different-from-tree-in-graph-theory","title":"Different from Tree in Graph Theory","text":"<p>A tree ADT is a structured way to store and manipulate hierarchical data, while a tree in graph theory is mathematical concept of a connected, acyclic graph.</p> Feature Tree ADT Tree in Graph Theory Definition Hierarchical data structure Special type of graph Root Always has a root May or may not have a root Direction Typically directed (from parents to children) Undirected (unless specified) Cycles No cycles No cycles Use Cases Data storage, searching Network structures, spanning trees"},{"location":"algorithms/backtracking/","title":"Backtracking","text":"<p>Backtracking is a general algorithm for finding all (or some) solutions to some computational problems, particularly constraint satisfaction problems. It incrementally builds candidates for solutions and abandons a candidate (\"backtracks\") as soon as it determines that the candidate cannot be extended to a valid solution.</p> <p>We can view the procedure of backtracking as a tree structure, where the root node represents the initial problem and the leaves represent the solutions. Each node in the tree represents a candidate solution, and the edges represent the choices made to reach that candidate. Backtracking reduces the search space by eliminating candidates (i.e. pruning the tree) that are not valid solutions.</p> <p>The following diagram illustrates the backtracking process:</p> <pre><code>graph TD\n    p(Problem)\n    c1(Candidate 1)\n    ci(Candidate i)\n    cn(Candidate n)\n    c11(Candidate 1.1, Fail)\n    ci1(Candidate i.j)\n    cn1(Candidate n.l)\n    sk(Solution k)\n    sm(Solution m)\n    p --&gt; c1 --&gt; c11\n    p --&gt; ci --&gt; ci1 --&gt; sk\n    p --&gt; cn --&gt; cn1 --&gt; sm\n    c11 --Backtrack--&gt; c1\n\n    style c11 fill:#FF8A8A</code></pre>"},{"location":"algorithms/backtracking/#how-backtracking-works","title":"How Backtracking Works","text":"<p>Backtracking is a depth-first search algorithm that explores all possible solutions to a problem. It does this by building a solution incrementally, one piece at a time, and discarding solutions that fail to satisfy the constraints of the problem as soon as they are detected. The algorithm can be summarized in the following steps:</p> <ol> <li>Choose: Select a candidate solution.</li> <li>Check: Check if the candidate solution is valid.</li> <li>Complete: If the candidate solution is complete, return it.</li> <li>Backtrack: If the candidate solution is not valid, backtrack to the previous step    and try another candidate solution.</li> <li>Repeat: Repeat the process until a solution is found or all candidates have been    exhausted.</li> <li>Return: If a solution is found, return it; otherwise, return failure.</li> </ol>"},{"location":"algorithms/backtracking/#code-template","title":"Code Template","text":"<p>The following code template summarizes some common patterns for the backtracking algorithm:</p> <pre><code>def backtrack(candidate):\n   # Base case\n   if is_solution(candidate):\n      output(candidate)\n      return\n\n   # iterate all possible candidates\n   for candidate in candidates:\n      if is_valid(candidate):\n         place(candidate)  # Try the partial candidate solution.\n         backtrack(candidate)  # Given the candidate, recursively explore further.\n         remove(candidate)  # Remove the candidate (backtrack)\n</code></pre> <p>Here are a few notes on the code template:</p> <ul> <li>The numeration of candidates is done in two levels:<ul> <li>The first level is the recursion. At each occurrence of the function, the function is one step further to the final solution.</li> <li>The second level is the iteration within a recursion. It iterates through all possible candidates for the current level of recursion.</li> </ul> </li> <li>The backtracking happens at the second level of the iteration within the recursion. It is after the recursive call to the function. This is because we need to explore all possible candidates for the current level of recursion before backtracking.</li> <li>Prune the search space by checking if the candidate is valid (<code>is_valid(candidate)</code>) before placing it.</li> <li>There are two symmetric functions, <code>place(candidate)</code> and <code>remove(candidate)</code>, which are used to add and remove the candidate from the current solution.</li> </ul>"},{"location":"algorithms/backtracking/#standard-backtracking-problems","title":"Standard Backtracking Problems","text":"<ul> <li>All permutations</li> <li>Knight's Tour</li> <li>N-Queens</li> <li>Rat in a Maze</li> <li>Subset Sum</li> <li>Sudoku Solver</li> <li>Graph Coloring</li> </ul>"},{"location":"algorithms/complexity-analysis/","title":"Complexity Analysis","text":""},{"location":"algorithms/complexity-analysis/#time-complexity","title":"Time Complexity","text":""},{"location":"algorithms/complexity-analysis/#common-time-complexity-calculations","title":"Common Time Complexity Calculations","text":"<ul> <li>\\(\\log n! \\approx n \\log n\\)</li> </ul>"},{"location":"algorithms/divide-and-conquer/","title":"Divide and Conquer","text":""},{"location":"algorithms/divide-and-conquer/#introduction","title":"Introduction","text":"<p>Divide and conquer is an algorithm design paradigm that breaks a problem into two or more smaller subproblems, solves each subproblem independently, and then combines their solutions to solve the original problem.</p> <p>The divide and conquer technique is the basis of efficient algorithms for many problems, such as sorting (e.g., quicksort, merge sort), multiplying large numbers (e.g., Karatsuba algorithm) and computing the discrete Fourier transform (FFT).</p>"},{"location":"algorithms/divide-and-conquer/#implementation-steps","title":"Implementation Steps","text":"<ol> <li>Divide: Split the problem into a set of smaller subproblems of the same type, \\({S_1, S_2, \\cdots, S_n}\\) where \\(n \\geq 2\\).</li> <li>Conquer: Solve each subproblem recursively. If the subproblem size is small enough, solve it as a base case.</li> <li>Combine: Merge the solutions of the subproblems to form the solution to the original problem.</li> </ol> <p>The essential part of the divide and conquer is to figure out the recurrence relationship, which subsequently defines the function of divide and combine.</p>"},{"location":"algorithms/divide-and-conquer/#comparison-with-other-methods","title":"Comparison with Other Methods","text":""},{"location":"algorithms/divide-and-conquer/#other-recursion-methods","title":"Other Recursion Methods","text":"<p>For divide and conquer, the problem is divided into two or more subproblems of the same type, while in other recursion methods, the problem is divided into one subproblem.</p>"},{"location":"algorithms/divide-and-conquer/#dynamic-programming","title":"Dynamic Programming","text":"<p>For divide and conquer, the subproblems are independent, while in dynamic programming, the subproblems are dependent and share subsubproblems. In other words, in dynamic programming, the solution to a subproblem is reused multiple times, while in divide and conquer, each subproblem is solved independently.</p>"},{"location":"algorithms/divide-and-conquer/#backtracking","title":"Backtracking","text":"<ul> <li> <p>Often the case, the divide-and-conquer problem has a single solution, while backtracking problem has unknown number of solutions.</p> </li> <li> <p>Each step of the divide-and-conquer problem is indispensable to build the final solution, while many steps of the backtracking problem are serving as attempts to search for the potential solution.</p> </li> <li> <p>The divide-and-conquer problem has a clear and predefined path, while the backtracking problem does not know the exact path in advance.</p> </li> </ul>"},{"location":"algorithms/dynamic-programming/","title":"Dynamic Programming","text":"<p>Dynamic Programming (DP) is a method for solving complex problems by breaking them down into simpler subproblems. These problems have the following characteristics:</p> <ul> <li>Optimal substructure: an optimal solution can be constructed from optimal solutions of its subproblems.</li> <li>Overlapping subproblems: the problem can be broken down into subproblems which are re-used multiple times.</li> </ul>"},{"location":"algorithms/dynamic-programming/#principles-of-dynamic-programming","title":"Principles of Dynamic Programming","text":"<ol> <li>Identify a small number of subproblems   For example, compute the max weight of \\(G_i\\), for \\(i = 1, 2, 3, \\cdots, n\\)</li> <li>Can quickly and correctly solve \"larger\" subproblems given the solution to \"smaller\" subproblems   Usually via a recursion such as <code>G[i] = max(G[i - 1]], G[i-2])</code></li> <li>After solving all subproblems, can quickly compute the final solution   Usually, it's just the answer for the \"biggest\" subproblem</li> </ol>"},{"location":"algorithms/dynamic-programming/#implementation","title":"Implementation","text":"<p>General idea:</p> <ul> <li>Divide a complex problem into a number of simpler overlapping subproblem.</li> <li>Define a recursive relation to solve larger subproblem from smaller subproblem.</li> <li>Store solutions to each of these subproblems, solving each subproblem only once.</li> <li>Use stored solutions to solve the original problem</li> </ul> <p>Framework for implementation:</p> <ul> <li>Define a state (a set of variables) that sufficiently describe a scenario.</li> <li>A function or data structure that will compute/contain the answer to the subproblem for every given state.</li> <li>A recurrence relation to transition between states. A recurrence relation is an equation that relates different states with each other.</li> <li>Base cases, so that our recurrence relation doesn't go on infinitely.</li> </ul> <p>There are two ways to implement dynamic programming:</p> <ul> <li>Bottom-up, also known as tabulation.</li> <li>Top-down, also known as memoization.</li> </ul>"},{"location":"algorithms/dynamic-programming/#bottom-up-tabulation","title":"Bottom-up (Tabulation)","text":"<p>Bottom-up is implemented with iteration and starts at the base case and iteratively computes the value of each subproblem.</p> <pre><code>F = array of length (n + 1)\nF[0] = 0\nF[1] = 1\nfor i from 2 to n:\n    F[i] = F[i - 1] + F[i - 2]\n</code></pre>"},{"location":"algorithms/dynamic-programming/#top-down-memoization","title":"Top-down (Memoization)","text":"<p>Top-down is implemented with recursion by breaking down large problems into small subproblems, and stores the results of each subproblem in a memoization table.</p> <pre><code>memo = hashmap\nFunction F(integer i):\n    if i is 0 or 1:\n        return i\n    if i doesn't exist in memo:\n        memo[i] = F(i - 1) + F(i - 2)\n    return memo[i]\n</code></pre>"},{"location":"algorithms/dynamic-programming/#compare-with-other-algorithms","title":"Compare with Other Algorithms","text":"<ul> <li>Greedy algorithm: always makes the locally optimal choice, but may not always lead to the globally optimal solution. It does not have overlapping subproblems.</li> <li>Divide and conquer: divides the problem into smaller subproblems, but these subproblems are not overlapping.</li> </ul>"},{"location":"algorithms/dynamic-programming/#references","title":"References","text":"<ul> <li>Dynamic programming - Princeton Course</li> </ul>"},{"location":"algorithms/recursion/","title":"Recursion","text":"<p>Recursion is a method of solving problems where the solution depends on solutions to smaller instances of the same problem, achieved by a function calling itself within its own code.</p> <p>A recursive algorithm contains the following key components:</p> <ol> <li>Base Case: when to stop the recursive function.</li> <li>Problem Decomposition: breaks a complex problem into smaller, similar subproblems.</li> <li>Recursive Step: calls itself with a modified input to solve subproblems, moving toward the base case.</li> </ol>"},{"location":"algorithms/recursion/#key-points","title":"Key points","text":"<ul> <li>On the surface, function calls itself</li> <li>Essentially, boil down a big problem to smaller ones (size n depends on size n-1, or n-2, ..., or n/2)</li> <li>Implementation:<ul> <li>Base case: smallest problem to solve</li> <li>Recursive rule: how to make the problem smaller</li> </ul> </li> <li>If recursive function calls are too deep (e.g., n or n^2), there isn't enough physical memory to handle the increasingly growing stack, leading to a <code>StackOverflowError</code>. The Java docs have a good explanation of this, describing it as an error that occurs because an application recurses too deeply. More over, recursive function call needs special consideration when implementing on an embedded controller which has limited function call stack.</li> </ul>"},{"location":"algorithms/recursion/#how-recursion-works-internally","title":"How Recursion Works Internally","text":"<ul> <li> <p>Function Stack:</p> <ul> <li>Each time a function calls itself, a new stack frame is created.</li> <li>The current state (local variables, node being processed, etc.) is saved on the stack until the function returns.</li> <li>This is why recursion can use a lot of memory if the tree is deep, leading to a space complexity of\u00a0O(n)\u00a0in the worst case.</li> </ul> </li> <li> <p>Returning to the Caller:</p> <ul> <li>After processing the left subtree, the function returns to the previous caller, where it resumes execution (processes the root, then the right subtree).</li> <li>Recursion ensures that the execution \"goes back\" to the previous step in the correct order.</li> </ul> </li> </ul>"},{"location":"algorithms/recursion/#how-to-implement-a-recursive-function","title":"How to Implement a Recursive Function","text":"<p>Before implementing a recursive function, need to figure out:</p> <ul> <li>Recurrence relation: the relationship between the result of a problem and the result of its subproblems.</li> <li>Base  case: the case where the answer is directly computed or returned without any further recursive calls.</li> </ul> <p>For implementation, call the function itself according to the recurrence relation until we reach the base case. Use memoization to eliminate the duplicate calculation problem, if it exists.</p>"},{"location":"algorithms/recursion/#potential-issues-duplicate-calculations","title":"Potential Issues: Duplicate Calculations","text":"<p>If not using recursion wisely, it might get very long computation time due to duplicate calculations.</p> <p>For example, for computing Fibonacci number using simple recursion, <code>F(4) = F(3) + F(2) = (F(2) + F(1)) + F(2)</code>, it computes <code>F(2)</code> twice, <code>F(1)</code> 3 times, and <code>f(0)</code> twice.</p> <pre><code>graph TD\n    f3_f2_f0((\"f(0)\"))\n    f3_f2_f1((\"f(1)\"))\n    f4_f2_f0((\"f(0)\"))\n    f4_f2_f1((\"f(1)\"))\n    f3_f1((\"f(1)\"))\n    f3_f2((\"f(2)\"))\n    f3((\"f(3)\"))\n    f4_f2((\"f(2)\"))\n    f4((\"f(4)\"))\n    f4 --&gt; f3\n    f4 --&gt; f4_f2\n    f4_f2 --&gt; f4_f2_f1\n    f4_f2 --&gt; f4_f2_f0\n    f3 --&gt; f3_f2\n    f3 --&gt; f3_f1\n    f3_f2 --&gt; f3_f2_f1\n    f3_f2 --&gt; f3_f2_f0\n\n    style f4_f2 fill:#F2D2BD\n    style f3_f2 fill:#F2D2BD\n    style f3_f1 fill:#FFBF00\n    style f3_f2_f1 fill:#FFBF00\n    style f4_f2_f1 fill:#FFBF00\n    style f4_f2_f0 fill:#FFE5B4\n    style f3_f2_f0 fill:#FFE5B4</code></pre> <p>The common technique to address this problem is memoization, using additional space to reduce compute time.</p> <p>Memorization is an optimization technique primarily to speed up computer program by storing the results of expensive function calls and returning the cached result when the same inputs occur again. (Source: wikipedia)</p>"},{"location":"algorithms/recursion/#complexity-analysis","title":"Complexity Analysis","text":""},{"location":"algorithms/recursion/#time-complexity","title":"Time Complexity","text":"<p>Given a recursion algorithm, its time complexity \\(O(T)\\) is</p> \\[O(T) = n O(s)\\] <p>where \\(n\\) is the number of recursion invocations and \\(O(s)\\) is the time complexity of calculation in each recursion call.</p> <p>We can use Execution Tree to figure out the number of recursion calls. The execution tree of a recursive function would form an <code>n-ary tree</code>, with <code>n</code> as the number of times recursion in each function call. For example, the execution of the Fibonacci function would form a binary tree.</p> Execution Tree <p>Execution tree is a tree that is used to denote the execution flow of a recursive function. Each node in the tree represents an invocation of the recursive function. Therefore, the total number of nodes in the tree corresponds to the number of recursion calls during the execution.</p> <p>Memoization is often applied to optimize the time complexity of recursion algorithm by reducing number of recursion calls, i.e., reducing the number of branches in the execution tree.</p>"},{"location":"algorithms/recursion/#space-complexity","title":"Space Complexity","text":"<p>The space complexity of a recursive algorithm consists of two parts:</p> <ol> <li>Recursion related space: the stack to keep track of recursive function calls.</li> <li>Non-recursion related space: memory space (normally in heap) that is not directly related to recursion and is allocated for the global variables.</li> </ol> <p>Note that memoization will take non-recursion related space to store intermediate results.</p>"},{"location":"algorithms/recursion/#applications","title":"Applications","text":""},{"location":"algorithms/recursion/#solve-tree-problem-recursively","title":"Solve Tree Problem Recursively","text":""},{"location":"algorithms/recursion/#top-down-solution","title":"Top-Down Solution","text":"<p>Top-down means that in each recursive call, we will visit the node first to come up with some values, and pass these values to its children when calling the function recursively.</p> <pre><code>top_down(root, params):\n    return specific value for null node  # base case\n    update the answer if needed\n    left_ans = top_down(root.left, left_params)\n    right_ans = top+down(root.right, right_params)\n    return the answer if needed\n</code></pre> <p>Before trying the top-down recursive solution, ask the following two questions:</p> <ol> <li>Can you determine some parameters to help the node know its answer?</li> <li>Can you use these parameters and the value of the node itself to determine what should be the parameters passed to its children.</li> </ol>"},{"location":"algorithms/recursion/#bottom-up-solution","title":"Bottom-Up Solution","text":"<p>Bottom-up means that in each recursive call, we will first call the function recursively for all the children nodes and then come up with the answer according to the returned values and the value of the current node itself.</p> <pre><code>bottom_up(root):\n    return specific value for null node\n    left_ans = bottom_up(root.left)\n    right_ans = bottom_up(root.right)\n    calculate answer based on left_ans, right_ans, root.val\n    return answers\n</code></pre> <p>Before trying the bottom-up recursive solution, ask the following question:</p> <ul> <li>If you know the answer of a node's children, can you calculate the answer of that node?</li> </ul>"},{"location":"algorithms/graph/","title":"Graph","text":""},{"location":"algorithms/graph/#concept","title":"Concept","text":"<ul> <li>Tree</li> </ul>"},{"location":"algorithms/graph/#algorithms","title":"Algorithms","text":"<ul> <li>Traversal<ul> <li>Breadth-first search</li> <li>Depth-first search</li> </ul> </li> <li>Minimum Spanning Tree<ul> <li>Kruskal's algorithm</li> <li>Prim's algorithm</li> </ul> </li> </ul>"},{"location":"algorithms/graph/breadth-first-search/","title":"Breadth-first Search (BFS)","text":"<p>The breadth-first search (BFS) is usually used to</p> <ul> <li>traverse all vertices in a graph;</li> <li>find the shortest path between two vertices in a graph where all edges have equal and positive weights.</li> </ul> <p>Sometimes, need a <code>visited</code> hash set to track nodes visited to prevent getting stuck in an infinite loop, e.g., in graph with cycle.</p> <p>Note may not need to use a <code>visited</code>. Can check the existing value to indicate whether it is visited or not.</p>"},{"location":"algorithms/graph/depth-first-search/","title":"Depth-First Search","text":""},{"location":"algorithms/graph/depth-first-search/#introduction","title":"Introduction","text":"<p>Goal: Systematically search through a graph</p>"},{"location":"algorithms/graph/depth-first-search/#implementation","title":"Implementation","text":"<p>There are two ways to implement DFS:</p> <ul> <li>recursive DFS using recursion   Use the implicit stack provided by the system, also know as the Call Stack.</li> </ul> <pre><code>visited = set()\ndef dfs(node, visited):\n    visited.add(node)\n        for neighbor in adjacent_list[node]:\n            if neighbor not in visited:\n                dfs(neighbor, visited)\n</code></pre> <ul> <li>iterative DFS using stack</li> </ul> <pre><code>def dfs(node):\n    stack = [node]\n    visited = set([node])\n    while stack:\n        curr = stack.pop()\n        for neighbor in adjacent_list[curr]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                stack.append(neighbor)\n</code></pre> <p>Sometimes, need addition parameters like</p> <ul> <li><code>visited</code> to indicate whether the node has visited to avoid loops, which can explicit or implicit (using existing values).</li> <li><code>state</code> with multiple states (no visited, in process, done) to indicate whether the node is visited or a cycle exists.</li> <li><code>turple</code> object, for example to store <code>(current node, parent node)</code>.</li> </ul>"},{"location":"algorithms/graph/depth-first-search/#tips","title":"Tips","text":"<ul> <li>How to find the shortest path?   Add one more parameter to indicate the shortest path you have already found</li> </ul>"},{"location":"algorithms/graph/depth-first-search/#typical-applications","title":"Typical Applications","text":"<ul> <li>Find all vertices connected to a given source vertex</li> <li>Find a path between two vertices</li> </ul>"},{"location":"algorithms/graph/tree/","title":"Tree in Graph Theory","text":"<p>A tree in graph theory is a special case of a graph, defined as a connected acyclic undirected graph.</p> <p>The graph theory tree can be:</p> <ul> <li>Rooted trees: one node is designated as the root. This is similar to tree ADTs.</li> <li>Unrooted trees: no designated root, often used in network topology)</li> </ul>"},{"location":"algorithms/graph/tree/#properties","title":"Properties","text":"<ul> <li>N nodes and N - 1 edges (since tree is connected)</li> <li>No cycles</li> <li>Unique path between any two nodes</li> </ul>"},{"location":"algorithms/graph/minimum-spanning-tree/","title":"Minimum Spanning Tree","text":"<p>A spanning tree is a subgraph that is a tree (a connected undirected graph without cycles) which includes all of the vertices in an undirected graph and all vertices are connected with the minimum number of edges (without any cycles). An undirected graph can have multiple spanning trees.</p> <p>A minimum spanning tree is a spanning tree with the minimum possible total edge weight in a weighted undirected graph. A weighted undirected graph can have multiple minimum spanning trees.</p> <p>Two classic algorithms to construct a minimum spanning tree:</p> <ul> <li>Kruskal's algorithm</li> <li>Prim's algorithm</li> </ul>"},{"location":"algorithms/graph/minimum-spanning-tree/#cut-property","title":"Cut Property","text":"<p>In graph theory, a cut is to put a graph into two disjoint subsets. A crossing edge is an edge that connects a vertex in one subset with a vertex in the other subset.</p> <p></p> <p>Cut property: for any cut of the graph, the edge with the least weight is also an edge of the minimum spanning tree.</p> <p>Proof:</p> <ul> <li>To connect two disjoint subsets, we need to at least one edge.</li> <li>If there are more than two edges, it will form a cycle since each disjoin set is connected locally and two added edges will form a cycle.</li> <li>If select an edge with a larger weight, that means we can always find a smaller spanning tree by chooses smaller weight. So it has to be the edge with the least weight.</li> </ul>"},{"location":"algorithms/graph/minimum-spanning-tree/kruskal-algorithm/","title":"Kruskal's Algorithm","text":""},{"location":"algorithms/graph/minimum-spanning-tree/kruskal-algorithm/#introduction","title":"Introduction","text":"<p>Kruskal's algorithm finds a minimum spanning forest of a weighted undirected graph. If the graph is connected, it finds a minimum spanning tree. It is a greedy algorithm that in each step adds to the forest the lowest-weight edge that will not form a cycle.</p>"},{"location":"algorithms/graph/minimum-spanning-tree/kruskal-algorithm/#algorithm","title":"Algorithm","text":""},{"location":"algorithms/graph/minimum-spanning-tree/kruskal-algorithm/#procedures","title":"Procedures","text":"<p>The key steps of the algorithm are sorting and the use of a union-find data structure to detect cycles.</p> <ol> <li>Ascending sort all edges by their weight.</li> <li>Add edges in the sorted into the Minimum Spanning Tree. Skip the edges that would produce cycles in the Minimum Spanning Tree.</li> <li>Repeat step 2 until \\(N - 1\\) edges are added.</li> </ol> Why only choose N - 1 edges <p>The minimum number of edges to connect all vertices in the graph is \\(N - 1\\). Adding one will cause a cycle and reducing one will miss connection to a vertex.</p>"},{"location":"algorithms/graph/minimum-spanning-tree/kruskal-algorithm/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li> <p>Time complexity: \\(O(E \\log E)\\) where \\(E\\) represents the number of edges.</p> <ul> <li>At first, sorting all the edges take \\(O(E \\log E)\\) time.</li> <li>For building the minimum spanning tree, check each edge whether both vertices belong to the same connected component, which takes \\(O(\\alpha(V))\\) operation, where \\(\\alpha\\) refers to the Inverse Ackermann function. In the worst case, the tree will not be completed until reaching the last edge, so this will take \\(O(E \\alpha(V))\\) time.</li> <li>In total, the time complexity is \\(O(E \\log E + E \\alpha(V)) = O(E \\log E)\\).</li> </ul> </li> <li> <p>Space complexity: \\(O(V)\\) or \\(O(V + E)\\), where \\(V\\) represents the number of vertices.</p> <ul> <li>Depending on sorting algorithm, sorting algorithms may use \\(O(\\log E)\\) or \\(O(E)\\) space.</li> <li>Keeping track of the root of every vertex in the union-find data structure requires \\(O(V)\\) space.</li> <li>In total, the space complexity is \\(O(V + \\log E)\\) or \\(O(V + E)\\).</li> </ul> </li> </ul>"},{"location":"algorithms/graph/minimum-spanning-tree/prim-algorithm/","title":"Prim's Algorithm","text":"<p>Prim's algorithm is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. The algorithm operates by building the tree one vertex at a time, from an arbitrary starting vertex, at each step adding the cheapest possible connection from the tree to another vertex by using cut property</p>"},{"location":"algorithms/graph/minimum-spanning-tree/prim-algorithm/#introduction","title":"Introduction","text":""},{"location":"algorithms/graph/minimum-spanning-tree/prim-algorithm/#algorithm","title":"Algorithm","text":"<ol> <li>Initialize a tree with a single vertex, chosen arbitrarily from the graph.</li> <li>Grow the tree by one edge: find the vertex with the minimum edge between vertices in the tree and ones not in the tree, and transfer it to the tree</li> <li>Repeat step 2 (until all vertices are in the tree)</li> </ol>"},{"location":"algorithms/graph/minimum-spanning-tree/prim-algorithm/#procedures","title":"Procedures","text":""},{"location":"algorithms/graph/minimum-spanning-tree/prim-algorithm/#complexity-analysis","title":"Complexity Analysis","text":""},{"location":"algorithms/graph/shortest-path/","title":"Overview of Single Source Shortest Path","text":"<p>Breadth-first search (BFS) algorithm is used to find the shortest path in unweighted graphs.</p> <p>For a weighted graph, the BSF doesn't work. There are two common single source shortest path algorithms.</p> <ol> <li>Dijkstra's algorithm (only works with non-negative weights)</li> <li>Bellman-Ford algorithm (works with any weights) --&gt;  improved version, shortest path faster algorithm</li> </ol> <p>Edge relaxation is to select the shortest path between two nodes.</p>"},{"location":"algorithms/graph/shortest-path/bellman-ford-algorithm/","title":"Bellman Ford Algorithm","text":""},{"location":"algorithms/graph/shortest-path/bellman-ford-algorithm/#basic-theorem","title":"Basic Theorem","text":"<p>Theorem 1: In a graph with no negative-weight cycles with N vertices, the shortest path between any two vertices has at most \\(n - 1\\) edges.</p> <p>Negative-weight cycle: sum of weights in the cycle &lt; 0.</p> <p>Theorem 2: In a graph with negative-weight cycles, there is no shortest path.</p>"},{"location":"algorithms/graph/shortest-path/bellman-ford-algorithm/#algorithm","title":"Algorithm","text":""},{"location":"algorithms/graph/shortest-path/dijkstra-algorithm/","title":"Dijkstra's Algorithm","text":"<p>Dijkstra's Algorithm uses a greedy approach. Each step selects the minimum weight from currently reached vertices to find the shortest path to other vertices.</p> <p>The greedy approach only guarantees that each step takes the optimal choice in the current state. How does Dijkstra's algorithm ensure that the final result is optimal? Require edge has non-negative weight.</p> <p>Limitation: can only work on graphs with non-negative weights.</p>"},{"location":"algorithms/graph/shortest-path/shortest-path-faster-algorithm/","title":"Shortest Path Faster Algorithm","text":""},{"location":"algorithms/graph/shortest-path/shortest-path-faster-algorithm/#algorithm","title":"Algorithm","text":"<ul> <li>Use a <code>queue</code> to maintain the next starting vertex of the edge to be traversed.</li> <li>Add the vertex to the queue when the shortest distance of a vertex is relaxed and the vertex is not in the <code>queue</code>.</li> <li>Iterate the process until the queue is empty.</li> </ul>"},{"location":"algorithms/graph/topological-sort/","title":"Topological Sorting","text":"<p>Topological sorting provides a linear sorting based on the required ordering between vertices in directed acyclic graphs.</p>"},{"location":"algorithms/graph/topological-sort/kahns-algorithm/","title":"Kahn's Algorithm","text":""},{"location":"algorithms/search/","title":"Basic Search Algorithms","text":"<ul> <li>Linear search</li> <li>Binary search</li> <li>Two Pointers</li> <li>Staircase traversal</li> </ul>"},{"location":"algorithms/search/binary-search/","title":"Binary Search Algorithm","text":""},{"location":"algorithms/search/binary-search/#introduction","title":"Introduction","text":"<p>Binary search is a search algorithm that finds the position of a target value within a sorted array.</p> <p>Worst-case performance: \\(O(\\log n)\\) Best-case performance: \\(O(1)\\) Average performance: \\(O(\\log n)\\) Worst-case space complexity: \\(O(1)\\)</p>"},{"location":"algorithms/search/binary-search/#general-steps","title":"General Steps","text":"<p>Answering the following questions before coding:</p> <ul> <li>What is the target item, value, and type? An index, between two indices, or something else.</li> <li>What bounds must the target item be within? It's usually easy to use inclusive bounds, using <code>low</code> to represent the lowest possible position of the target and <code>high</code> to be the highest possible position.</li> <li>What can we conclude when <code>isReachable(mid)</code> returns true (\"yes\")? Don't accidentally exclude the target.</li> <li>What can we conclude when <code>isReachable(mid)</code> returns false (\"no\")? Don't accidentally exclude the target.</li> <li>How do we know when we've found the target item?</li> <li>Which calculation for mid should we use?</li> </ul>"},{"location":"algorithms/search/binary-search/#tips","title":"Tips","text":"<ul> <li>How to determine the while loop condition, <code>l &lt; r</code>, <code>l &lt;= r</code>, or <code>l &lt; r - 1</code>?   Choose the condition that will not infinity while loop. Check what would happen when   only two elements and 1 element left in the array. For example,</li> </ul> <pre><code>x  x  x  5   7  x  x  x\n        l/m  r\n</code></pre> <p>We can see what <code>l = m + 1</code> and <code>r = m</code> can both shrink the size by 1. When just one   element left,</p> <pre><code>x  x  x  5    x  x  x  x\n        l/m/r\n</code></pre> <p><code>r = m</code> can't shrink the size any more.</p> <ul> <li>How to update <code>mid</code>?<ul> <li>If using <code>hi = mid - 1</code>, use the higher midpoint, <code>mid = (lo + hi + 1) / 2</code>.</li> <li>If using <code>lo = mid + 1</code>, use the lower midpoint, <code>mid = (lo + hi) / 2</code>.</li> <li>If using above both, then use either lower or higher midpoint</li> </ul> </li> </ul>"},{"location":"algorithms/search/binary-search/#references","title":"References","text":"<ul> <li>wiki - binary search algorithm</li> <li>LeetCode answer on forgetting the binary search pattern</li> <li>Python bisect implementation</li> </ul>"},{"location":"algorithms/search/staircase-traversal/","title":"Staircase Traversal","text":""},{"location":"algorithms/search/staircase-traversal/#introduction","title":"Introduction","text":"<p>Staircase traversal is a powerful technique for searching and counting efficiently in a row-wise and column-wise sorted matrix. It runs in \\(O(n)\\) time, making it more efficient than brute-force \\(O(n^2)\\). It is often paired with binary search to further optimize problems (e.g., kth smallest element in a sorted matrix).</p>"},{"location":"algorithms/search/staircase-traversal/#why-is-it-called-staircase-traversal","title":"Why is it Called \"Staircase\" Traversal?","text":"<ul> <li>Start at the top-right corner (or bottom-left corner). This is the key step. Based on the sorted properties, after each comparison, we can clear remove one direction (either row or column).</li> <li>Move left if the current element is large.</li> <li>Move down if the current element is small.</li> <li>The movement resembles walking down a staircase.</li> </ul>"},{"location":"algorithms/search/staircase-traversal/#example","title":"Example","text":"<p>Given a\u00a0sorted matrix:</p> \\[\\begin{bmatrix} 1 &amp; 5 &amp; 9 \\\\ 10 &amp; 11 &amp; 13 \\\\ 12 &amp; 13 &amp; 15 \\end{bmatrix}\\] <p>Suppose we need to count how many elements are\u00a0\u2264 10.</p> <ol> <li>Start at\u00a0top-right (matrix[0][2] = 9).</li> <li>Since\u00a09 \u2264 10, count all elements in this column up to row 0 \u2192 count\u00a03.</li> <li>Move\u00a0down\u00a0to (matrix[1][2] = 13).</li> <li>Since\u00a013 &gt; 10, move\u00a0left\u00a0to (matrix[1][1] = 11).</li> <li>Since\u00a011 &gt; 10, move\u00a0left\u00a0to (matrix[1][0] = 10).</li> <li>Since\u00a010 \u2264 10, count all elements in this column up to row 1 \u2192 count\u00a05.</li> <li>Move\u00a0down\u00a0to (matrix[2][0] = 12), but\u00a012 &gt; 10, so stop.</li> </ol> <p>Total count =\u00a05 elements\u00a0\u2264 10.</p>"},{"location":"algorithms/search/staircase-traversal/#similar-problems","title":"Similar Problems","text":"<ul> <li>Search a 2D matrix II</li> <li>Find kth smallest element in a sorted matrix</li> </ul>"},{"location":"algorithms/sorting/","title":"Sorting Algorithms","text":"<p>Sorting algorithms are a class of algorithms that put elements of a list in a certain order. The most common orders are numerical order and lexicographical order. The algorithms differ in their method of sorting, their efficiency, and their use cases.</p>"},{"location":"algorithms/sorting/#types-of-sorting-algorithms","title":"Types of Sorting Algorithms","text":"<p>There are several types of sorting algorithms, including but not limited to:</p> <ul> <li>Bubble Sort</li> <li>Insertion Sort</li> <li>Selection Sort</li> <li>Shell Sort</li> <li>Quick Sort</li> <li>Merge Sort</li> <li>Heap Sort</li> <li>Counting Sort</li> <li>Bucket Sort</li> <li>Radix Sort</li> <li>Tim Sort</li> </ul>"},{"location":"algorithms/sorting/#complexity-analysis","title":"Complexity Analysis","text":""},{"location":"algorithms/sorting/#reference","title":"Reference","text":"<ul> <li>Sorting algorithm - Wiki</li> </ul>"},{"location":"algorithms/sorting/heap-sort/","title":"Heap Sort","text":"<p>Selection sort repeated finds the minimum element by traversing the unsorted part of the list. Heapsort improves upon this by quickly finding the maximum element through the maintenance of a max-heap.</p>"},{"location":"algorithms/sorting/merge-sort/","title":"Merge Sort","text":"<p>Merge Sort is a divide-and-conquer algorithm to sort an array. It is based on the concept of merging two sorted arrays into a single sorted array.</p> <p>It is particularly useful for sorting linked lists and large datasets that do not fit into memory.</p> <p>The algorithm works as follows:</p> <ol> <li>Divide: Split the array into two halves.</li> <li>Conquer: Recursively sort the two halves.</li> <li>Merge: Merge the two sorted halves into a single sorted array.</li> <li>Base Case: If the array has one or zero elements, it is already sorted.</li> </ol> <p>Note that</p> <ul> <li>Stability: Merge Sort is a stable sort, meaning that it preserves the relative order of equal elements.</li> <li>In-Place: Merge Sort is not an in-place sort, as it requires additional space for the temporary arrays used during the merge process.</li> </ul>"},{"location":"algorithms/sorting/merge-sort/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time Complexity: The time complexity of Merge Sort is \\(O(n \\log n)\\) in all cases (best, average, and worst).</li> <li>Space Complexity: The space complexity is \\(O(n)\\) due to the temporary arrays used for merging.</li> </ul>"},{"location":"algorithms/sorting/merge-sort/#applications","title":"Applications","text":"<ul> <li>Merge Sort is particularly useful for sorting linked lists and large datasets that do not fit into memory. It is also a good choice for external sorting, where the data is too large to fit into memory and must be sorted using external storage (like disk drives).</li> </ul>"},{"location":"algorithms/sorting/quick-sort/","title":"Quick Sort","text":"<p>Quick Sort is a highly efficient sorting algorithm and is based on partitioning of array into smaller sub-arrays. A large array is divided into two smaller sub-arrays: the smaller elements and the larger elements.</p> <p>Quick Sort can be implemented using recursion. The steps are as follows:</p> <ol> <li>Choose an element from the array as a pivot.</li> <li>Partitioning: rearrange the array so that all elements with values less than the pivot come before it, and all elements with values greater than the pivot come after it.</li> <li>Recursively apply the above steps to the sub-arrays of elements with smaller values and those with greater values.</li> <li>The base case for the recursion is when the array has one or zero elements, in which case it is already sorted.</li> </ol> <p>Note that:</p> <ul> <li>Quick Sort is not a stable sort, meaning that the relative order of equal sort items is not preserved.</li> </ul>"},{"location":"algorithms/sorting/quick-sort/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>The average time complexity is \\(O(n \\log n)\\), but the worst-case time complexity is \\(O(n^2)\\), which can occur when the smallest or largest element is always chosen as the pivot.</li> <li>The space complexity is \\(O(\\log n)\\) due to the recursive stack space.</li> </ul>"},{"location":"algorithms/sorting/sorted-array-tips/","title":"Tips for Sorted Array or Matrix","text":"<p>In an interview, whenever you're given a question where the input array is sorted, here are some super useful things to consider:</p> <ul> <li>Binary Search</li> <li>Two (or three) pointers</li> <li>A sliding window</li> <li>Traversing from the right</li> </ul> <p>For row-wise and column-wise sorted matrix:</p> <ul> <li>Binary Search</li> <li>Staircase Traversal</li> </ul> <p>Make sure to write down a couple examples and try experimenting with these approaches. Even understanding that these approaches may aid in finding an answer with a sorted array, you're showing your interviewer that you have a good understanding of the array data structure. Be mindful of negative values and duplicates as you're experimenting!</p>"},{"location":"data-structure/binary-tree/binary-tree/","title":"Binary Tree","text":""},{"location":"data-structure/binary-tree/binary-tree/#introduction","title":"Introduction","text":"<p>A binary tree is one of the most typical tree data structure. There are at most two children per node.</p>"},{"location":"data-structure/binary-tree/binary-tree/#variations","title":"Variations","text":"<ul> <li>Balanced binary tree: a binary tree in which the depth of the left and right subtrees of every node differ by 1 or less.<ul> <li>Property: If a tree has \\(n\\) number of nodes, and it is balanced, then the height or level of the tree \\(=O(\\log_2(n))\\)</li> </ul> </li> <li>Complete binary tree: a binary tree in which every level, except possibly the last, is completely filled, and all nodes are as far left as possible.<ul> <li>Property: If a tree is complete tree, then it must be a balanced tree.</li> </ul> </li> <li>Binary search tree (BST): For every single node in the tree, the values in its left subtree are all smaller than its value, and the values in its right subtree are all larger than its value. ^bst-definition<ul> <li>Property: If printing the value of the nodes in BST in in-order sequence, then it forms an ascending order.</li> <li>Question: what if there are duplicate values? Augment every tree node to store count together with regular fields like key, left, and right pointers (change the class definition).</li> </ul> </li> </ul>"},{"location":"data-structure/binary-tree/binary-tree/#different-traversal-methods","title":"Different Traversal Methods","text":"<p>Tree traversal refers to the process of visiting each node in a tree data structure, exactly once. Since a tree may be traversed in multiple ways, the traversal is classified by the order in which the nodes are visited. The tree traversal algorithms can be classified into two categories:</p> <ul> <li>Depth-First Search (DFS) Algorithm: it starts with the root node and first visits all nodes of one branch as deep as possible of the chosen node before going to the next sibling. There are three popular approaches: in-order, pre-order, and post-order.<ul> <li>Pre-order traversal: visit the root first, then the left subtree, and finally the right subtree.</li> <li>In-order traversal: traverse the left subtree first, then visit the root, and finally traverse the right subtree.</li> <li>Post-order traversal: traverse the left subtree first, then traverse the right subtree, and finally visit the root.<ul> <li>When deleting nodes in a tree, it will be in post-order. Delete a node's left and right children before delete the node itself.</li> <li>Post-order is widely used in mathematical expressions.</li> </ul> </li> </ul> </li> <li>Breadth-First Search (BFS) Algorithm: it starts from the root node and visits all nodes of current depth before moving to the next depth in the tree. The traversal is also called level-order traversal.</li> </ul> <p>Traversing a tree needs to store nodes in some way for later visiting. This is often done via a stack (LIFO) or a queue (FIFO) or call stack (implicit during recursion). Depth-first search is easily implemented via a stack or the call stack during recursion while breadth-first search is easily implemented via a queue.</p>"},{"location":"data-structure/binary-tree/binary-tree/#references","title":"References","text":"<ul> <li>Tree traversal - wiki</li> </ul>"},{"location":"data-structure/heap/","title":"Heap","text":"","tags":["Data Structure"]},{"location":"data-structure/heap/#introduction","title":"Introduction","text":"<p>Heap is a tree-based data structure that satisfies the heap property:</p> <ul> <li>The value of each node must be no greater than (or no less than) the value of its child nodes.</li> </ul> <p>Heap is not a priority queue but a way to implement it.</p> <p>There are two kinds of heaps:</p> <ul> <li>Max Heap: Each node in the Heap has a value no less than its child nodes. Therefore, the top element (root node) has the largest value in the Heap.</li> <li>Min Heap:Each node in the Heap has a value no larger than its child nodes. Therefore, the top element (root node) has the smallest value in the Heap.</li> </ul>","tags":["Data Structure"]},{"location":"data-structure/heap/#common-operations","title":"Common Operations","text":"<ul> <li><code>heapify</code>: create a heap out of given array of elements.</li> <li><code>push</code>: Add an element into the heap.</li> <li><code>peek</code>: find a maximum item of a max-heap, or a minimum item of a min-heap.</li> <li><code>pop</code>: returns the ono of maximum value from a max heap (or minimum value from a min) and remove it from the heap.</li> <li><code>size</code>: return the number of items in the heap.</li> </ul> <p>Usual space an time complexity:</p> Heap method Time complexity Space complexity <code>heapify</code> \\(O(N)\\) \\(O(N)\\) <code>push</code> \\(O(\\log\u2061N)\\) \\(O(1)\\) <code>peak</code> \\(O(1)\\) \\(O(1)\\) <code>pop</code> \\(O(\\log\u2061N)\\) \\(O(1)\\) <code>size</code> \\(O(1)\\) \\(O(1)\\) <p>\\(N\\) is the number of elements in the heap.</p> Creating a Heap from an array <ul> <li>Create an empty heap and insert elements one by one takes $O(N \\log N) time. It goes through \\(N\\) elements and insert each of them takes \\(O(\\log N)\\) time.</li> <li><code>Heapify</code> directly takes \\(O(N)\\) time. It considers an array as a tree and swap values to form a heap. The max number of swaps is \\(N\\).</li> </ul>","tags":["Data Structure"]},{"location":"data-structure/heap/#variants","title":"Variants","text":"<ul> <li>Binary heap</li> <li>Min-Max heap</li> <li>Fibonacci heap</li> <li>...</li> </ul>","tags":["Data Structure"]},{"location":"data-structure/heap/#built-in-libraries","title":"Built-in Libraries","text":"<p>Python provides <code>heapq</code> for min heap.</p>","tags":["Data Structure"]},{"location":"data-structure/heap/#applications-of-heap","title":"Applications of Heap","text":"<ul> <li>Heap Sort</li> <li>The Top-K problem</li> <li>The K-th element</li> </ul>","tags":["Data Structure"]},{"location":"data-structure/heap/#references","title":"References","text":"<ul> <li>Wiki - Heap</li> </ul>","tags":["Data Structure"]},{"location":"data-structure/heap/kth-element/","title":"The K-th Element","text":"<p>Finding the K-th element using the same approaches as finding the top K elements.</p>"},{"location":"data-structure/heap/top-k-problem/","title":"The Top K Problem","text":"<p>Use the Heap data structure to obtain top K's largest or smallest elements.</p>"},{"location":"data-structure/heap/top-k-problem/#approach-1-heap-with-all-elements","title":"Approach 1 - Heap with All Elements","text":""},{"location":"data-structure/heap/top-k-problem/#top-k-largest-elements-using-approach-1","title":"Top K Largest Elements Using Approach 1","text":"<ol> <li>Construct a Max Heap.</li> <li>Add all elements into the Max Heap (heapify).</li> <li>Traverse and pop the top element (max value) and store the value into the result array.</li> <li>Repeat step 3 \\(K\\) times until finding K largest elements.</li> </ol> <p>Note that</p> <ul> <li>The result array stores \\(K\\) largest elements.</li> <li>The element for the \\(K\\)th pop is the K-th largest element.</li> </ul>"},{"location":"data-structure/heap/top-k-problem/#top-k-smallest-elements-using-approach-1","title":"Top K Smallest Elements Using Approach 1","text":"<ol> <li>Construct a Min Heap.</li> <li>Add all elements into the Min Heap (heapify).</li> <li>Traverse and pop the top element (min value) and store the value into the result array.</li> <li>Repeat step 3 until finding the K smallest elements.</li> </ol> <p>Note that</p> <ul> <li>The result array stores \\(K\\) smallest elements.</li> <li>The element for the \\(K\\)th pop is the K-th smallest element.</li> </ul>"},{"location":"data-structure/heap/top-k-problem/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(N + K \\log N)\\) <ul> <li>Constructing a max heap by heapify an array (step 2) takes \\(O(N)\\) time.</li> <li>Pop element from the heap takes \\(O(\\log N)\\) time and this process repeat \\(K\\) times.</li> <li>So the total time complexity is \\(O(N) + O(K \\log N) = O(N + K \\log N)\\).</li> </ul> </li> <li>Space complexity: \\(O(N)\\)     The heap stores all \\(N\\) elements.</li> </ul>"},{"location":"data-structure/heap/top-k-problem/#approach-2-heap-with-k-elements","title":"Approach 2 - Heap with K Elements","text":""},{"location":"data-structure/heap/top-k-problem/#top-k-largest-elements-using-approach-2","title":"Top K Largest Elements Using Approach 2","text":"<ol> <li>Construct a Min Heap with size \\(K\\).</li> <li>Add elements one by one to the Min Heap.</li> <li>If heap size &gt; \\(K\\), pop the min element from the heap.</li> <li>Repeat step 2 and 3 until all elements have been processed.</li> </ol> <p>Note that</p> <ul> <li>The \\(K\\) elements in the Min Heap are the \\(K\\) largest elements.</li> <li>The top element in the Min Heap is the \\(K\\)-th largest element.</li> </ul>"},{"location":"data-structure/heap/top-k-problem/#top-k-smallest-elements-using-approach-2","title":"Top K Smallest Elements Using Approach 2","text":"<ol> <li>Construct a Max Heap with size \\(K\\).</li> <li>Add elements one by one to the Max Heap.</li> <li>If heap size &gt; \\(K\\), pop the max element from the heap.</li> <li>Repeat step 2 and 3 until all elements have been processed.</li> </ol> <p>Note that</p> <ul> <li>The \\(K\\) elements in the Max Heap are the \\(K\\) smallest elements.</li> <li>The top element in the Max Heap is the \\(K\\)-th smallest element.</li> </ul>"},{"location":"data-structure/heap/top-k-problem/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(N \\log K)\\) <ul> <li>Adding \\(K\\) items one by one to the heap takes takes \\(O(K \\log K)\\). Yet, heapifying the first \\(K\\) items takes \\(O(K)\\).</li> <li>Popping element from the heap takes \\(O(\\log K)\\) since the heap size is \\(K\\). In the worst case, it may pop \\(N - K\\) times. So the time complexity is \\(O((N - K) \\log K)\\).</li> <li>So the total time complexity is <ul> <li>\\(O(K \\log K) + O((N - K) \\log K) = O(N \\log K)\\).</li> <li>or \\(O(K) + O((N - K) \\log K) = O(K + (N - K) \\log K)\\) with heapify.</li> </ul> </li> </ul> </li> <li>Space complexity: \\(O(K)\\)     The heap stores at most \\(K\\) elements.</li> </ul>"},{"location":"data-structure/heap/top-k-problem/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - All Elements \\(O(N + K \\log N)\\) \\(O(N)\\) Approach 2 - \\(K\\) Elements \\(O(N \\log K)\\) \\(O(K)\\)"},{"location":"data-structure/linked-list/linked-list/","title":"Linked List","text":""},{"location":"data-structure/linked-list/linked-list/#main-concepts","title":"Main Concepts","text":"<p>A linked list is a collection of nodes and each node contains at least two fields:</p> <ul> <li><code>Data</code> contains the value</li> <li><code>Next</code> contains the reference to the next node</li> <li><code>Prev</code> contains the reference to the previous node (used for doubly linked list)</li> </ul> <p>The first node is usually called the head and used as the starting point of any iteration through the list. The last must have its next reference pointing to <code>None</code> or <code>Null</code> to determine the end of the list.</p> <p></p>"},{"location":"data-structure/linked-list/linked-list/#different-types-of-linked-list","title":"Different Types of Linked List","text":"<ul> <li>Singly linked list </li> <li>Doubly linked list </li> <li>Circular linked list: the last node points back to the head of the list to form a circle instead of pointing to None </li> </ul>"},{"location":"data-structure/linked-list/linked-list/#practical-applications","title":"Practical Applications","text":"<ul> <li>Implement queues, stacks, or graphs</li> <li>Used for more complex tasks, such as lifecycle management for an operation system application</li> </ul>"},{"location":"data-structure/linked-list/linked-list/#list-vs-linked-list","title":"List Vs. Linked List","text":""},{"location":"data-structure/linked-list/linked-list/#memory","title":"Memory","text":"<ul> <li>Arrays or lists use a contiguous memory block to store references to data</li> <li>Linked lists don't use contiguous memory and store references as part of their own elements</li> </ul>"},{"location":"data-structure/linked-list/linked-list/#performance","title":"Performance","text":"<ul> <li>For Python lists:<ul> <li>Insert elements at the end of a list is \\(O(1)\\)</li> <li>Insert at the beginning of the list, the average time complexity is \\(O(n)\\)</li> </ul> </li> <li>Linked lists:<ul> <li>Insert or remove elements at the beginning or end of a list, the time complexity is \\(O(1)\\)</li> </ul> </li> </ul> <p>So for</p> <ul> <li>queue: linked list is better than normal list</li> <li>stack: linked list is similar to normal list since insert and remove at the end of the list</li> </ul>"},{"location":"data-structure/linked-list/linked-list/#access-elements","title":"Access Elements","text":"<p>For retrieval:</p> <ul> <li>Lists: \\(O(1)\\) time to find element via index</li> <li>Linked list: \\(O(n)\\), since traverse the whole list to find the element</li> </ul> <p>For searching for a specific element, both lists and linked lists take \\(O(n)\\) time</p>"},{"location":"data-structure/linked-list/linked-list/#implementations","title":"Implementations","text":"<ul> <li>Singly linked list</li> <li>Doubly linked list</li> <li>Circular linked list</li> </ul>"},{"location":"data-structure/linked-list/linked-list/#references","title":"References","text":"<ul> <li>Real python linked list</li> </ul>"},{"location":"data-structure/queue/queue/","title":"Queue","text":""},{"location":"data-structure/queue/queue/#introduction","title":"Introduction","text":"<p>The <code>queue</code> is a typical FIFO (first-in-first-out) data structure with two main operations:</p> <ul> <li><code>Enqueue</code>: appends a new element to the queue</li> <li><code>Dequeue</code>: removes the first element from the queue</li> </ul> <p></p>"},{"location":"data-structure/queue/queue/#implementation","title":"Implementation","text":"<p>Two different data structure can be used to implement the <code>queue</code>:</p> <ul> <li>array</li> <li>linked list</li> </ul>"},{"location":"data-structure/queue/queue/#different-types-of-queue","title":"Different Types of Queue","text":"<ul> <li>Circular queue (implemented using either array of linked list)</li> <li>Double-ended queue, <code>deque</code> (the name is ponounced as <code>deck</code>), allows appending and popping from either side of the queue with approximately \\(O(1)\\) performance.</li> </ul>"},{"location":"data-structure/queue/queue/#references","title":"References","text":"<ul> <li>linked list</li> </ul>"},{"location":"data-structure/stack/stack/","title":"Stack","text":""},{"location":"data-structure/stack/stack/#introduction","title":"Introduction","text":"<p>Stack is a last-in-first-out data structure, supporting two main operations:</p> <ul> <li><code>push</code>: add a new element to the end</li> <li><code>pop</code>: remove the last element</li> </ul> <p></p>"},{"location":"data-structure/stack/stack/#implementation","title":"Implementation","text":"<p>Two different data structure can be used to implement the <code>stack</code>:</p> <ul> <li>resizing array</li> <li>linked list</li> </ul>"},{"location":"data-structure/stack/stack/#references","title":"References","text":"<ul> <li>linked list</li> </ul>"},{"location":"data-structure/union-find/union-find/","title":"Union Find","text":""},{"location":"data-structure/union-find/union-find/#introduction","title":"Introduction","text":"<p>The <code>union-find</code> data structure is also known as the <code>disjoint set</code> data structure. It is a data structure that has algorithms built-in.</p> <p>The <code>union-find</code> transforms the problem of check whether vertices are connected to whether vertices have the same root node. There are two important functions:</p> <ul> <li>The <code>find</code> function finds the root node of a given vertex.</li> <li>The <code>union</code> function unions two vertices and makes their root nodes the same.</li> </ul> <p>Where is Union-Find used?</p> <ul> <li>Connected components in networks</li> <li>Kruskal's Minimum Spanning Tree (MST)</li> <li>Cycle detection in graphs</li> <li>Percolation problems</li> <li>Friendship networks (social media applications)</li> </ul>"},{"location":"data-structure/union-find/union-find/#implementation","title":"Implementation","text":"<p>The various implementations focus on how to implement and optimize <code>find</code> and <code>union</code> functions.</p> <pre><code>class UnionFind:\n    def __init__(self, size):\n    def find(self, x):\n    def union(self, x, y):\n    def connected(self, x, y):\n</code></pre> <pre><code>flowchart TD\n    start[\"Union Find Implementation\"]\n    quickFind(\"Quick Find\")\n    quickUnion(\"Quick Union\")\n    unionByRank(\"Union by Rank\")\n    pathCompression(\"Path Compression\")\n    final(\"Union by Rank + Path Compression\")\n\n    start --&gt; quickFind\n    start --&gt; quickUnion\n    quickUnion --&gt; unionByRank --&gt; final\n    quickUnion --&gt; pathCompression --&gt; final</code></pre>"},{"location":"data-structure/union-find/union-find/#quick-find-implementation","title":"Quick Find Implementation","text":"<p>The array stores the <code>root</code> nodes.</p> Python <pre><code>class UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n\n    def find(self, x):\n        return self.root[x]\n\n    def union(self, x, y):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            for i in range(len(self.root)):\n                if self.root[i] == root_y:\n                    self.root[i] = root_x\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n</code></pre>"},{"location":"data-structure/union-find/union-find/#complexity-of-quick-find","title":"Complexity of Quick Find","text":"<ul> <li>Time complexity:<ul> <li>Union find constructor: \\(O(n)\\), initialize an array of size \\(n\\) with the values equal to the corresponding indices.</li> <li><code>find</code> function: \\(O(1)\\)</li> <li><code>union</code> function: \\(O(n)\\), need to traverse the entire array and update the root vertices.</li> <li><code>connected</code> function: \\(O(1)\\)</li> </ul> </li> <li>Space complexity: \\(O(n)\\)   The root array stores \\(n\\) elements.</li> </ul>"},{"location":"data-structure/union-find/union-find/#quick-union-implementation","title":"Quick Union Implementation","text":"<p>The array stores either <code>parent</code> or <code>root</code> node.</p> Python <pre><code>class UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n\n    def find(self, x):\n        while x != self.root[x]:\n            x = self.root[x]\n        return x\n\n    def union(self, x, y):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            self.root[root_y] = root_x\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n</code></pre>"},{"location":"data-structure/union-find/union-find/#complexity-of-quick-union","title":"Complexity of Quick Union","text":"<ul> <li>Time complexity:<ul> <li>Union find constructor: \\(O(n)\\), initialize an array of size \\(n\\) with the values equal to the corresponding indices.</li> <li><code>find</code> function: \\(O(n)\\), in the worst case scenario, we need to traverse all \\(n\\) vertices. For a balanced tree, it only needs to traverse the depth of the tree, i.e., \\(O(\\log n)\\).</li> <li><code>union</code> function: \\(O(n)\\) in the worst case since it involves <code>find</code> function calls.</li> <li><code>connected</code> function: \\(O(n)\\) in the worst case since it involves <code>find</code> function calls.</li> </ul> </li> <li>Space complexity: \\(O(n)\\)   The root array stores \\(n\\) elements.</li> </ul>"},{"location":"data-structure/union-find/union-find/#union-by-rank-implementation","title":"Union by Rank Implementation","text":"<p>This implementation improves <code>Quick Union</code> by optimizing the <code>union</code> function, choosing the parent node based on the height of each vertex. This can limit the maximum height of each vertex.</p> Python <pre><code>class UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n        self.rank = [1] * size\n\n    def find(self, x):\n        while x != self.root[x]:\n            x = self.root[x]\n        return x\n\n    def union(self, x, y):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = root_x\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = root_y\n            else:  # root_x == root_y\n                self.root[root_y] = root_x\n                self.rank[root_x] += 1\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n</code></pre>"},{"location":"data-structure/union-find/union-find/#complexity-of-quick-by-rank","title":"Complexity of Quick by Rank","text":"<ul> <li>Time complexity:<ul> <li>Union find constructor: \\(O(n)\\), create and fill the <code>root</code> and <code>rank</code> arrays.</li> <li><code>find</code> function: \\(O(\\log n)\\) in the worst case where repeated union components of equal rank (double number of nodes) leads to logarithmic height growth.</li> <li><code>union</code> function: \\(O(\\log n)\\) in the worst case since it involves <code>find</code> function calls.</li> <li><code>connected</code> function: \\(O(\\log n)\\) in the worst case since it involves <code>find</code> function calls.</li> </ul> </li> <li>Space complexity: \\(O(n)\\)   The <code>root</code> and <code>rank</code> arrays store \\(n\\) elements each.</li> </ul> Logarithmic Height Growth <p>Because the rank only increases when both trees have the same rank (i.e., the number of nodes doubles each time we increase the height), the maximum height (rank) of any tree will be logarithmic in terms of the number of nodes, \\(n\\). Specifically, after \\(k\\) rank increases, the tree will have at least \\(2^k\\) nodes. Thus, if we have \\(n\\) nodes, the maximum height \\(h\\) will satisfy, \\(2^h \\leq n\\), so \\(h = O(\\log n)\\).</p>"},{"location":"data-structure/union-find/union-find/#path-compression-implementation","title":"Path Compression Implementation","text":"<p>This implementation improves <code>Quick Union</code> by optimizing the <code>find</code> function with path compression. The path compression updates the parent node of all traversed elements to their root node. When searching for the root node of the same element again, only need to traverse two elements to find its root node.</p> Python <pre><code>class UnionFind:\n    def __init__(self, size):\n        self.root = [i for i in range(size)]\n\n    def find(self, x):\n        if x == self.root[x]:\n            return x\n        self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x, y):\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            self.root[root_y] = root_x\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n</code></pre>"},{"location":"data-structure/union-find/union-find/#complexity-of-path-compression","title":"Complexity of Path Compression","text":"<ul> <li>Time complexity:<ul> <li>Union find constructor: \\(O(n)\\), create and fill the <code>root</code> array.</li> <li><code>find</code> function: \\(O(n)\\) in the worst case and \\(O(\\log n)\\) on average, refer to Top-Down Analysis of Path Coompression where R. Seidel and M. Sharir discuss the upper bound running time when path compression is used with arbitrary linking.</li> <li><code>union</code> function: \\(O(n)\\) in the worst case and \\(O(\\log n)\\) on average, since it depends on <code>find</code> function calls.</li> <li><code>connected</code> function: \\(O(n)\\) in the worst case and \\(O(\\log n)\\) on average, since it depends on <code>find</code> function calls.</li> </ul> </li> <li>Space complexity: \\(O(n)\\)   The root array stores \\(n\\) elements.</li> </ul>"},{"location":"data-structure/union-find/union-find/#union-by-rank-path-compression-implementation","title":"Union by Rank + Path Compression Implementation","text":"<p>This implementation optimize the <code>quick union</code> with both <code>union by rank</code> and <code>path compression</code>.</p> Python <pre><code>class UnionFind:\n    def __init__(self, size)::\n        self.root = [i for i in range(size)]\n        self.rank = [1] * size  # (1)\n\n    def find(self, x):  # (2)\n        if x != self.root[x]:\n            self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x, y):  # (3)\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = root_x\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = root_y\n            else:\n                self.root[root_y] = root_x\n                self.rank[root_x] += 1\n\n    def connected(self, x, y):\n        return self.find(x) == self.find(y)\n</code></pre> <ol> <li>Use a rank array to store the height of each vertex with initial value of 1.</li> <li>Path compression optimization.</li> <li>Union by rank optimization.</li> </ol>"},{"location":"data-structure/union-find/union-find/#complexity-of-union-by-rank-path-compression","title":"Complexity of Union by Rank + Path Compression","text":"<ul> <li>Time complexity:<ul> <li>Union find constructor: \\(O(n)\\), create and fill the <code>root</code> and <code>rank</code> arrays.</li> <li><code>find</code> function: amortized time complexity is \\(O(\\alpha(n))\\), where \\(\\alpha(n)\\) is the inverse Ackermann function. The <code>Union by Rank</code> optimization keeps the tree shallow by attaching the smaller tree under the root of the larger tree. The rank (or approximate height) of each tree grows logarithmically, ensuring that trees stay balanced. The <code>Path Compression</code> optimization further flatten the structure by making visited node on the path directly connected to the root. The combination of <code>Union by Rank</code> and <code>Path Compression</code> ensures that the tree remains flat, and each node's depth is minimized over time.</li> <li><code>union</code> function: amortized time complexity is \\(O(\\alpha(n))\\) since it depends on the <code>find</code> function.</li> <li><code>connected</code> function: amortized time complexity is \\(O(\\alpha(n))\\) since it depends on the <code>find</code> function.</li> </ul> </li> <li>Space complexity: \\(O(n)\\)   The <code>root</code> and <code>rank</code> arrays store \\(n\\) elements each.</li> </ul> Inverse Ackermann Function <p>The Ackermann function, \\(A(m, n)\\), grows so fast that for relatively small values of \\(m\\) and \\(n\\), the function produces enormous numbers. The inverse Ackermann function essentially \"reverse\" the Ackermann function to answer the question: \"How many times do we need to apply the Ackermann function's recusion before reaching a certain value?\"</p> <p>Formally, \\(\\alpha(n)\\) is the smallest integer \\(m\\) such that \\(A(m, m) \\geq n\\). For any practical value of \\(n\\), \\(\\alpha(n)\\) is extremely small. For example, if \\(n \\leq 2^{65536}\\), then \\(\\alpha(n) \\leq 5\\).</p> Time-Complexity Analysis <p>Refer to Cornell CS Union-Find lecture. Here is the local copy.</p>"},{"location":"data-structure/union-find/union-find/#comparison-of-different-implementations","title":"Comparison of Different Implementations","text":"<p>The table below summarize the time complexity and space complexity of different implementations:</p> Approach Constructor Time Complexity <code>find</code> Tme Complexity <code>union</code> Time Complexity <code>connected</code> Time Complexity Space Complexity Quick Find \\(O(n)\\) \\(O(1)\\) \\(O(n)\\) \\(O(1)\\) \\(O(n)\\) Quick Union \\(O(n)\\) \\(O(n)\\) worst, \\(O(h)\\) average \\(O(n)\\) worst, \\(O(h)\\) average \\(O(n)\\) worst, \\(O(h)\\) average \\(O(n)\\) Union by Rank \\(O(n)\\) \\(O(\\log n)\\) \\(O(\\log n)\\) \\(O(\\log n)\\) \\(O(n)\\) Path Compression \\(O(n)\\) \\(O(n)\\) worst, \\(O(\\log n)\\) average \\(O(n)\\) worst, \\(O(\\log n)\\) average \\(O(n)\\) worst, \\(O(\\log n)\\) average \\(O(n)\\) Union by Rank + Path Compression \\(O(n)\\) amortized \\(O(\\alpha(n))\\) amortized \\(O(\\alpha(n))\\) amortized \\(O(\\alpha(n))\\) \\(O(n)\\)"},{"location":"lc-solutions/","title":"My LC Solutions","text":""},{"location":"lc-solutions/lc-template/","title":"LCxxx. Title","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem xxx: Description</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#approach-","title":"Approach -","text":"<p>Solution</p> Python <pre><code>code\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#approach-2-","title":"Approach 2 -","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc-template/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/","title":"LC1. Two Sum","text":"","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1: Given an array of integers <code>nums</code>\u00a0and an integer <code>target</code>, return indices of the two numbers such that they add up to <code>target</code>.</p> <p>You may assume that each input would have exactly one solution, and you may not use the same element twice.</p> <p>You can return the answer in any order.</p>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#clarification","title":"Clarification","text":"<ul> <li>Target and numbers can be negative</li> <li>indices: zero-based or one-based</li> <li>sorted or unsorted?</li> <li>solution exsit for a given target and only one</li> </ul>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#assumption","title":"Assumption","text":"","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#solution","title":"Solution","text":"","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#approach-brute-force","title":"Approach - Brute Force","text":"<p>Use two nested for-loops to loop trough all possible pairs and compute sum. If <code>sum == target</code>, return indices.</p> PythonC++ <pre><code>class Solution:\n    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:\n        for i in range(len(nums)):\n            for j in range(i + 1, len(nums)):\n                if nums[i] + nums[j] == target:\n                    return [i, j]\n</code></pre> <pre><code>class Solution {\npublic:\n    vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) {\n        for (int i = 0; i &lt; nums.size(); i++) {\n            for (int j = i + 1; j &lt; nums.size(); j++) {\n                if ((nums[i] + nums[j]) == target) {\n                    return {i, j};\n                }\n            }\n        }\n        return {};\n    }\n};\n</code></pre>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^2)\\)     Since using two nested for-loops, the time complexity is \\(O(n^2)\\).  </li> <li>Space complexity: \\(O(1)\\)     The space required doesn't depend on the size of the input array. So only constant space is used. </li> </ul>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#approach-two-pass-hash-table","title":"Approach - Two-Pass Hash Table","text":"<p>To improve the runtime complexity, we can use a hash table to efficiently check whether <code>target - num</code> exists for any <code>num</code> in the array and get its index if exists. </p> <p>We can reduce the lookup time from \\(O(n)\\) to \\(O(1)\\) by trading space for time. Note that lookup in a hash table should be amortized \\(O(1)\\) time as long as the hash function was chosen carefully. Otherwise, if a collision occurred, a lookup could degenerate to \\(O(n)\\) time.</p> <p>We can use two pass to solve the problem:</p> <ol> <li>Add each element's value as a key and its index as a value to the hash table</li> <li>Check if each element's complement, <code>target - num</code> exists in the hash table. If exists, return current index and its complement's index. Note that: make sure the complement is not num itself.</li> </ol> C++ <pre><code>class Solution {\npublic:\n    vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) {\n        unordered_map&lt;int, int&gt; seen;\n        for (int i = 0; i &lt; nums.size(); i++) {\n            seen[nums[i]] = i;\n        }\n\n        for (int i = 0; i &lt; nums.size(); i++) {\n            int complement = target - nums[i];\n            if (seen.find(complement) != seen.end() &amp;&amp; seen[complement] != i) {\n                return {i, seen[complement]};\n            }\n        }\n\n        return {};\n    }\n};\n</code></pre>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It takes \\(O(n)\\) to update the hash map and another \\(O(n)\\) to check whether complement exists. So the total time complexity is \\(O(n) = O(n) + O(n)\\). </li> <li>Space complexity: \\(O(n)\\)     The hash table takes at most \\(O(n)\\) space. </li> </ul>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#approach-hash-table","title":"Approach - Hash Table","text":"<p>We need to find 2 numbers <code>a</code> and <code>b</code> so that <code>a + b == target</code>. That means for any given <code>a</code>, we need to find <code>b</code> with <code>b = target - a</code>. To effectively find <code>b</code>, we can use a hash table to store previous <code>&lt;num, index&gt;</code>, using array element as key and its index as value. Then for each <code>a</code>, search for <code>target - a</code> in the table.  If it is found and is not the same element as <code>a</code>, then we are done. </p> <p>Note that each time we search for <code>target - a</code> first and then add update hash table, so we will not hit the same element twice. Even there are duplicated numbers, hash map stores the recent one, which is still the valid answer. </p> PythonC++ <pre><code>class Solution:\ndef twoSum(self, nums: List[int], target: int) -&gt; List[int]:\n    value_index_map = {}\n    for i in range(len(nums)):\n        complement = target - nums[i]\n        if complement in value_index_map:\n            return [value_index_map[complement], i]\n\n        value_index_map[nums[i]] = i # (1)\n</code></pre> <ol> <li>If encounter the same number, stores the most recent one</li> </ol> <pre><code>class Solution {\npublic:\n    vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) {\n        unordered_map&lt;int, int&gt; seen;\n        for (int i = 0; i &lt; nums.size(); i++) {\n            int complement = target - nums[i];\n            if (seen.find(complement) != seen.end()) {\n                return {seen[complement], i};\n            }\n            seen[nums[i]] = i;\n        }\n        return {};\n    }\n};\n</code></pre>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#complexity-analysis_2","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Traverse the whole array once and each lookup in the hash table costs only \\(O(1)\\) time. So the total time complexity is \\(O(n)\\).  </li> <li>Space complexity: \\(O(n)\\)     The hash table stores at most \\(n\\) elements. Therefore the space complexity is \\(O(n)\\).</li> </ul>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Brute Force \\(O(n^2)\\) \\(O(1)\\) Approach - Two-Pass Hash Table \\(O(n)\\) \\(O(n)\\) Approach - Hash Table \\(O(n)\\) \\(O(n)\\)","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0001-two-sum/#test","title":"Test","text":"","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0001-0099/lc0002-add-two-numbers/","title":"LC2. Add Two Numbers","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0002-add-two-numbers/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 2: You are given two\u00a0non-empty\u00a0linked lists representing two non-negative integers. The digits are stored in\u00a0reverse order, and each of their nodes contains a single digit. Add the two numbers and return the sum\u00a0as a linked list.</p> <p>You may assume the two numbers do not contain any leading zero, except the number 0 itself.</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0002-add-two-numbers/#clarification","title":"Clarification","text":"<ul> <li>two linked list have different number of nodes</li> <li>Modify the existing node?</li> <li>Reverse order</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0002-add-two-numbers/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0002-add-two-numbers/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0002-add-two-numbers/#approach-elementary-math","title":"Approach - Elementary Math","text":"<p>Follow the elementary math on sum, begin by summing the least-significant digits, which are the heads of l1 and l2. Summing two digits may overflow and needs additional variable <code>carry</code> to store overflow value.</p> Python <pre><code>class Solution:\n    def addTwoNumbers(self, l1: Optional[ListNode], l2: Optional[ListNode]) -&gt; Optional[ListNode]:\n        dummy = ListNode(-1, None)\n\n        p1 = l1\n        p2 = l2\n        p = dummy\n        carry = 0\n        while p1 or p2 or carry &gt; 0:\n            if p1 is None:\n                val1 = 0\n            else:\n                val1 = p1.val\n                p1 = p1.next\n\n            if p2 is None:\n                val2 = 0\n            else:\n                val2 = p2.val\n                p2 = p2.next\n\n            sum_node = val1 + val2 + carry\n            carry = sum_node // 10\n            p.next = ListNode(sum_node % 10, None)\n\n            p = p.next\n\n        return dummy.next\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0002-add-two-numbers/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Need to go through \\(max(n_1, n_2)\\) nodes, where \\(n_1\\) is the number of nodes of l1 and \\(n_2\\) is the number of nodes of l2.</li> <li>Space complexity: \\(O(n)\\)     Need to create a linked list to store the sum, which contains at most \\(max(n1, n2) + 1\\) nodes.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0002-add-two-numbers/#test","title":"Test","text":"<ul> <li>one list is longer than the other</li> <li>one list is an empty list</li> <li>the sum could have an extra carry of one at the end</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/","title":"LC4. Median of Two Sorted Arrays","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 4: Given two sorted arrays\u00a0<code>nums1</code>\u00a0and\u00a0<code>nums2</code>\u00a0of size\u00a0<code>m</code>\u00a0and\u00a0<code>n</code>\u00a0respectively, return\u00a0the median\u00a0of the two sorted arrays.</p> <p>The overall run time complexity should be\u00a0<code>O(log (m+n))</code>.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#clarification","title":"Clarification","text":"<ul> <li>sorted vs. unsorted?</li> <li>different sizes?</li> <li>any duplicates?</li> <li>median definition?</li> <li>data type?</li> <li>time complexity requirement?</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#assumption","title":"Assumption","text":"<ul> <li>At least one array is not emepty</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#solution","title":"Solution","text":"<p>Start from median definition to find solutions. </p> <p>Median definition: the median is the \"middle\" of a sorted list of numbers. \\(\\text{median}(x) = (x \\lfloor (n+1)/2 \\rfloor + x \\lceil (n+1)/2 \\rceil)/2\\), where \\(x\\) is an ordered list of \\(n\\) numbers, and \\(\\lfloor \\cdot \\rfloor\\) and \\(\\lceil \\cdot \\rceil\\) denotes the floor and ceiling functions, respectively.</p> <ul> <li>If n is odd, the median is \\((n + 1)/2\\) th element. </li> <li>If n is even, the median is the average of \\((n + 1)/2\\) th and \\((n + 1)/2 + 1\\) th elements </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#approach-two-pointers","title":"Approach - Two Pointers","text":"<p>Have two pointers for each array. Move the pointer with smaller value forward at each step. Continue moving the pointers until reaching half of the total number of elements. Based on median definition, calculate median value.</p> Python <pre><code>class Solution:\n    def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -&gt; float:\n        m, n = len(nums1), len(nums2)\n        i, j = 0, 0\n\n        value = 0\n        for count in range(0, (m + n) // 2 + 1):\n            value_prev = value\n            if i &gt;= m:\n                value = nums2[j]\n                j += 1\n            elif j &gt;= n:\n                value = nums1[i]\n                i += 1\n            else:\n                if nums1[i] &lt;= nums2[j]:\n                    value = nums1[i]\n                    i += 1\n                else:\n                    value = nums2[j]\n                    j += 1\n\n        if (m + n) % 2 == 1:\n            return value\n        else:\n            return (value + value_prev) / 2\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(m + n)\\) Since moving pointer one step per execution, it takes \\((m + n) // 2\\) steps to find the median. So the time complexity is \\(O(m + n)\\).</li> <li>Space complexity: \\(O(1)\\) Use several variables. </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#approach-find-k-th-smallest","title":"Approach - Find k-th smallest","text":"<p>Based on the median definition, we can convert the problem to find \\((m + n + 1)/2\\)-th smallest elements, where \\(m\\) and \\(n\\) are total number of array 1 and array 2, respectively. </p> <ul> <li>Idea: In every iteration, compare first k/2 elements of array A with the first k/2 elements of array B and delete k/2 elements.</li> <li>How to reduce search size? k -&gt; k/2 -&gt; (k - k/2)/2 ... -&gt; 1</li> <li>How to delete k/2? If <code>a[aLeft + k/2 - 1] &lt;= b[bLeft + k/2 - 1]</code>, delete elements from <code>a[aLeft]</code> to <code>a[aLeft + k/2 - 1]</code> since <code>a[aLeft + k/2 - 1]</code> is smaller than the k-th smallest element and therefore the k-th smallest element can not be among <code>a[aLeft]</code> to <code>a[aLeft + k/2 - 1]</code>. <code>aLeft</code> is the array A's left border to consider from. <code>bLeft</code> is the array B's left border to consider from.  Note the total number of elements in comparison is k (k/2 elements from <code>aLeft</code> to <code>aLeft + k/2 - 1</code> and k/2 elements from <code>bLeft</code> to <code>aLeft + k/2 - 1</code>). if k-th smallest elements is among <code>a[aLeft]</code> to <code>a[aLeft + k/2 - 1]</code> (assuming <code>a[m]</code>), it means that there shouldn't be any element that is larger than <code>a[m]</code>. However, at least <code>b[bLeft + k/2 - 1]</code> is larger than <code>a[m]</code> since <code>b[bLeft + k/2 - 1] &gt;= a[aLeft + k/2 - 1] &gt;= a[m]</code>.</li> <li> <p>Base cases:</p> <ul> <li>If <code>aLeft &gt; a.length</code> (finish searching array a), return <code>b[bLeft + k - 1]</code>, the k-th smallest element (must in b). </li> <li>If <code>bLeft &gt; b.length</code> (finish searching array b), return <code>b[aLeft + k - 1]</code>, the k-th smallest element (must in a). </li> <li>If <code>k == 1</code>,  the k-th smallest elements should be the smaller one of <code>a[aLeft]</code> and <code>b[bLeft]</code>. Remember the search sapce is reduced from k -&gt; k/2 -&gt; ... -&gt; 1. The k-th smallest elements should be found when <code>k == 1</code> </li> </ul> </li> <li> <p>Corner cases:</p> <ul> <li>If <code>a.length</code> is too small (doesn't have k/2 elements), remove elements from b first until a has k/2 elements after reducing search space (k).</li> <li>If <code>b.length</code> is too small ((doesn't have k/2 elements)), remove elements from a first until b has k/2 elements after reducing search space (k).</li> </ul> </li> </ul> Java <pre><code>class Solution {\n    public double findMedianSortedArrays(int[] nums1, int[] nums2) {\n        // if (nums1 == null || nums1.length == 0 || nums2 == null || nums2.length == 0)\n        //     return Double.NaN;\n\n        int k = (nums1.length + nums2.length + 1)/2;\n\n        if ((nums1.length + nums2.length)%2 == 0)\n            return ((double) findKSmallest(nums1, nums2, k) + (double) findKSmallest(nums1, nums2, k+1))/2;\n        else\n            return findKSmallest(nums1, nums2, k);\n    }\n\n    public int findKSmallest(int[] nums1, int[] nums2, int k) {\n        int n1 = nums1.length;\n        int n2 = nums2.length;\n        int i = 0; // starting index of nums1 array\n        int j = 0; // starting index of nums2 array\n\n        while (k &gt;= 1) {\n            // Eliminate k elements based on comparison results\n            if (i &gt;= n1) { // finish searching all elments in nums1\n                return nums2[j + k - 1];\n            }\n            else if (j &gt;= n2) { // finish searching all elments in nums1\n                return nums1[i + k - 1];\n            }\n            else if (k == 1)\n                return nums1[i] &lt;= nums2[j] ? nums1[i] : nums2[j];\n            else if (i + k/2 - 1 &gt;= n1) // not enough elements in nums1\n                j = j + k/2;\n            else if (j + k/2 - 1 &gt;= n2) // not enought elements in nums2\n                i = i + k/2;\n            else if (nums1[i + k/2 - 1] &lt;= nums2[j + k/2 - 1])\n                i = i + k/2;\n            else\n                j = j + k/2;\n\n            k = k - k/2; // update k to search in next iteration\n        }\n\n        return 0;\n    }\n}\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log (m+n))\\) Since binary search is used to find \\((m + n + 1)/2\\) th smallest element, the time complexity is \\(O(\\log ((m + n + 1)/2)) \\rightarrow O(\\log (m+n))\\)</li> <li>Space complexity: \\(O(1)\\) as using several internal variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#approach-binary-search-with-partition","title":"Approach - Binary Search with Partition","text":"<p>Median property: the median is the value separating the higher half from the lower half. </p> <p>References:  </p> <ul> <li>Good explanation video from Tushar Roy</li> <li>Example solution from Tushar Roy</li> <li>LeetCode solution</li> </ul> <p>Based on the the use of median for dividing, we can find partition position at two arrays and obtain the median value: 1. Cut A into two parts at a random position i: <pre><code>          left_A             |        right_A\n    A[0], A[1], ..., A[i-1]  |  A[i], A[i+1], ..., A[m-1]\n</code></pre> Since A has m elements, so there are m + 1 cuttings (i = 0 ~ m). left_A length is i and right_A length is m - i. Note when <code>i = 0</code>, left_A is empty, and when <code>i = m</code>, right_A is empty.  </p> <ol> <li> <p>Similarly cut B into two parts at a random position j: <pre><code>          left_B             |        right_B\n    B[0], B[1], ..., B[j-1]  |  B[j], B[j+1], ..., B[n-1]\n</code></pre> Since B has n elements, left_B length is j and right_B length is m - j. Note when <code>j = 0</code>, left_B is empty, and when <code>j = n</code>, right_B is empty.</p> </li> <li> <p>Put left_A and left_B into one set, left_part, and put right_A and right_B into another set, right_part: <pre><code>          left_part          |        right_part\n    A[0], A[1], ..., A[i-1]  |  A[i], A[i+1], ..., A[m-1]\n    B[0], B[1], ..., B[j-1]  |  B[j], B[j+1], ..., B[n-1]\n</code></pre> If we can ensure:</p> </li> <li> <p><code>len(left_part) == len(right_part)</code> for even number of (m+n), or <code>len(left_part) == len(right_part) + 1</code> for odd number of (m+n)  <code>i + j = m - i + n - j</code> when <code>m + n</code> is even; <code>i + j = m - i + n - j + 1</code> when <code>m + n</code> is odd. if <code>n &gt;= m</code>, we can simplify <code>i = 0 ~ m</code> and <code>j = (m + n + 1)/2 - i</code>. Note <code>(m + n + 1)/2</code> works for both odd and even case since integer divide results are the same between \\(\\frac{m+n}{2}\\) and \\(\\frac{m+n+1}{2}\\).     </p> </li> <li><code>max(left_part) &lt;= min(right_part)</code> Just check <code>B[j - 1] &lt;= A[i]</code> and <code>A[i - 1] &lt;= B[j]</code>. Since A and B are sorted, <code>A[i - 1] &lt;= A[i]</code> and <code>B[j - 1] &lt;= B[j]</code> and therefore no need to compare.   </li> </ol> <p>Then the median can compute from the middle 4 elements (<code>A[i-1]</code>, <code>B[j-1]</code>, <code>A[i]</code>, and <code>B[j]</code>). </p> <ul> <li><code>max(A[i - 1], B[j - 1])</code>, when m + n is odd</li> <li><code>(max(A[i -1], B[j - 1]) + min(A[i], B[j]))/2</code>, when m + n is even</li> </ul> <p>The algorithm is simplified as: <pre><code>Searching i in [0, m] to find an object i such that:\n    B[j - 1] &lt;= A[i] and A[i - 1] &lt;= B[j], where j = (m + n + 1)/2 - i\n</code></pre> We can use binary search method to search i (j is changed accordingly). There are 3 situations to consider:</p> <ul> <li><code>B[j - 1] &lt;= A[i]</code> and <code>A[i - 1] &lt;= B[j]</code> The object is found and stop searching.</li> <li><code>B[j - 1] &gt; A[i]</code> Means A[i] is too small. We need to adjust i to get <code>B[j - 1] &lt;= A[i]</code>.<ul> <li>Can we increase i? Yes, Because when i is increased (A[i] is increased), j will be decreased (B[j - 1] is decreased). So the search range is changed to [i + 1, right].</li> <li>Can we decrease i? No! Because when i is decreased (A[i] is decreased further), j will be increased (B[j - 1] is increased further). Therefore, <code>B[j - 1] &lt;= A[i]</code> will be never satisfied.  </li> </ul> </li> <li><code>A[i - 1] &gt; B[j]</code> Means A[i - 1] is too big. And we must decrease i to get <code>A[i - 1] &lt;= B[j]</code>. So the search range is changed to [left, i - 1].</li> </ul> <p>Edge Case: <code>A[i - 1]</code> doesn't exist when <code>i == 0</code>; <code>A[i]</code> doesn't exist when <code>i == m</code>; <code>A[j - 1]</code> doesn't exist when <code>j == 0</code>, <code>A[j]</code> doesn't exist when <code>j == n</code>. We can ignore non-exist elements in the calculation and comparison.</p> JavaPython <pre><code>class Solution {\n    public double findMedianSortedArrays(int[] nums1, int[] nums2) {\n        if ((nums1 == null || nums1.length == 0) &amp;&amp; (nums2 == null || nums2.length == 0))\n            return Double.NaN;\n\n        if (nums1.length &gt; nums2.length)\n            return findMedianSortedArrays(nums2, nums1);\n\n        int m = nums1.length;\n        int n = nums2.length;\n\n        int left = 0;\n        int right = m; // not m - 1, since this is partition position, which can be 0 ~ m (inclusive)\n        int i; // partition position for array nums 1 \n        int j; // partition position for array nums 2\n\n        // Binary search of partition position\n        while (left &lt;= right) {\n            i = left + (right - left)/2;\n            j = (m + n + 1)/2 - i; // (m + n + 1)/2 is the index of median\n\n            // handle edeg cases:\n            int maxLeft1 = i == 0 ? Integer.MIN_VALUE : nums1[i - 1];\n            int maxLeft2 = j == 0 ? Integer.MIN_VALUE : nums2[j - 1];\n\n            int minRight1 = i == m ? Integer.MAX_VALUE : nums1[i];\n            int minRight2 = j == n ? Integer.MAX_VALUE : nums2[j];\n\n            // Corner case: i == 0 or m, j == 0 or n\n            if (maxLeft1 &gt; minRight2)\n                right = i - 1;\n            else if (maxLeft2 &gt; minRight1)\n                left = i + 1;\n            else  { // found: nums1[i - 1] &lt;= nums2[j], nums2[i - 1] &lt;= nums1[i]\n                if ((m + n)%2 == 0) // even number\n                    return (double) (Math.max(maxLeft1, maxLeft2) + Math.min(minRight1, minRight2))/2;\n                else\n                    return (double) Math.max(maxLeft1, maxLeft2);\n            }\n        }\n\n        return Double.NaN;\n    }\n}\n</code></pre> <pre><code>class Solution:\n    def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -&gt; float:\n        if (not nums1 or len(nums1) == 0) and (not nums2 or len(nums2) == 0):\n            return float(\"nan\")\n\n        if len(nums1) &gt; len(nums2):\n            return self.findMedianSortedArrays(nums2, nums1)\n\n        m, n = len(nums1), len(nums2)\n        left, right = 0, m\n        while left &lt;= right:\n            i = (left + right) // 2\n            j = (m + n + 1) // 2 - i  # (m + n + 1) / 2 is the index of median\n            # Handle edge case\n            if i == 0:\n                max_left_1 = float('-inf')  # (1)\n            else:\n                max_left_1 = nums1[i - 1]\n\n            if j == 0:\n                max_left_2 = float('-inf')\n            else:\n                max_left_2 = nums2[j - 1]\n\n            if i == m:\n                min_right_1 = float('inf')  # (2)\n            else:\n                min_right_1 = nums1[i]\n\n            if j == n:\n                min_right_2 = float('inf')\n            else:\n                min_right_2 = nums2[j]\n\n            if max_left_1 &gt; min_right_2:\n                right = i - 1\n            elif max_left_2 &gt; min_right_1:\n                left = i + 1\n            else:\n                if (m + n) % 2 == 0:\n                    return (max(max_left_1, max_left_2) + min(min_right_1, min_right_2)) / 2\n                else:\n                    return max(max_left_1, max_left_2)\n\n        return float(\"nan\")\n</code></pre> <ol> <li>Python has no integer min.</li> <li>Python has no integer max.</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#complexity-analysis_2","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log (\\min(m, n)))\\) Since we only binary search the array with smaller the size, the time complexity is \\(O(\\log (\\min(m, n)))\\) </li> <li>Space complexity: \\(O(1)\\) as using several internal variables. </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#complexity-summary","title":"Complexity Summary","text":"Time Complexity Space Complexity Approach - Two pointers \\(O(m + n)\\) \\(O(1)\\) Approach - Find kth smallest \\(O(\\log (m + n))\\) \\(O(1)\\) Approach - Binary search with partition \\(O(\\log (\\min(m, n)))\\) \\(O(1)\\)","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0004-median-of-two-sorted-arrays/#test","title":"Test","text":"<ul> <li>Test corner cases</li> <li>Test general cases: total number is odd and even</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0015-3sum/","title":"LC15. 3Sum","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0015-3sum/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 15: Given an integer array nums, return all the triplets\u00a0<code>[nums[i], nums[j], nums[k]]</code>\u00a0such that\u00a0<code>i != j</code>,\u00a0<code>i != k</code>, and\u00a0<code>j != k</code>, and\u00a0<code>nums[i] + nums[j] + nums[k] == 0</code>.</p> <p>Notice that the solution set must not contain duplicate triplets.</p>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0015-3sum/#clarification","title":"Clarification","text":"<ul> <li>find triplets with sum == 0</li> <li>no duplicate triplets</li> <li>sorted or unsorted?</li> <li>target or array values can be negative</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0015-3sum/#assumption","title":"Assumption","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0015-3sum/#solution","title":"Solution","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0015-3sum/#approach-sort-two-pointers","title":"Approach - Sort + Two Pointers","text":"<p>Here are general steps:</p> <ol> <li>Sort array first. </li> <li>Fix <code>nums[i]</code> by iterating along the array. Then the problem become to a smaller problem <code>Two Sum</code></li> <li>Using two pointers <code>front</code> and <code>back</code> for remaining elements to find <code>nums[front] + nums[back] == target - nums[i]</code></li> </ol> Note <p>Remember to remove duplicates</p> Python <pre><code>class Solution:\n    def threeSum(self, nums: List[int]) -&gt; List[List[int]]:\n        target = 0\n        nums.sort()\n        triplets = []\n        n = len(nums)\n        for i in range(n - 2):\n            if nums[i] &gt; 0:\n                break\n\n            # Process duplicates of number 1\n            if i &gt; 0 and nums[i] == nums[i - 1]:\n                continue\n\n            front = i + 1\n            back = n - 1\n            while (front &lt; back):\n                s = nums[i] + nums[front] + nums[back]\n\n                if s &lt; target:\n                    front += 1\n                elif s &gt; target:\n                    back -= 1\n                else:\n                    current_triplet = [nums[i], nums[front], nums[back]]\n                    triplets.append(current_triplet)\n\n                    # Process duplicates of number 2\n                    while (front &lt; back and nums[front] == current_triplet[1]):\n                        front += 1\n\n                    # Process duplicates of number 3\n                    while (front &lt; back and nums[back] == current_triplet[2]):\n                        back -= 1\n\n        return triplets\n</code></pre>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0015-3sum/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^2)\\) <ul> <li>Before for-loop, the sort complexity is \\(O(n \\log n)\\). </li> <li>In the for loop, using two pointers will take \\(O(n)\\) time. So time complexity of for-loop is \\(O(n^2)\\) So the total time complexity is \\(O(n \\log n) + O(n^2) = O(n^2)\\)</li> </ul> </li> <li>Space complexity: \\(O(sorting)\\) <ul> <li>Sort algorithm will take some space. For quick sort, the space complexity is \\(O(sorting) = O(\\log n)\\). For merge sort, the space complexity is \\(O(sorting) = O(n)\\) </li> <li>The rest of code using index variables, which take \\(O(1)\\) space So the total space complexity is \\(O(sorting) + O(1) = O(sorting)\\)</li> </ul> </li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0015-3sum/#test","title":"Test","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/","title":"17. Letter Combinations of a Phone Number","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 17: Given a string containing digits from 2-9 inclusive, return all possible letter combinations that the number could represent. Return the answer in any order.</p> <p>A mapping of digits to letters (just like on the telephone buttons) is given below. Note that 1 does not map to any letters.</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#clarification","title":"Clarification","text":"<ul> <li>Input is digit string 2 - 9 (no 0 and 1)</li> <li>Return letter combinations in any order</li> <li>Only 1 letter from each digit? Yes</li> <li>Does digits order matter?</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#solution","title":"Solution","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#approach-1-backtracking","title":"Approach 1: Backtracking","text":"<p>We can build combinations one digit at a time and explore all possible paths by:</p> <ul> <li>choosing a letter from all possible letters under a digit</li> <li>recursively proceed to the next digit</li> <li>Repeat until a full-length combinations is formed.</li> <li>Backtracking by removing the last letter and trying the next one.</li> </ul> Python <pre><code>class Solution:\n    def __init__(self):\n        self.DIGIT_TO_LETTERS = {\n            \"2\": \"abc\",\n            \"3\": \"def\",\n            \"4\": \"ghi\",\n            \"5\": \"jkl\",\n            \"6\": \"mno\",\n            \"7\": \"pqrs\",\n            \"8\": \"tuv\",\n            \"9\": \"wxyz\",\n        }\n\n    def letterCombinations(self, digits: str) -&gt; List[str]:\n        if not digits:\n            return []\n        self.results = []\n        self._backtrack(digits, 0, \"\")\n        return self.results\n\n    def _backtrack(self, digits: str, index: int, curr: list[str]) -&gt; None:\n        # Base case\n        if len(curr) == len(digits):\n            self.results.append(curr)\n            return\n\n        if digits[index] in self.DIGIT_TO_LETTERS:\n            possible_letters = self.DIGIT_TO_LETTERS[digits[index]]\n            for letter in possible_letters:\n                self._backtrack(digits, index + 1, curr + letter)  # (1)\n</code></pre> <ol> <li>Implicit backtrack since string is not immutable, which is equivalent to the following if using <code>curr</code> list <pre><code>curr.append(letter)\nself._backtrack(digits, index + 1, curr)\ncurr.pop()\n</code></pre></li> </ol>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(k^n \\cdot n)\\) where \\(n\\) is the number of digits in the input and \\(k\\) is the maximum number of letters mapped to a digit (the max is 4 for digit <code>7</code> and <code>9</code>)<ul> <li>For \\(n\\) digits, the total number of combinations is \\(k^n\\).</li> <li>For each combination, it takes \\(O(n)\\) time to build the string (one letter per digit).</li> <li>So the total time complexity is \\(O(k^n \\cdot n)\\).</li> </ul> </li> <li>Space complexity: \\(O(k^n \\cdot n)\\)<ul> <li>The recursive call stack takes \\(O(n)\\) space since the depth of recursion is \\(n\\).</li> <li>Since return all combinations, the output list has \\(O(k^n)\\) string and each string has length \\(n\\), which takes \\(O(k^n \\cdot n)\\) space.</li> <li>So the total space complexity is \\(O(k^n \\cdot n) + O(n) = O(k^n \\cdot n)\\).</li> </ul> </li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#approach-2","title":"Approach 2:","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0017-letter-combinations-of-a-phone-number/#test","title":"Test","text":"<ul> <li>Test empty digits</li> <li>Test one digit</li> <li>Test multiple digits</li> <li>Test multiple digits with duplicates</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0018-4sum/","title":"LC18. 4Sum","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0018-4sum/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem xx: Given an array\u00a0<code>nums</code>\u00a0of\u00a0<code>n</code>\u00a0integers, return\u00a0an array of all the\u00a0unique\u00a0quadruplets <code>[nums[a], nums[b], nums[c], nums[d]]</code>\u00a0such that:</p> <ul> <li><code>0 &lt;= a, b, c, d\u00a0&lt; n</code></li> <li><code>a</code>,\u00a0<code>b</code>,\u00a0<code>c</code>, and\u00a0<code>d</code>\u00a0are\u00a0distinct.</li> <li><code>nums[a] + nums[b] + nums[c] + nums[d] == target</code></li> </ul> <p>You may return the answer in\u00a0any order.</p>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0018-4sum/#clarification","title":"Clarification","text":"<ul> <li>unique quadruplets</li> <li>index different</li> <li>sum == target</li> <li>no particular order</li> <li>target or array values can be negative</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0018-4sum/#assumption","title":"Assumption","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0018-4sum/#solution","title":"Solution","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0018-4sum/#approach-sort-two-pointers","title":"Approach - Sort + Two Pointers","text":"<p>Here are general steps:</p> <ol> <li>Sort array first. Since it involves at least two for-loops \\(O(n^2)\\), the time complexity from sort \\(O(n \\log n)\\) won't make it worse</li> <li>Fix <code>nums[i]</code> and <code>nums[j]</code> by iterating the combination of <code>nums[i]</code> and <code>nums[j]</code>. Then the problem become to a smaller problem <code>Two Sum</code></li> <li>Using two pointers <code>left</code> and <code>right</code> for remaining elements to find <code>nums[left] + nums[right] == target - nums[i] - nums[j]</code></li> </ol> Note <p>Remember to remove duplicates</p> Python <pre><code>class Solution:\ndef fourSum(self, nums: List[int], target: int) -&gt; List[List[int]]:\n    n = len(nums)\n    quadruplets = []\n    nums.sort()\n    for i in range(n):\n        # Skip duplicates on the 1st element\n        if i &gt; 0 and nums[i] == nums[i - 1]:\n            continue\n        for j in range(i + 1, n):\n            # Skip duplicates on the 1st element\n            if j &gt; i + 1 and nums[j] == nums[j - 1]:\n                continue\n            left = j + 1\n            right = n - 1\n            target_2sum = target - nums[i] - nums[j]\n            while left &lt; right:\n                s = nums[left] + nums[right]\n                if s &lt; target_2sum:\n                    left += 1\n                elif s &gt; target_2sum:\n                    right -= 1\n                else:\n                    current_quadruplet = [nums[i], nums[j], nums[left], nums[right]]\n                    quadruplets.append(current_quadruplet)\n\n                    # Skip duplicates on the 3rd element\n                    while left &lt; right and nums[left] == current_quadruplet[2]:\n                        left += 1\n\n                    # Skip duplicates on the 4th element\n                    while left &lt; right and nums[right] == current_quadruplet[3]:\n                        right -= 1\n\n    return quadruplets\n</code></pre>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0018-4sum/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^3)\\) <ul> <li>Before two for-loops, the sort complexity is \\(O(n \\log n)\\). </li> <li>Two for-loops count for \\(O(n^2)\\). In the 2nd for loop, using two pointers will take \\(O(n)\\) time. So time complexity of two for-loops is \\(O(n^3)\\) So the total time complexity is \\(O(n \\log n) + O(n^3) = O(n^3)\\)</li> </ul> </li> <li>Space complexity: \\(O(sorting)\\) <ul> <li>Sort algorithm will take some space. For quick sort, the space complexity is \\(O(sorting) = O(\\log n)\\). For merge sort, the space complexity is \\(O(sorting) = O(n)\\) </li> <li>The rest of code using index variables, which take \\(O(1)\\) space So the total space complexity is \\(O(sorting) + O(1) = O(sorting)\\)</li> </ul> </li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0018-4sum/#test","title":"Test","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0020-valid-parentheses/","title":"LC20. Valid Parentheses","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0001-0099/lc0020-valid-parentheses/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 20: Given a string\u00a0<code>s</code>\u00a0containing just the characters\u00a0<code>'('</code>,\u00a0<code>')'</code>,\u00a0<code>'{'</code>,\u00a0<code>'}'</code>,\u00a0<code>'['</code>\u00a0and\u00a0<code>']'</code>, determine if the input string is valid.</p> <p>An input string is valid if:</p> <ol> <li>Open brackets must be closed by the same type of brackets.</li> <li>Open brackets must be closed in the correct order.</li> <li>Every close bracket has a corresponding open bracket of the same type.</li> </ol>","tags":["Stack"]},{"location":"lc-solutions/lc0001-0099/lc0020-valid-parentheses/#clarification","title":"Clarification","text":"<ul> <li>string only contains brackets</li> <li>string can starts with multiple open brackets, for example, '([{()}])', but need to close in the correct order</li> <li>Every close bracket has a open bracket</li> <li>What about empty string?</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0001-0099/lc0020-valid-parentheses/#assumption","title":"Assumption","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0001-0099/lc0020-valid-parentheses/#solution","title":"Solution","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0001-0099/lc0020-valid-parentheses/#approach-stack","title":"Approach - Stack","text":"<p>Use stack to store open brackets. When encounter close brackets, pop up open bracket and check whether they are valid parentheses. The stack should be empty at the end.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    PARENTHESE_MAP = {\")\": \"(\", \"}\": \"{\", \"]\": \"[\"}\n\n    def isValid(self, s: str) -&gt; bool:\n        if not s or len(s) % 2 == 1:\n            return False\n\n        stack = deque()\n        for letter in s:\n            # If the letter is an closing bracket\n            if letter in self.PARENTHESE_MAP:\n                if stack:\n                    last_open_bracket = stack.pop()\n                else:\n                    return False\n                if last_open_bracket != self.PARENTHESE_MAP[letter]:\n                    return False\n            else:\n                stack.append(letter)\n\n        return not stack\n</code></pre>","tags":["Stack"]},{"location":"lc-solutions/lc0001-0099/lc0020-valid-parentheses/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)  Traverse the given string one character at a time for total \\(n\\) characters and push and pop operation on a stack take \\(O(1)\\) time.</li> <li>Space complexity: \\(O(n)\\)  In the worst case, push all \\(n\\) brackets.</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0001-0099/lc0020-valid-parentheses/#test","title":"Test","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/","title":"21. Merge Two Sorted Lists","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 21: You are given the heads of two sorted linked lists\u00a0<code>list1</code>\u00a0and\u00a0<code>list2</code>.</p> <p>Merge the two lists into one\u00a0sorted\u00a0list. The list should be made by splicing together the nodes of the first two lists.</p> <p>Return\u00a0the head of the merged linked list.</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#clarification","title":"Clarification","text":"<ul> <li>Two lists may have different length. May be empty</li> <li>Two lists are sorted</li> <li>Merge nodes or merge values</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#approach-1-iteration","title":"Approach 1: Iteration","text":"<p>Start with a dummy head and then compare list1 and list 2 one node at a time. Add nodes with smaller value to the list. Need to handle situation where either list 1 or list 2 ends first.</p> PythonJava <pre><code>class Solution:\n    def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -&gt; Optional[ListNode]:\n        dummy_head = ListNode(-1, None)\n\n        p = dummy_head\n        while list1 or list2:\n            if list1 is None:\n                p.next = list2\n                list2 = list2.next\n            elif list2 is None:\n                p.next = list1\n                list1 = list1.next\n            else:\n                if list1.val &lt;= list2.val:\n                    p.next = list1\n                    list1 = list1.next\n                else:\n                    p.next = list2\n                    list2 = list2.next\n\n            p = p.next\n\n        return dummy_head.next\n</code></pre> <pre><code>class Solution {\n    public ListNode mergeTwoLists(ListNode l1, ListNode l2) {\n\n        // Handle corner case\n        if (l1 == null &amp;&amp; l2 == null) return null;\n        if (l1 == null) return l2;\n        if (l2 == null) return l1;\n\n        ListNode dummyHead = new ListNode(-1);\n        ListNode p = dummyHead; // pointer for the new linked list starting from dummy head\n        ListNode p1 = l1; // pointer for l1 linked list\n        ListNode p2 = l2; // pointer for l2 linked list\n\n        while (p1 != null || p2 != null) {\n            if (p1 == null) {\n                p.next = p2;\n                p2 = p2.next;\n            }\n            else if (p2 == null) {\n                p.next = p1;\n                p1 = p1.next;\n            }\n            else {\n                if (p1.val &lt;= p2.val) {\n                    p.next = p1;\n                    p1 = p1.next;\n                }\n                else {\n                    p.next = p2;\n                    p2 = p2.next;\n                }\n            }\n\n            p = p.next;\n        }\n\n        return dummyHead.next;\n\n    }\n}\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n + m)\\)   The number of iterations of the while loop equals to the sum of the lengths of the two   lists, \\(n + m\\).</li> <li>Space complexity: \\(O(1)\\)   Only use several pointers.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#approach-2-recursion","title":"Approach 2: Recursion","text":"<p>This problem can also be solved using recursion.</p> PythonJava <pre><code>class Solution:\n    def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -&gt; Optional[ListNode]:\n        # Base case\n        if list1 is None:\n            return list2\n\n        if list2 is None:\n            return list1\n\n        # Recursion\n        if list1.val &lt;= list2.val:\n            list1.next = self.mergeTwoLists(list1.next, list2)\n            return list1\n        else:\n            list2.next = self.mergeTwoLists(list1, list2.next)\n            return list2\n</code></pre> <pre><code>class Solution {\n    public ListNode mergeTwoLists(ListNode l1, ListNode l2) {\n        // Base case:\n        if (l1 == null) return l2;\n        if (l2 == null) return l1;\n\n        // Recursively break down problem into a smaller one\n        if (l1.val &lt;= l2.val) {\n            l1.next = mergeTwoLists(l1.next, l2);\n            return l1;\n        }\n        else {\n            l2.next = mergeTwoLists(l1, l2.next);\n            return l2;\n        }\n\n    }\n}\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n + m)\\)   It will go through both lists (total \\(n + m\\) nodes) one node at a time.</li> <li>Space complexity: \\(O(n + m)\\)   Auxiliary stack space due to recursive function calls. The recursive function will be   called \\(n + m\\) times.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - iteration \\(O(n + m)\\) \\(O(1)\\) Approach - recursion \\(O(n + m)\\) \\(O(n + m)\\)","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0021-merge-two-sorted-lists/#test","title":"Test","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/","title":"22. Generate Parentheses","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 22: Given <code>n</code> pairs of parentheses, write a function to generate all combinations of well-formed parentheses.</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#solution","title":"Solution","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#approach-1-backtracking","title":"Approach 1: Backtracking","text":"<p>We can view the problem as a tree of choices. The root is <code>(</code>. At each step, we can either add a left parenthesis <code>(</code> or a right parenthesis <code>)</code> based on conditions:</p> <ul> <li>Add a left parenthesis if we have not used all <code>n</code> left parentheses.</li> <li>Add a right parenthesis<ul> <li>if we have not used all <code>n</code> right parentheses.</li> <li>if the number of right parentheses used is less than the number of left parentheses used. This ensures that the parentheses are well-formed</li> </ul> </li> </ul> <pre><code>graph TD\n    A[\"(\"] --&gt; B1[\"(\"]\n    A --&gt; B2[\")\"]\n    B1 --&gt; C1[\"(\"]\n    B1 --&gt; C2[\")\"]\n    B2 --&gt; C3[\"(\"]\n    B2 --&gt; C4[\")\"]\n\n    style C4 fill:#f9f</code></pre> <p>We can use backtracking to generate all combinations of well-formed parentheses. If we encounter invalid combination, we backtrack to the previous step and try another option.</p> Python <pre><code>class Solution:\n    def generateParenthesis(self, n: int) -&gt; List[str]:\n        self.result = []\n        self._generate([], n, n)\n        return self.result\n\n    def _generate(self, combination: list[str], n_left_remain: int, n_right_remain: int) -&gt; None:\n        # Base case\n        if n_left_remain == 0 and n_right_remain == 0:\n            self.result.append(\"\".join(combination))\n            return\n\n        # Add left parenthesis\n        if n_left_remain &gt; 0:\n            combination.append('(')\n            self._generate(combination, n_left_remain - 1, n_right_remain)\n            combination.pop()\n\n        # Add right parenthesis and ensure valid combination\n        if n_right_remain &gt; 0 and n_left_remain &lt; n_right_remain:\n            combination.append(')')\n            self._generate(combination, n_left_remain, n_right_remain - 1)\n            combination.pop()\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(\\frac{4^n}{\\sqrt{n}})\\) <ul> <li>The number of valid combinations of parentheses is given by the Catalan number \\(C_n = \\frac{1}{n+1}\\binom{2n}{n} \\approx \\frac{4^n}{n^{3/2}\\sqrt{\\pi}}\\).</li> <li>Each valid combination takes \\(O(n)\\) time to build, converting from list to string.</li> <li>Therefore, the total time complexity is \\(O(C_n \\cdot n) = O(\\frac{4^n \\cdot n}{n^{3/2}}) = O(\\frac{4^n}{\\sqrt{n}})\\).</li> </ul> </li> <li>Space complexity: \\(O(\\frac{4^n}{\\sqrt{n}})\\) <ul> <li>The maximum depth of the recursion stack is \\(2n\\) (since we append one character per call), which takes \\(O(n)\\) space.</li> <li>The result list store \\(C_n\\) strings (all valid combinations) and each string contains \\(2n\\) letters. So the result list takes \\(O(C_n \\cdot 2n) = O(\\frac{4^n}{\\sqrt{n}})\\) space.</li> <li>Therefore, the total space complexity is \\(O(n + C_n \\cdot n) = O(\\frac{4^n}{\\sqrt{n}})\\).</li> </ul> </li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#approach-2","title":"Approach 2:","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Backtracking \\(O(\\frac{4^n}{\\sqrt{n}})\\) \\(O(\\frac{4^n}{\\sqrt{n}})\\) Approach 2 - \\(O(1)\\) \\(O(n)\\)","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0022-generate-parentheses/#test","title":"Test","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/","title":"LC23. Merge k Sorted Lists","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 23: You are given an array of\u00a0<code>k</code>\u00a0linked-lists\u00a0<code>lists</code>, each linked-list is sorted in ascending order.</p> <p>Merge all the linked-lists into one sorted linked-list and return it.</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#clarification","title":"Clarification","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#approach-recursion","title":"Approach - Recursion","text":"<p>Break down merge k lists into subproblem of merge two lists by recursively merging two sub-lists.</p> Python <pre><code>class Solution:\n    def mergeKLists(self, lists: List[Optional[ListNode]]) -&gt; Optional[ListNode]:\n        n = len(lists)\n        # Base case\n        if not lists:\n            return None\n        elif n == 1:\n            return lists[0]\n        elif n == 2:\n            return self.mergeTwoLists(lists[0], lists[1])\n\n        return self.mergeTwoLists(self.mergeKLists(lists[0:n//2]), self.mergeKLists(lists[n//2:]))\n\n    def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -&gt; Optional[ListNode]:\n        dummy_head = ListNode(-1, None)\n\n        p = dummy_head\n        while list1 or list2:\n            if list1 is None:\n                p.next = list2\n                list2 = list2.next\n            elif list2 is None:\n                p.next = list1\n                list1 = list1.next\n            else:\n                if list1.val &lt;= list2.val:\n                    p.next = list1\n                    list1 = list1.next\n                else:\n                    p.next = list2\n                    list2 = list2.next\n\n            p = p.next\n\n        return dummy_head.next\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(k n \\log_2 k)\\)     We can pply the same idea as the merge sort algorithm, by merging the first array with the second, the third with the fourth, and so on and then repeatedly apply this until all of the arrays have been merged. We do \\(O(kn)\\) work to merge the k arrays of size n into k/2 arrays of size 2n, and then continue doing \\(O(kn)\\) work \\(O(log_2k)\\) times until we have a single array of size kn. Thus, the running time of this approach is \\(O(kn log k)\\) <pre><code>       1             1 list with kn elements\n     /   \\\n    1     2          2 sub lists with (k/2)n elements\n  /  \\   /  \\\n 1    2 3   4        4 sub lists with (k/4)n elements\n ....                k/2 sub lists with 2n elements\n ...                 k sub lists with n elements\n</code></pre></li> <li>Space complexity: \\(O(\\log_2 k)\\)     The function recursive call depth is \\(\\log_2 k\\).</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#approach-iteration","title":"Approach - Iteration","text":"<p>Descriptions</p> Java <pre><code>class Solution {\n    public ListNode mergeKLists(ListNode[] lists) {\n        if (lists == null || lists.length == 0) return null;\n\n        int n = lists.length;\n\n        for (int step = 1; step &lt; n; step = 2*step) {\n            for (int i = 0; i &lt; n - step; i = i + 2*step) {\n                lists[i] = merge2Lists(lists[i], lists[i+step]);\n            }\n        }\n\n        return lists[0];\n\n    }\n\n    private ListNode merge2Lists(ListNode l1, ListNode l2) {\n        if (l1 == null) return l2;\n        if (l2 == null) return l1;\n\n        ListNode dummyHead = new ListNode(-1);\n        ListNode p = dummyHead; \n\n        while (l1 != null || l2 != null) {\n            if (l1 == null) {\n                p.next = l2;\n                break;\n            }\n            else if (l2 == null) {\n                p.next = l1;\n                break;\n            }\n            else if (l1.val &lt;= l2.val) {\n                p.next = l1;\n                l1 = l1.next;\n            }\n            else {\n                p.next = l2;\n                l2 = l2.next;\n            }\n            p = p.next;\n        }\n\n        return dummyHead.next;\n    }\n}\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O()\\)     Explanation  </li> <li>Space complexity: \\(O()\\)     Explanation</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - a \\(O()\\) \\(O()\\) Approach - b \\(O()\\) \\(O()\\)","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0023-merge-k-sorted-lists/#test","title":"Test","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/","title":"24. Swap Nodes in Paris","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 24: Given a linked list, swap every two adjacent nodes and return its head. You must solve the problem without modifying the values in the list's nodes (i.e., only nodes themselves may be changed.)</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#clarification","title":"Clarification","text":"<ul> <li>Swap nodes by pairs (not reversal of the whole linked list)</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#approach-1-recursion","title":"Approach 1: Recursion","text":"<p>We can use recursion method to swap the first two nodes and recursively process the rest.</p> Python <pre><code>class Solution:\n    def swapPairs(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        if head is None or head.next is None:\n            return head\n\n        new_head = head.next\n        head.next = self.swapPairs(head.next.next)\n        new_head.next = head\n\n        return new_head\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Need to go through all \\(n\\) nodes.</li> <li>Space complexity: \\(O(n)\\)   Recursion call stack will take \\(O(n)\\) for \\(n\\) recursive function calls.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#approach-2-iteration","title":"Approach 2: Iteration","text":"<p>We can use iteration method to swap the nodes on the go. We use a dummy node to simplify handling the head swap and maintain a pointer (<code>prev</code>) to track the previous node. Then swap each pair by adjusting links.</p> python <pre><code>class Solution:\n    def swapPairs(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        if head is None or head.next is None:\n            return head\n\n        dummy_head = ListNode(-1)\n        prev_node = dummy_head\n        curr_node = head\n\n        while curr_node and curr_node.next:\n            next_node = curr_node.next\n\n            # Swap\n            prev_node.next = next_node\n            curr_node.next = next_node.next\n            next_node.next = curr_node\n\n            # Update prev and curr for next swap\n            prev_node = curr_node\n            curr_node = curr_node.next\n\n        return dummy_head.next\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   Go through all \\(n\\) nodes.</li> <li>Space complexity: \\(O(n)\\)   Only use limited variables like dummy, prev, curr.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Recursion \\(O(n)\\) \\(O(n)\\) Approach - Iteration \\(O(n)\\) \\(O(1)\\)","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0024-swap-nodes-in-pairs/#test","title":"Test","text":"<ul> <li>Empty list (None)</li> <li>Only one node (<code>[1]</code>)</li> <li>Odd number of nodes (<code>[1,2,3]</code>) \u2192 The last node remains in place</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/","title":"LC26. Remove Duplicates from Sorted Array","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 26: Given an integer array <code>nums</code> sorted in non-decreasing order, remove the duplicates in-place such that each unique element appears only once. The relative order of the elements should be kept the same.</p> <p>Return <code>k</code> after placing the final result in the first <code>k</code> slots of <code>nums</code>.</p> <p>Do not allocate extra space for another array. You must do this by modifying the input array in-place with O(1) extra memory.</p>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/#similar-questions","title":"Similar questions:","text":"<ul> <li>LC27 Remove Element</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/#clarification","title":"Clarification","text":"<ul> <li>Sorted integer array</li> <li>Remove duplicate in-place</li> <li>Keep the relative order</li> <li>Empty array?</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/#assumption","title":"Assumption","text":"<p>Input array has at least 2 elements.</p>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/#solution","title":"Solution","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/#approach-two-pointers","title":"Approach - Two Pointers","text":"<p>Since the array is sorted, duplicates will show up together in neighbor. Take advantage of this pattern, we will use two pointers: - One pointer <code>i</code> to track the index of unique element - The other pointer <code>j</code> to track the index of current element Essentially, once an element is encountered, simply bypass its duplicates and move on to the next unique element. So - When <code>nums[i] == nums[j]</code>, increase <code>j</code> to skip the duplicate - When <code>nums[i] != nums[j]</code>,  the duplicate ends and copy the value to <code>nums[i+1]</code> and increase <code>i</code> </p> C++Python <pre><code>class Solution {\npublic:\n    int removeDuplicates(vector&lt;int&gt;&amp; nums) {\n        if (nums.size() == 0) return 0; // later j starts with 1.\n\n        int i = 0;\n        for (int j = 1; j &lt; nums.size(); j++) { // (1)\n            if (nums[i] != nums[j]) {\n                i++;\n                nums[i] = nums[j];\n            }\n        }\n\n        return i + 1; // (2)\n    }\n};\n</code></pre> <ol> <li><code>j</code> starts from 1</li> <li>Return number of elements instead of index</li> </ol> <pre><code>def removeDuplicates(self, nums: List[int]) -&gt; int:\n    j = 0\n    for i in range(1, len(nums)): # (1)\n        if nums[j] != nums[i]:\n            j += 1\n            nums[j] = nums[i]\n    return j + 1 # (2)\n</code></pre> <ol> <li><code>i</code> starts from 1</li> <li>Return number of elements instead of index</li> </ol>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Iterate the whole array once.</li> <li>Space complexity: \\(O(1)\\)     Only use two pointers.</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0026-remove-duplicates-from-sorted-array/#test","title":"Test","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/","title":"LC27. Remove Element","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 27: Given an integer array <code>nums</code> and an integer <code>val</code>, remove all occurrences of <code>val</code> in <code>nums</code> in-place. The relative order of the elements may be changed.</p> <p>Return <code>k</code> after placing the final result in the first <code>k</code> slots of <code>nums</code>.</p> <p>Do not allocate extra space for another array. You must do this by modifying the input array in-place with O(1) extra memory.</p>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#similar-questions","title":"Similar questions:","text":"<ul> <li>LC26 Remove duplicates from sorted array</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#clarification","title":"Clarification","text":"<ul> <li>Remove all occurrences of val</li> <li>No change on array size</li> <li>Store the result in the first part of the array</li> <li>In-place mean? no allocation of additional array; modify the input array</li> <li>Return number of elements</li> <li>Go through examples</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#assumption","title":"Assumption","text":"<ul> <li>Number of elements is within the range of integer type</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#solution","title":"Solution","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#approach-two-pointers-with-move","title":"Approach - Two Pointers With Move","text":"<p>Use two pointers: - One pointer <code>i</code> to track the next location to store the element that is not <code>val</code> - The other pointer <code>j</code> moves along the array, tracking the index of the current element  </p> Note <p>Clearly understand the physical meanings of two pointers</p> <p>Initialize both pointer with zeros, and - When <code>nums[j] == val</code>, skip this element by increasing <code>j</code>. - When <code>nums[j] != val</code>, copy value to <code>nums[i]</code>, i.e., <code>nums[i] = nums[j]</code>, </p> C++Python <pre><code>class Solution {\npublic:\n    int removeElement(vector&lt;int&gt;&amp; nums, int val) {\n        int i = 0;\n        for (int j = 0; j &lt; nums.size(); j++) {\n            if (nums[j] != val) {\n                nums[i++] = nums[j];\n            }\n        }\n        return i; // i already plus 1 so no need index to number of elements conversion\n    }\n}; \n</code></pre> <pre><code>def removeElement(self, nums: List[int], val: int) -&gt; int:\n    j = 0\n    for i in range(len(nums)):\n        if nums[i] != val:\n            nums[j] = nums[i]\n            j += 1\n    return j\n</code></pre>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Iterate the whole array once.   </li> <li>Space complexity: \\(O(1)\\)     Only use two pointers.</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#approach-two-pointers-with-swap","title":"Approach - Two Pointers With Swap","text":"<p>Use two pointers: - One pointer <code>i</code> to track the location to store the element that is not <code>val</code> - One pointer <code>n</code>  represents the current array length, which will be reduced if <code>nums[i] == val</code></p> <p>When <code>nums[i] == val</code>,  - Swap the current element at index <code>i</code> with the last element <code>n - 1</code> - Reduce array size <code>n</code> </p> <p>Note that the last element at <code>n - 1</code> is swapped could be the value needs to be removed. In the next iteration, the swapped element will be checked.</p> <p>Compared to previous approach, it is more efficient when the number of elements to remove is small. The drawback is that the relative order is not maintained. </p> <pre><code>class Solution {\npublic:\n    int removeElement(vector&lt;int&gt;&amp; nums, int val) {\n        int i = 0;\n        int n = nums.size();\n\n        while (i &lt; n) {\n            if (nums[i] == val) {\n                nums[i] = nums[n - 1];\n                n--; // reduce array size\n            }\n            else {\n                i++;\n            }\n        }\n\n        return i;\n    }\n};\n</code></pre>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\) <code>while</code> condition ends at <code>i == n</code> where <code>i</code> starts from the beginning and <code>n</code> starts from the end. It traverse at most <code>n</code> steps.   </li> <li>Space complexity: \\(O(1)\\)     Use several local variables with constant space complexity. </li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Two pointers with move \\(O(n)\\) \\(O(1)\\) Approach - Two pointers with swap \\(O(n)\\) \\(O(1)\\)","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0027-remove-element/#test","title":"Test","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0033-search-in-rotated-sorted-array/","title":"LC33. Search in Rotated Sorted Array","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0033-search-in-rotated-sorted-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 33: There is an integer array\u00a0<code>nums</code>\u00a0sorted in ascending order (with\u00a0distinct\u00a0values).</p> <p>Prior to being passed to your function,\u00a0<code>nums</code>\u00a0is\u00a0possibly rotated\u00a0at an unknown pivot index\u00a0<code>k</code>\u00a0(<code>1 &lt;= k &lt; nums.length</code>) such that the resulting array is\u00a0<code>[nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]</code>\u00a0(0-indexed). For example,\u00a0<code>[0,1,2,4,5,6,7]</code>\u00a0might be rotated at pivot index\u00a0<code>3</code>\u00a0and become\u00a0<code>[4,5,6,7,0,1,2]</code>.</p> <p>Given the array\u00a0<code>nums</code> after\u00a0the possible rotation and an integer\u00a0<code>target</code>, return\u00a0the index of <code>target</code> if it is in <code>nums</code>, or <code>-1</code> if it is not in <code>nums</code>.</p> <p>You must write an algorithm with\u00a0<code>O(log n)</code>\u00a0runtime complexity.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0033-search-in-rotated-sorted-array/#clarification","title":"Clarification","text":"<ul> <li>nums sorted in ascending order</li> <li>no duplicates</li> <li>array is rotated at certain index</li> <li>find target</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0033-search-in-rotated-sorted-array/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0033-search-in-rotated-sorted-array/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0033-search-in-rotated-sorted-array/#approach-binary-search","title":"Approach - Binary Search","text":"<p>The original array is sorted in ascending order and then rotated at some pivot. So the array can be always divided into two parts: one part is sorted and the other part is unsorted, containing the pivot. It is easy to check whether the target is in the sorted part and search inside that part. If the target is in the unsorted part, we can further divide the unsorted part into two parts (again one part will be sorted and the other will be unsorted) and continue to check the sorted part. This allow us using binary search to find the target.</p> <p>The search space starts from the whole array and shrinks over each iteration, using `[left, right]`` to indicate the search space. The mid is the separation point to divide the search space into two parts, one is sorted and the other is unsorted.</p> <p>We need to handle the the first 3 situations below:</p> <ol> <li><code>nums[left] &lt;= nums[mid] &lt;= nums[right]</code>, the whole array is sorted</li> <li><code>nums[left] &gt; nums[mid] &lt;= nums[right]</code>,  right half is sorted</li> <li><code>nums[left] &lt;= nums[mid] &gt; nums[right]</code>,  left half is sorted</li> <li><code>nums[left] &gt; nums[mid] &gt; nums[right]</code>, impossible since array is sorted in non-decreasing</li> </ol> <p>So we can compare <code>nums[left]</code> and <code>nums[mid]</code> to decide which half is sorted - If <code>nums[left] &lt;= nums[mid]</code>, the sub-array <code>[left, mid]</code> is sorted. This is true when an array has no duplicates. It is easy to check whether the target is inside this part. If not, continue to divide and search the right half. - If <code>nums[left] &gt; nums[mid]</code>,the right sub-array <code>[mid,right]</code> is sorted. We can check whether the target is in the right part. If not, continue to divide and search the left half.</p> Python <pre><code>class Solution:\n    def search(self, nums: List[int], target: int) -&gt; int:\n        left, right = 0, len(nums) - 1\n\n        while left &lt;= right:\n            mid = (left + right) // 2\n\n            if target == nums[mid]:\n                return mid\n            elif nums[left] &lt;= nums[mid]:\n                # [left, mid] section is sorted\n                if nums[left] &lt;= target and target &lt; nums[mid]:\n                    right = mid - 1\n                else:\n                    left = mid + 1\n            else:\n                # [mid, right] section is sorted\n                if nums[mid] &lt; target and target &lt;= nums[right]:\n                    left = mid + 1\n                else:\n                    right = mid - 1\n\n        return -1\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0033-search-in-rotated-sorted-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)     Essentially still use binary search. So the time complexity is \\(O(\\log n)\\).  </li> <li>Space complexity: \\(O(1)\\)     Use several index variables for binary search.  </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0034-find-first-and-last-position-of-element-in-sorted-array/","title":"LC34. Find First and Last Position of Element in Sorted Array","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0034-find-first-and-last-position-of-element-in-sorted-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 34: Given an array of integers\u00a0<code>nums</code>\u00a0sorted in non-decreasing order, find the starting and ending position of a given\u00a0<code>target</code>\u00a0value.</p> <p>If\u00a0<code>target</code>\u00a0is not found in the array, return\u00a0<code>[-1, -1]</code>.</p> <p>You must\u00a0write an algorithm with\u00a0<code>O(log n)</code>\u00a0runtime complexity.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0034-find-first-and-last-position-of-element-in-sorted-array/#clarification","title":"Clarification","text":"<ul> <li>array sorted, non-decreasing</li> <li>start and end position for target</li> <li>there are duplicates</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0034-find-first-and-last-position-of-element-in-sorted-array/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0034-find-first-and-last-position-of-element-in-sorted-array/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0034-find-first-and-last-position-of-element-in-sorted-array/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Use binary search twice, one searches start position and the other searches the end position. </p> Python <pre><code>class Solution:\n    def searchRange(self, nums: List[int], target: int) -&gt; List[int]:\n        left, right = 0, len(nums) - 1\n        if right &lt; 0:\n            return [-1, -1]\n\n        # Find the start position\n        while left &lt; right:\n            mid = (left + right) // 2\n            if target == nums[mid]:\n                right = mid\n            elif target &gt; nums[mid]:\n                left = mid + 1\n            else:\n                right = mid - 1\n\n        if nums[left] == target:\n            start_pos = left\n        else:\n            start_pos = -1\n\n        # Find the end position\n        left, right = max(0, start_pos), len(nums) - 1\n\n        while left &lt; right - 1:\n            mid = (left + right) // 2\n            if target == nums[mid]:\n                left = mid\n            elif target &gt; nums[mid]:\n                left = mid + 1\n            else:\n                right = mid - 1\n\n        if nums[right] == target:\n            end_pos = right\n        elif nums[left] == target:\n            end_pos = left\n        else:\n            end_pos = -1\n\n        return [start_pos, end_pos]\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0034-find-first-and-last-position-of-element-in-sorted-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)     Use binary search twice. Each binary search takes at most \\(\\log n\\) steps and total steps are at most \\(2 \\log n\\).</li> <li>Space complexity: \\(O(1)\\)     Only use several index variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0035-search-insert-position/","title":"LC35. Search Insert Position","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0035-search-insert-position/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 35: Given a sorted array of distinct integers and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order.</p> <p>You must\u00a0write an algorithm with\u00a0<code>O(log n)</code>\u00a0runtime complexity.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0035-search-insert-position/#clarification","title":"Clarification","text":"<ul> <li>sorted array</li> <li>distinct integers (no duplicates)</li> <li>find insert position (index?)</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0035-search-insert-position/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0035-search-insert-position/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0035-search-insert-position/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since the array is sorted, the problem can be solved by using Binary Search. The key part is to understand what is searching for. Here is the insert position (not the target). The Search range is the range of array, \\([0, n \u2212 1]\\). @Zhengguan Li provide some good explanations.</p> <ul> <li>If <code>nums[mid] == target</code>, return <code>mid</code>.</li> <li>If <code>target &gt; nums[mid]</code>, <code>mid</code> is not the potential insert position while <code>mid + 1</code> is. so <code>left = mid + 1</code>.</li> <li>If <code>target &lt; nums[mid]</code>, <code>mid</code> is the potential insert position and <code>right = mid</code>.</li> </ul> <p>To determine the while loop condition, we can use two-element case to test our left/right operations: <code>left = mid + 1</code> and <code>right = mid</code>. We can see that it can be safely reduced to one element but not zero. So we need end the while loop when there is only one element left, i.e., <code>while(left &lt; right)</code>.</p> PythonC++ <pre><code>class Solution:\n    def searchInsert(self, nums: List[int], target: int) -&gt; int:\n        left, right = 0, len(nums) - 1\n\n        while left &lt; right:\n            mid = (left + right) // 2\n\n            if target == nums[mid]:\n                return mid\n            elif target &lt; nums[mid]:\n                right = mid  # (1)\n            else:\n                left = mid + 1\n\n        if nums[left] &lt; target:\n            return left + 1\n        else:\n            return left\n</code></pre> <ol> <li>Not mid - 1, since mid could be a potential insert position</li> </ol> <pre><code>class Solution {\npublic:\n    int searchInsert(vector&lt;int&gt;&amp; nums, int target) {\n        if (nums.empty()) {\n            return -1;\n        }\n\n        int left = 0;\n        int right = nums.size() - 1;\n        int mid;\n\n        while (left &lt; right) {\n            mid = left + (right - left)/2;\n\n            if (target == nums[mid]) {\n                return mid;\n            }\n            else if (target &gt; nums[mid]) {\n                left = mid + 1;\n            }\n            else {\n                right = mid;\n            }\n        }\n\n        // 1 element left at the end\n        // post-processing\n        return nums[left] &lt; target ? left + 1 : left;\n    }\n};\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0035-search-insert-position/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)     Since using binary search, the time complexity is \\(O(\\log n)\\) </li> <li>Space complexity: \\(O(1)\\)     Only use limited variables for binary search.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0035-search-insert-position/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0037-sudoku-solver/","title":"37. Sudoku Solver","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0037-sudoku-solver/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 37: Write a program to solve a Sudoku puzzle by filling the empty cells.</p> <p>A sudoku solution must satisfy\u00a0all of the following rules:</p> <ol> <li>Each of the digits\u00a0<code>1-9</code>\u00a0must occur exactly once in each row.</li> <li>Each of the digits\u00a0<code>1-9</code>\u00a0must occur exactly once in each column.</li> <li>Each of the digits\u00a0<code>1-9</code>\u00a0must occur exactly once in each of the 9\u00a0<code>3x3</code>\u00a0sub-boxes of the grid.</li> </ol> <p>The\u00a0<code>'.'</code>\u00a0character indicates empty cells.</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0037-sudoku-solver/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0037-sudoku-solver/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0037-sudoku-solver/#solution","title":"Solution","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0037-sudoku-solver/#approach-1-backtracking","title":"Approach 1: Backtracking","text":"<p>We can use the backtracking algorithm to solve the Sudoku puzzle. The idea is to fill in the empty cells one by one, checking for validity at each step. If a cell cannot be filled, we backtrack to the previous cell and try the next possible number.</p> <p>To check if a number can be placed in a cell, We can use</p> <ul> <li>sets to keep track of the numbers that have already been placed in each row, column, and sub-box.</li> <li>list of integers with bitwise operations to keep track of the numbers that have already been placed in each row, column, and sub-box.</li> </ul> <p>To optimize the solution, we can use the following techniques:</p> <ul> <li>Most Constrained Variable: Choose the cell with the fewest possible candidates   to fill next. This reduces the search space and speeds up the backtracking process.</li> </ul> Python <pre><code>class SudokuSolver:\n    def __init__(self, board: list[list[str]]):\n        self.board = board\n        self.rows = [set() for _ in range(9)]\n        self.cols = [set() for _ in range(9)]\n        self.boxes = [set() for _ in range(9)]\n        self.empty_cells = []\n\n        self._initialize()\n\n    def _initialize(self):\n        for r in range(9):\n            for c in range(9):\n                val = self.board[r][c]\n                if val == \".\":\n                    self.empty_cells.append((r, c))\n                else:\n                    self._place_number(r, c, val)\n\n    def _place_number(self, r: int, c: int, val: str):\n        self.board[r][c] = val\n        self.rows[r].add(val)\n        self.cols[c].add(val)\n        self.boxes[(r // 3) * 3 + c // 3].add(val)\n\n    def _remove_number(self, r: int, c: int, val: str):\n        self.board[r][c] = \".\"\n        self.rows[r].remove(val)\n        self.cols[c].remove(val)\n        self.boxes[(r // 3) * 3 + c // 3].remove(val)\n\n    def _get_candidates(self, r: int, c: int) -&gt; set:\n        return set(str(d) for d in range(1, 10)) - self.rows[r] - self.cols[c] - self.boxes[(r // 3) * 3 + c // 3]\n\n    def _select_most_constrained_cell(self) -&gt; tuple[int, int, int, set]:\n        best_cell = None\n        fewest_candidates = 10\n        best_candidates = set()\n        for i, (r, c) in enumerate(self.empty_cells):\n            candidates = self._get_candidates(r, c)\n            if len(candidates) &lt; fewest_candidates:\n                best_cell = (i, r, c)\n                best_candidates = candidates\n                fewest_candidates = len(candidates)\n            if fewest_candidates == 1:\n                break  # Early exit if only one possibility\n        return best_cell + (best_candidates,)\n\n    def _backtrack(self) -&gt; bool:\n        if not self.empty_cells:\n            return True\n\n        i, r, c, candidates = self._select_most_constrained_cell()\n        self.empty_cells.pop(i)\n\n        for num in candidates:\n            self._place_number(r, c, num)\n            if self._backtrack():\n                return True\n            self._remove_number(r, c, num)\n\n        self.empty_cells.insert(i, (r, c))\n        return False\n\n    def solve(self):\n        self._backtrack()\n\n\nclass Solution:\n    def solveSudoku(self, board: list[list[str]]) -&gt; None:\n        solver = SudokuSolver(board)\n        solver.solve()\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0037-sudoku-solver/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li> <p>Time complexity: \\(O(9^m)\\) where \\(m\\) is the number of empty cells.</p> <ul> <li>Initial setup and iteration through the board takes \\(O(1)\\) time since the board size is fixed with 81 cells.</li> <li>Recursion with backtracking could explore all 9 possible values for each empty cell in the worst case. So the time complexity is \\(O(9^m)\\). The number of empty cells is at most 81, and each cell can have 9 possible values. The upper bound of time complexity is \\(O(9^81)\\), which occurs when all cells are empty.</li> <li>In practice, the average time complexity is much lower due to the pruning effect of backtracking and the use of the most constrained variable heuristic.</li> </ul> </li> <li> <p>Space complexity: \\(O(m)\\)</p> <ul> <li>Storage of the sets for rows, columns, and boxes takes \\(O(1)\\) space since each of these sets holds a maximum of 9 elements.</li> <li>Recursion stack space can go as deep as the number of empty cells, \\(m\\), which is at most 81 for a completely empty board.</li> </ul> </li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0037-sudoku-solver/#test","title":"Test","text":"<ul> <li>Empty Sudoku   Input: An empty Sudoku board.   Output: The board is filled with a valid Sudoku solution.</li> <li>Sudoku with One Empty Cell   Input: A Sudoku board with only one empty cell.   Output: The board is filled with a valid Sudoku solution.</li> <li>Sudoku with Multiple Empty Cells   Input: A Sudoku board with multiple empty cells.   Output: The board is filled with a valid Sudoku solution.</li> <li>Sudoku with All Cells Empty   Input: A Sudoku board with all cells empty.   Output: The board is filled with a valid Sudoku solution.</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0046-permutations/","title":"46. Permutations","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0046-permutations/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 46: Given an array\u00a0<code>nums</code>\u00a0of distinct integers, return all the possible\u00a0permutations. You can return the answer in\u00a0any order.</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0046-permutations/#clarification","title":"Clarification","text":"<ul> <li>Order matters (different from combinations)</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0046-permutations/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0046-permutations/#solution","title":"Solution","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0046-permutations/#approach-1-backtracking","title":"Approach 1: Backtracking","text":"<p>The problem can be viewed as a tree traversal problem. The tree starts with an empty root. Each level of the tree represents a position in the permutation. The children of a node are the remaining numbers to fill the next level(position). When reaching the leaf nodes (the last level of the tree), we have a complete permutation. Then we need to backtrack to explore other branches of the tree.</p> <pre><code>graph TD\n    root((\" \")) --&gt; l11((1))\n    root((\" \")) --&gt; l12((2))\n    root((\" \")) --&gt; l13((3))\n    l11 --&gt; l21((2))\n    l11 --&gt; l22((3))\n    l12 --&gt; l23((1))\n    l12 --&gt; l24((3))\n    l13 --&gt; l25((1))\n    l13 --&gt; l26((2))\n    l21 --&gt; l31((3))\n    l22 --&gt; l32((2))\n    l23 --&gt; l33((3))\n    l24 --&gt; l34((1))\n    l25 --&gt; l35((2))\n    l26 --&gt; l36((1))</code></pre> Python <pre><code>class Solution:\n    def permute(self, nums: List[int]) -&gt; List[List[int]]:\n        self.results = []\n        self._backtrack(nums, [])\n        return self.results\n\n    def _backtrack(self, nums: List[int], curr: List[int]) -&gt; None:\n        # Base case\n        if len(curr) == len(nums):\n            self.results.append(curr[:])  # Use [:] to add a copy of list\n\n        for num in nums:\n            if num not in curr:\n                curr.append(num)\n                self._backtrack(nums, curr)\n                curr.pop()\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0046-permutations/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\cdot n!)\\)   The number of permutation of \\(n\\) numbers is \\(n!\\). For each permutation, we need to   copy it to the final results, which takes \\(O(n)\\) time. So the total time complexity   is \\(O(n \\cdot n!)\\).</li> <li>Space complexity: \\(O(n!)\\) <ul> <li>The final result store all permutations, which takes \\(O(n!)\\) space.</li> <li>The recursion stack takes \\(O(n)\\) space since the depth is the number of elements of the input array.</li> <li>The array <code>curr</code> takes \\(O(n)\\) space since it stores the current permutation.</li> <li>So the total space complexity is \\(O(n!) + O(n) + O(n) = O(n!)\\).</li> </ul> </li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0046-permutations/#test","title":"Test","text":"<ul> <li>Test 2 numbers</li> <li>Test 3 numbers</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/","title":"50. Pow(x, n)","text":"","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 50: Implement\u00a0pow(x, n), which calculates\u00a0<code>x</code>\u00a0raised to the power\u00a0<code>n</code>\u00a0(i.e.,\u00a0<code>xn</code>).</p>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#clarification","title":"Clarification","text":"<ul> <li>x or n can be negative?</li> <li><code>x == 0</code>?</li> <li>data type of <code>x</code> and <code>n</code>?</li> </ul>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#solution","title":"Solution","text":"<p>The straightforward approach is to use brutal force to multiple <code>x</code> by <code>n</code> times. Yet, there is a more efficient method by exponentiation using squaring.</p> <p>If we get the result of \\(x^{n/2}\\), we dont' need to multiply x for another n/2 times. Instead, we can use equation \\(x^{n} = (x^{n/2})^2\\). So we can optimize the calculation based on the equation below:  </p> \\[x^n = \\begin{cases} {(x^{\\frac{n}{2}})}^2 &amp; \\text{when n is even}\\\\ (x^{\\frac{n}{2}})^2 x &amp; \\text{when n is odd} \\end{cases}\\] \\[ \\text{or }  x^n = \\begin{cases} {(x^2)}^{\\frac{n}{2}}  &amp; \\text{when n is even}\\\\ {(x^2)}^{\\frac{n}{2}} x  &amp; \\text{when n is odd} \\end{cases} \\] <p>In all approaches, the <code>n &lt; 0</code> case is converted to <code>n &gt; 0</code> case by making the following substitutions:</p> <ul> <li><code>x = 1/x</code></li> <li><code>n = -n</code>.</li> </ul> <p>We need to handle corner cases for these substitutions: divide by zero for \\(0^{-n}\\) (usually is undefined and need clarifications) and integer overflow in non-Python languages.</p> Divide by Zero for <code>1/x</code> <p>For floating point numbers, IEEE754 defines <code>1.0/0.0</code> as <code>Infinity</code>, <code>-1.0/0.0</code> as <code>-Infinity</code> and <code>0.0/0.0</code> as <code>NaN</code>. Many programming languages follows this and handle them implicitly. Yet, division by zero with <code>int</code> will throw an exception.</p> Integer Overflow of <code>n = -n</code> in Java or C++ <p>In Java, the int is represented by two's complement form with range <code>[-2,147,483,648, 2,147,483,647]</code> or <code>[$-2^{31}$, $2^{31}-1$]</code>. We need to take care of over flow case for the min value: <code>-(-2,147,483,648) = -2,147,483,648</code>. There are two ways to deal with this case:</p> <ul> <li>Define a 64-bit integer to hold the 32-bit value (Python automatically handle this). No overflow for 32-bit integer calculation.</li> <li>Add if statement to check the special case <code>n == -2,147,483,648</code> and take care of it explicitly.</li> </ul>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#approach-1-fast-recursion","title":"Approach 1: Fast Recursion","text":"<p>We can recursively compute power value by reduce <code>n</code> by half.</p> Time Complexity Differences between <code>myPow(x, n/2)*myPow(x, n/2)</code> and <code>halfResult = myPow(x, n/2) halfResult*halfResult</code> <ul> <li><code>myPow(x, n/2)*myPow(x, n/2)</code> will call myPow twice for each recursion. The total functions calls grow exponentially: \\(1 + 2 + 2^2 + \\cdots + 2^{\\log n} = 2^{\\log n + 1} - 1\\) (For k-bit binary, 0~k bits are 1, \\(2^0 + 2^1 + \\cdots + 2^k = 2^{k+1} - 1\\)). The time complexity is \\(\\mathcal{O}(n)\\) and the space complexity is \\(\\mathcal{O}(\\log n)\\) for recursive function calls. <pre><code>            2^n                     1\n        /         \\\n    2^{n/2}         2^{n/2}         2\n    /    \\         /       \\  \n2^{n/4} 2^{n/4} 2^{n/4} 2^{n/4}     2^2\n...                                 ...\n</code></pre></li> <li><code>halfResult = myPow(x, n/2) halfResult*halfResult</code> only call myPow function once for each recursion. This can be considered as memoization of above approach. The time complexity is \\(\\mathcal{O}(\\log n)\\) and the space complexity is \\(\\mathcal{O}(\\log n)\\) for recursive function calls. <pre><code>    2^n\n    |\n    2^{n/2}\n    |\n    2^{n/4}\n    |\n    ...\n</code></pre></li> </ul> PythonJava <pre><code>class Solution:\n    def myPow(self, x: float, n: int) -&gt; float:\n        # Base case\n        if n == 0:\n            return 1.0\n        if n == 1:\n            return x\n        if x == 0.0:\n            return 0.0\n\n        # Handle negative n\n        if n &lt; 0:\n            n = -n\n            x = 1 / x\n\n        # Power by squaring\n        x_half = self.myPow(x, n // 2)\n        if n % 2 == 0:\n            return x_half * x_half\n        else:\n            return x_half * x_half * x\n</code></pre> <pre><code>class Solution {\n    public double myPow(double x, int n) {\n        if (n &lt; 0) {\n            if (n == Integer.MIN_VALUE)\n                return myPow(x, n + 1)*(1/x); // x^n = x^(n+1)*x^(-1)\n            else {\n                x = 1/x; // Divided by zero is implicitly handled by floating point division.\n                n = -n;\n            }\n        }\n\n        if (n == 0) {\n            return 1.0; // base case\n        }\n\n        double halfResult = myPow(x, n/2);\n        if (n % 2 == 0)\n            return halfResult*halfResult;\n        else\n            return halfResult*halfResult*x;\n    }\n}\n</code></pre>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)   Each time <code>n</code> is reduced by half by using the equation \\(x^{n} = (x^{n/2})^2\\). Thus we   need at most \\(\\mathcal{O}(\\log n)\\) computations to get the result.</li> <li>Space complexity: \\(O(\\log n)\\)   We need to call the recursion function \\(\\mathcal{O}(\\log n)\\) times and need constant   space (store the result of \\(x^{n/2}\\)) for each computation. So the space complexity is   \\(\\mathcal{O}(\\log n)\\).</li> </ul>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#approach-2-fast-iteration","title":"Approach 2: Fast Iteration","text":"<p>By following the same idea, we can also use an iterative solution.</p> python <pre><code>class Solution:\n    def myPow(self, x: float, n: int) -&gt; float:\n        # Base case\n        if n == 0:\n            return 1.0\n\n        # Handle negative n\n        if n &lt; 0:\n            if math.isclose(x, 0.0, abs_tol=1e-9):\n                return 0.0\n            n = -n\n            x = 1 / x\n\n        # Power by squaring\n        result = 1.0\n        while n &gt; 0:\n            if n % 2 == 1:  # (1)\n                result *= x\n                n -= 1\n            x = x * x\n            n = n // 2\n\n        return result\n</code></pre> <ol> <li>Handle two cases: (1) When <code>n</code> is odd and (2) the last step (n is odd or even), update the result.</li> </ol>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)   At each iteration, <code>n</code> is reduced by half. So there is total \\(\\log n\\) number of iterations.</li> <li>Space complexity: \\(O(1)\\)   Limited variables.</li> </ul>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Fast Recursion \\(O(\\log n)\\) \\(O(\\log n)\\) Approach - Fast Iteration \\(O(\\log n)\\) \\(O(1)\\)","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0050-powx-n/#test","title":"Test","text":"<ul> <li>n = 0 (should return 1)</li> <li>x = 0 (should return 0 for positive n, handle 0\u2070 case)</li> <li>x = negative (ensure correct handling of odd/even n)</li> <li>n = negative (test division cases for small x)</li> <li>Very large n (ensure efficient handling)</li> </ul>","tags":["Math","Recursion"]},{"location":"lc-solutions/lc0001-0099/lc0051-n-queens/","title":"51. N-Queens","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0051-n-queens/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 51: The\u00a0n-queens\u00a0puzzle is the problem of placing\u00a0<code>n</code>\u00a0queens on an\u00a0<code>n x n</code>\u00a0chessboard such that no two queens attack each other.</p> <p>Given an integer\u00a0<code>n</code>, return\u00a0all distinct solutions to the\u00a0n-queens puzzle. You may return the answer in\u00a0any order.</p> <p>Each solution contains a distinct board configuration of the n-queens' placement, where\u00a0<code>'Q'</code>\u00a0and\u00a0<code>'.'</code>\u00a0both indicate a queen and an empty space, respectively.</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0051-n-queens/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0051-n-queens/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0051-n-queens/#solution","title":"Solution","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0051-n-queens/#approach-1-backtracking","title":"Approach 1: Backtracking","text":"<p>The solution is similar to the N-Queens II problem. The only difference is that we need to return all distinct solutions instead of just counting them. We can do this by storing the valid solutions in a list and returning that list at the end.</p> Python <pre><code>class Solution:\n    def solveNQueens(self, n: int) -&gt; List[List[str]]:\n        self.ans = []\n        empty_board = [[\".\"] * n for _ in range(n)]\n        self.solve(n, 0, set(), set(), set(), empty_board)\n        return self.ans\n\n    def solve(\n        self,\n        n: int,\n        i_row: int,\n        cols: set[int],\n        diagonals: set[int],\n        anti_diagonals: set[int],\n        state,\n    ) -&gt; None:\n        if i_row == n:  # Find valid solution\n            self.ans.append(self._create_board(state))\n            return\n\n        for i_col in range(n):\n            curr_diagonal = i_row - i_col\n            curr_anti_diagonal = i_row + i_col\n\n            # Check whether the queen is placeable\n            if (\n                i_col in cols\n                or curr_diagonal in diagonals\n                or curr_anti_diagonal in anti_diagonals\n            ):\n                continue\n\n            # Add the queen to the board\n            cols.add(i_col)\n            diagonals.add(curr_diagonal)\n            anti_diagonals.add(curr_anti_diagonal)\n            state[i_row][i_col] = \"Q\"\n\n            # Move on to the next row with the updated state\n            self.solve(n, i_row + 1, cols, diagonals, anti_diagonals, state)\n\n            # Remove the queen since we have already explored all valid paths\n            cols.remove(i_col)\n            diagonals.remove(curr_diagonal)\n            anti_diagonals.remove(curr_anti_diagonal)\n            state[i_row][i_col] = \".\"\n\n    def _create_board(self, state: list[list[str]]):\n        board = []\n        for row in state:\n            board.append(\"\".join(row))\n        return board\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0051-n-queens/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li> <p>Time complexity: \\(O(n!)\\)</p> <ul> <li>It takes \\(O(n!)\\) to find all possible solutions. For each row, we have \\(n\\) choices, and for each choice, we have \\(n-1\\) choices for the next row, and so on.</li> <li>To build each valid solution, it takes \\(O(n^2)\\). Yet, the number of valid solutions, \\(s_n\\) is much smaller than \\(n!\\), \\(s_n &lt;&lt; n\\).</li> <li>So the overall time complexity is \\(O(n! + s_n \\cdot n^2) = O(n!)\\).</li> </ul> </li> <li> <p>Space complexity: \\(O(n)\\) </p> <ul> <li>The recursion stack takes \\(O(n)\\) space, since it goes up to \\(n\\) levels deep (number of rows).</li> <li>The hashsets <code>cols</code>, <code>diagonals</code>, and <code>anti_diagonals</code> take \\(O(n)\\) since they store one value for each row.</li> <li>The board takes \\(O(n^2)\\) space since it is a 2D array of size \\(n \\times n\\).</li> <li>The list <code>ans</code> takes \\(O(n^2)\\) space since it stores all valid solutions.</li> <li>So the overall space complexity is \\(O(n) + O(n) + O(n) + O(n^2) + O(n^2) = O(n^2)\\).</li> </ul> </li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0051-n-queens/#test","title":"Test","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0052-n-queens-ii/","title":"52. N-Queens II","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0052-n-queens-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 52: The n-queens puzzle requires placing <code>n</code> queens on an <code>n x n</code> chessboard such that no two queens attack each other.</p> <p>Given an integer <code>n</code>, return the number of distinct solutions to the n-queens puzzle.</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0052-n-queens-ii/#clarification","title":"Clarification","text":"<ul> <li>The chessboard is of size <code>n x n</code>, where <code>n</code> is the number of queens.</li> <li>A queen can attack any square in the same row, column, or diagonal.</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0052-n-queens-ii/#assumption","title":"Assumption","text":"<ul> <li><code>n</code> is a positive integer.</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0052-n-queens-ii/#solution","title":"Solution","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0052-n-queens-ii/#approach-1-backtracking","title":"Approach 1: Backtracking","text":"<p>We solve the N-Queens problem using backtracking. The idea is to place a queen row by row and recursively attempt to place queens in subsequent rows to build valid solutions.</p> <ul> <li>If a valid solution is found (i.e., all queens are placed), it is counted as one distinct solution.</li> <li>If no valid placement exists in the current row, we backtrack by removing the last placed queen and going back to previous row to try other possibilities.</li> </ul> <p>A queen can attach any square in the same row, column, or diagonal. So we need to:</p> <ul> <li>Place 1 queen in each row.</li> <li>Place 1 queen in each column.</li> <li>Ensure no two queens are in each diagonal and anti-diagonal.</li> </ul> <p>We start with placing 1 queen in each row and use sets to track columns, diagonals, and anti-diagonals occupied by queens.</p> How to check diagonal and anti-diagonal? <p>Get good explanations from LeetCode editorial solution. - The diagonal of a square is defined by the difference between its row and column   indices. For example, the diagonal of (i, j) is <code>i - j</code>. If two squares have the same   diagonal number, they are in the same diagonal line.</p> <p></p> <ul> <li>The anti-diagonal of a square is defined by the sum of its row and column indices. For   example, the anti-diagonal of (i, j) is <code>i + j</code>. If two squares have the same anti-diagonal number,   they are in the same anti-diagonal line.</li> </ul> <p></p> Python <pre><code>class Solution:\n    def totalNQueens(self, n: int) -&gt; int:\n        return self.solve(n, 0, set(), set(), set())\n\n    def solve(\n        self,\n        n: int,\n        i_row: int,\n        cols: set[int],\n        diagonals: set[int],\n        anti_diagonals: set[int],\n    ) -&gt; int:\n        # Base case: All queens are placed\n        if i_row == n:\n            return 1\n\n        n_solutions = 0\n        for i_col in range(n):\n            curr_diagonal = i_row - i_col\n            curr_anti_diagonal = i_row + i_col\n            # Check if the position is valid\n            if (\n                i_col in cols\n                or curr_diagonal in diagonals\n                or curr_anti_diagonal in anti_diagonals\n            ):\n                continue\n\n            # Place the queen\n            cols.add(i_col)\n            diagonals.add(curr_diagonal)\n            anti_diagonals.add(curr_anti_diagonal)\n\n            # Recurse to the next row\n            n_solutions += self.solve(n, i_row + 1, cols, diagonals, anti_diagonals)\n\n            # Backtrack\n            cols.remove(i_col)\n            diagonals.remove(curr_diagonal)\n            anti_diagonals.remove(curr_anti_diagonal)\n\n        return n_solutions\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0052-n-queens-ii/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n!)\\)<ul> <li>Each queen must be placed in a different row and column.</li> <li>The first queen can be placed in <code>n</code> columns, the second queen in <code>n-1</code> columns, and so on. So in the worst case, we have <code>n!</code> placements to check.</li> <li>The backtracking algorithm prunes invalid placements early, reducing the number of recursive calls. The worst-case time complexity is still \\(O(n!)\\), but the average case is much better.</li> </ul> </li> <li>Space complexity: \\(O(n)\\)<ul> <li>Recursive call stack depth is <code>n</code> since placing 1 queen in each row. So call stack uses \\(O(n)\\) space.</li> <li>Hashsets stores the columns, diagonals, and anti-diagonals for at most \\(n\\) queens:<ul> <li><code>cols</code>: \\(O(n)\\)</li> <li><code>diagonals</code>: \\(O(n)\\)</li> <li><code>anti_diagonals</code>: \\(O(n)\\)</li> </ul> </li> <li>So the total space complexity is \\(O(n) + O(n) + O(n) + O(n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0052-n-queens-ii/#test","title":"Test","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0069-sqrt-x/","title":"LC69. Sqrt(x)","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0069-sqrt-x/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 69: Given a non-negative integer\u00a0<code>x</code>, return\u00a0the square root of <code>x</code> rounded down to the nearest integer. The returned integer should be\u00a0non-negative\u00a0as well.</p> <p>You\u00a0must not use\u00a0any built-in exponent function or operator.</p> <ul> <li>For example, do not use\u00a0<code>pow(x, 0.5)</code>\u00a0in c++ or\u00a0<code>x ** 0.5</code>\u00a0in python.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0069-sqrt-x/#clarification","title":"Clarification","text":"<ul> <li>non-negative</li> <li>square root of x in integer</li> <li>round it down</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0069-sqrt-x/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0069-sqrt-x/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0069-sqrt-x/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Mathematically, <code>i = sqrt(x)</code> can be viewed as <code>x = i * i</code>. The problem is to find an integer <code>i</code> in the search space <code>[1, x]</code> such that <code>i * i &lt;= x</code> and <code>(i + 1) * (i + 1) &gt; x</code>. If <code>i * i &gt; x</code>, we can exclude values larger than or equal to <code>i</code>. If <code>i * i &lt; x</code>, we can exclude the value smaller than i. With this property, we can solve this problem using binary search. There are somethings to pay attention to: \u2022 overflow caused by <code>i * i</code> in the evaluation <code>i * i &gt; x</code>; \u2022 can not simply check <code>i == x/i</code> to determine whether the answer is found since there may be multiple values satisfied this equations due to integer division.</p> PythonC++ <pre><code>class Solution:\n    def mySqrt(self, x: int) -&gt; int:\n        left, right = 0, x\n\n        while left &lt; right - 1:\n            mid = (left + right) // 2\n            mid_square = mid * mid\n            if x == mid_square:\n                return mid\n            elif x &lt; mid_square:\n                right = mid - 1\n            else:\n                left = mid\n\n        if right * right &lt;= x:\n            return right\n        else:\n            return left\n</code></pre> <pre><code>class Solution {\npublic:\n    int mySqrt(int x) {\n        if (x &lt;= 1) {\n            return x;\n        }\n\n        int left = 1;\n        int right = x;\n        int mid;\n\n        while (left &lt;= right) {\n            mid = left + (right - left)/2;\n\n            if ((mid &lt;= x/mid) &amp;&amp; ((mid + 1) &gt; x/(mid + 1))) {\n                return mid;\n            }\n            else if (mid &gt; x/mid) {\n                right = mid - 1;\n            }\n            else {\n                left = mid + 1; \n            }\n        }\n        return -1;\n    }\n};\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0069-sqrt-x/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) Since using the binary search, the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\) Only use several variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0069-sqrt-x/#test","title":"Test","text":"<ul> <li>x &lt;= 1 case</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0070-climbing-stairs/","title":"70. Climbing Stairs","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0070-climbing-stairs/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 70: You are climbing a staircase. It takes\u00a0<code>n</code>\u00a0steps to reach the top.</p> <p>Each time you can either climb\u00a0<code>1</code>\u00a0or\u00a0<code>2</code>\u00a0steps. In how many distinct ways can you climb to the top?</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0070-climbing-stairs/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0070-climbing-stairs/#assumption","title":"Assumption","text":"<ul> <li>\\(n &gt;= 1\\)</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0070-climbing-stairs/#solution","title":"Solution","text":"<p>One can reach \\(n\\)th step in two distinct ways:</p> <ul> <li>Taking a step from \\((n - 1)\\)th step</li> <li>Taking a step of 2 from \\((n - 2)\\)th step. Note that take 1 step twice from \\((n - 2)\\)th step is covered by \\((n - 1)\\)th step.</li> </ul> <p>So the total number of distinct ways to reach \\(n\\)th step is the sum of ways of reaching \\((n \u2212 1)\\)th step and ways of reaching \\((n \u2212 2)\\)th step. Let \\(f(i)\\) denotes the number of distinct ways to reach \\(i\\)th step, then we have \\(f(i) = f(i \u2212 1) + f(i \u2212 2)\\). This becomes a problem of finding \\(i\\)th number of the Fibonacci series with base cases \\(f(1) = 1\\) and \\(f(2) = 2\\). Check 509 Fibonacci Number for detailed solutions.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0070-climbing-stairs/#test","title":"Test","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/","title":"LC 74. Search a 2D Matrix","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/#problem-description","title":"Problem Description","text":"<p>Leetcode Problem 74: You are given an\u00a0<code>m x n</code>\u00a0integer matrix\u00a0<code>matrix</code>\u00a0with the following two properties:</p> <ul> <li>Each row is sorted in non-decreasing order.</li> <li>The first integer of each row is greater than the last integer of the previous row.</li> </ul> <p>Given an integer\u00a0<code>target</code>, return\u00a0<code>true</code> if <code>target</code> is in <code>matrix</code> or <code>false</code> otherwise.</p> <p>You must write a solution in\u00a0<code>O(log(m * n))</code>\u00a0time complexity.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/#clarification","title":"Clarification","text":"<ul> <li>sorted or unsorted?</li> <li>how is it sorted? row, column, any other properties</li> <li>how big is the size?</li> <li>data type</li> <li>return value? boolean, linear index, or indices (row and column)</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/#assumption","title":"Assumption","text":"<ul> <li><code>m * n</code> won't cause overflow</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/#solution","title":"Solution","text":"<p>Taking advantages of the matrix properties, we can use binary search here. Two approaches:</p> <ol> <li>Use binary search twice: search along the row and then along the column for the target row (if exists)</li> <li>The matrix \\(m \\times n\\) can be considered as a sorted array of length \\(m \\times n\\). Then apply binary search on a sorted array instead of a matrix. </li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/#approach-1-binary-search-twice-on-the-matrix","title":"Approach 1: Binary search twice on the matrix","text":"<p>Binary search along the row and then along the column for the target row.</p> <ul> <li>Search along the row is a slightly modified version of classic binary search. It uses the first and last element of middle row for comparison instead of just one element. The row with potential target should meet condition: <code>target &gt;= matrix[mr][0] &amp;&amp; target &lt;= matrix[mr][nCol-1]</code></li> <li>Search along the column is a classic binary search.</li> </ul> Java <pre><code>class Solution {\n    public boolean searchMatrix(int[][] matrix, int target) {\n        if (matrix == null || matrix.length == 0 || matrix[0].length == 0)\n            return false;\n\n        int nRow = matrix.length;\n        int nCol = matrix[0].length;\n\n        int tr = 0;   // top row\n        int br = nRow - 1; // bottom row\n        int mr = -1; // middle row between top and bottom rows\n\n        // Binary search along the row\n        while (tr &lt;= br){\n            mr = tr + (br - tr)/2;\n            if (target &lt; matrix[mr][0]){\n                br = mr - 1;\n            }\n            else if (target &gt; matrix[mr][nCol-1]){\n                tr = mr + 1;\n            }\n            else\n            {\n                break;\n            }\n        }\n\n        if (tr &gt; br || mr &lt; 0)\n            return false;\n\n        int lc = 0; // left column\n        int rc = nCol - 1; // right column\n        int mc;     // middle column between left and right columns\n        // Binary search along the column\n        while (lc &lt;= rc){\n            mc = lc + (rc - lc)/2;\n            if (target &lt; matrix[mr][mc]){\n                rc = mc - 1;\n            }\n            else if(target &gt; matrix[mr][mc]){\n                lc = mc + 1;\n            }\n            else{\n                return true;\n            }\n        }\n\n        return false;\n\n    }\n}\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/#approach-2-binary-search-on-a-sorted-array-transformed-from-the-matrix","title":"Approach 2: Binary search on a sorted array (transformed from the matrix)","text":"<p>Based on the matrix properties, the matrix \\(m \\times n\\) can be considered as a sorted array of length \\(m \\times n\\). A classic binary search can be applied on this sorted array.</p> <p>Matrix to array: <code>matrix[r][c] -&gt; a[r * n + c]</code> Array to matrix: <code>a[x] -&gt; matrix[x/m][x%n]</code></p> <p>Drawbacks </p> <ul> <li><code>m*n</code> may overflow for large m and n</li> <li><code>/</code> and <code>%</code> are expensive operations</li> </ul> JavaPython <pre><code>class Solution {\n    public boolean searchMatrix(int[][] matrix, int target) {\n    // Use binary search on linear index of a matrix\n    if (matrix.length == 0 || matrix[0].length == 0) {\n        return false;\n    }\n\n    int nRow = matrix.length;\n    int nCol = matrix[0].length;\n\n    int left = 0;\n    int right = nRow*nCol - 1; // -1 for zero-based indexing\n    int middle;\n    int iRow;\n    int iCol;\n    int element;\n    while (left &lt;= right){\n        middle = left + (right - left)/2;\n\n        // Convert linear index to matrix indices\n        // Use nCol below for matrix sorted by rows\n        // Otherwise use nRow for matrix sorted by columns\n        iRow = middle/nCol;\n        iCol = middle%nCol;\n        element = matrix[iRow][iCol];\n        if (target &lt; element)\n            right  = middle - 1;\n        else if (target &gt; element)\n            left = middle + 1;\n        else\n            return true;\n\n    }\n\n    return false;\n\n    }\n}\n</code></pre> <pre><code>class Solution:\n    def searchMatrix(self, matrix: List[List[int]], target: int) -&gt; bool:\n        m, n = len(matrix), len(matrix[0])\n        left, right = 0, m * n - 1\n\n        while left &lt;= right:\n            mid = (left + right) // 2\n            i = mid // n\n            j = mid % n\n            value = matrix[i][j]\n\n            if value == target:\n                return True\n            elif target &gt; value:\n                left = mid + 1\n            else:\n                right = mid - 1\n\n        return False\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li> <p>Time complexity: \\(\\mathcal{O}(\\log(mn))\\) for both approaches.  </p> <ul> <li>Approacheh 1: For the worse case, search along the row needs \\(\\log m\\) number of iterations  and search along the column needs \\(\\log n\\) number of iterations. So the total number is \\(\\log mn  = \\log m + \\log n\\) for the worst case. Therefore the time complexity is \\(\\mathcal{O}(\\log(mn))\\).</li> <li>Approach 2: It uses the classic binary searc on \\(m \\times n\\) elements. Therefore the time complexity is \\(\\mathcal{O}(\\log(mn))\\).</li> </ul> </li> <li> <p>Space complexity: \\(\\mathcal{O}(1)\\). Both approaches use several more variables than classic binary search but they still use \\(\\mathcal{O}(1)\\) space</p> </li> </ul> Time Complexity Space Complexity Approach 1 \\(\\mathcal{O}(\\log(mn))\\) \\(\\mathcal{O}(1)\\) Approach 2 \\(\\mathcal{O}(\\log(mn))\\) \\(\\mathcal{O}(1)\\)","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0074-search-a-2d-matrix/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0075-sort-colors/","title":"75 Sort colors","text":"<p># LC75. Sort Colors</p>","tags":["Array","Two Pointers","Sorting"]},{"location":"lc-solutions/lc0001-0099/lc0075-sort-colors/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 75: Given an array <code>nums</code> with <code>n</code> objects colored red, white, or blue, sort them in-place so that objects of the same color are adjacent, with the colors in the order red, white, and blue.</p> <p>We will use the integers <code>0</code>, <code>1</code>, and <code>2</code> to represent the color red, white, and blue, respectively</p> <p>You must solve this problem without using the library's sort function.</p>","tags":["Array","Two Pointers","Sorting"]},{"location":"lc-solutions/lc0001-0099/lc0075-sort-colors/#clarification","title":"Clarification","text":"","tags":["Array","Two Pointers","Sorting"]},{"location":"lc-solutions/lc0001-0099/lc0075-sort-colors/#assumption","title":"Assumption","text":"","tags":["Array","Two Pointers","Sorting"]},{"location":"lc-solutions/lc0001-0099/lc0075-sort-colors/#solution","title":"Solution","text":"","tags":["Array","Two Pointers","Sorting"]},{"location":"lc-solutions/lc0001-0099/lc0075-sort-colors/#approach-three-pointers","title":"Approach - Three Pointers","text":"<p>The problem is known as Dutch National Flag Problem and first was proposed by Edsger W. Dijkstra. We can use three pointers to solve the problem (or consider it as a dual-pivot partitioning sub-routine of quick sort algorithm, see the java solution below): - One pointer, <code>p0</code>, to track the rightmost boundary of zeros - Another pointer, <code>p2</code>, to track the leftmost boundary of twos - The other pointer, <code>curr</code>, is for the current element under the consideration </p> <p></p> <p>The idea is to move <code>curr</code> pointer along the array,  </p> <ul> <li>If <code>nums[curr] == 0</code>, swap it with <code>nums[p0]</code> </li> <li>If <code>nums[curr] == 2</code>, swap it with <code>nums[p2]</code> </li> <li>If <code>nums[curr]==1</code>, move forward</li> </ul> <p>We know after swapping, we need to increase <code>p0</code>, i.e., <code>p0++</code>, and decrease <code>p2</code>, i.e., <code>p2--</code>. Yet, it is tricky to determine whether to increase <code>curr</code>.  </p> <ul> <li>If <code>nums[curr] == 2</code>, after swapping with <code>p2</code>, we should not increase <code>curr</code> since the number swapped from <code>p2</code> can be 0, 1, or 2, which needs to be further processed  </li> <li> <p>If <code>nums[curr] == 0</code>, combine the below two cases, we should increase <code>curr</code>:  </p> <ul> <li>If <code>curr == p0</code> as initialization, both pointers need to be increased, <code>curr++</code> and <code>p0++</code> </li> <li>If <code>curr &gt; p0</code>, the number swapped back from <code>p0</code> can only be 1. As <code>curr</code> has passed <code>p0</code> (they were initialized same), the only way to separate these two when encountering 1. So leaving <code>curr</code> where it is (<code>curr == 1</code>, which will be increased in next execution) or increasing <code>curr</code>, does not make a difference. To cover both <code>curr &gt; p0</code> and <code>curr == p0</code> conditions, we should use <code>curr++</code>.  </li> </ul> </li> </ul> <p>Another two conditions to consider:  </p> <ul> <li><code>while</code> condition should use <code>curr &lt;= p2</code> instead of <code>curr &lt; p2</code>, since <code>curr == p2</code> is not processed yet. We need to decide whether it goes to p0, p2, or stay where it is.  </li> <li>When using unsigned integer for pointer, need to handle edge case of <code>p2</code> where <code>p2--</code> will cause overflow when <code>p2==0</code>.  </li> </ul> <p>The problem can be considered as a dual-pivot partitioning sub-routine of quick sort algorithm (as shown in the Java solution below).</p> PythonC++Java <pre><code>class Solution:\n    def sortColors(self, nums: List[int]) -&gt; None:\n        \"\"\"\n        Do not return anything, modify nums in-place instead.\n        \"\"\"\n        p0, curr, p2 = 0, 0, len(nums) - 1\n\n        while curr &lt;= p2:\n            if (nums[curr] == 0):\n                nums[p0], nums[curr] = nums[curr], nums[p0]\n                p0 += 1\n                curr += 1\n            elif (nums[curr] == 2):\n                nums[p2], nums[curr] = nums[curr], nums[p2]\n                p2 -= 1\n            else:\n                curr += 1\n</code></pre> <pre><code>class Solution {\npublic:\n    void sortColors(vector&lt;int&gt;&amp; nums) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size p0 = 0;\n        vec_size p2 = nums.size() - 1;\n        vec_size curr = 0;\n\n        while (curr &lt;= p2) {\n            if (nums[curr] == 0) {\n                swap(nums[curr++], nums[p0++]);\n            }\n            else if (nums[curr] == 2) {\n                if (p2 == 0) {\n                    break; // handle unsigned int (0 - 1 case)\n                }\n                else {\n                    swap(nums[curr], nums[p2--]);\n                }\n\n            }\n            else {\n                curr++;\n            }\n        }\n    }\n};\n</code></pre> <pre><code>public void sortColors(int[] nums) {\n    int lo = 0, hi = nums.length - 1, i = 0;\n\n    while (i &lt;= hi) {\n        if      (nums[i] == 0) swap(nums, lo++, i++);\n        else if (nums[i] == 2) swap(nums, i, hi--);\n        else if (nums[i] == 1) i++;\n    }\n}\n\nprivate void swap(int[] nums, int i, int j) {\n    int t = nums[i];\n    nums[i] = nums[j];\n    nums[j] = t;\n}\n</code></pre>","tags":["Array","Two Pointers","Sorting"]},{"location":"lc-solutions/lc0001-0099/lc0075-sort-colors/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Since it is one pass along the array of length n. </li> <li>Space complexity: \\(O(1)\\)     Only use 3 pointers, a constant space solution. </li> </ul>","tags":["Array","Two Pointers","Sorting"]},{"location":"lc-solutions/lc0001-0099/lc0075-sort-colors/#test","title":"Test","text":"","tags":["Array","Two Pointers","Sorting"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/","title":"77. Combinations","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 77: Given two integers\u00a0<code>n</code>\u00a0and\u00a0<code>k</code>, return\u00a0all possible combinations of <code>k</code> numbers chosen from the range <code>[1, n]</code>.</p> <p>You may return the answer in\u00a0any order.</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#clarification","title":"Clarification","text":"<ul> <li>Does the order matter? No, <code>[1, 2]</code> is the same as <code>[2, 1]</code>.</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#solution","title":"Solution","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#approach-1-backtracking","title":"Approach 1: Backtracking","text":"<p>We can use backtracking to explore all possible combinations of numbers from <code>1</code> to <code>n</code>. The idea is to build the combinations incrementally, adding one number at a time and removing it if it doesn't lead to a valid combination. The algorithm explores all possible combinations by recursively calling itself with the next number to be added. The base case is when the length of the current combination equals <code>k</code>, at which point we add the combination to the result list.</p> <p>The best way to understand this problem is to visualize the backtracking process as a tree.</p> <ul> <li>The root node is empty, representing the initial state.</li> <li>The first level with \\(n\\) nodes, representing the numbers from <code>1</code> to <code>n</code> that can be chosen for the first position of the combination.</li> <li>To prevent duplicate combinations, each node only has children with numbers greater than the current number. So from the 2nd level to \\(k + 1\\)th level, each node contains nodes from <code>curr + 1</code> to <code>n</code> nodes.</li> </ul> <p>The following diagram illustrates the tree structure:</p> <pre><code>graph TD\n    root(\"[]\")\n    n1(1)\n    n2(2)\n    n3(3)\n    n4(4)\n    n1_1(2)\n    n1_2(3)\n    n1_3(4)\n    n2_1(3)\n    n2_2(4)\n    n3_1(4)\n\n    root --&gt; n1\n    root --&gt; n2\n    root --&gt; n3\n    root --&gt; n4\n\n    n1 --&gt; n1_1\n    n1 --&gt; n1_2\n    n1 --&gt; n1_3\n    n2 --&gt; n2_1\n    n2 --&gt; n2_2\n    n3 --&gt; n3_1\n\n    style n1_1 fill:#9ACD32\n    style n1_2 fill:#9ACD32\n    style n1_3 fill:#9ACD32\n    style n2_1 fill:#9ACD32\n    style n2_2 fill:#9ACD32\n    style n3_1 fill:#9ACD32</code></pre> <p>Solving this problem is equivalent to finding all paths from the root node to the leaf nodes of the tree. Each path represents a unique combination of numbers.</p> <p>Optimization: There are some paths that don't lead to any solution (e.g., node 4 in the tree diagram). We can avoid paths like these by limiting the range of numbers to be considered. Instead of exploring all numbers from <code>1</code> to <code>n</code>, we can limit the range to <code>[start, n - (k - len(path)) + 1]</code>. This ensures that we only consider numbers that can be part of a valid combination. This optimization reduces the number of recursive calls and speeds up the algorithm.</p> Python <pre><code>class Solution:\n    def combine(self, n: int, k: int) -&gt; List[List[int]]:\n        self.result = []\n        self.n = n\n        self.k = k\n        self._backtrack(1, [])\n        return self.result\n\n    def _backtrack(self, start: int, path: list[int]) -&gt; None:\n        # Base case\n        if len(path) == self.k:\n            self.result.append(path[:])  # curr[:] makes a copy\n            return\n\n        # Optimization: No need to go beyond n - (k - len(path)) + 1\n        end = self.n - (self.k - len(path)) + 1\n        for num in range(start, end + 1):\n            path.append(num)\n            self._backtrack(num + 1, path)\n            path.pop()\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(C(n, k) \\times k)\\)<ul> <li>The number of combinations is given by the binomial coefficient \\(C(n, k) = \\frac{n!}{k!(n-k)!}\\).</li> <li>Each combination takes \\(O(k)\\) time to copy it into the result list (when <code>len(path) == k</code>).</li> <li>The total time complexity is \\(O(C(n, k) \\times k)\\).</li> </ul> </li> <li>Space complexity: \\(O(C(n, k) \\times k)\\)<ul> <li>Call stack space: at most, the recursion depth goes to \\(k\\) since we stop once we have \\(k\\) elements.</li> <li>The path list stores at most \\(k\\) elements.</li> <li>The result list stores all combinations, which takes \\(O(C(n, k) \\times k)\\) space.</li> <li>The total space complexity is \\(O(k) + O(k) + O(C(n, k) \\times k) = O(C(n, k) \\times k)\\).</li> </ul> </li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#approach-2","title":"Approach 2:","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0077-combinations/#test","title":"Test","text":"<ul> <li>Test <code>n = 1, k = 1</code></li> <li>Test normal case <code>n = 4, k = 2</code></li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/","title":"LC80. Remove Duplicates from Sorted Array II","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 80: Given an integer array <code>nums</code> sorted in non-decreasing order, remove some duplicates in-placesuch that each unique element appears at most twice. The relative order of the elements should be kept the same.</p> <p>Since it is impossible to change the length of the array in some languages, you must instead have the result be placed in the first part of the array <code>nums</code>. More formally, if there are <code>k</code> elements after removing the duplicates, then the first <code>k</code> elements of <code>nums</code>\u00a0should hold the final result. It does not matter what you leave beyond the first\u00a0<code>k</code>\u00a0elements.</p> <p>Return <code>k</code> after placing the final result in the first <code>k</code>slots of <code>nums</code>.</p> <p>Do not allocate extra space for another array. You must do this by modifying the input array in-placewith O(1) extra memory.</p>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#similar-questions","title":"Similar Questions:","text":"<ul> <li>LC26 Remove duplicates from sorted array</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#clarification","title":"Clarification","text":"<ul> <li><code>num</code> is sorted in non-decreasing order</li> <li>Remove duplicate number &gt; 2 times</li> <li>Keep the relative order</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#assumption","title":"Assumption","text":"<ul> <li>Number of elements is within the range of integer type (Python integer type doesn't have this problem)</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#solution","title":"Solution","text":"<p>Both solutions provided below can be extended to the case with at most <code>k</code> duplicates.  </p>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#approach-two-pointers","title":"Approach - Two Pointers","text":"<p>The idea is to simply overwrite the duplicate elements that are unwanted instead of actually remove elements. To achieve this, a two-pointer approach will be used, where - one pointer <code>i</code> tracks the index of the last valid element, and <code>i+1</code> is the next location that can be overwritten - the other pointer <code>j</code> iterates over the array Additional variable <code>nAppears</code> is used to track the count of  a particular element in the array. Note that <code>nAppears</code> is initialized and reset with <code>1</code>, since for any element itself counts appearing once. If <code>nAppears &lt;= 2</code>, we can move the element from index <code>j</code> to index <code>i++</code></p> C++Python <pre><code>class Solution {\npublic:\n    int removeDuplicates(vector&lt;int&gt;&amp; nums) {\n        if (nums.empty()) return 0;\n\n        int i = 0;\n        int nAppears = 1; \n\n        for (int j = 1; j &lt; nums.size(); j++) {\n            if (nums[i] != nums[j]) {\n                nAppears = 1;\n            }\n            else {\n                nAppears++;\n            }\n\n            if (nAppears &lt;= 2) {\n                i++;\n                nums[i] = nums[j];\n            }\n        }\n        return i+1;\n    }\n}; \n</code></pre> <pre><code>class Solution:\n    def removeDuplicates(self, nums: List[int]) -&gt; int:\n        i = 0\n        n_appear = 1\n        for j in range(1, len(nums)):\n            if nums[i] == nums[j]:\n                n_appear += 1\n            else:\n                n_appear = 1 # (1)\n\n            if n_appear &lt;= 2:\n                i += 1\n                nums[i] = nums[j]\n        return i + 1\n</code></pre> <ol> <li>if number itself, it appears once</li> </ol>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     The for loop iterates the each element once. </li> <li>Space complexity: \\(O(1)\\)     Use two pointers and <code>nAppears</code>. </li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#approach-sliding-window","title":"Approach - Sliding Window","text":"<p>For better understanding, assume there is a sliding window of size <code>2</code> with <code>i</code> at the right boundary of the window, indicating  the next position that can be overwritten, <code>|nums[i-2], nums[i-1]| nums[i]</code>. So the sliding windows contains elements <code>nums[i-2]</code> and <code>nums[i-1]</code>. Then we can compare the new element <code>nums[i]</code> with <code>nums[i-2]</code>, if they are equal, we have 3 duplicates (using the property: array is sorted and nondecreasing) and therefore should skip this element. Otherwise, we can copy the new element to the location of index <code>i</code>.  </p> C++Python <pre><code>class Solution {\npublic:\n    int removeDuplicates(vector&lt;int&gt;&amp; nums) {\n        int i = 0;\n        for (int num : nums) {\n            if (i &lt; 2 || num &gt; nums[i - 2]) {\n                nums[i++] = num;\n            }\n        }\n        return i;\n    }\n};\n</code></pre> <pre><code>i = 0\nfor num in nums:\n    if i &lt; 2 or num &gt; nums[i - 2]:\n        nums[i] = num\n        i += 1\n\nreturn i\n</code></pre>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Since it iterates the whole array, the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(1)\\)     Use one pointer. </li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Two Pointers \\(O(n)\\) \\(O(1)\\) Approach - Two Pointers + Sliding Window \\(O(n)\\) \\(O(1)\\)","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0080-remove-duplicates-from-sorted-array-ii/#test","title":"Test","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0001-0099/lc0081-search-in-rotated-sorted-array-ii/","title":"LC81. Search in Rotated Sorted Array II","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0081-search-in-rotated-sorted-array-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 81: There is an integer array\u00a0<code>nums</code>\u00a0sorted in non-decreasing order (not necessarily with\u00a0distinct\u00a0values).</p> <p>Before being passed to your function,\u00a0<code>nums</code>\u00a0is\u00a0rotated\u00a0at an unknown pivot index\u00a0<code>k</code>\u00a0(<code>0 &lt;= k &lt; nums.length</code>) such that the resulting array is\u00a0<code>[nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]</code>\u00a0(0-indexed). For example,\u00a0<code>[0,1,2,4,4,4,5,6,6,7]</code>might be rotated at pivot index\u00a0<code>5</code>\u00a0and become\u00a0<code>[4,5,6,6,7,0,1,2,4,4]</code>.</p> <p>Given the array\u00a0<code>nums</code> after\u00a0the rotation and an integer\u00a0<code>target</code>, return\u00a0<code>true</code> if <code>target</code> is in <code>nums</code>, or <code>false</code> if it is not in <code>nums</code>.</p> <p>You must decrease the overall operation steps as much as possible.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0081-search-in-rotated-sorted-array-ii/#clarification","title":"Clarification","text":"<ul> <li>sorted and rotated</li> <li>have duplicates</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0081-search-in-rotated-sorted-array-ii/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0081-search-in-rotated-sorted-array-ii/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0081-search-in-rotated-sorted-array-ii/#approach-binary-search","title":"Approach - Binary Search","text":"<p>This is a follow-up problem to LC33 - Search in Rotated Sorted Array. The difference is that it contains duplicates. We can still divide the array into a sorted part and a unsorted part and then search. Due to duplicates, </p> <ul> <li>For situation 1 in LC33, <code>nums[left] &lt;= nums[mid] &lt;= nums[right]</code>, when <code>nums[left] == nums[mid] == nums[right]</code>, we don\u2019t know which part (left or right) is sorted. For example, <code>[3,1,3,3,3,3,3]</code> with left part unsorted and <code>[3, 3, 3, 3, 3, 1, 3]</code> with right part unsorted. For this case, if <code>target != nums[mid]</code>, we can increase left and decrease right by 1.</li> </ul> Python <pre><code>class Solution:\n    def search(self, nums: List[int], target: int) -&gt; bool:\n        left, right = 0, len(nums) - 1\n\n        while left &lt;= right:\n            mid = (left + right) // 2\n            if nums[mid] == target:\n                return True\n            elif nums[left] == nums[mid] and nums[mid] == nums[right]:\n                left += 1\n                right -= 1\n            elif nums[left] &lt;= nums[mid]:  # (1)\n                # [left, mid] non-decreasing\n                if nums[left] &lt;= target and target &lt; nums[mid]:\n                    right = mid - 1\n                else:\n                    left = mid + 1\n            else:\n                # [mid, right] non-decreasing\n                if nums[mid] &lt; target and target &lt;= nums[right]:\n                    left = mid + 1\n                else:\n                    right = mid - 1\n\n        return False\n</code></pre> <ol> <li>Add <code>=</code> to handle case `left == mid``</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0081-search-in-rotated-sorted-array-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) for the average, \\(O(n)\\) for the worst case     In the worst case, just move left pointer by one, which needs n steps. So the time complexity is \\(O(n)\\). For the average case, since using binary search, the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\)     Only use limited variables for indices.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0081-search-in-rotated-sorted-array-ii/#test","title":"Test","text":"<ul> <li>Only two numbers, e.g. <code>[3, 1]</code></li> <li>Test array with `nums[left] == nums[mid]``</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/","title":"84. Largest Rectangle In Histogram","text":"","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 84: Given an array of integers\u00a0<code>heights</code>\u00a0representing the histogram's bar height where the width of each bar is\u00a0<code>1</code>, return\u00a0the area of the largest rectangle in the histogram.</p>","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#clarification","title":"Clarification","text":"<ul> <li>The largest area could be just one bar or shared area of multiple bars</li> </ul>","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#solution","title":"Solution","text":"","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#approach-1-brute-force","title":"Approach 1: Brute Force","text":"<p>This problem can be solved using a brute force approach. The idea is to iterate over each bar in the histogram, find the width of the rectangle that can be formed with that bar as the smallest height, and then calculate the area of that rectangle as <code>height * width</code>. The maximum area found during this process will be the answer.</p> Python <pre><code>class Solution:\n    def largestRectangleArea(self, heights: List[int]) -&gt; int:\n        n = len(heights)\n        max_area = 0\n        for i in range(n):\n            count = 1  # count consecutive heights &gt;= current height, start with 1 including the current height\n\n            # Check right side, starting from the right neighbor\n            for j in range(i + 1, n):\n                if heights[j] &gt;= heights[i]:\n                    count += 1\n                else:\n                    break\n            # Check left side, starting from the left neighbor\n            for j in range(i - 1, -1, -1):\n                if heights[j] &gt;= heights[i]:\n                    count += 1\n                else:\n                    break\n\n            # Calculate area and update the max area\n            max_area = max(heights[i] * count, max_area)\n\n        return max_area\n</code></pre>","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n^2)\\)   The outer loop iterates over each bar, and the inner loops check the left and right   neighbors of each bar. In the worst case, this results in \\(O(n^2)\\) time complexity.</li> <li>Space complexity: \\(O(1)\\)   The algorithm uses a constant amount of space to store variables like <code>max_area</code> and   <code>count</code>, regardless of the input size.</li> </ul>","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#approach-2-monotonic-increasing-stack","title":"Approach 2: Monotonic Increasing Stack","text":"<p>This problem can be solved using a monotonic increasing stack. The idea is to maintain a stack to store indices of the bars in increasing order of their heights. When we encounter a bar that is shorter than the bar at the top of the stack, we pop from the stack and calculate the area of the rectangle formed with the popped bar as the smallest height.</p> <ul> <li>The height of the rectangle is the height of the popped bar.</li> <li>The width of the rectangle is determined by:<ul> <li>If the stack is empty after popping, the width is the current index <code>i</code>, i.e., <code>width = i</code>. This means that the popped bar is the smallest height in the rectangle since the stack is monotonic increasing. The rectangle extends from the beginning of the histogram to the current index.</li> <li>If the stack is not empty, the width is the difference between the current index <code>i</code> and the index of the new top of the stack, <code>stack[-1]</code>, minus one, <code>width = i - stack[-1] - 1</code>. Since the stack is in increasing order, the popped bar is larger than previous bar (index of <code>[stack[-1]</code>, top of the stack after popping). The popped bar is also smaller than the current bar, which triggers the popping. Therefore, <code>previous bar (index of stack[-1]) &lt;= popped bar &gt; current bar (i)</code>. The range of rectangle extends from <code>stack[-1]</code> to the current index <code>i</code>, minus one to exclude <code>stack[-1]</code> since the <code>corresponding bar &lt;= popped bar</code>.</li> </ul> </li> </ul> <p>The area is calculated as <code>height * width</code>, where <code>height</code> is the height of the popped bar and <code>width</code> is the width of the rectangle. We continue this process until we have processed all the bars in the histogram.</p> python <pre><code>class Solution:\n    def largestRectangleArea(self, heights: List[int]) -&gt; int:\n        stack = []  # Stack to store indices of the bars\n        max_area = 0\n        n = len(heights)\n\n        for i in range(n + 1):  # Use n + 1 to flush the stack at the end\n            # Use 0 as the height for the last bar to flush the stack\n            # (1)\n            current_height = heights[i] if i &lt; n else 0\n\n            while stack and heights[stack[-1]] &gt; current_height:\n                height = heights[stack.pop()]\n                if not stack:\n                    width = i\n                else:\n                    width = i - stack[-1] - 1\n                max_area = max(max_area, height * width)\n\n            stack.append(i)\n</code></pre> <ol> <li>This ensures that all bars are processed and the stack is empty at the end. This is a trick to handle the last bar and calculate the area for all remaining bars in the stack.</li> </ol>","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   The algorithm processes each bar in the histogram once, and each bar is pushed and   popped from the stack at most once, resulting in a linear time complexity.</li> <li>Space complexity: \\(O(n)\\)   The stack can store all the indices of the bars in the worst case, leading to a linear   space complexity.</li> </ul>","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Brute \\(O(n^2)\\) \\(O(1)\\) Approach 2 - Monotonic Stack \\(O(n)\\) \\(O(n)\\)","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0084-largest-rectangle-in-histogram/#test","title":"Test","text":"","tags":["Monotonic Stack"]},{"location":"lc-solutions/lc0001-0099/lc0088-merge-sorted-array/","title":"LC88. Merge Sorted Array","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0088-merge-sorted-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 88: You are given two integer arrays <code>nums1</code> and <code>nums2</code>, sorted in non-decreasing order, and two integers <code>m</code> and <code>n</code>, representing the number of elements in <code>nums1</code> and <code>nums2</code> respectively.</p> <p>Merge <code>nums1</code> and <code>nums2</code> into a single array sorted in non-decreasing order.</p> <p>The final sorted array should not be returned by the function, but instead be stored inside the array <code>nums1</code>. To accommodate this, <code>nums1</code> has a length of <code>m + n</code>, where the first <code>m</code> elements denote the elements that should be merged, and the last <code>n</code> elements are set to <code>0</code> and should be ignored. <code>nums2</code>has a length of <code>n</code>.</p>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0088-merge-sorted-array/#clarification","title":"Clarification","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0088-merge-sorted-array/#assumption","title":"Assumption","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0088-merge-sorted-array/#solution","title":"Solution","text":"","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0088-merge-sorted-array/#approach","title":"Approach","text":"<p>The problem can be considered as a revert sorting problem, comparing and merging elements by iterating backwards. We can use three pointers: - <code>p1</code> starts from the last element of nums1 - <code>p2</code> starts from the last element of nums2 - <code>p</code> starts from the last position of nums1</p> <p>By iterating backwards, we compare elements at <code>p1</code> and <code>p2</code> and move the large one to <code>p</code>.</p> <p>Follow-up questions: How to make sure that elements in <code>nums1</code> are not accidentally overwritten by iterating backwards?</p> <p>Answers:  - Start from the initialization <code>p1 + n = p</code> and <code>p2 = n-1</code>. - When doing merge sorting, <code>p</code> is always decreased by 1 and either <code>p1</code> or <code>p2</code> is decreased by 1     - When reducing <code>p1</code>, the gap between <code>p</code> and <code>p1</code> stays the same and no overwritten     - When reducing <code>p2</code>, the gap between <code>p</code> and <code>p1</code> shrinks by 1, at most <code>n</code> times. After <code>n</code> times, <code>p = p1</code> and therefore no overwritten. </p> PythonC++ <pre><code>class Solution:\n    def merge(self, nums1: List[int], m: int, nums2: List[int], n: int) -&gt; None:\n        \"\"\"\n        Do not return anything, modify nums1 in-place instead.\n        \"\"\"\n        i = m - 1\n        j = n - 1\n\n        for k in range(m + n - 1, -1, -1):\n            # k from m + n - 1 to 0\n            if i &lt; 0:\n                nums1[k] = nums2[j]\n                j -= 1\n            elif j &lt; 0:\n                nums1[k] = nums1[i]\n                i -= 1\n            elif nums1[i] &gt;= nums2[j]:\n                nums1[k] = nums1[i]\n                i -= 1\n            else:\n                nums1[k] = nums2[j]\n                j -= 1\n</code></pre> <pre><code>class Solution {\npublic:\n    void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) {\n        int i = m - 1;\n        int j = n - 1;\n        // int k = m + n - 1;\n\n        for (int k = m + n - 1; k &gt;= 0; k--) {\n            // if (i &lt; 0 &amp;&amp; j &lt; 0) {\n            //     break;\n            // } // no need since k &lt; 0 and won't enter the for loop\n        if (i &lt; 0) {\n                // only nums2 elements left\n                nums1[k] = nums2[j--];\n            }\n            else if (j &lt; 0) {\n                // Can be skipped and no need copy since the elements are there\n                // only nums1 elements left\n                // nums1[k] = nums1[i--]; // no need copy\n            }\n            else {\n                // compare elements and move the larger \n                if (nums2[j] &gt; nums1[i]) {\n                    nums1[k] = nums2[j--];\n                }\n                else {\n                    nums1[k] = nums1[i--];\n                }\n            }\n        }\n\n    }\n};\n</code></pre>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0088-merge-sorted-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n+m)\\)     Since iterating backwards of all positions of nums1 (total <code>m+n</code>), the time complexity is \\(O(n+m)\\).   </li> <li>Space complexity: \\(O(1)\\)     Only using three pointers and therefore constant space complexity.</li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0088-merge-sorted-array/#test","title":"Test","text":"<ul> <li>Two empty arrays</li> <li>One array is empty</li> <li>Normal case with smaller <code>m</code></li> <li>Normal case with smaller <code>n</code></li> </ul>","tags":["Array","Two Pointers"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/","title":"91. Decode Ways","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 91: You have intercepted a secret message encoded as a string of numbers. The message is\u00a0decoded\u00a0via the following mapping:</p> <p><code>\"1\" -&gt; 'A'   \"2\" -&gt; 'B'   ...   \"25\" -&gt; 'Y'   \"26\" -&gt; 'Z'</code></p> <p>However, while decoding the message, you realize that there are many different ways you can decode the message because some codes are contained in other codes (<code>\"2\"</code>\u00a0and\u00a0<code>\"5\"</code>\u00a0vs\u00a0<code>\"25\"</code>).</p> <p>For example,\u00a0<code>\"11106\"</code>\u00a0can be decoded into:</p> <ul> <li><code>\"AAJF\"</code>\u00a0with the grouping\u00a0<code>(1, 1, 10, 6)</code></li> <li><code>\"KJF\"</code>\u00a0with the grouping\u00a0<code>(11, 10, 6)</code></li> <li>The grouping\u00a0<code>(1, 11, 06)</code>\u00a0is invalid because\u00a0<code>\"06\"</code>\u00a0is not a valid code (only\u00a0<code>\"6\"</code>\u00a0is valid).</li> </ul> <p>Note: there may be strings that are impossible to decode.</p> <p>Given a string s containing only digits, return the\u00a0number of ways\u00a0to\u00a0decode\u00a0it. If the entire string cannot be decoded in any valid way, return\u00a0<code>0</code>.</p> <p>The test cases are generated so that the answer fits in a\u00a032-bit\u00a0integer.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#solution","title":"Solution","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#approach-1-dynamic-programming","title":"Approach 1: Dynamic Programming","text":"<p>This problem can be solved using dynamic programming:</p> <ul> <li>State: <code>dp[i]</code>: the number of ways to decode the substring <code>s[0:i]</code></li> <li>Transition: at each position <code>i</code>, we look at the last one digit and the last two digits.<ul> <li>Single digit decode:<ul> <li>valid if <code>s[i] != '0'</code>. Decode <code>s[i]</code> as one letter.</li> <li>The number of ways to decode the first <code>i</code> characters is the same as the number of ways to decode the first <code>i-1</code> characters: <code>dp[i] = dp[i - 1]</code>.</li> </ul> </li> <li>Two digits decode:<ul> <li>valid if <code>10 &lt;= s[i-1:i+1] &lt;= 26</code>. Decode last two digits <code>s[i-1:i+1]</code> as one letter.</li> <li>The number of ways to decode the first <code>i</code> characters is the same as the number of ways to decode the first <code>i-2</code> characters: <code>dp[i] = dp[i - 2]</code>.</li> </ul> </li> <li>So <code>dp[i] = dp[i - 1] + dp[i - 2]</code> if both single and two digits can be decoded.</li> </ul> </li> <li>Base case:<ul> <li>dp(0) = 1, empty string has one way to decode.</li> <li>dp(1) = 1 if <code>s[0] != '0'</code> else 0</li> </ul> </li> </ul> Python <pre><code>class Solution:\n    def numDecodings(self, s: str) -&gt; int:\n        if s[0] == \"0\":\n            return 0\n\n        pprev = 1\n        prev = 1\n        for i in range(1, len(s)):\n            curr = 0\n\n            if s[i] != \"0\":\n                curr = prev\n\n            # Check whether s[i-1: i+1] are valid\n            if 10 &lt;= int(s[i - 1 : i + 1]) &lt;= 26:\n                curr += pprev\n\n            prev, pprev = curr, prev\n\n        return prev\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   We iterate through the string once, performing constant-time operations for each character.</li> <li>Space complexity: \\(O(1)\\)   We only use a fixed amount of space for the variables <code>prev</code>, <code>pprev</code>, and <code>curr</code>.</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#approach-2-graph-traversal","title":"Approach 2: Graph Traversal","text":"<p>The problem can be visualized as a directed graph where each node represents a position in the string, and edges represent valid decoding steps. We can use a breadth-first search (BFS) or depth-first search (DFS) to explore all possible decoding paths.</p> <p>Take \"326\" as a example:</p> <pre><code>graph TD;\n    0 --3--&gt; 1;\n    1 --2--&gt; 2;\n    1 --26--&gt; 3;\n    2 --6--&gt; 3;\n    style 0 fill:#f9f,stroke:#333,stroke-width:4px</code></pre> python <pre><code>from collections import deque\n\nclass Solution:\n    def numDecodings(self, s: str) -&gt; int:\n        if not s or s[0] == '0':\n            return 0\n\n        # BFS initialization\n        queue = deque([0])  # Start from the first character\n        count = 0\n\n        while queue:\n            i = queue.popleft()\n            if i == len(s):\n                count += 1\n                continue\n\n            # Single digit decode\n            if s[i] != '0':\n                queue.append(i + 1)\n\n            # Two digits decode\n            if i + 1 &lt; len(s) and 10 &lt;= int(s[i:i + 2]) &lt;= 26:\n                queue.append(i + 2)\n\n        return count\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Dynamic Programming \\(O(n)\\) \\(O(1)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0091-decode-ways/#test","title":"Test","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/","title":"LC92. Reverse Linked List II","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 92: Given the\u00a0<code>head</code>\u00a0of a singly linked list and two integers\u00a0<code>left</code>\u00a0and\u00a0<code>right</code>\u00a0where\u00a0<code>left &lt;= right</code>, reverse the nodes of the list from position\u00a0<code>left</code>\u00a0to position\u00a0<code>right</code>, and return\u00a0the reversed list.</p>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#clarification","title":"Clarification","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#assumption","title":"Assumption","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#solution","title":"Solution","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#approach-iteration","title":"Approach - Iteration","text":"<p>The problem can be solved using iterations. @hi-malik explains really well how to solve this problme using an iterative method. The basic idea is to reverse the node one-by-one by using 3 pointers, <code>prev</code>, <code>curr</code>, and <code>forw</code>:</p> <ul> <li><code>curr.next = forw.next</code></li> <li><code>forw.next = curr.next or prev.next</code>, not sure and need to use an example to find whether to use <code>curr.next</code> or <code>prev.next</code></li> <li><code>prev.next = forw</code></li> <li><code>forw = curr.next</code></li> </ul> <p>Moreover, a dummy head is used to handle the case where <code>left = 1</code> and <code>prev</code> is assigned with the dummy head.</p> Python <pre><code>class Solution:\n    def reverseBetween(self, head: Optional[ListNode], left: int, right: int) -&gt; Optional[ListNode]:\n        dummy = ListNode(0, head)\n        prev = dummy\n\n        for i in range(left - 1): # 0 ~ left - 2\n            prev = prev.next  # 1 ~ left - 1\n\n        curr = prev.next # left\n        for i in range(right - left):\n            forw = curr.next\n            curr.next = forw.next\n            forw.next = prev.next\n            prev.next = forw\n\n        return dummy.next\n</code></pre>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Iteration through the list \\(O(right)\\) time and worst case \\(O(n)\\)</li> <li>Space complexity: \\(O(1)\\)     Store 4 pointers (prev, curr, forw, and dummy)</li> </ul>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#approach-stack","title":"Approach - Stack","text":"<p>Use stack to store the sublist that need to be reversed. After filling it up, then pop it up one by one and reverse the sublist easily. @vanAmsen provides a good solution on using stack.</p> <p>In Python, using <code>deque</code> is better than <code>list</code> in expanding memory when growing stack.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def reverseBetween(self, head: Optional[ListNode], left: int, right: int) -&gt; Optional[ListNode]:\n        dummy = ListNode(0, head)\n        prev = dummy\n        stack = deque()\n\n        for _ in range(left - 1):\n            prev = prev.next  # prev: 1 ~ left - 1\n\n        current = prev.next # left\n\n        for _ in range(right - left + 1):\n            stack.append(current)\n            current = current.next\n\n        while stack:\n            prev.next = stack.pop()\n            prev = prev.next\n\n        prev.next = current\n\n        return dummy.next\n</code></pre>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Need to go through the linked list in worst case, which takes \\(O(n)\\) time when right == n.</li> <li>Space complexity: \\(O(n)\\)     Need \\(O(n)\\) space for stack. </li> </ul>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#approach-recursion","title":"Approach - Recursion","text":"<p>The problem can be solved using recursion but difficult to find clean solution. WarrenChen shares a recursive method that is relative easy to follow.</p> Python <pre><code>class Solution:\n    def reverseBetween(self, head: Optional[ListNode], left: int, right: int) -&gt; Optional[ListNode]:\n        if left == right:\n            return head\n\n        if left &gt; 1:\n            head.next = self.reverseBetween(head.next, left - 1, right - 1) # head will be changed in side of the function\n            return head\n        else:\n            next = head.next\n            new_head = self.reverseBetween(next, 1, right - 1)\n            next_next = next.next\n            next.next = head\n            head.next = next_next\n            return new_head\n</code></pre>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#complexity-analysis_2","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Need to do recursion \\(O(right)\\) time and worst case is \\(O(n)\\) when right == n.</li> <li>Space complexity: \\(O(n)\\)     Need \\(O(n)\\) space to store recursion function call.  </li> </ul>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - iteration \\(O(n)\\) \\(O(1)\\) Approach - stack \\(O(n)\\) \\(O(n)\\) Approach - recursion \\(O(n)\\) \\(O(n)\\)","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0092-reverse-linked-list-ii/#test","title":"Test","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/","title":"LC94. Binary Tree Inorder Traversal","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 94: Given the root of a binary tree, return the inorder traversal of its nodes' values.</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#clarification","title":"Clarification","text":"<ul> <li>Definition of inorder traversal</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#approach-1-recursion","title":"Approach 1 - Recursion","text":"<p>This problem can be solved using the classic recursive method by defining a new helper function <code>inorder</code>. In the helper function,</p> <pre><code>inorder(root.left, values)  # recursively traverse the left subtree\nvalues.append(root.val)  # visit root/parent node\ninorder(root.right, values)  # recursively traverse the right subtree\n</code></pre> python <pre><code>class Solution:\n    def inorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        result = []\n        self.inorder(root, result)\n        return result\n\n    def inorder(self, node: Optional[TreeNode], result: List[int]):\n        if node is None:\n            return\n\n        self.inorder(node.left, result)\n        result.append(node.val)\n        self.inorder(node.right, result)\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   The algorithm visits each node exactly once for total \\(n\\) nodes.</li> <li>Space complexity: \\(O(n)\\)   The recursion stack takes \\(O(n)\\) space in the worst case (for example, every node   only has left child). In the best case (a balanced binary tree),   the recursion stack takes \\(O(\\log n)\\) space.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#approach-2-iteration-with-stack","title":"Approach 2 - Iteration with Stack","text":"<p>Instead of using recursion, we can traverse the nodes by using stack to store the nodes and pop it up when reaching the end of the left branch.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def inorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        values = []\n        stack = deque()\n\n        curr_node = root\n        while curr_node or stack:\n            if curr_node:\n                stack.append(curr_node)  # (1)\n                curr_node = curr_node.left\n            else:\n                curr_node = stack.pop()\n                values.append(curr_node.val)  # (2)\n                curr_node = curr_node.right\n\n        return values\n</code></pre> <ol> <li>To return the root later.</li> <li>Append after all left children.</li> </ol>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   Each node (total \\(n\\) nodes) is pushed once to and popped once from the stack. So the   time complexity is \\(O(2n) = O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>In the worst case (for example, every node only has left child), the stack will hold all \\(n\\) nodes.</li> <li>In the best case (a balanced binary tree), stack will hold \\(\\log n\\) nodes due to the height of the tree.</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#approach-3-morris-traversal","title":"Approach 3 - Morris Traversal","text":"<p>We can use Morris traversal which is similar to the solution in preorder traversal. The only difference is in when to visit node after finding predecessor:</p> <ul> <li>Preorder traversal: visit node when <code>predecessor.right</code> is <code>None</code> (before exploring left), since root/parent needs to be the first (root - left - right) before exploring the left.</li> <li>Inorder traversal: visit node when <code>predecessor.right</code> is <code>curr_node</code> (after exploring left), since root/parent needs to be middle (left - middle - right).</li> </ul> python <pre><code>class Solution:\n    def inorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        output = []\n        curr_node = root\n        while curr_node:\n            if curr_node.left:\n                # Find predecessor, the rightmost node of the left sub-tree.\n                predecessor = curr_node.left\n                while predecessor.right and predecessor.right != curr_node:\n                    predecessor = predecessor.right\n\n                # Handle two conditions out of while loops\n                if not predecessor.right:  # (1)\n                    predecessor.right = curr_node\n                    curr_node = curr_node.left\n                else:  # (2)\n                    output.append(curr_node.val)\n                    predecessor.right = None\n                    curr_node = curr_node.right\n            else:\n                output.append(curr_node.val)\n                curr_node = curr_node.right\n\n        return output\n</code></pre> <ol> <li>Condition 1: <code>predecessor.right</code> is <code>None</code>. The left sub-tree is not explored.</li> <li>Condition 2: <code>predecessor.right</code> is the <code>curr_node</code>. The left sub-tree has been visited.</li> </ol>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n)\\)     We visit each node twice, one for establishing link and one for removing. Therefore     the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>Visit nodes taking \\(O(1)\\) space.</li> <li>The return list takes \\(O(n)\\) space to save all node values.</li> <li>The total space complexity is \\(O(n) = O(1) + O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity (Overall) Space Complexity (Visit) Approach - Recursion \\(O(n)\\) \\(O(n)\\) $O(n) Approach - Iteration \\(O(n)\\) \\(O(n)\\) $O(n) Approach - Morris \\(O(n)\\) \\(O(n)\\) $O(1)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0094-binary-tree-inorder-traversal/#test","title":"Test","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/","title":"95. Unique Binary Search Trees II","text":"","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 95: Given an integer <code>n</code>, return all the structurally unique BST's (binary search trees), which has exactly <code>n</code> nodes of unique values from <code>1</code> to <code>n</code>. Return the answer in any order.</p>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#solution","title":"Solution","text":"","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#approach-1-recursion","title":"Approach 1: Recursion","text":"<p>A binary search tree has the property: the left subtree contains all values less than the root and the right subtree contains all values greater than the root.</p> <p>Based on the above property, we can recursively construct all possible BSTs by</p> <ol> <li>Choosing each number from <code>1</code> to <code>n</code> as the root node.</li> <li>Recursively constructing all possible left subtrees using the numbers less than the root.</li> <li>Recursively constructing all possible right subtrees using the numbers greater than the root.</li> <li>Combining the left and right subtrees with the root node.</li> <li>Storing the result in a memoization dictionary to avoid recomputation.</li> <li>Returning the list of all unique BSTs.</li> </ol> Python <pre><code>class Solution:\n  def generateTrees(self, n: int) -&gt; List[Optional[TreeNode]]:\n      memo = {}\n      return self.allPossibleBst(1, n, memo)\n\n  def allPossibleBst(self, start: int, end: int, memo: dict[tuple, list]) -&gt; List[Optional[TreeNode]]:\n      # Base case\n      if start &gt; end:\n          return [None]\n      if start == end:\n          return [TreeNode(start)]\n      if (start, end) in memo:\n          return memo[(start, end)]\n\n      result = []\n      # Iterate through all values and construct left and right subtree recursively\n      for i in range(start, end + 1):\n          left_sub_trees = self.allPossibleBst(start, i - 1, memo)\n          right_sub_trees = self.allPossibleBst(i + 1, end, memo)\n\n          # Loop through all left and right subtrees and connect them to ith root\n          for left in left_sub_trees:\n              for right in right_sub_trees:\n                  root = TreeNode(i, left, right)\n                  result.append(root)\n\n      # Store the result in memoization dictionary\n      # to avoid recomputation\n      # for the same range of start and end\n      memo[(start, end)] = result\n      return result\n</code></pre>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(\\frac{4^n}{\\sqrt{n}})\\) <ul> <li>Number of trees: The total number of unique BSTs with <code>n</code> nodes is given by the <code>n</code>th Catalan number (Refer to LC95 for more details), which is \\(C_n = \\frac{1}{n+1} \\binom{2n}{n} \\approx \\frac{4^n}{n^{3/2}\\sqrt{\\pi}}\\).</li> <li>Build each tree: Each of these BSTs has \\(n\\) nodes and takes \\(O(n)\\) time to construct.</li> <li>So the total time complexity is \\(O(n \\cdot C_n) = O(n \\cdot \\frac{4^n}{n^{3/2}\\sqrt{\\pi}}) = O(\\frac{4^n}{\\sqrt{n}})\\).</li> </ul> </li> <li>Space complexity: \\(O(\\frac{4^n}{\\sqrt{n}})\\) <ul> <li>Call stack: In the worst case, the recursion depth is \\(n\\) (recursively called \\(n\\) times), taking \\(O(n)\\) space.</li> <li>Memoization: The memoization dictionary stores the results of all possible BSTs for each range of <code>start</code> and <code>end</code>, which is \\(\\sum_{k = 1}^n (n - k + 1) C_k k\\). So the space complexity is \\(O(n C_n) = O(\\frac{4^n}{\\sqrt{n}})\\).</li> <li>Result list: The result list stores all unique BSTs (\\(C_n\\) trees) and each tree contains \\(n\\) nodes. So the space complexity is \\(O(n C_n)\\).</li> <li>Total space complexity: \\(O(n + n C_n + n C_n) = O(n C_n) = O(\\frac{4^n}{\\sqrt{n}})\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#approach-2","title":"Approach 2:","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0095-unique-binary-search-trees-ii/#test","title":"Test","text":"","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/","title":"96. Unique Binary Search Trees","text":"","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 96: Given an integer <code>n</code>, return the number of structurally unique BST's (binary search trees) which has exactly <code>n</code> nodes of unique values from <code>1</code> to <code>n</code>.</p>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#solution","title":"Solution","text":"","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#approach-1-dynamic-programming","title":"Approach 1: Dynamic Programming","text":"<p>For a given root node <code>i</code>, the number of unique BSTs is the product of the number of unique BSTs that from the left subtree based on subsequence \\(1, 2, \\cdots, i - 1\\) and the right subtree based on sequence \\(i + 1, i + 2, \\cdots, n\\).</p> <p>Based on this observation, we can solve the problem using dynamic programming. To do so, we can define two functions:</p> <ul> <li><code>G(n)</code>: the number of unique BSTs that can be formed with <code>n</code> nodes (i.e., length of a sequence).</li> <li><code>F(i, n)</code>: the number of unique BSTs that can be formed with <code>i</code> as the root node with total \\(n\\) nodes (\\(1 \\leq i \\leq n\\)).</li> </ul> <p>Based on above definitions, we can derive the following equations:</p> <ul> <li>\\(G(n) = \\sum_{i=1}^{n} F(i, n)\\): sum of all unique BSTs with <code>i</code> as the root node where <code>i</code> ranges from 1 to n.</li> <li>\\(F(i, n) = G(i - 1) \\cdot G(n - i)\\): the number of unique BSTs with root <code>i</code> is the product of all unique number of BSTs formed with <code>i - 1</code> nodes in the left subtree and <code>n - i</code> nodes in the right subtree.</li> <li>\\(G(0) = 1\\), \\(G(1) = 1\\): base case</li> </ul> <p>So combine above equations together, we obtain:</p> \\[G(n) = \\sum_{i=1}^{n} G(i - 1) \\cdot G(n - i)\\] Python <pre><code>class Solution:\n    def numTrees(self, n: int) -&gt; int:\n        G = [0] * (n + 1)\n        G[0], G[1] = 1, 1\n\n        for i in range(2, n + 1):\n            for j in range(1, i + 1):\n                G[i] += G[j - 1] * G[i - j]\n\n        return G[n]\n</code></pre>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n^2)\\)   The outer loop runs <code>n - 1</code> times and the inner loop runs <code>i</code> times, where <code>i</code> ranges from   <code>2</code> to <code>n</code>. The total number of iterations is \\(\\sum_{i=2}^{n} i = \\frac{(n+2)(n-1)}{2}\\).   So the total time complexity is \\(O(n^2)\\).</li> <li>Space complexity: \\(O(n)\\)   We use an array <code>G</code> of size <code>n + 1</code> to store the number of unique BSTs for each <code>i</code>   from <code>0</code> to <code>n</code>. So the space complexity is \\(O(n)\\).</li> </ul>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#approach-2-math","title":"Approach 2: Math","text":"<p>The sequence of <code>G(n)</code> is known as the Catalan number. The <code>n</code>th Catalan number can be computed using the following formula:</p> \\[C_n = \\frac{1}{n + 1} \\binom{2n}{n} = \\frac{(2n)!}{(n + 1)!n!}\\] <p>where \\(C_n\\) is the <code>n</code>th Catalan number, and \\(\\binom{2n}{n}\\) is the binomial coefficient defined as \\(\\binom{n}{k} = \\frac{n!}{k!(n - k)!}\\).</p> python <pre><code>class Solution:\n    def numTrees(self, n: int) -&gt; int:\n        return factorial(2 * n) // (factorial(n) * factorial(n + 1))\n</code></pre>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   The time complexity is dominated by the computation of the factorials. The   computation of the factorials takes \\(O(n)\\) time.</li> <li>Space complexity: \\(O(1)\\)   The space complexity is \\(O(1)\\) because we are using a constant amount of space to   store the factorials.</li> </ul>","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Dynamic Programming \\(O(n^2)\\) \\(O(n)\\) Approach - Math \\(O(n)\\) \\(O(1)\\)","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0096-unique-binary-search-trees/#test","title":"Test","text":"","tags":["Dynamic Programming","Binary Search Tree","Math"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/","title":"98. Validate Binary Search Tree","text":"","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 98: Given the\u00a0<code>root</code>\u00a0of a binary tree,\u00a0determine if it is a valid binary search tree (BST).</p> <p>A\u00a0valid BST\u00a0is defined as follows:</p> <ul> <li>The left\u00a0subtree\u00a0of a node contains only nodes with keys\u00a0less than\u00a0the node's key.</li> <li>The right subtree of a node contains only nodes with keys\u00a0greater than\u00a0the node's key.</li> <li>Both the left and right subtrees must also be binary search trees.</li> </ul>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#solution","title":"Solution","text":"","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#approach-1-validate-range","title":"Approach 1: Validate Range","text":"<p>We can use either recursive or iterative method to check if the current node's value is within the valid range.</p> <p>For a binary search tree:</p> <ul> <li>Left subtree: all values &lt; current node's value</li> <li>Right subtree: all values &gt; current node's value</li> </ul> <p>So to update the valid range:</p> <ul> <li>Only update the <code>high</code> limit when going left</li> <li>Only update the <code>low</code> limit when going right</li> </ul> PythonPython - Iteration <pre><code>class Solution:\n    def isValidBST(self, root: Optional[TreeNode]) -&gt; bool:\n        return self.validate_subtree(root, float(\"-inf\"), float(\"inf\"))\n\n    def validate_subtree(self, node: Optional[TreeNode], low: float, high: float) -&gt; bool:\n        # Base case\n        if node is None:\n            return True\n\n        # Validate the root value\n        if not (low &lt; node.val &lt; high):\n            return False\n\n        # Recursively check left and right trees\n        return self.validate_subtree(node.left, low, node.val) and \\\n               self.validate_subtree(node.right, node.val, high)\n</code></pre> <pre><code>from collections import deque\nimport math\n\nclass Solution:\n    def isValidBST(self, root: Optional[TreeNode]) -&gt; bool:\n        if root is None:\n            return True\n\n        stack = deque([(root, -math.inf, math.inf)])\n        while stack:\n            node, low, high = stack.pop()\n            if not node:\n                continue\n\n            # Check if the current node's value is within the valid range\n            if node.val &lt;= low or node.val &gt;= high:\n                return False\n\n            # Push the left and right children onto the stack with updated bounds\n            # update upper bound when search left\n            # update lower bound when search right\n            stack.append((node.left, low, node.val))\n            stack.append((node.right, node.val, high))\n\n        return True\n</code></pre>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   We traverse each node once, so the time complexity is linear in terms of the number of   nodes.</li> <li> <p>Space complexity: \\(O(n)\\) </p> <ul> <li>For recursive approach, the space complexity is \\(O(h)\\), where \\(h\\) is the height of the tree. In the worst case, the tree can be skewed, leading to a space complexity of \\(O(n)\\).</li> <li>For iterative approach, the space complexity in the worst case is \\(O(n)\\) due to the stack used for DFS traversal. For a skewed tree below, stack can hold \\(n / 2\\) nodes.</li> </ul> <pre><code>2\n \\\n  6\n /  \\\n3    7\n    /  \\\n   4    8\n</code></pre> </li> </ul>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#approach-2-in-order-validation","title":"Approach 2: In-Order Validation","text":"<p>One key property of binary search trees is that in-order traversal of a BST yields a strictly increasing sequence of values.</p> <p>We can use this property to validate the BST by performing an in-order traversal and checking if the current node's value is greater than the previous node's value.</p> <p>In the recursive approach, we need to define class property <code>self.prev</code> to store the last visited node's value properly instead of passing <code>prev</code> as a parameter.</p> <ul> <li><code>self.prev</code> is updated and shared across recursive calls.</li> <li><code>prev</code> in parameter is passed by value. Each recursive call gets its own copy and the updated value doesn't pass to the next recursive call.</li> </ul> Difference Between Defining <code>self.prev</code> in <code>__init__</code> and <code>isValidBST</code> Location When is\u00a0<code>self.prev</code>\u00a0created? Scope When is it reset? <code>__init__</code> When the object is instantiated (e.g.\u00a0<code>sol = Solution()</code>) Available to all methods in the class Only reset if you explicitly do so <code>isValidBST</code> Each time\u00a0<code>isValidBST()</code>\u00a0is called Also available to other methods once created Always reset at the start of\u00a0<code>isValidBST</code> pythonpython - Iteration <pre><code>class Solution:\n    def isValidBST(self, root: Optional[TreeNode]) -&gt; bool:\n        self.prev = -math.inf  # Reset before each new validation\n        return self._inorder_validate(root)\n\n    def _inorder_validate(self, node: Optional[TreeNode]) -&gt; bool:\n        if node is None:\n            return True\n\n        if not self._inorder_validate(node.left):\n            return False\n\n        if node.val &lt;= self.prev:\n            return False\n\n        self.prev = node.val\n\n        return self._inorder_validate(node.right)\n</code></pre> <pre><code>from collections import deque\n\nclass Solution:\n    def isValidBST(self, root: Optional[TreeNode]) -&gt; bool:\n        prev_val = -math.inf\n        stack = deque()\n\n        node = root\n        while node or stack:\n            if node:  # Explore left subtree\n                stack.append(node)\n                node = node.left\n            else:  # Finish exploring left subtree and continue to right subtree\n                node = stack.pop()\n                if node.val &lt;= prev_val:\n                    return False\n                prev_val = node.val\n                node = node.right\n\n        return True\n</code></pre>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   We traverse each node once in both recursive and iterative approaches, so the time   complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\)   The recursive function stack depth in the recursive approach and stack size in the   iterative approach is determined by the height of the tree, \\(O(h)\\).<ul> <li>In the worst case (skewed tree), \\(h = n\\).</li> <li>In the best case (balanced tree), \\(h = \\log n\\). Therefore, the space complexity is \\(O(n)\\) in the worst case and \\(O(\\log n)\\) in the best case.</li> </ul> </li> </ul>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Validate Range (recursion or iteration) \\(O(n)\\) \\(O(n)\\) Approach - Inorder validation (recursion or iteration) \\(O(n)\\) \\(O(n)\\)","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0001-0099/lc0098-validate-binary-search-tree/#test","title":"Test","text":"","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/","title":"100. Same Tree","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 100: Given the roots of two binary trees <code>p</code> and <code>q</code>, write a function to check if they are the same or not.</p> <p>Two binary trees are considered the same if they are structurally identical, and the nodes have the same value.</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#clarification","title":"Clarification","text":"<ul> <li>Same tree: structurally identical and nodes have the same value</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#approach-1-recursion","title":"Approach 1: Recursion","text":"<p>We can use the same <code>isSameTree</code> function to do recursive function calls by checking</p> <ul> <li>if the current node values are equal</li> <li>if the left and right subtrees are the same.</li> </ul> <p>If both conditions are true, we can return <code>True</code>. Otherwise, we return <code>False</code>.</p> Python <pre><code>class Solution:\n    def isSameTree(self, p: Optional[TreeNode], q: Optional[TreeNode]) -&gt; bool:\n        # Base case: if both trees are empty, they are the same\n        if p is None and q is None:\n            return True\n\n        if p is None or q is None:\n            return False\n\n        if p.val != q.val:\n            return False\n\n        # Recursively check if left and right subtrees are the same\n        return self.isSameTree(p.left, q.left) and self.isSameTree(p.right, q.right)\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   We visit each node exactly once. The number of nodes is \\(n\\).</li> <li>Space complexity: \\(O(n)\\)   The space is used by the recursive function call stack. The number of recursive calls is   the height of the tree. In the worst case, the tree is linear and has the height of \\(n\\).   In the best case, the tree is balanced and has the height of \\(\\log n\\).   So the space complexity is \\(O(n)\\) in the worst case and \\(O(\\log n)\\) in the best case.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#approach-2-iteration","title":"Approach 2: Iteration","text":"<p>The problem can also be solved using Breadth-First Search (BFS) by using a queue to store the pairs of nodes from both trees. We will check if the nodes are the same and then add their left children pair and right children pair to the queue.</p> python <pre><code>from collections import deque\n\nclass Solution:\n    def isSameTree(self, p: Optional[TreeNode], q: Optional[TreeNode]) -&gt; bool:\n        queue = deque([(p, q)])\n\n        while queue:\n            node_p, node_q = queue.popleft()\n            if not self.check(node_p, node_q):\n                return False\n\n            if node_p:  # node_q is not None as well, otherwise, it will return in previous step\n                queue.append((node_p.left, node_q.left))\n                queue.append((node_p.right, node_q.right))\n\n        return True\n\n    def check(self, p: Optional[TreeNode], q: Optional[TreeNode]) -&gt; bool:\n        if p is None and q is None:\n            return True\n\n        if p is None or q is None:\n            return False\n\n        if p.val != q.val:\n            return False\n\n        return True\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   We visit each node exactly once. The number of nodes is \\(n\\).</li> <li>Space complexity: \\(O(n)\\)   The space is used by the queue to store the nodes. In the worst case, the queue will   store all nodes of one level. The number of nodes at most is \\(n/2\\) for a complete   binary tree.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Recursion \\(O(n)\\) \\(O(n)\\) Approach - Iteration \\(O(n)\\) \\(O(n)\\)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0100-same-tree/#test","title":"Test","text":"<ul> <li>Test two empty trees or one empty tree</li> <li>Test two trees with different structures</li> <li>Test two trees with different values</li> <li>Test two trees with the same structure and values</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/","title":"LC101. Symmetric Tree","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 101: Given the\u00a0<code>root</code> of a binary tree,\u00a0check whether it is a mirror of itself\u00a0(i.e., symmetric around its center).</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#clarification","title":"Clarification","text":"<ul> <li>Mirror definition:<ul> <li>symmetric around its center/root (values are symmetric).</li> <li>left subtree is a mirror reflection of the right subtree.</li> </ul> </li> <li>What to return for an empty root? Return true.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#approach-iteration","title":"Approach - Iteration","text":"<p>We can check mirroring by using two queues:</p> <ul> <li>left queue to store nodes in the left subtree with pushing order like left - &gt; right.</li> <li>right queue to store nodes in the right subtree with reversed pushing order (right -&gt; left).</li> </ul> <p>Then we can compare nodes one at a time from both queues. if any node is empty or values are not equal, the tree is not symmetric.</p> Python <pre><code>from collections import deque\n\n\nclass Solution:\n    def isSymmetric(self, root: Optional[TreeNode]) -&gt; bool:\n        left_queue = deque()\n        right_queue = deque()\n\n        if not root:\n            return False\n\n        left_queue.append(root.left)\n        right_queue.append(root.right)\n\n        while left_queue and right_queue:\n            left_size = len(left_queue)\n            right_size = len(right_queue)\n\n            if left_size != right_size:\n                return False\n\n            for _ in range(left_size):\n                left_node = left_queue.popleft()\n                right_node = right_queue.popleft()\n\n                if left_node is None and right_node is None:\n                    continue\n\n                if (\n                    left_node is None\n                    or right_node is None\n                    or (left_node.val != right_node.val)\n                ):\n                    return False\n\n                # For left queue, pushing order is left -&gt; right\n                left_queue.append(left_node.left)\n                left_queue.append(left_node.right)\n\n                # For right queue, reverse pushing order to right -&gt; left for symmetric comparison\n                right_queue.append(right_node.right)\n                right_queue.append(right_node.left)\n\n        return True\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)     Traverse the entire tree with \\(n\\) nodes.</li> <li>Space complexity: \\(O(n)\\)     The total size of two queues is the number of nodes in the last level. In the worst     case, there are \\(n / 2\\) nodes in the last level. Som the space complexity is \\(O(n)\\).</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#approach-2-recursion","title":"Approach 2 - Recursion","text":"<p>A binary tree is symmetric if the left subtree is a mirror reflection of the right subtree. Two trees are a mirror reflection of each other if:</p> <ol> <li>Their two roots have the same value.</li> <li>The right subtree of each tree is a mirror reflection of the left subtree of the other tree.</li> </ol> <p>We can use recursive method to check mirroring.</p> python <pre><code>class Solution:\n    def isSymmetric(self, root: Optional[TreeNode]) -&gt; bool:\n        return self.is_mirror(root, root)\n\n    def is_mirror(self, t1: Optional[TreeNode], t2: Optional[TreeNode]) -&gt; bool:\n        if t1 is None and t2 is None:\n            return True\n\n        if t1 is None or t2 is None:\n            return False\n\n        return (\n            t1.val == t2.val\n            and self.is_mirror(t1.left, t2.right)\n            and self.is_mirror(t1.right, t2.left)\n        )\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)     It traverses the entire input tree with \\(n\\) nodes in the worst case.</li> <li>Space complexity: \\(O(n)\\)   The space is used by recursive function call stack. The number of recursive class is   bounded by the height of the tree. In the worst case, the tree is linear and the   height is \\(O(n)\\).</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Iteration \\(O(n)\\) \\(O(n)\\) Approach - Recursion \\(O(n)\\) \\(O(n)\\)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0101-symmetric-tree/#test","title":"Test","text":"<ul> <li>Test empty root</li> <li>Tes simple case, root with same left and right and different left and right.</li> <li>Test simple case where root is symmetric</li> <li>Test simple case where root is not symmetric but have the same node values</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/","title":"LC102. Binary Tree Level Order Traversal","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 102: Given the root of a binary tree, return the level order traversal of its nodes' values. (i.e., from left to right, level by level).</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#clarification","title":"Clarification","text":"<ul> <li>level order traversal</li> <li>nodes' values</li> <li>what's the return value format?</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#approach-1-bfs","title":"Approach 1 - BFS","text":"<p>We can use breadth-first search (BFS) to traverse the tree level by level. Add values of each level to a list and append it to the result list. Remember to handle edge case: empty root.</p> Python <pre><code>from collections import deque\n\n\nclass Solution:\n    def levelOrder(self, root: Optional[TreeNode]) -&gt; List[List[int]]:\n        values = []\n        if not root:\n            return values\n\n        queue = deque([root])\n        while queue:\n            size = len(queue)\n            level_values = []\n            for _ in range(size):\n                curr_node = queue.popleft()\n                level_values.append(curr_node.val)\n                if curr_node.left:\n                    queue.append(curr_node.left)\n                if curr_node.right:\n                    queue.append(curr_node.right)\n            values.append(level_values)\n\n        return values\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)     Visit \\(n\\) nodes exact once.</li> <li>Space complexity: \\(O(n)\\) <ul> <li>queue size is changing but with the max size reached by storing all nodes in the last level. The last level contains \\(n / 2\\) nodes.</li> <li>return output contains \\(n\\) values, takes \\(O(n)\\) space.</li> <li>So the total time complexity is \\(O(n / 2) + O(n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#approach-2-dfs","title":"Approach 2: DFS","text":"<p>We can also use depth-first search (DFS) to traverse the tree by using a helper function. The helper function will take the current node and the current level as arguments. It will recursively traverse the tree and add the values of each level to corresponding position in the list. This approach ensures that we maintain the order of nodes at each level.</p> python <pre><code>class Solution:\n    def levelOrder(self, root: Optional[TreeNode]) -&gt; List[List[int]]:\n        results = []\n        self.levelHelper(root, 0, results)\n        return results\n\n    def levelHelper(self, node: Optional[TreeNode], height: int, results: List[List[int]]) -&gt; None:\n        # Base case\n        if node is None:\n            return\n\n        # Expand results for new level\n        if len(results) &lt;= height:\n            results.append([])\n\n        results[height].append(node.val)\n        self.levelHelper(node.left, height + 1, results)\n        self.levelHelper(node.right, height + 1, results)\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   The algorithm visits each node exactly once, so the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>Recursion stack space is \\(O(h)\\), where \\(h\\) is the height of the tree. In the worst case, the height of the tree can be \\(n\\) (for a skewed tree), so the space complexity is \\(O(n)\\).</li> <li>The output list <code>results</code> will contain \\(n\\) values, so the space complexity is \\(O(n)\\).</li> <li>So the total space complexity is \\(O(n) + O(h) = O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - BFS \\(O(n)\\) \\(O(n)\\) Approach 2 - DFS \\(O(n)\\) \\(O(n)\\)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0102-binary-tree-level-order-traversal/#test","title":"Test","text":"<ul> <li>Test empty tree</li> <li>Test single node tree</li> <li>Test two levels tree</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/","title":"LC104. Maximum Depth of Binary Tree","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 104: Given the\u00a0<code>root</code>\u00a0of a binary tree, return\u00a0its maximum depth.</p> <p>A binary tree's\u00a0maximum depth\u00a0is the number of nodes along the longest path from the root node down to the farthest leaf node.</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#clarification","title":"Clarification","text":"<ul> <li>maximum depth definition: number of nodes along the longest path</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#approach-recursion","title":"Approach - Recursion","text":"<p>We can find the maximum depth of the current node based on the maximum depth of left and right subtrees.</p> Python <pre><code>class Solution:\n    def maxDepth(self, root: Optional[TreeNode]) -&gt; int:\n        if not root:\n            return 0\n\n        left_depth = self.maxDepth(root.left)\n        right_depth = self.maxDepth(root.right)\n        return max(left_depth, right_depth) + 1\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)     Each node is visited once and thus the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\)     The function call stack goes as deep as the height of the tree. In the worst case,     the tree depth is \\(n\\) (e.g., each noe has only one left child node).</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#approach-2-bfs","title":"Approach 2 - BFS","text":"<p>The problem can be solved using breadth-first search by traversing the tree level by level. Each level corresponds to a depth in the tree. We increase the depth only when we finish processing all nodes at a given level.</p> python <pre><code>from collections import deque\n\n\nclass Solution:\n    def maxDepth(self, root: Optional[TreeNode]) -&gt; int:\n        queue = deque()\n        if root:\n            queue.append(root)\n\n        depth = 0\n        while queue:\n            size = len(queue)\n            for _ in range(size):\n                curr_node = queue.popleft()\n                if curr_node.left:\n                    queue.append(curr_node.left)\n                if curr_node.right:\n                    queue.append(curr_node.right)\n            depth += 1\n\n        return depth\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)     Each node is visited exactly once. So the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\)     The queue doesn't hold all nodes at once, but at its peak, it holds the     widest level of the tree, i.e., the last level. For a full binary tree, the     total depth is \\(h = \\log_2(n)\\) and the last level contains \\(n / 2\\) nodes. So the     space complexity is \\(O(n / 2) = O(n)\\).</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Recursion \\(O(n)\\) \\(O(n)\\) Approach - BFS \\(O(n)\\) \\(O(n)\\)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0104-maximum-depth-of-binary-tree/#test","title":"Test","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0105-construct-binary-tree-from-preorder-and-inorder-traversal/","title":"LC105. Construct Binary Tree from Preorder and Inorder Traversal","text":"","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0105-construct-binary-tree-from-preorder-and-inorder-traversal/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 105: Given two integer arrays\u00a0<code>preorder</code>\u00a0and\u00a0<code>inorder</code>\u00a0where\u00a0<code>preorder</code>\u00a0is the preorder traversal of a binary tree and\u00a0<code>inorder</code>\u00a0is the inorder traversal of the same tree, construct and return\u00a0the binary tree.</p>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0105-construct-binary-tree-from-preorder-and-inorder-traversal/#clarification","title":"Clarification","text":"<ul> <li>Return root node of binary tree?</li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0105-construct-binary-tree-from-preorder-and-inorder-traversal/#assumption","title":"Assumption","text":"<ul> <li>Both preorder and inorder lists are for the same tree.</li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0105-construct-binary-tree-from-preorder-and-inorder-traversal/#solution","title":"Solution","text":"","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0105-construct-binary-tree-from-preorder-and-inorder-traversal/#approach-optimized-recursion","title":"Approach - Optimized Recursion","text":"<p>We can follow the similar optimized recursion method from LC106 based on the following observations:</p> <ul> <li>In the preorder list, <code>[root, left subtree, right subtree]</code>, the root node is the first node.</li> <li>In the inorder list, <code>[left subtree, root, right subtree]</code>, the root node is in the middle.</li> </ul> <p>We can find the root easily from the preorder list. The root node splits the inorder list into left and right subtrees. We can recursively break down the lists into left subtree, right subtree, and root. Then link them from bottom up.</p> Python <pre><code>class Solution:\n    def __init__(self):\n        self.inorder_index_map = {}\n\n    def buildTree(self, preorder: List[int], inorder: List[int]) -&gt; Optional[TreeNode]:\n        self.inorder_index_map = {val: idx for idx, val in enumerate(inorder)}\n        return self.build(preorder, inorder, 0, len(preorder) - 1, 0, len(inorder) - 1)\n\n    def build(\n        self,\n        preorder: List[int],\n        inorder: List[int],\n        pre_left: int,\n        pre_right: int,\n        in_left: int,\n        in_right: int,\n    ) -&gt; Optional[TreeNode]:\n        # Base case\n        if pre_left &gt; pre_right or in_left &gt; in_right:\n            return None\n\n        # The first value of preorder list is the root\n        root_val = preorder[pre_left]\n        root = TreeNode(root_val)\n\n        # Find index of root in the inorder list\n        idx_inorder_root = self.inorder_index_map[root_val]\n        left_size = idx_inorder_root - in_left\n\n        # Recursively break down the lists in two left and right subtrees\n        root.left = self.build(\n            preorder,\n            inorder,\n            pre_left + 1,\n            pre_left + left_size,\n            in_left,\n            idx_inorder_root - 1,\n        )  # `pre_left + 1` to exclude the root\n        root.right = self.build(\n            preorder,\n            inorder,\n            pre_left + left_size + 1,\n            pre_right,\n            idx_inorder_root + 1,\n            in_right,\n        )\n\n        return root\n</code></pre>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0105-construct-binary-tree-from-preorder-and-inorder-traversal/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)<ul> <li>Building dictionary <code>inorder_index_map</code> takes \\(O(n)\\) time.</li> <li>Recursive calls takes \\(O(n)\\) since each node processed onces and take \\(O(1)\\) for each recursion.</li> <li>So the total time complexity is \\(O(n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\)<ul> <li>Recursive call stack takes \\(O(n)\\) in the worst case.</li> <li>The dictionary <code>inorder_index_map</code> takes \\(O(n)\\).</li> <li>So the total space complexity is \\(O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0105-construct-binary-tree-from-preorder-and-inorder-traversal/#test","title":"Test","text":"<ul> <li>Single-node tree (<code>[1]</code>)\u00a0\u2192 Should return\u00a0<code>TreeNode(1)</code>.</li> <li>right-skewed tree (<code>inorder == preorder</code>)\u00a0\u2192 Handles correctly.</li> <li>Left-skewed tree\u00a0\u2192 Works efficiently.</li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/","title":"LC106. Construct Binary Tre from Inorder and Postorder Traversal","text":"","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 106: Given two integer arrays\u00a0<code>inorder</code>\u00a0and\u00a0<code>postorder</code>\u00a0where\u00a0<code>inorder</code>\u00a0is the inorder traversal of a binary tree and\u00a0<code>postorder</code>\u00a0is the postorder traversal of the same tree, construct and return\u00a0the binary tree.</p>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#clarification","title":"Clarification","text":"<ul> <li>Use both inorder and postorder list to construct the binary tree.</li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#assumption","title":"Assumption","text":"<ul> <li>Inorder and postorder lists are from the same tree.</li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#solution","title":"Solution","text":"","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#approach-recursion","title":"Approach - Recursion","text":"<p>From observation</p> <ul> <li>In the preorder list, <code>[root, left subtree, right subtree]</code>, the root node is the first node.</li> <li>In the inorder list, <code>[left subtree, root, right subtree]</code>, the root node is in the middle.</li> <li>In the postorder list, <code>[left subtree, right subtree, root]</code>, the root is the last node.</li> </ul> <p>We can find the root easily from the preorder/postorder list. The root node splits the inorder list into left and right subtrees. Based on number of nodes in left and right subtrees, we can also split the preorder/postorder list into left and right subtrees.</p> <p>We can recursively break down the lists into left subtree, right subtree, and root. Then link them from bottom up.</p> Python <pre><code>class Solution:\n    def buildTree(self, inorder: List[int], postorder: List[int]) -&gt; Optional[TreeNode]:\n        # Base cases\n        if len(inorder) == 0 and len(postorder) == 0:\n            return None\n\n        if len(inorder) == 1 and len(postorder) == 1:\n            return TreeNode(inorder[0])\n\n        # Create root from the last element of postorder list (root value)\n        root_val = postorder[-1]\n        root = TreeNode(root_val)\n\n        # Based on the root, break down inorder list into left and right subtrees\n        idx_root_inorder = inorder.index(root_val)\n        inorder_left = inorder[0:idx_root_inorder]\n        inorder_right = inorder[idx_root_inorder + 1:]\n\n        # Based on the length of left subtree, break down the postorder list\n        postorder_left = postorder[0:len(inorder_left)]\n        postorder_right = postorder[len(inorder_left):-1]\n\n        # Recursively find the root of left and right subtrees\n        left_root = self.buildTree(inorder_left, postorder_left)\n        right_root = self.buildTree(inorder_right, postorder_right)\n\n        # Connect root with subtrees\n        root.left = left_root\n        root.right = right_root\n\n        return root\n</code></pre>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n^2)\\)<ul> <li>For each recursion<ul> <li>Search for the root index takes \\(O(n)\\).</li> <li>Slices the lists takes \\(O(k)\\), where \\(k\\) is the size of sub-list. In the worst case, either left or right sub-list may only reduce by \\(1\\) each recursion.</li> </ul> </li> <li>In the worst case, recursion may takes up to \\(n\\) times for a skewed tree.<ul> <li>Time complexity due to search is \\(O(n^2)\\).</li> <li>Time complexity due to slicing lists is \\(O(n) + O(n-1) + \\cdots + O(1) = O(n^2 / 2) = O(n^2)\\).</li> </ul> </li> <li>So the total time complexity is \\(O(n^2) + O(n^2 / 2) = O(n^2)\\)</li> </ul> </li> <li>Space complexity: \\(O(n^2)\\)<ul> <li>Recursive call stack takes \\(O(n)\\) space. The recursion depth is equal to the height of the tree. In the worst case, the height is \\(n\\).</li> <li>List slicing takes \\(O(n^2)\\) space. Each recursion call creates new slices of inorder and postorder lists, which takes \\(O(k)\\) space per level space. In the worst case, the size of \\(k\\) is reduced by 1 after each recursion. So the space complexity is \\(O(n) + O(n - 1) + \\cdots + O(1) = O(n^2 / 2)\\).</li> <li>So the total space complexity is \\(O(n^2) + O(n^2 / 2) = O(n^2)\\).</li> </ul> </li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#approach-2-optimized-recursion","title":"Approach 2 - Optimized Recursion","text":"<p>We can optimize the solution 1 by</p> <ul> <li>Uses a hashmap for quick lookup<ul> <li>A dictionary (<code>inorder_index_map</code>) stores the index of each node in <code>inorder</code> for \\(O(1)\\) lookups, eliminating the \\(O(n)\\) <code>.index</code> search in each recursion.</li> </ul> </li> <li>Avoids list slicking:<ul> <li>Instead of creating new lists of <code>inorder_left</code>, <code>inorder_right</code>, etc., we pass index ranges to <code>build</code> , reducing unnecessary time and space usage.</li> </ul> </li> </ul> python <pre><code>class Solution:\n    def __init__(self):\n        self.inorder_index_map = {}\n\n    def buildTree(self, inorder: List[int], postorder: List[int]) -&gt; Optional[TreeNode]:\n        self.inorder_index_map = {val: idx for idx, val in enumerate(inorder)}  # O(n) time and O(n) space\n        return self.build(inorder, postorder, 0, len(inorder) - 1, 0, len(postorder) - 1)\n\n    def build(self, inorder: list[int], postorder: list[int], in_left: int, in_right: int, post_left: int, post_right: int) -&gt; Optional[TreeNode]:\n        # Base cases (empty list)\n        if in_left &gt; in_right or post_left &gt; post_right:\n            return None\n\n        # Root value is the last element in postorder\n        root_val = postorder[post_right]\n        root = TreeNode(root_val)\n\n        # Get index of root in inorder list\n        idx_inorder_root = self.inorder_index_map[root_val]\n\n        # Number of nodes in left subtree\n        left_size = idx_inorder_root - in_left\n\n        # Recursively construct left and right subtrees\n        root.left = self.build(inorder, postorder, in_left, idx_inorder_root - 1, post_left, post_left + left_size - 1)\n        root.right = self.build(inorder, postorder, idx_inorder_root + 1, in_right, post_left + left_size, post_right - 1)  # pos_right - 1 to exclude the root in the end\n\n        return root\n</code></pre>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)<ul> <li>Building dictionary <code>inorder_index_map</code> takes \\(O(n)\\) time.</li> <li>Recursive calls takes \\(O(n)\\) since each node processed onces and take \\(O(1)\\) for each recursion.</li> <li>So the total time complexity is \\(O(n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\)<ul> <li>Recursive call stack takes \\(O(n)\\) in the worst case.</li> <li>The dictionary <code>inorder_index_map</code> takes \\(O(n)\\).</li> <li>So the total space complexity is \\(O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Recursion \\(O(n^2)\\) \\(O(n^2)\\) Approach - Optimized Recursion \\(O(n)\\) \\(O(n)\\)","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0106-construct-binary-tree-from-inorder-and-postorder-traversal/#test","title":"Test","text":"<ul> <li>Single-node tree (<code>[1]</code>)\u00a0\u2192 Should return\u00a0<code>TreeNode(1)</code>.</li> <li>Left-skewed tree (<code>inorder == postorder</code>)\u00a0\u2192 Handles correctly.</li> <li>Right-skewed tree\u00a0\u2192 Works efficiently.</li> </ul>","tags":["Binary Tree","Divide and Conquer"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/","title":"LC112. Path Sum","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 112: Given the\u00a0<code>root</code>\u00a0of a binary tree and an integer\u00a0<code>targetSum</code>, return\u00a0<code>true</code>\u00a0if the tree has a\u00a0root-to-leaf path such that adding up all the values along the path equals\u00a0<code>targetSum</code>.</p> <p>A\u00a0leaf\u00a0is a node with no children.</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#clarification","title":"Clarification","text":"<ul> <li>root-to-leaf not root-to-any-node</li> <li>leaf node definition: node with no children</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#approach-recursion","title":"Approach - Recursion","text":"<p>We can use the same <code>hasPathSum</code> function to do recursive function calls by subtracting <code>targetSum</code> from the current node value.</p> Python <pre><code>class Solution:\n    def hasPathSum(self, root: Optional[TreeNode], targetSum: int) -&gt; bool:\n        if root is None:  # include empty root, empty left node, or empty right node\n            return False\n\n        targetSum -= root.val\n        if root.left is None and root.right is None:  # check leaf node\n            return targetSum == 0\n\n        return self.hasPathSum(root.left, targetSum) or self.hasPathSum(root.right, targetSum)\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)     We visit each node exactly once. The number of nodes is \\(n\\).</li> <li>Space complexity: \\(O(n)\\)     The space is used by recursive function call stack. The number of recursive calls is     the height of the tree. In the worst case, the tree is linear and has the height of \\(n\\).</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#approach-2-iteration","title":"Approach 2 - Iteration","text":"<p>The problem can also be solved using Breadth-First Search (BFS) by using a queue store <code>(node, sum)</code> pairs.</p> python <pre><code>from collections import deque\n\n\nclass Solution:\n    def hasPathSum(self, root: Optional[TreeNode], targetSum: int) -&gt; bool:\n        return self._bfs(root, targetSum)\n\n    def _bfs(self, node: Optional[TreeNode], target_sum: int) -&gt; bool:\n        queue = deque()\n\n        if node:\n            queue.append((node, node.val))  # (node, sum)\n\n        while queue:\n            curr_node, curr_sum = queue.popleft()\n\n            if (\n                curr_node.left is None\n                and curr_node.right is None\n                and curr_sum == target_sum\n            ):\n                return True\n\n            if curr_node.left:\n                queue.append((curr_node.left, curr_sum + curr_node.left.val))\n\n            if curr_node.right:\n                queue.append((curr_node.right, curr_sum + curr_node.right.val))\n\n        return False\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)     In the worst case, it goes through all \\(n\\) nodes.</li> <li>Space complexity: \\(O(n)\\)     The largest queue size is the number of nodes in the last level, which could be     \\(n / 2\\) in the worst case.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Recursion \\(O(n)\\) \\(O(n)\\) Approach - Iteration \\(O(n)\\) \\(O(n)\\)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0112-path-sum/#test","title":"Test","text":"<ul> <li>Empty tree (<code>[]</code>) \u2192 Should return <code>False</code>.</li> <li>Single-node tree (<code>[1]</code>) with <code>targetSum == 1</code> \u2192 Should return <code>True</code>.</li> <li>Tree with no valid path \u2192 Should return <code>False</code>.</li> <li>Test normal case where target sum exists \u2192 Should return <code>True</code>.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/","title":"LC116. Populating Next Right Pointers in Each Node","text":"","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 116: You are given a\u00a0perfect binary tree\u00a0where all leaves are on the same level, and every parent has two children. The binary tree has the following definition:</p> <p>struct Node {   int val;   Node left;   Noderight;   Node *next; }</p> <p>Populate each next pointer to point to its next right node. If there is no next right node, the next pointer should be set to\u00a0<code>NULL</code>.</p> <p>Initially, all next pointers are set to\u00a0<code>NULL</code>.</p>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#clarification","title":"Clarification","text":"<ul> <li>Perfect binary tree</li> <li>What does it mean to populate each next pointer to point to its next right node?   binary tree already uses left and right. Update the next node to point to the right   node. If not exist, set it to Null</li> </ul>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#solution","title":"Solution","text":"","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#approach-1-level-order-traversal","title":"Approach 1: Level Order Traversal","text":"<p>We can use BFS to traverse nodes level by level by using a queue. For each level, pop the node and update its next node with the first node in the queue (using peek) and add its left and right nodes to the queue if exists. If no next node available, update the next with null.</p> Python <pre><code>class Solution:\n    def connect(self, root: 'Optional[Node]') -&gt; 'Optional[Node]':\n        if not root:\n            return root\n\n        queue = deque([root])\n\n        while queue:\n            size = len(queue)\n            for i in range(size):\n                node_i = queue.popleft()\n\n                # Update next node\n                if i &lt; size - 1:\n                    node_i.next = queue[0]\n\n                # Add left and right nodes to the queue\n                if node_i.left:\n                    queue.append(node_i.left)\n                if node_i.right:\n                    queue.append(node_i.right)\n\n        return root\n</code></pre>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Each node is processed exactly once. For processing each node, it takes \\(O(1)\\) time to   popping the node from the queue and establishing the next pointer.</li> <li>Space complexity: \\(O(n)\\)   Since it is a perfect binary tree which means the last level contains \\(n/2\\) nodes. So   the space complexity of the queue depends on the maximum number of nodes in a level,   i.e., the last level. So the time complexity is \\(O(n/2) = O(n)\\).</li> </ul>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#approach-2-use-established-next-pointers-in-upper-level","title":"Approach 2: Use established next pointers in upper level","text":"<p>Refer to detailed explanations in LC Editorial section.</p> <p>The main idea is when at level \\(k - 1\\), establishes the next pointers for level \\(k\\). Once done with connections , move to level \\(k\\) and do the same thing for \\(k + 1\\). Note that for level <code>0</code>, it only has one root node and the next pointer is already established.</p> <p>When traverse a particular level with nodes connected. Think of nodes on that level formulate a linked list with head on the leftmost node.</p> <p>When establish connections in the next level, there are two types of <code>next</code> pointer connections:</p> <ul> <li>connection between the two children of a given node.</li> </ul> <p></p> <ul> <li>connection between nodes which have a different parent.</li> </ul> <p></p> python <pre><code>class Solution:\n  def connect(self, root: 'Optional[Node]') -&gt; 'Optional[Node]':\n      if not root:\n          return root\n\n      leftmost = root\n\n      # It's done when reaching the final level\n      while leftmost.left:\n\n          # Establishing the corresponding links for the next level\n          head = leftmost\n          while head:\n              # Link left and right children nodes\n              head.left.next = head.right\n\n              # Link children nodes between two parent nodes\n              if head.next:\n                  head.right.next = head.next.left\n\n              head = head.next  # Move to next node on the same level\n\n          # Move to the next level\n          leftmost = leftmost.left\n\n      return root\n</code></pre>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   Similar to solution 1, it process \\(n\\) nodes exactly once.</li> <li>Space complexity: \\(O(1)\\)   No additional data structure used.</li> </ul>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Level Order Traversal \\(O(n)\\) \\(O(n)\\) Approach 2 - Use Established Next Connections \\(O(n)\\) \\(O(1)\\)","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0116-populating-next-right-pointers-in-each-node/#test","title":"Test","text":"","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/","title":"LC117. Populating Next Right Pointers in Each Node II","text":"","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 117: Given a binary tree</p> <pre><code>struct Node {\n  int val;\n  Node *left;\n  Node *right;\n  Node *next;\n}\n</code></pre> <p>Populate each next pointer to point to its next right node. If there is no next right node, the next pointer should be set to\u00a0<code>NULL</code>.</p> <p>Initially, all next pointers are set to\u00a0<code>NULL</code>.</p>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#clarification","title":"Clarification","text":"<ul> <li>Binary tree is not perfect and may miss left, right, or both nodes.</li> </ul>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#solution","title":"Solution","text":"","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#approach-1-level-order-traversal","title":"Approach 1: Level Order Traversal","text":"<p>The same level order traversal solution from LC116 can be applied here. No matter whether the binary tree is perfect or not.</p>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#approach-2-using-established-next-pointers-in-the-upper-level","title":"Approach 2: Using established next pointers in the upper level","text":"<p>We can use the same idea from LC116: Only move on to the next level when completing establishing the next pointers for the current level. We can use these next pointers to establish the connections for the next level.</p> <p>Since the tree is not perfect, we need to have some way to find the left most node of the next level. The <code>dummy</code> node usage from @davidtan1890 is a really smart way to store the left most node of the next level without using if/else conditions check.</p> pythonpython - no dummy <pre><code>class Solution:\n    def connect(self, root: 'Node') -&gt; 'Node':\n        if not root:\n            return None\n\n        dummy = Node(-1)  # dummy node, the next node stores the head of the next level\n        prev = dummy  # the previous node on the next level\n        curr = root  # current node of current level\n        while curr:\n            # Explore the current level first\n            # Check left child\n            if curr.left:\n                prev.next = curr.left\n                prev = prev.next\n            # Check right child\n            if curr.right:\n                prev.next = curr.right\n                prev = prev.next\n            # Move to the next node of the current level\n            curr = curr.next\n\n            # Move to the next level if reaching the end of the current level\n            if curr is None:\n                curr = dummy.next\n\n                # Reset dummy.next and prev to store for next level.\n                dummy.next = None\n                prev = dummy\n\n        return root\n</code></pre> <pre><code>class Solution:\n    def connect(self, root: 'Node') -&gt; 'Node':\n        if not root:\n            return None\n\n        left_most = None  # head of the next level\n        prev = None  # the leading node on the next level\n        curr = root  # current node of current level\n        while curr:\n            # Explore the current level first\n            # Check left child\n            if curr.left:\n                if prev:\n                    prev.next = curr.left\n                else:\n                    left_most = curr.left\n                prev = curr.left\n            # Check right child\n            if curr.right:\n                if prev:\n                    prev.next = curr.right\n                else:\n                    left_most = curr.right\n                prev = curr.right\n            # Move to the next node of the current level\n            curr = curr.next\n\n            # Move to the next level if reaching the end of the current level\n            if curr is None:\n                curr = left_most\n                left_most = None\n                prev = None\n\n        return root\n</code></pre>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)     Explore each node exactly once.</li> <li>Space complexity: \\(O(1)\\)     Just use limited number of variables.</li> </ul>","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Level Order Traversal \\(O(n)\\) \\(O(n)\\) Approach - Use Established Next Connections \\(O(n)\\) \\(O(1)\\)","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0117-populating-next-right-pointers-in-each-node-ii/#test","title":"Test","text":"","tags":["Binary Tree","Breadth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/","title":"118. Pascal's Triangle","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 118: Given an integer\u00a0<code>numRows</code>, return the first numRows of\u00a0Pascal's triangle.</p> <p>In\u00a0Pascal's triangle, each number is the sum of the two numbers directly above it as shown:</p> <p></p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#clarification","title":"Clarification","text":"<ul> <li>Definition of Pascal's Triangle.</li> <li>return empty list when <code>numRows</code> is 0 or negative?</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#solution","title":"Solution","text":"<p>Definition of Pascal's triangle:</p> <ul> <li><code>1</code> on both sides</li> <li><code>i</code>th row contains <code>i + 1</code> numbers</li> <li><code>f(i, j) = f(i - 1, j - 1) + f(i - 1, j)</code>, <code>1 &lt;= i &lt; n - 1</code>, excluding two ends</li> </ul> <p>assuming 0-based indexing.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#approach-1-iteration","title":"Approach 1: Iteration","text":"<p>Based on the property off Pascal's triangle, we can compute the current row based on the previous row. We can do it iteratively.</p> Python <pre><code>class Solution:\n    def generate(self, numRows: int) -&gt; List[List[int]]:\n        results = []\n\n        for i_row in range(numRows):\n            curr_row = [1] * (i_row + 1)  # initialize the current row with ones\n\n            # Update column from 1 to n - 2 excluding two ends 0 and n - 1\n            # This will naturally skip the 1st and 2nd rows.\n            for j in range(1, len(curr_row) - 1):\n                prev_row = results[i_row - 1]\n                for j_col in range(1, i_row):\n                    curr_row[j_col] = prev_row[j_col - 1] + prev_row[j_col]\n\n            results.append(curr_row)\n\n        return results\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n^2)\\)   There are nested-for loops: the outer loops runs \\(n\\) times while the inner loop   increases by row, from 1, 2, 3, ..., n. The total number of executions is   \\(1 + 2 + \\cdots + n = \\frac{n (n + 1)}{2}\\). So the time complexity is \\(O(n^2)\\).</li> <li>Space complexity: \\(O(n^2)\\) <ul> <li><code>prev_row</code> and <code>curr_row</code> take \\(O(n)\\) space.</li> <li>The result list takes \\(O(n^2)\\) space.</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#approach-2-recursion","title":"Approach 2: Recursion","text":"<p>We can also solve the problem using recursion. Recursively compute triangle with \\(k - 1\\) rows and add the current row after that.</p> python <pre><code>class Solution:\n    def generate(self, numRows: int) -&gt; List[List[int]]:\n        # Base case\n        if numRows &lt;= 0:\n            return []\n\n        if numRows == 1:\n            return [[1]]\n\n        triangle = self.generate(numRows - 1)\n        prev_row = triangle[-1]\n        curr_row = [1] * numRows\n        for j in range(1, numRows - 1):\n            curr_row[j] = prev_row[j - 1] + prev_row[j]\n\n        triangle.append(curr_row)\n\n        return triangle\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n^2)\\) <ul> <li>The recursion will takes \\(n\\) calls</li> <li>For each call, it will go through all row numbers. The row number is decreasing from n to 1.</li> <li>So the total execution is \\(n + n - 1 + \\cdots + 1 = \\frac{n (n + 1)}{2}\\).</li> </ul> </li> <li>Space complexity: \\(O(n^2)\\) <ul> <li>recursion function call stack stakes \\(O(n)\\) space.</li> <li><code>prev_row</code> and <code>curr_row</code> takes \\(O(n)\\) space.</li> <li>the result list takes \\(O(n^2)\\) space.</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Iteration \\(O(n^2)\\) \\(O(n^2)\\) Approach - Recursion \\(O(n^2)\\) \\(O(n^2)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0118-pascals-triangle/#test","title":"Test","text":"<ul> <li>Test simple cases where <code>numRows</code> is 1 or 2.</li> <li>Test normal cases with small number of rows.</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/","title":"LC119. Pascal's Triangle II","text":"","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 119: Given an integer\u00a0<code>rowIndex</code>, return the\u00a0<code>rowIndexth</code>\u00a0(0-indexed) row of the\u00a0Pascal's triangle.</p> <p>In\u00a0Pascal's triangle, each number is the sum of the two numbers directly above it as shown:</p> <p></p>","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#clarification","title":"Clarification","text":"","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#assumption","title":"Assumption","text":"","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#solution","title":"Solution","text":"","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#approach-1-math","title":"Approach 1 - Math","text":"<p>Each row (0-indexing) of Pascal's triangle is the binomial coefficients: \\(C(r, 0),\\; C(r, 1),\\; \\cdots,\\; C(r, r)\\), where \\(C(r, 0) = C(r, r) = 1\\) and \\(C(r, k) = \\frac{r!}{k! (r - k)!}\\).</p> <p>There are two main recurrence relation can be derived from \\(C(r, k)\\) equation:</p> <ol> <li>Between two rows: \\(C(r, k) = C(r - 1, k - 1) + C(r - 1, k)\\), i.e., Pascal's triangle</li> <li>Within a row: \\(C(r, k) = C(r, k - 1) \\frac{r - k + 1}{k}\\)</li> </ol> Derivation of between-row recurrence relation \\[\\begin{eqnarray}   C(r - 1, k - 1) + C(r - 1, k) &amp;=&amp; \\frac{(r - 1)!}{(k - 1)! (r - k)!} + \\frac{(r - 1)!}{k! (r - k - 1)!} \\\\   &amp;=&amp; \\frac{(r - 1)! k}{k! (r - k)!} + \\frac{(r - 1)! (r - k)}{k! (r - k)!} \\\\   &amp;=&amp; \\frac{r!}{k! (r - k)!} \\\\   &amp;=&amp; C(r, k) \\\\ \\end{eqnarray}\\] Derivation of within-a-row recurrence relation \\[\\begin{equation}   \\frac{C(r, k)}{C(r, k - 1)} = \\frac{\\frac{r!}{k! (r - k)!}}{\\frac{r!}{(k - 1)! (r - k + 1)!}} = \\frac{r - k + 1}{k} \\end{equation}\\] <p>We can use the 2nd recurrence elation within a row to directly compute consecutive binomial coefficients in the same row.</p> Python <pre><code>class Solution:\ndef getRow(self, rowIndex: int) -&gt; List[int]:\n   row = [1] * (rowIndex + 1)\n   for i in range(1, rowIndex):\n       row[i] = row[i - 1] * (rowIndex - i + 1) // i\n\n   return row\n</code></pre>","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Just use one for loop to compute row elements.</li> <li>Space complexity: \\(O(n)\\)   The result contains \\(n\\) elements for \\(n\\)-th row.</li> </ul>","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#approach-2-iteration","title":"Approach 2 - Iteration","text":"<p>The problem can be solved by iteratively computing from \\(0\\)th to \\(n\\)th row of Pascal's triangle by using the first recurrence relation shown above.</p> Python <pre><code>class Solution:\n  def getRow(self, rowIndex: int) -&gt; List[int]:\n     prev_row = [1]\n     for i_row in range(1, rowIndex + 1):\n           curr_row = [1] * (i_row + 1)\n           for j_col in range(1, i_row):\n              curr_row[j_col] = prev_row[j_col - 1] + prev_row[j_col]\n\n           prev_row = curr_row\n\n     return prev_row  # 1st row or prev_row == curr_row\n</code></pre>","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^2)\\)   Use two for-loops to go through each element of each row.</li> <li>Space complexity: \\(O(n)\\)   Stores two rows' elements.</li> </ul>","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#approach-2-recursion","title":"Approach 2 - Recursion","text":"<p>Based on the first recurrence relation, the problem can be solved by recursively call function itself to compute the row above until reach the base cases. The base cases are \\([1]\\) for \\(0\\)th row.</p> Python <pre><code>class Solution:\n  def getRow(self, rowIndex: int) -&gt; List[int]:\n     # Base case\n     if rowIndex == 0:\n           return [1]\n\n     curr_row = [1] * (rowIndex + 1)\n     prev_row = self.getRow(rowIndex - 1)\n     for j in range(1, rowIndex):\n           curr_row[j] = prev_row[j - 1] + prev_row[j]\n\n     return curr_row\n</code></pre>","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n^2)\\)   The function will be recursively calling \\(n\\) times and within each function there is a   for-loop to go through all elements for that row. Therefore, the time complexity is \\(O(n^2)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>Recursive function call stack takes \\(O(n)\\) space, since the depth will reach \\(n\\).</li> <li>Store current and previous rows takes \\(O(n)\\).</li> <li>So the total space complexity is \\(O(n) + O(n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Math \\(O(n)\\) \\(O(n)\\) Approach - Iteration \\(O(n^2)\\) \\(O(n)\\) Approach - Recursion \\(O(n^2)\\) \\(O(n)\\)","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0119-pascals-triangle-ii/#test","title":"Test","text":"","tags":["Array","Math","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/","title":"LC133. Clone Graph","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 133: Given a reference of a node in a\u00a0connected\u00a0undirected graph.</p> <p>Return a\u00a0deep copy\u00a0(clone) of the graph.</p> <p>Each node in the graph contains a value (<code>int</code>) and a list (<code>List[Node]</code>) of its neighbors.</p> <pre><code>class Node {\n    public int val;\n    public List&lt;Node&gt; neighbors;\n}\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#clarification","title":"Clarification","text":"<ul> <li>What does deep copy mean?</li> <li>The example of list just show neighbors of each node</li> <li>The actual function input is a node not a list</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#solution","title":"Solution","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#approach-dfs","title":"Approach - DFS","text":"<p>Copy the node while traversing the graph (either using depth-first search or breadth-first search). To prevent getting stuck in a cycle, we need to track the visited codes that have already been copied.</p> Python <pre><code>from typing import Optional\nclass Solution:\n    def __init__(self):\n        # Dictionary: key is the visited node and value is the clone node\n        # This helps to avoid cycle.\n        self.visited = {}\n\n    def cloneGraph(self, node: Optiona['Node']) -&gt; Optional['Node']:\n        if not node:\n            return None\n\n        return self.dfs(node)\n\n    def dfs(self, node: Optional['Node']) -&gt; Optional['Node']:\n        if node in self.visited:\n            return self.visited[node]\n\n        clone_node = Node(node.val)\n\n        if node.neighbors:\n            clone_node.neighbors = [] # chnage from None to [] to store neighbors\n            self.visited[node] = clone_node\n            clone_node.neighbors = [self.dfs(n) for n in node.neighbors]\n\n        return clone_node\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#complexity-analysis-of-dfs-approach","title":"Complexity Analysis of DFS Approach","text":"<ul> <li>Time complexity: \\(O(n + m)\\) where \\(n\\) is number of nodes (vertices) and \\(m\\) is a number of edges   When doing DFS, it will traverse all node and edges.  </li> <li>Space complexity: \\(O(n)\\)   The space usage consists of two parts: 1) <code>visited</code> hash map to store all node and clone nodes, which is \\(O(n)\\) and 2) recursion call stack \\(O(h)\\). So the space complexity is \\(O(n) + O(h) = O(n)\\)</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#approach2-bfs","title":"Approach2 - BFS","text":"<p>Similar to DFS method, we can use breadth-first search method to traverse the graph and make copies. Again, we need a way to track visited nodes.</p> python <pre><code>from collections import deque\nclass Solution:\n    def cloneGraph(self, node: Optional['Node']) -&gt; Optional['Node']:\n        if not node:\n            return None\n\n        # Dictionary to store the visited node\n        # key: node; value: clone node\n        visited = {}\n\n        queue = deque()\n        queue.append(node)\n        visited[node] = Node(node.val)\n\n        while queue:\n            current_node = queue.popleft()\n\n            for neighbor_node in current_node.neighbors:\n                if not visited[current_node].neighbors:\n                    visited[current_node].neighbors = []\n\n                if neighbor_node not in visited:\n                    queue.append(neighbor_node)\n                    visited[neighbor_node] = Node(neighbor_node.val)\n\n                visited[current_node].neighbors.append(visited[neighbor_node])\n\n        return visited[node]\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n + m)\\)  where \\(n\\) is a number of nodes (vertices) and \\(m\\) is a number of edges   It traverse all nodes and edges once to make clone. With visited, preventing from visiting nodes more than once.</li> <li>Space complexity: \\(O(n)\\)   The overall space is the combination of space occupied by <code>visited</code> dictionary, \\(O(n)\\), storing all nodes and space of queue, \\(O(w)\\), store nodes at one layer, i.e., width of the graph.</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - DFS \\(O(n + m)\\) \\(O(n)\\) Approach - BFS \\(O(n + m)\\) \\(O(n)\\)","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0133-clone-graph/#test","title":"Test","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/","title":"139. Word Break","text":"","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 139: Given a string\u00a0<code>s</code>\u00a0and a dictionary of strings\u00a0<code>wordDict</code>, return\u00a0<code>true</code>\u00a0if\u00a0<code>s</code>\u00a0can be segmented into a space-separated sequence of one or more dictionary words.</p> <p>Note\u00a0that the same word in the dictionary may be reused multiple times in the segmentation.</p>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#solution","title":"Solution","text":"","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#approach-1-breadth-first-search","title":"Approach 1: Breadth-First Search","text":"<p>The process of segmenting a string into a sequence of words can be modeled as a graph where</p> <ul> <li>each node represents a position (i.e., index) in the string. When reaching node with index <code>i</code>, it means <code>s[0:i]</code> (<code>i</code> is excluded) is successfully segmented into a sequence of valid words.</li> <li>each edge represents a word, <code>s[i:j]</code> from the dictionary, where <code>i</code> is index in parent node and <code>j</code> is index in a child node.</li> </ul> <p>We can use the BFS approach to explore all possible paths from the start index (<code>0</code>) to the end index of the string (<code>len(s)</code>). If we find a path that reaches the end of the string, we return <code>True</code>. If we exhaust all possible paths, we return <code>False</code>.</p> <pre><code>graph TD\n    p(\"0\")\n    c1(\"4\")\n    c2(\"3\")\n    c3(\"2\")\n    c11(\"8\")\n    c21(\"5\")\n    c211(\"8\")\n    p --leet--&gt; c1 --code--&gt; c11\n    p --lee--&gt; c2 --tc--&gt; c21 --\"ode\"--&gt; c211\n    p --le--&gt; c3\n    style c11 fill:green\n    style c211 fill:green</code></pre> Python <pre><code>from collections import deque\n\nclass Solution:\n    def wordBreak(self, s: str, wordDict: List[str]) -&gt; bool:\n        queue = deque([0])  # start index\n        seen = set()\n\n        while queue:\n            start =  queue.popleft()\n            if start == len(s):\n                return True\n\n            for word in wordDict:\n                end = start + len(word)\n                if end &gt; len(s) or end in seen:\n                    continue\n\n                if s[start:end] == word:\n                    queue.append(end)\n                    seen.add(end)\n\n        return False\n</code></pre>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\cdot k \\cdot m)\\) where \\(n\\) is the length of the string, \\(k\\) is the number of words in the dictionary, and \\(m\\) is the maximum length of the words.<ul> <li>In the worst case, we may visit each index of string <code>s</code> (i.e., each node) at most once, which is \\(O(n)\\).</li> <li>For each index (node),<ul> <li>try all <code>k</code> words,</li> <li>each word check costs \\(O(m)\\) due to string slicing <code>s[start:end]</code>.</li> </ul> </li> <li>The total cost is \\(O(n \\cdot k \\cdot m)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li><code>queue</code> holds at most \\(O(n)\\) indices.</li> <li><code>seen</code> holds at most \\(O(n)\\) indices.</li> <li>The total cost is \\(O(n) + O(n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#approach-2-top-down-dynamic-programming","title":"Approach 2: Top-Down Dynamic Programming","text":"<p>The problem can also be solved using a top-down dynamic programming approach with memoization.</p> <ul> <li>State: <code>dp[i]</code> is <code>True</code> if the substring <code>s[0:i]</code> (<code>i</code> is not included) can be segmented into a sequence of valid words.</li> <li>Transition: For each index <code>i</code>, we need to check two conditions:<ol> <li>If <code>s[j:i]</code> is a valid word in the dictionary, where <code>j</code> is any index from <code>0</code> to <code>i</code>.</li> <li>If <code>dp[j]</code> is <code>True</code>, meaning the substring <code>s[0:j]</code> can be segmented into valid words. So the transition can be expressed as: <code>dp[i] = any(s[i - len(word) : i] == word and dp[i - len(word)] for word in words)</code></li> </ol> </li> <li>Base Case: <code>dp[i] = True</code> for <code>i &lt;= 0</code> because we can build an empty string from no words.</li> </ul> python <pre><code>class Solution:\n    def wordBreak(self, s: str, wordDict: List[str]) -&gt; bool:\n        return self._wordBreak(s, tuple(wordDict), len(s))\n\n    @cache\n    def _wordBreak(self, s: str, words: Tuple[str], end: int) -&gt; bool:\n        if end &lt;= 0:\n            return True\n\n        for word in words:\n            if s[end - len(word) : end] == word and self._wordBreak(s, words, end - len(word)):\n                return True\n\n        return False\n</code></pre>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n \\cdot k \\cdot m)\\) <ul> <li>There are at most \\(n\\) states of <code>dp[i]</code> and we only calculate each state once due to memoization(\\(O(n)\\)).</li> <li>The input <code>wordDict</code> is converted to a tuple, which is immutable and can be used as a cache key, which is \\(O(k)\\)</li> <li>For each state,<ul> <li>try all <code>k</code> words,</li> <li>each word check costs \\(O(m)\\) due to string slicing <code>s[start:end]</code>.</li> </ul> </li> <li>The total cost is \\(O(k) + O(n \\cdot k \\cdot m) = O(n \\cdot k \\cdot m)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>The memoization cache stores at most \\(O(n)\\) states.</li> <li>The input <code>wordDict</code> is converted to a tuple, which takes \\(O(k)\\).</li> <li>The recursion stack can go up to \\(O(n)\\) deep.</li> <li>The total cost is \\(O(n) + O(k) + O(n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#approach-3-bottom-up-dynamic-programming","title":"Approach 3: Bottom-Up Dynamic Programming","text":"<p>The problem can also be solved using a bottom-up dynamic programming approach. We will use</p> <ul> <li>an array <code>dp</code> where <code>dp[i]</code> is <code>True</code> if the substring <code>s[0:i + 1]</code> (<code>i</code> is included but not <code>i + 1</code>) can be segmented into a sequence of valid words.</li> <li>the same recurrence relation <code>dp[i] = any(s[i - len(word) + 1 : i] == word and dp[i - len(word)] for word in words)</code></li> </ul> <p>Note that <code>dp[i]</code> is slightly different from the previous approaches. Here, <code>dp[i]</code> is <code>True</code> if the substring <code>s[0:i + 1]</code> can be segmented into valid words, while in the previous approaches, <code>dp[i]</code> is <code>True</code> if the substring <code>s[0:i]</code> can be segmented into valid words. Both approaches are equivalent. Just want to show different definitions of <code>dp[i]</code>.</p> python <pre><code>class Solution:\ndef wordBreak(self, s: str, wordDict: List[str]) -&gt; bool:\n    dp = [False] * len(s)\n    for i in range(len(s)):\n        for word in wordDict:\n            # Handle out of bounds case\n            if i &lt; len(word) - 1:\n                continue\n\n            if i == len(word) - 1 or dp[i - len(word)]:\n                if s[i - len(word) + 1 : i + 1] == word:\n                    dp[i] = True\n                    break\n\n    return dp[-1]\n</code></pre>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n \\cdot k \\cdot m))\\)   Similar to previous approaches, we calculate \\(O(n)\\) states in total and each state   takes \\(O(m \\cdot k)\\) to compute.</li> <li>Space complexity: \\(O(n)\\)   We use an array <code>dp</code> of size \\(O(n)\\) to store the results of subproblems.</li> </ul>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - BFS \\(O(n \\cdot k \\cdot m)\\) \\(O(n)\\) Approach - Top-Down Dynamic Programming \\(O(n \\cdot k \\cdot m)\\) \\(O(n)\\) Approach - Bottom-Up Dynamic Programming \\(O(n \\cdot k \\cdot m)\\) \\(O(n)\\)","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0139-word-break/#test","title":"Test","text":"<ul> <li>Test empty string and empty dictionary: <code>wordBreak(\"\", [])</code> should return <code>True</code>.</li> <li>Test single character string and single character dictionary: <code>wordBreak(\"a\", [\"a\"])</code> should return <code>True</code>.</li> <li>Test single character string and empty dictionary: <code>wordBreak(\"a\", [])</code> should return <code>False</code>.</li> <li>Test string that can be segmented: <code>wordBreak(\"leetcode\", [\"leet\", \"code\"])</code> should return <code>True</code>.</li> <li>Test string that cannot be segmented: <code>wordBreak(\"leetcode\", [\"leet\", \"c\"])</code> should return <code>False</code>.</li> </ul>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0141-linked-list-cycle/","title":"LC141. Linked List Cycle","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0141-linked-list-cycle/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 141: Given\u00a0<code>head</code>, the head of a linked list, determine if the linked list has a cycle in it.</p> <p>There is a cycle in a linked list if there is some node in the list that can be reached again by continuously following the\u00a0<code>next</code>\u00a0pointer. Internally,\u00a0<code>pos</code>\u00a0is used to denote the index of the node that\u00a0tail's\u00a0<code>next</code>\u00a0pointer is connected to.\u00a0Note that\u00a0<code>pos</code>\u00a0is not passed as a parameter.</p> <p>Return\u00a0<code>true</code> if there is a cycle in the linked list. Otherwise, return\u00a0<code>false</code>.</p>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0141-linked-list-cycle/#clarification","title":"Clarification","text":"<ul> <li>Definition of a cycle</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0141-linked-list-cycle/#assumption","title":"Assumption","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0141-linked-list-cycle/#solution","title":"Solution","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0141-linked-list-cycle/#approach-slowfast-pointers","title":"Approach - slow/fast pointers","text":"<p>The problem can be solved using slow/fast pointers: - slow pointer moves one step every execution - fast pointer moves two steps every execution If there is a cycle, the two pointers will meet.</p> <p>Mathematically, we are looking for \\((v_{fast} - v_{slow}) * \\text{n_steps} = \\text{length} * n\\), where </p> <ul> <li>\\(v_{fast}\\) is the speed of fast pointer</li> <li>\\(v_{slow}\\) is the speed of slow pointer</li> <li><code>n_steps</code> is the number of steps taken before meet</li> <li><code>length</code> is the length of the linked list</li> <li><code>n</code> is integer. We can always find a <code>n</code> to satisfy the equation, e.g., \\(n = v_{fast} - v_{slow}\\).</li> </ul> Python <pre><code>class Solution:\n    def hasCycle(self, head: Optional[ListNode]) -&gt; bool:\n        if head is None or head.next is None:\n            return False\n\n        slow, fast = head, head\n\n        while fast and fast.next:\n            slow = slow.next\n            fast = fast.next.next\n\n            if slow == fast:\n                return True\n\n        return False\n</code></pre>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0141-linked-list-cycle/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It has go through the whole list at least once to let two pointers meet.</li> <li>Space complexity: \\(O(1)\\)     Use two pointers.</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0141-linked-list-cycle/#test","title":"Test","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0142-linked-list-cycle-ii/","title":"LC142. Linked List Cycle II","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0142-linked-list-cycle-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 142: Given the\u00a0<code>head</code>\u00a0of a linked list, return\u00a0the node where the cycle begins. If there is no cycle, return <code>null</code>.</p> <p>There is a cycle in a linked list if there is some node in the list that can be reached again by continuously following the\u00a0<code>next</code>\u00a0pointer. Internally,\u00a0<code>pos</code>\u00a0is used to denote the index of the node that tail's\u00a0<code>next</code>\u00a0pointer is connected to (0-indexed). It is\u00a0<code>-1</code>\u00a0if there is no cycle.\u00a0Note that <code>pos</code> is not passed as a parameter.</p> <p>Do not modify\u00a0the linked list.</p>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0142-linked-list-cycle-ii/#clarification","title":"Clarification","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0142-linked-list-cycle-ii/#assumption","title":"Assumption","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0142-linked-list-cycle-ii/#solution","title":"Solution","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0142-linked-list-cycle-ii/#approach-slowfast-pointers","title":"Approach - Slow/fast pointers","text":"<p>The problem can be solved by using the Floyd\u2019s cycle detection method to find the meet point, which consists of two phases:</p> <ul> <li>Phase I: Detect a cycle and find the meeting point if there is a cycle Use a slow pointer that moves 1 step a time and a fast pointer that moves 2 steps a time to detect a cycle and find the meeting point if there is a cycle. Follow the approach in LC141 Linked List Cycle</li> <li> <p>Phase II: If there is a cycle, return the entry location of the cycle For analysis, define the following notations:</p> <ul> <li>\\(l_1\\): the distance (i.e., number of nodes) between the head and the entry point of the cycle</li> <li>\\(l_2\\): the distance (i.e., number of nodes) between the entry point and the meeting point in the cycle</li> <li>\\(c\\): length of the cycle</li> <li>\\(n\\): number of cycles the fast pointer moves (\\(n &gt;= 1\\))</li> </ul> <pre><code>flowchart LR\n    head((H))\n    entry((E))\n    meet(((M)))\n\n    head --l1--&gt; entry\n    entry --l2--&gt; meet\n    meet --c - l2--&gt; entry</code></pre> <p>When slow and fast pointers meet,</p> <ul> <li>the travel distance of the slow pointer is \\(l_1 + l_2\\)</li> <li>the travel distance of the fast pointer is \\(l_1 + l_2 + nc\\)</li> <li>since the fast pointer moves twice fast as the slow pointer, the travel distance of the fast pointer is twice as the slow pointer,</li> </ul> \\[ \\begin{eqnarray}  2(l_1 + l_2) &amp;=&amp; l_1 + l_2 + nc \\\\  l_1 + l_2 &amp;=&amp; nc \\\\ l_1 &amp;=&amp; (n\u22121)c+(c\u2212l_2)  \\end{eqnarray} \\] <p>The above equation implies that the distance, \\(l_1\\), between the head and entry point of the cycle is equal to the distance, \\(c - l_2\\), between the meeting point and entry point along the direction of the forward movement. So we can have two pointers with the same speed (1 step a time). One starts from the head and the other starts from the meeting points. When these two pointers meet, the meeting node is where the cycle begins.</p> </li> </ul> PythonC++ <pre><code>class Solution:\n    def detectCycle(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        if head is None or head.next is None:\n            return None\n\n        slow = head\n        fast = head\n        entry = head\n\n        while fast.next and fast.next.next:\n            slow = slow.next\n            fast = fast.next.next\n\n            if slow == fast:  # there is a cycle\n                while slow != entry:  # find entry location when slow == entry\n                    slow = slow.next\n                    entry = entry.next\n\n                return entry\n</code></pre> <pre><code>class Solution {\npublic:\n    ListNode *detectCycle(ListNode *head) {\n        if (head == nullptr || head-&gt;next == nullptr) return nullptr;\n\n        ListNode* slow = head;\n        ListNode* fast = head;\n        ListNode* entry = head;\n\n        while (fast != nullptr &amp;&amp; fast-&gt;next != nullptr) {\n            slow = slow-&gt;next;\n            fast = fast-&gt;next-&gt;next;\n\n            // Detect a cycle and find the entry point\n            if (slow == fast) {\n                while (entry != slow) {\n                    entry = entry-&gt;next;\n                    slow = slow-&gt;next;\n                }\n\n                return entry;\n            }\n        }\n\n        return nullptr;\n    }\n};\n</code></pre>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0142-linked-list-cycle-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Denotes n as the total number of nodes in the linked list. For time complexity, analyze the following two cases separately:     \u2013 List has no cycle: The fast pointer reaches the end first. Since it moves two steps a time, the time complexity is O(n/2).     \u2013 List has a cycle: For Phase I, it takes l1 + l2 iterations to find the meet point. For Phase II, it takes c \u2212 l2 iterations to find the entry point of the cycle. So the total number of iterations is l1 + l2 + c \u2212 l2 = n.</li> <li>Space complexity: \\(O(1)\\)     Only use several pointers.</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0142-linked-list-cycle-ii/#test","title":"Test","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/","title":"LC143. Reorder List","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 143: You are given the head of a singly linked-list. The list can be represented as:</p> <p>L0 \u2192 L1 \u2192 \u2026 \u2192 Ln - 1 \u2192 Ln</p> <p>Reorder the list to be on the following form:</p> <p>L0 \u2192 Ln \u2192 L1 \u2192 Ln - 1 \u2192 L2 \u2192 Ln - 2 \u2192 \u2026</p> <p>You may not modify the values in the list's nodes. Only nodes themselves may be changed.</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#clarification","title":"Clarification","text":"<ul> <li>Re-order the node not the value</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#approach-stack","title":"Approach - Stack","text":"<p>Use stack to store nodes. Then use one pointer, <code>p1</code>, go from head, and the other pointer, <code>p2</code>, go from end of nodes by popping from stack. Reorder the list, use <code>p1</code> and <code>p2</code>. When <code>p1 == p2</code> or <code>p1.next = p2</code>, finish the reordering</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def reorderList(self, head: Optional[ListNode]) -&gt; None:\n        \"\"\"\n        Do not return anything, modify head in-place instead.\n        \"\"\"\n        stack = deque()\n\n        slow = head\n        fast = head\n        while fast and fast.next:\n            stack.append(slow)\n            slow = slow.next\n            fast = fast.next.next\n\n        front = head\n        while front and stack:\n            tail = stack.pop()\n\n            if front is tail:\n                front.next = None\n                break\n            elif front.next is tail:\n                tail.next = None\n                break\n            else:\n                nxt = front.next\n                front.next = tail\n                tail.next = nxt\n                front = nxt\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It takes \\(n\\) steps to store nodes in stack and \\(n/2\\) steps to reorder the list. So the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\)     Use stack to store \\(n\\) nodes.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#approach-split-reverse-and-merge","title":"Approach - Split, Reverse and Merge","text":"<p>The problem can be solved by the following steps: 1. Split the list by two halves 2. Reverse the 2nd half 3. Merge the 1st half and the reversed 2nd half by reordering</p> PythonJava <pre><code>class Solution:\n    def reorderList(self, head: Optional[ListNode]) -&gt; None:\n        \"\"\"\n        Do not return anything, modify head in-place instead.\n        \"\"\"\n\n        if head is None or head.next is None or head.next.next is None:\n            return\n\n        head_2ndHalf = self.splitListByHalf(head)\n\n        head_2ndHalf = self.reverseList(head_2ndHalf)\n\n        self.mergeList(head, head_2ndHalf)\n\n    def splitListByHalf(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        \"\"\"\n        Split the list by half and return the head of 2nd half.\n        The 1st half of list will end with None\n        \"\"\"\n\n        slow = head\n        fast = head\n        while fast and fast.next:\n            prev = slow\n            slow = slow.next\n            fast = fast.next.next\n\n        prev.next = None # 1st half of list end with None\n        return slow\n\n    def reverseList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        prev = None\n        curr = head\n\n        while curr:\n            nxt = curr.next\n            curr.next = prev\n            prev = curr\n            curr = nxt\n\n        return prev\n\n    def mergeList(self, head1: Optional[ListNode], head2: Optional[ListNode]) -&gt; None:\n        p1 = head1\n        p2 = head2\n\n        while p1 and p2:\n            nxt1 = p1.next\n            nxt2 = p2.next\n            p1.next = p2\n            if nxt1:\n                p2.next = nxt1\n            p1 = nxt1\n            p2 = nxt2\n</code></pre> <pre><code>class Solution {\n    public void reorderList(ListNode head) {\n        // If empty, 1 or 2 nodes, no need to reorder and return\n        if (head == null || head.next == null || head.next.next == null) return;\n\n        ListNode h2 = splitListByHalf(head);\n\n        // Reverse the 2nd half\n        ListNode l2 = reverseList(h2);\n\n        mergeList(head, l2);\n\n    }\n\n    private ListNode splitListByHalf(ListNode head) {\n        ListNode slow = head;\n        ListNode fast = head;\n        ListNode prev = head;\n\n        // Find the start of 2nd half use a slow and fast pointers\n        // After while loop, slow is the start node of the 2nd half\n        while (fast != null &amp;&amp; fast.next != null) {\n            prev = slow;\n            slow = slow.next;\n            fast = fast.next.next;\n        }\n        prev.next = null; // the end node of the first half point to null\n        return slow;\n    }\n\n    private ListNode reverseList(ListNode head) {\n        ListNode prev = null;\n        ListNode curr = head;\n        ListNode next;\n\n        while (curr != null) {\n            next = curr.next;\n            curr.next = prev;\n            prev = curr;\n            curr = next;\n        }\n\n        return prev;\n    }\n\n    private void mergeList(ListNode l1, ListNode l2) {\n        // Pairing\n        // number of nodes in 2nd half == number of nodes in 1st half (even number nodes)\n        // number of nodes in 2nd half == number of nodes in 1st half + 1 (odd number nodes)\n        ListNode p1 = l1;\n        ListNode p2 = l2;\n        ListNode n1;  // hold next node of the first half\n        ListNode n2;  // hold next node of the 2nd half\n        while (p1 != null) {\n            n1 = p1.next;\n            n2 = p2.next;\n            p1.next = p2;\n            if (n1 != null) p2.next = n1;\n            p1 = n1;\n            p2 = n2;\n        }\n\n    }\n}\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It takes \\(n/2\\) steps to split the list, \\(n/2\\) steps to reverse the list, and \\(n/2\\) steps to merge the list. So the total steps are \\(3n/2\\) and time complexity is \\(O(n)\\)</li> <li>Space complexity: \\(O(1)\\)     Just use several pointers</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Stack \\(O(n)\\) \\(O(n)\\) Approach - Split, reverse, merge \\(O(n)\\) \\(O(1)\\)","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0143-reorder-list/#test","title":"Test","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/","title":"LC144. Binary Tree Preorder Traversal","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 144: Given the\u00a0<code>root</code>\u00a0of a binary tree, return\u00a0the preorder traversal of its nodes' values.</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#approach-recursion","title":"Approach - Recursion","text":"<p>We can recursively traverse the tree in pre-order by defining a new helper function <code>preorder</code>. In the helper function,</p> <pre><code>values.append(root.val)  # visit root/parent node\npreorder(root.left, values)  # recursively traverse the left subtree\npreorder(root.right, values)  # recursively traverse the right subtree\n</code></pre> Python <pre><code>class Solution:\n    def preorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        value_list = []\n        self.preorder(root, value_list)\n        return value_list\n\n    def preorder(self, root: Optional[TreeNode],\n            value_list: List[int]) -&gt; None:\n        if root is None:\n            return\n\n        value_list.append(root.val)\n        self.preorder(root.left, value_list)\n        self.preorder(root.right, value_list)\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)     The algorithm will visit all nodes exact once via recursive function call and     therefore the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>Recursive function call takes \\(O(h)\\) space for the call stack. The \\(h\\) is the height of the binary tree, which could be the total number of nodes \\(n\\) in the worst case.</li> <li>The return list takes \\(O(n)\\) space to save all node values.</li> <li>The total space complexity is \\(O(n) = O(h) + O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#approach-2-iteration","title":"Approach 2 - Iteration","text":"<p>We can also iteratively traverse the tree, traverse the root and left first and use stack to store right nodes that will be visited later.</p> python <pre><code>class Solution:\n    def preorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        values = []\n        stack = deque()\n\n        curr_node = root\n        while curr_node or stack:\n            if curr_node:\n                values.append(curr_node.val)\n                stack.append(curr_node)  # To return the root later.\n                curr_node = curr_node.left\n            else:\n                curr_node = stack.pop()\n                curr_node = curr_node.right\n\n        return values\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)     Each node (total \\(n\\) nodes) is pushed once to and popped once from the stack. So the     time complexity is \\(O(2n) = O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>The stack needs to store the right nodes which could be \\(n\\) in the worst case.</li> <li>The return list takes \\(O(n)\\) space to save all node values.</li> <li>The total space complexity is \\(O(n) = O(n) + O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#approach-3-morris-traversal","title":"Approach 3 - Morris Traversal","text":"<p>We can use Morris Traversal to visit nodes by using temporary links instead of using recursion and stack. It modifies the tree temporarily. The general idea is to</p> <ul> <li>Before exploring the left tree, find the rightmost node in the left tree. That's also the last node to visit in the left tree.</li> <li>Establish a temporary link between the rightmost node and the current node. So it can come back after exploring the left tree.</li> <li>Then explore the left tree (use similar approach). When it comes back to the current node with the temporary link, it indicates the left sub-tree has visited.</li> </ul> python <pre><code>class Solution:\n    def preorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        output = []\n        curr_node = root\n        while curr_node:\n            if curr_node.left:\n                # (2)\n                predecessor = curr_node.left\n                while predecessor.right and predecessor.right is not curr_node:\n                    predecessor = predecessor.right\n\n                # Two conditions out of while loops\n                if not predecessor.right:  # (3)\n                    output.append(curr_node.val)  # (4)\n                    predecessor.right = curr_node  # (5)\n                    curr_node = curr_node.left\n                else:  # (6)\n                    predecessor.right = None  # (7)\n                    curr_node = curr_node.right\n            else:  # (1)\n                output.append(curr_node.val)\n                curr_node = curr_node.right\n\n        return output\n</code></pre> <ol> <li>Left is None then add node value to output and go to right since no left sub-tree to visit.</li> <li>Find predecessor of the current node, the rightmost node of the left sub-tree.</li> <li>Condition 1: <code>predecessor.right</code> is <code>None</code>. The left sub-tree is not explored.</li> <li>This is the root node of a sub-tree. For preorder traversal, add the root node first.</li> <li>Establish a temporary link from predecessor to current.</li> <li>Condition 2: <code>predecessor.right</code> is the <code>curr_node</code>, coming back to the current node from the predecessor. This indicate the left sub-tree has been visited.</li> <li>Remove the temporary link.</li> </ol>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n)\\)     We visit each node twice, one for establishing link and one for removing. Therefore     the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>Visit nodes taking \\(O(1)\\) space.</li> <li>The return list takes \\(O(n)\\) space to save all node values.</li> <li>The total space complexity is \\(O(n) = O(1) + O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity (Overall) Space Complexity (Visit) Approach - Recursion \\(O(n)\\) \\(O(n)\\) $O(n) Approach - Iteration \\(O(n)\\) \\(O(n)\\) $O(n) Approach - Morris \\(O(n)\\) \\(O(n)\\) $O(1)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#test","title":"Test","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0144-binary-tree-preorder-traversal/#references","title":"References","text":"<ul> <li>Morris Inorder Tree Traversal - Tushar Roy Youtube Channel</li> <li>Tree traversal - wiki</li> <li>Binary Tree - My Notes</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/","title":"LC144. Binary Tree Postorder Traversal","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 144: Given the\u00a0<code>root</code>\u00a0of a binary tree, return\u00a0the postorder traversal of its nodes' values.</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#approach-recursion","title":"Approach - Recursion","text":"<p>We can recursively traverse the tree in post-order by defining a new helper function <code>postorder</code>. In the helper function,</p> <pre><code>postorder(root.left, values)  # recursively traverse the left subtree\npostorder(root.right, values)  # recursively traverse the right subtree\nvalues.append(root.val)  # visit root/parent node\n</code></pre> Python <pre><code>class Solution:\n    def postorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        values = []\n        self.postorder(root, values)\n        return values\n\n    def postorder(self, root: Optional[TreeNode], values: list[int]) -&gt; None:\n        if root is None:\n            return\n\n        self.postorder(root.left, values)\n        self.postorder(root.right,values)\n        values.append(root.val)\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)     The algorithm will visit all nodes exact once via recursive function call and     therefore the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>Recursive function call takes \\(O(h)\\) space for the call stack. The \\(h\\) is the height of the binary tree, which could be the total number of nodes \\(n\\) in the worst case.</li> <li>The return list takes \\(O(n)\\) space to save all node values.</li> <li>The total space complexity is \\(O(n) = O(h) + O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#approach-2-iteration-modified-preorder-traversal","title":"Approach 2 - Iteration (Modified Preorder Traversal)","text":"<p>The preorder traversal visits nodes in order of <code>root -&gt; left subtree -&gt; right subtree</code>. We can modify the order to <code>root -&gt; right subtree -&gt; left subtree</code>. After traversing the entire tree, we can reverse the result list to get the correct postorder sequences <code>left subtree -&gt; right subtree -&gt; root</code>.</p> python <pre><code>class Solution:\n    def postorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        values = []\n        stack = deque()\n\n        curr_node = root\n        while curr_node or stack:\n            if curr_node:\n                values.append(curr_node.val)\n                stack.append(curr_node)\n                curr_node = curr_node.right  # (1)\n            else:\n                curr_node = stack.pop()\n                curr_node = curr_node.left  # (2)\n\n        return values[::-1]  # (3)\n</code></pre> <ol> <li>Change preorder order to search the right subtree first instead of the left subtree.</li> <li>Different from preorder, move to left subtree.</li> <li>Reverse the result list to get the correct postorder sequence.</li> </ol>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\) <ul> <li>Each node (total \\(n\\) nodes) is pushed once to and popped once from the stack. So the time complexity of traversal is \\(O(2n) = O(n)\\)</li> <li>Reverse the result takes \\(O(n)\\) time.</li> <li>So the total time complexity is \\(O(n) = O(n) + O(n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>The stack needs to store the right nodes which could be \\(n\\) in the worst case.</li> <li>The return list takes \\(O(n)\\) space to save all node values.</li> <li>The total space complexity is \\(O(n) = O(n) + O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#approach-3-iteration","title":"Approach 3 - Iteration","text":"<p>The preorder traversal visits nodes in order of <code>root -&gt; left subtree -&gt; right subtree</code>. We can modify the order to <code>root -&gt; right subtree -&gt; left subtree</code>. After traversing the entire tree, we can reverse the result list to get the correct postorder sequences <code>left subtree -&gt; right subtree -&gt; root</code>.</p> python <pre><code>class Solution:\n    def postorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n        values = []\n        stack = deque()\n\n        last_visited = None  # Track the previously processed node\n        curr_node = root\n        while curr_node or stack:\n            if curr_node:  # (1)\n                stack.append(curr_node)\n                curr_node = curr_node.left\n            else:\n                peek = stack[-1]  # (2)\n                if peek.right is None or peek.right == last_visited:  # (3)\n                    values.append(peek.val)\n                    last_visited = stack.pop()  # (4)\n                else:  # (5)\n                    curr_node = peek.right\n\n        return values\n</code></pre> <ol> <li>Explore the left subtree first.</li> <li>Get the top node from the stack.</li> <li>Append root value when no right child or the right subtree is visited.</li> <li>Both its left and right children (if any) are already processed. Mark it as visited so we don't visit it again.</li> <li>Explore the right subtree.</li> </ol>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n)\\)     Each node (total \\(n\\) nodes) is pushed once to and popped once from the stack. So     the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>The stack needs to store the right nodes which could be \\(n\\) in the worst case.</li> <li>The return list takes \\(O(n)\\) space to save all node values.</li> <li>The total space complexity is \\(O(n) = O(n) + O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#approach-4-morris-traversal","title":"Approach 4 - Morris Traversal","text":"<p>We can use Morris traversal similar to what used in preorder traversal but with two main changes:</p> <ul> <li>Create a dummy root to ensure the root node is processed.<ul> <li>In postorder traversal, the root is processed last.</li> <li>In Morris traversal, the node is processed when removing the temporary link from its predecessor but the real root has no predecessor.</li> </ul> </li> <li>Need to reverse the path before appending values.<ul> <li>Morris traversal ensures we visit the left subtree before processing the root and right.</li> <li>When collecting the right subtree, Morris traversal naturally returns the right subtree in <code>root -&gt; right</code> order.</li> <li>So need to reversing the collected right subtree order to <code>right -&gt; root</code>. Since <code>left</code> is added early, the proper post traversal order, <code>left -&gt; right -&gt; root</code>, is maintained.</li> </ul> </li> </ul> <p>For example, after building links and come back to node 1, <code>[2, 5, 7]</code> is on the left path and needed to be reversed. Since adding dummy node, the root 1 is included in the left path <code>[1, 3, 8, 9]</code>.</p> <pre><code>graph TD\n    dummy --&gt; 1\n    1 --&gt; 2\n    1 --&gt; 3\n    2 --&gt; 4\n    2 --&gt; 5\n    5 --&gt; 6\n    5 --&gt; 7\n    3 --&gt; 8\n    8 --&gt; 9\n    9 -.-&gt; dummy\n    7 -.-&gt; 1\n    6 -.-&gt; 5\n    4 -.-&gt; 2</code></pre> python <pre><code>class Solution:\n    def postorderTraversal(self, root: Optional[TreeNode]) -&gt; List[int]:\n\n        # (1)\n        dummy = TreeNode(-1)\n        dummy.left = root\n        curr_node = dummy\n        values = []\n\n        while curr_node:\n            if curr_node.left:  # (2)\n                # (3)\n                predecessor = curr_node.left\n                while predecessor.right and predecessor.right is not curr_node:\n                    predecessor = predecessor.right\n\n                if not predecessor.right:  # (4)\n                    predecessor.right = curr_node  # (5)\n                    curr_node = curr_node.left\n                else:  # (6)\n                    predecessor.right = None  # (7)\n                    values.extend(self.reverseRightPathValues(curr_node.left, predecessor))  # (8)\n                    curr_node = curr_node.right\n            else:\n                curr_node = curr_node.right\n\n        return values\n\ndef reverseRightPathValues(self, start_node: TreeNode, end_node: TreeNode) -&gt; list[int]:\n    values = []\n    while start_node is not end_node:\n        values.append(start_node.val)\n        start_node = start_node.right\n    values.append(end_node.val)\n    values.reverse()\n    return values\n</code></pre> <ol> <li>Add a dummy node to ensure the root is properly processed.</li> <li>Explore the left tree first.</li> <li>Find predecessor of the current node, the rightmost node of the left subtree.</li> <li>Condition 1: <code>predecessor.right</code> is <code>None</code>. The left sub-tree is not explored.</li> <li>Establish a temporary link from predecessor to current.</li> <li>Condition 2: <code>predecessor.right</code> is the <code>curr_node</code>, coming back to the current node from the predecessor. This indicate the left sub-tree has been visited.</li> <li>Remove the temporary link.</li> <li>Reverse the node order from <code>root -&gt; right</code> to <code>right -&gt; root</code>. Then append to values where <code>left</code> is already in. So they are in right postorder.</li> </ol>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#complexity-analysis-of-approach-4","title":"Complexity Analysis of Approach 4","text":"<ul> <li>Time complexity: \\(O(n)\\) <ul> <li>We visit each node twice, one for establishing link and one for removing. So the time complexity of traversal is \\(O(n)\\).</li> <li>The reversing is done only on subtree, it is \\(O(h) &lt;&lt; O(n)\\).</li> <li>So the total time complexity is \\(O(n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Visit nodes taking \\(O(1)\\) space.</li> <li>The return list takes \\(O(n)\\) space to save all node values.</li> <li>The total space complexity is \\(O(n) = O(1) + O(n)\\).</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity (Overall) Space Complexity (Visit) Approach - Recursion \\(O(n)\\) \\(O(n)\\) $O(n) Approach - Iteration (modified preorder) \\(O(n)\\) \\(O(n)\\) $O(n) Approach - Iteration \\(O(n)\\) \\(O(n)\\) $O(n) <p>Approach - Morris    | \\(O(n)\\)          | \\(O(n)\\)                     | $O(1)</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#test","title":"Test","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0145-binary-tree-postorder-traversal/#references","title":"References","text":"<ul> <li>Morris Inorder Tree Traversal - Tushar Roy Youtube Channel</li> <li>Iterative Postorder Traversal of Binary Tree Using One Stack - Tushar Roy Youtube Channel</li> <li>Tree traversal - wiki</li> <li>Binary Tree - My Notes</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0100-0199/lc0150-evaluate-reverse-polish-notation/","title":"LC150. Evaluate Reverse Polish Notation","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0150-evaluate-reverse-polish-notation/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 150: You are given an array of strings\u00a0<code>tokens</code>\u00a0that represents an arithmetic expression in a\u00a0Reverse Polish Notation.</p> <p>Evaluate the expression. Return\u00a0an integer that represents the value of the expression.</p> <p>Note\u00a0that:</p> <ul> <li>The valid operators are\u00a0<code>'+'</code>,\u00a0<code>'-'</code>,\u00a0<code>'*'</code>, and\u00a0<code>'/'</code>.</li> <li>Each operand may be an integer or another expression.</li> <li>The division between two integers always\u00a0truncates toward zero.</li> <li>There will not be any division by zero.</li> <li>The input represents a valid arithmetic expression in a reverse polish notation.</li> <li>The answer and all the intermediate calculations can be represented in a\u00a032-bit\u00a0integer.</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0150-evaluate-reverse-polish-notation/#clarification","title":"Clarification","text":"<ul> <li>What are valid operators</li> <li>What about division by 0?</li> <li>What to do with incorrect expression?</li> <li>Go through examples</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0150-evaluate-reverse-polish-notation/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0150-evaluate-reverse-polish-notation/#solution","title":"Solution","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0150-evaluate-reverse-polish-notation/#approach-stack","title":"Approach - Stack","text":"<p>Use stack to solve the problem:</p> <ul> <li>push numbers to stack</li> <li>for operators, pop up two operands and push result to stack</li> </ul> <p>For integer division, in Python:</p> <ul> <li><code>a // b</code>: truncate the result to the smaller value</li> <li><code>int(a / b)</code>: do float division <code>a / b</code> and then use <code>int</code> function to truncate toward zero.</li> </ul> <p>Inflix Notation vs. Reverse Polish Notation</p> PythonPython - Lambda <pre><code>class Solution:\ndef evalRPN(self, tokens: List[str]) -&gt; int:\n    stack = deque()\n\n    for token in tokens:\n        if token in \"+-*/\":\n            operand2 = stack.pop()\n            operand1 = stack.pop()\n            if token == '+':\n                stack.append(operand1 + operand2)\n            elif token == '-':\n                stack.append(operand1 - operand2)\n            elif token == '*':\n                stack.append(operand1 * operand2)\n            elif token == '/':\n                stack.append(int(operand1 / operand2))\n            else:\n                pass\n                # the operator is not supported\n        else:\n            stack.append(int(token))\n\n    return stack.pop()\n</code></pre> <pre><code>class Solution:\nOPERATIONS = {\n    \"+\": lambda a, b: a + b,\n    \"-\": lambda a, b: a - b,\n    \"/\": lambda a, b: int(a / b),\n    \"*\": lambda a, b: a * b,\n}\n\ndef evalRPN(self, tokens: List[str]) -&gt; int:\n    stack = deque()\n\n    for token in tokens:\n        if token in self.OPERATIONS:\n            operand2 = stack.pop()\n            operand1 = stack.pop()\n            operation = self.OPERATIONS[token]\n            stack.append(operation(operand1, operand2))\n        else:\n            stack.append(int(token))\n\n    return stack.pop()\n</code></pre>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0150-evaluate-reverse-polish-notation/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   We do a linear search of all \\(n\\) numbers. The operation of each step is \\(O(1)\\) (either <code>push</code> or two <code>pop</code>s with math operation).</li> <li>Space complexity: \\(O(n)\\)   In the worst case, the stack will have all the numbers (~ \\(n/2\\)).</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0150-evaluate-reverse-polish-notation/#test","title":"Test","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0153-find-minimum-in-rotated-sorted-array/","title":"LC153. Find Minimum in Rotated Sorted Array","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0153-find-minimum-in-rotated-sorted-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 153: Suppose an array of length\u00a0<code>n</code>\u00a0sorted in ascending order is\u00a0rotatedbetween\u00a0<code>1</code>\u00a0and\u00a0<code>n</code>\u00a0times. For example, the array\u00a0<code>nums = [0,1,2,4,5,6,7]</code>\u00a0might become:</p> <ul> <li><code>[4,5,6,7,0,1,2]</code>\u00a0if it was rotated\u00a0<code>4</code>\u00a0times.</li> <li><code>[0,1,2,4,5,6,7]</code>\u00a0if it was rotated\u00a0<code>7</code>\u00a0times.</li> </ul> <p>Notice that\u00a0rotating\u00a0an array\u00a0<code>[a[0], a[1], a[2], ..., a[n-1]]</code>\u00a01 time results in the array\u00a0<code>[a[n-1], a[0], a[1], a[2], ..., a[n-2]]</code>.</p> <p>Given the sorted rotated array\u00a0<code>nums</code>\u00a0of\u00a0unique\u00a0elements, return\u00a0the minimum element of this array.</p> <p>You must write an algorithm that runs in\u00a0<code>O(log n) time.</code></p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0153-find-minimum-in-rotated-sorted-array/#clarification","title":"Clarification","text":"<ul> <li>sorted and rotated</li> <li>unique elements (no duplicates)</li> <li>the array can be rotated back to it original values</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0153-find-minimum-in-rotated-sorted-array/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0153-find-minimum-in-rotated-sorted-array/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0153-find-minimum-in-rotated-sorted-array/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since the array is originally sorted and rotated between 1 and n times, there will be two potential forms after rotations:</p> <ul> <li>The whole array is sorted in the ascending order (i.e., the array rotates back to the original one );</li> <li>There is a pivot point in the array, which separate the array into two halves: one half is sorted and the other is not sorted.</li> </ul> <p>So if we can detect which half is not sorted, we know that the minimum value should be in that unsorted half and ignore the sorted half. If both halves are sorted, the first left element is the minimum. If we split the array into two halves, <code>[left, mid]</code> and <code>[mid + 1, right]</code>, there are 4 kinds of relationship among <code>nums[left]</code>, <code>nums[mid]</code>, and <code>nums[right]</code>:</p> <ol> <li><code>nums[left] &lt;= nums[mid] &lt;= nums[right]</code>, <code>min</code> is <code>nums[left]</code></li> <li><code>nums[left] &gt; nums[mid] &lt;= nums[right]</code>, <code>[left, mid]</code> is not sorted and <code>min</code> is in the left half</li> <li><code>nums[left] &lt;= nums[mid] &gt; nums[right]</code>, <code>[mid, right]</code> is not sorted and <code>min</code> is in the right half</li> <li><code>nums[left] &gt; nums[mid] &gt; nums[right]</code>, impossible since the original array is sorted in ascending order.</li> </ol> <p>So we can check <code>nums[mid]</code> and <code>nums[right]</code>:</p> <ul> <li>If <code>nums[mid] &gt; nums[right]</code>, search the right half, covering the relationship 3</li> <li>If <code>nums[mid] &lt;= nums[right]</code>, search the left half, covering the relationship 1 and 2, since in both cases the minimum is on the left.</li> </ul> Note <p>If we just check <code>nums[left]</code> and <code>nums[mid]</code>, the condition <code>nums[left] &lt;= nums[mid]</code> can't distinguish relationship 1 and 3 which requires searching in two different directions. This requires an addition condition check on whether the whole array is sorted.</p> Python <pre><code>class Solution:\n    def findMin(self, nums: List[int]) -&gt; int:\n        left, right = 0, len(nums) - 1\n\n        while left &lt; right:\n            mid = (left + right) // 2\n            if nums[mid] &gt; nums[right]:\n                left = mid + 1\n            else:\n                right = mid\n\n        return nums[left]\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0153-find-minimum-in-rotated-sorted-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)     Since using binary search, the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\)     Only use two variables for indices. </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0153-find-minimum-in-rotated-sorted-array/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0154-find-minimum-in-rotated-sorted-array-ii/","title":"LC154. Find Minimum in Rotated Sorted Array II","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0154-find-minimum-in-rotated-sorted-array-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 154: Suppose an array of length\u00a0<code>n</code>\u00a0sorted in ascending order is\u00a0rotatedbetween\u00a0<code>1</code>\u00a0and\u00a0<code>n</code>\u00a0times. For example, the array\u00a0<code>nums = [0,1,4,4,5,6,7]</code>\u00a0might become:</p> <ul> <li><code>[4,5,6,7,0,1,4]</code>\u00a0if it was rotated\u00a0<code>4</code>\u00a0times.</li> <li><code>[0,1,4,4,5,6,7]</code>\u00a0if it was rotated\u00a0<code>7</code>\u00a0times.</li> </ul> <p>Notice that\u00a0rotating\u00a0an array\u00a0<code>[a[0], a[1], a[2], ..., a[n-1]]</code>\u00a01 time results in the array\u00a0<code>[a[n-1], a[0], a[1], a[2], ..., a[n-2]]</code>.</p> <p>Given the sorted rotated array\u00a0<code>nums</code>\u00a0that may contain\u00a0duplicates, return\u00a0the minimum element of this array.</p> <p>You must decrease the overall operation steps as much as possible.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0154-find-minimum-in-rotated-sorted-array-ii/#clarification","title":"Clarification","text":"<ul> <li>sorted and rotated</li> <li>contain duplicates</li> <li>the array can be rotated back to it original values</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0154-find-minimum-in-rotated-sorted-array-ii/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0154-find-minimum-in-rotated-sorted-array-ii/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0154-find-minimum-in-rotated-sorted-array-ii/#approach-binary-search","title":"Approach - Binary Search","text":"<p>The big difference between this problem and LC153 is that the array may contain duplicates. So when <code>nums[mid] == nums[right]</code>, the position of minimum could be in either left or right of mid (e.g., <code>[3,3,3,3,1,3]</code>, or <code>[3,1,3,3,3,3]</code>). So</p> <ul> <li>For relationship 1, <code>nums[left] &lt;= nums[mid] &lt;= nums[right]</code>, <code>min</code> could be on either left half or right half when <code>nums[left] == nums[mid] == nums[right]</code></li> </ul> <p>So we need to hanlde the special case <code>nums[left] == nums[mid] == nums[right]</code></p> Python <pre><code>class Solution:\n    def findMin(self, nums: List[int]) -&gt; int:\n        left, right = 0, len(nums) - 1\n\n        while left &lt; right:\n            mid = (left + right) // 2\n\n            if nums[mid] &gt; nums[right]:\n                left = mid + 1\n            elif nums[left] == nums[mid] and nums[mid] == nums[right]:\n                left += 1\n                right -= 1\n            else:\n                right = mid\n\n        return nums[left]\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0154-find-minimum-in-rotated-sorted-array-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) for average case, \\(O(n)\\) for the worst case     In the worst case, it reduce the search space by two elements at a time and takes \\(O(n)\\) time. For the average case, the time complexity is \\(O(\\log n)\\) with the binary search.</li> <li>Space complexity: \\(O(1)\\)     Only use two variables for indices. </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0154-find-minimum-in-rotated-sorted-array-ii/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0100-0199/lc0155-min-stack/","title":"LC155. Min Stack","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0155-min-stack/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 155: Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.</p> <p>Implement the\u00a0<code>MinStack</code>\u00a0class:</p> <ul> <li><code>MinStack()</code>\u00a0initializes the stack object.</li> <li><code>void push(int val)</code>\u00a0pushes the element\u00a0<code>val</code>\u00a0onto the stack.</li> <li><code>void pop()</code>\u00a0removes the element on the top of the stack.</li> <li><code>int top()</code>\u00a0gets the top element of the stack.</li> <li><code>int getMin()</code>\u00a0retrieves the minimum element in the stack.</li> </ul> <p>You must implement a solution with\u00a0<code>O(1)</code>\u00a0time complexity for each function.</p>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0155-min-stack/#clarification","title":"Clarification","text":"<ul> <li>Normal stack operation + retrieve the minimum</li> <li>O(1) time complexity</li> <li>What value should return for invalid cases: pop(), getMin, top() if no values in stack</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0155-min-stack/#assumption","title":"Assumption","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0155-min-stack/#solution","title":"Solution","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0155-min-stack/#approach-stack-of-valuemin-paris","title":"Approach - Stack of Value/Min Paris","text":"<p>Use one stack to store <code>(value, min)</code> pair.</p> Python <pre><code>from collections import deque\n\nclass MinStack:\n\n    def __init__(self):\n        self.stack = deque()\n\n    def push(self, val: int) -&gt; None:\n        # Push (val, min) pair\n        # If the stack is empty, the min value is the first value\n        if not self.stack:\n            self.stack.append((val, val))\n            return\n\n        current_min = self.stack[-1][1]\n        self.stack.append((val, min(val, current_min)))\n\n    def pop(self) -&gt; None:\n        self.stack.pop()\n\n    def top(self) -&gt; int:\n        return self.stack[-1][0]\n\n    def getMin(self) -&gt; int:\n        return self.stack[-1][1]\n</code></pre>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0155-min-stack/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(1)\\) for all operations Similar to stand stack operations.</li> <li>Space complexity: \\(O(n)\\) The worse case to save all (value, min) pairs. The space used is \\(O(2 n) = O(n)\\).</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0155-min-stack/#test","title":"Test","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/","title":"167 Two sum ii - input array is sorted","text":"<p>tags:     - Array     - Two Pointers     - Sliding Window     - Hash Table</p>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#lc167-two-sum-ii-input-array-is-sorted","title":"LC167. Two Sum II - Input Array Is Sorted","text":""},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 167: Given a\u00a01-indexed\u00a0array of integers\u00a0<code>numbers</code>\u00a0that is already\u00a0sorted in non-decreasing order, find two numbers such that they add up to a specific\u00a0<code>target</code>\u00a0number. Let these two numbers be\u00a0<code>numbers[index1]</code>\u00a0and\u00a0<code>numbers[index2]</code>\u00a0where\u00a0<code>1 &lt;= index1 &lt; index2 &lt;\u00a0numbers.length</code>.</p> <p>Return\u00a0the indices of the two numbers, <code>index1</code> and <code>index2</code>,\u00a0added by one\u00a0as an integer array <code>[index1, index2]</code> of length 2.</p> <p>The tests are generated such that there is\u00a0exactly one solution. You\u00a0may not\u00a0use the same element twice.</p> <p>Your solution must use only constant extra space.</p>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#clarification","title":"Clarification","text":"<ul> <li>Sorted array</li> <li>there is\u00a0exactly one solution</li> <li><code>0-indexed</code> or <code>1-indexed</code></li> </ul>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#assumption","title":"Assumption","text":""},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#solution","title":"Solution","text":""},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#approach-sliding-window","title":"Approach - Sliding Window","text":"<p>Since the array is sorted, the sum of two numbers from left half &lt; the sum of two numbers from right. We can use sliding window to find the target by </p> <ul> <li>Move closer to the right if current sum &lt; target  </li> <li>Move closer to the left if current sum &gt; target</li> </ul> Tip <p>Initialize sliding window left pointer with the first position and right pointer with the last position of the array</p> Python <pre><code>class Solution:\n    def twoSum(self, numbers: List[int], target: int) -&gt; List[int]:\n        left = 0\n        right = len(numbers) - 1\n\n        while left &lt; right:\n            sum = numbers[left] + numbers[right]\n            if sum == target:\n                return [left + 1, right + 1] # (1)\n            elif sum &lt; target:\n                left += 1\n            else:\n                right -= 1\n\n        return [-1, -1] # (2)\n</code></pre> <ol> <li>Add one for <code>1-indexed</code> array</li> <li>This is for the general case, the solution doesn't exist. It can be removed for this problem, since there is\u00a0exactly one solution</li> </ol>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Go through the array at most once.</li> <li>Space complexity: \\(O(1)\\)     Just use two index variables</li> </ul>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since the array is sorted, we can use binary search to effectively find <code>target - val</code> if exists for any given <code>val</code>. Iterate through the array and use binary search to find <code>target - val</code>.</p> Python <pre><code>class Solution:\n    def twoSum(self, numbers: List[int], target: int) -&gt; List[int]:\n        for i, num in enumerate(numbers):\n            j = bisect.bisect_left(numbers, target - num, lo=i+1, hi=len(numbers)-1)\n            if j != len(numbers) and numbers[j] == target - num:\n                return [i + 1, j + 1] # (1)\n</code></pre> <ol> <li>Convert from 0-indexed to 1-indexed number</li> </ol>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\)     Iterate through the array once.  </li> <li>Space complexity: \\(O(1)\\)     Only using two index variables.</li> </ul>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#approach-hash-map","title":"Approach - Hash Map","text":"<p>Iterate through the array and store the <code>(value, index)`` in hash map. For any new value, check whether</code>target - value` exists in the hashmap. If exists, return indices.</p> Python <pre><code>class Solution:\n    def twoSum(self, numbers: List[int], target: int) -&gt; List[int]:\n        value_index_map = {}\n\n        for i, num in enumerate(numbers):\n            if target - num in value_index_map:\n                return [value_index_map[target - num] + 1, i + 1]\n\n            value_index_map[num] = i\n</code></pre>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#complexity-analysis_2","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Iterate through the array once.  </li> <li>Space complexity: \\(O(n)\\)     Use hashmap to store at most \\(n-1\\) items</li> </ul>"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Sliding Window \\(O(n)\\) \\(O(1)\\) Approach - Binary Search \\(O(n \\log n)\\) \\(O(1)\\) Approach - Hash Map \\(O(n)\\) \\(O(n)\\)"},{"location":"lc-solutions/lc0100-0199/lc0167-two-sum-ii-input-array-is-sorted/#test","title":"Test","text":""},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/","title":"LC189. Rotate Array","text":"","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 189: Given an array, rotate the array to the right by <code>k</code> steps, where <code>k</code> is non-negative.</p>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#clarification","title":"Clarification","text":"<ul> <li>Rotate to the right: fill the left with the elements coming out of the right</li> <li>\\(k\\) is non-negative</li> </ul>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#assumption","title":"Assumption","text":"","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#solution","title":"Solution","text":"<p>There are 3 different approaches to solve the problem:</p> <ol> <li>Brute force using two loops to  rotate the array</li> <li>Use additional array</li> <li>Reverse</li> </ol> <p>Note that we have <code>k = k % n</code> to handle the case where \\(k &gt;= n\\). </p>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#approach-brute-force","title":"Approach - Brute Force","text":"<p>The straightforward approach is to rotate all the elements of the array \\(k\\) times and each time move all elements to the right by \\(1\\) step.</p> <pre><code>class Solution {\npublic:\n    void rotate(vector&lt;int&gt;&amp; nums, int k) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size n = nums.size();\n        int temp; \n        for (int i = 0; i &lt; k; i++) {\n            temp = nums[n-1];\n            for (vec_size j = n - 1; j &gt;= 1; j--) {\n                nums[j] = nums[j-1];\n            }\n            nums[0] = temp;\n        }\n    }\n};\n</code></pre>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\times k)\\)      It takes \\(O(n)\\) to shift all elements by one step. Since it is shifted \\(k\\) times, the time complexity is \\(O(n \\times k)\\).</li> <li>Space complexity: \\(O(1)\\)     Just use <code>temp</code> and indices with constant space.</li> </ul>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#approach-using-extra-array","title":"Approach - Using Extra Array","text":"<p>We use an extra array to place element of the array at its correct position, i.e., the number at index <code>i</code> in the original array is placed at the index <code>(i + k) % length of array</code> in the new array. Then, copy the elements from the new array to the original one. </p> PythonC++ <pre><code>class Solution:\ndef rotate(self, nums: List[int], k: int) -&gt; None:\n    \"\"\"\n    Do not return anything, modify nums in-place instead.\n    \"\"\"\n    # Method 1: swap with temperary array\n    k %= len(nums)\n    temp = nums[-k:]\n    nums[k:] = nums[:-k]\n    nums[:k] = temp\n</code></pre> <pre><code>class Solution {\npublic:\n    void rotate(vector&lt;int&gt;&amp; nums, int k) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size n = nums.size();\n        vector&lt;int&gt; aux(n);\n\n        // Save rotated array to the auxiliary array\n        for (vec_size i = 0; i &lt; n; i++) {\n            aux[(i + k) % n] = nums[i];\n        }\n\n        // Copy the value back\n        for (vec_size i = 0; i &lt; n; i++) {\n            nums[i] = aux[i];\n        }\n    }\n};\n</code></pre>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It takes \\(O(n)\\) to put the numbers in the new array and \\(O(n)\\) to copy the values to the original array. So the time complexity is \\(O(n) = O(n) + O(n)\\) </li> <li>Space complexity: \\(O(n)\\)     Needs a new array with the same size of the original array.</li> </ul>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#approach-reverse","title":"Approach - Reverse","text":"<p>The following approach is shared by @danny6514 and explained by @xingyze: </p> <ol> <li>Reverse all the elements of the array, \"---&gt;--&gt;\" to \"&lt;--&lt;---\"</li> <li>Reverse the first \\(k\\) elements \"&lt;--\", we can get \"--&gt;&lt;---\"</li> <li>Reverse the rest \\(n-k\\) elements \"&lt;---\", we can get \"--&gt;---&gt;\"</li> </ol> PythonC++ <pre><code>class Solution:\ndef rotate(self, nums: List[int], k: int) -&gt; None:\n    \"\"\"\n    Do not return anything, modify nums in-place instead.\n    \"\"\"\n    k %= len(nums)\n    n = len(nums)\n    self.reverse(nums, 0, n - 1)\n    self.reverse(nums, 0, k - 1)\n    self.reverse(nums, k, n - 1)\n\ndef reverse(self, nums: List[int], start: int, end: int) -&gt; None:\n    while start &lt; end:\n        temp = nums[start]\n        nums[start] = nums[end]\n        nums[end] = temp\n        start += 1\n        end -= 1\n</code></pre> <pre><code>class Solution {\npublic:\n    void rotate(vector&lt;int&gt;&amp; nums, int k) {\n        vector&lt;int&gt;::size_type n = nums.size();\n        if (n &lt;= 1) return; // k % 0 is undefined and no need to rotate for zero or 1 element\n        k = k % n; // make sure k is within [0, n)\n        // If no element to rotate or rotate 0 time, return\n        if (k &lt; 1) return;\n\n        reverse(nums, 0, n - 1);\n        reverse(nums, 0, k - 1);\n        reverse(nums, k, n - 1);\n    }\n\nprivate:\n    void reverse(vector&lt;int&gt;&amp; nums, vector&lt;int&gt;::size_type begin, vector&lt;int&gt;::size_type end) {\n        while (begin &lt; end) {\n            swap(nums[begin], nums[end]);\n            begin++;\n            if (end == 0) {\n                break;\n            }\n            else {\n                end--;\n            }\n        }\n    }\n};\n</code></pre>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#complexity-analysis_2","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     The array is reversed total of two times. So the time complexity is \\(O(n) = O(n) + O(n)\\) </li> <li>Space complexity: \\(O(1)\\)     Just use some pointers of constant space. </li> </ul>","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Brute Force \\(O(n \\times k)\\) \\(O(1)\\) Approach - Use Extra Array \\(O(n)\\) \\(O(n)\\) Approach - Reverse \\(O(n)\\) \\(O(1)\\)","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0189-rotate-array/#test","title":"Test","text":"","tags":["Array"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/","title":"198. House Robber","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 198: You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security systems connected and it will automatically contact the police if two adjacent houses were broken into on the same night.</p> <p>Given an integer array\u00a0<code>nums</code>\u00a0representing the amount of money of each house, return the maximum amount of money you can rob tonight\u00a0without alerting the police.</p> <p>Example 1:</p> <p>Input: nums = [1,2,3,1] Output: 4 Explanation: Rob house 1 (money = 1) and then rob house 3 (money = 3). Total amount you can rob = 1 + 3 = 4.</p> <p>Example 2:</p> <p>Input: nums = [2,7,9,3,1] Output: 12 Explanation: Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1). Total amount you can rob = 2 + 9 + 1 = 12.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#clarification","title":"Clarification","text":"<ul> <li>No two adjacent houses can be robbed</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#solution","title":"Solution","text":"<p>To solve the problem, we need to figure out:</p> <ol> <li>Define state of the problem using a function or array. We can use <code>rob(i)</code> to represent the maximum amount of money at house <code>i</code>.</li> <li> <p>Find recurrence relation to transit between states. For house <code>i</code>, a robber has 2 options:</p> <ol> <li>Rob the house. It means it can't rob the house before (i.e., house <code>i - 1</code>). He gets all cumulative money from house <code>i - 2</code> and the money from house <code>i</code>.</li> <li>Do not rob the house. He gets all cumulative money from house <code>i - 1</code>. So we can represent the above mentioned relation in the following equation:</li> </ol> \\[ \\text{rob}(i) = \\max(\\text{rob}(i - 2) + \\text{nums}[i], \\text{rob}(i - 1)) \\] </li> <li> <p>Determine base cases to stop recurrence relation:</p> <ul> <li>\\(\\text{rob}(0) = \\text{nums}[0]\\)</li> <li>\\(\\text{rob}(1) = \\max(\\text{nums}[0], \\text{nums}[1])\\)</li> </ul> </li> </ol>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#approach-1-recursive-memoization","title":"Approach 1: Recursive + Memoization","text":"<p>Based on the relationship, we can use recursive method with memoization to calculate the max amount of money for each house.</p> Python <pre><code>class Solution:\ndef rob(self, nums: List[int]) -&gt; int:\n    self.memo = {}\n    return self.rob_i(nums, len(nums) - 1)\n\ndef rob_i(self, nums: List[int], i: int) -&gt; int:\n    # Base case\n    if i &lt; 0:\n        return 0\n\n    # Memoization\n    if i in self.memo:\n        return self.memo[i]\n\n    max_prev1 = self.rob_i(nums, i - 1)\n    max_prev2 = self.rob_i(nums, i - 2)\n\n    max_current = max(max_prev1, max_prev2 + nums[i])\n    self.memo[i] = max_current  # Update memo\n    return max_current\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   The recursive calls take at most \\(n\\) times due to memoization and each call takes   \\(O(1)\\) time. So the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>The memoization table takes \\(O(n)\\) space to store max amount of money for each house.</li> <li>The recursion stack takes \\(O(n)\\) space since the recursion depth is at most \\(n\\).</li> <li>The total space complexity is \\(O(n) + O(n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#approach-2-iteration","title":"Approach 2: Iteration","text":"<p>From the relationship equation, to calculate the maximum amount of money of the current house, we only need to know the maximum amount of money of the previous two houses. So we can use iteration to calculate the maximum amount of money for each house by using two variables <code>prev1</code> and <code>prev2</code> (no need to use an array).</p> python <pre><code>class Solution:\n    def rob(self, nums: List[int]) -&gt; int:\n        n = len(nums)\n        if n == 0:\n            return 0\n        prev1 = 0\n        prev2 = 0\n        for num in nums:\n            curr = max(prev1, prev2 + num)\n            prev1, prev2 = curr, prev1\n\n        return curr\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   Go through \\(n\\) numbers using a for-loop and each iteration takes \\(O(1)\\) time.   So the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(1)\\)   Use 3 variables, <code>prev1</code>, <code>prev2</code>, and <code>curr</code>, to do the calculations. So the space   complexity is \\(O(1)\\).</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Recursion + Memoization \\(O(n)\\) \\(O(n)\\) Approach 2 - Iteration \\(O(n)\\) \\(O(1)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0100-0199/lc0198-house-robber/#test","title":"Test","text":"<ul> <li>Test empty list</li> <li>Test single house</li> <li>Test two houses</li> <li>Test multiple houses</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/","title":"LC200. Number of Islands","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 200: Given an\u00a0<code>m x n</code>\u00a02D binary grid\u00a0<code>grid</code>\u00a0which represents a map of\u00a0<code>'1'</code>s (land) and\u00a0<code>'0'</code>s (water), return\u00a0the number of islands.</p> <p>An\u00a0island\u00a0is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water.</p>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#clarification","title":"Clarification","text":"<ul> <li>Definition of islands: connected <code>1</code>s surrounded by <code>0</code>s or edges of matrix (assume edges are surrounded by <code>0</code>s)</li> <li>Peninsula and island may be better words to describe</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#assumption","title":"Assumption","text":"<ul> <li>Matrix is surrounded by water</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#solution","title":"Solution","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#approach-bfs","title":"Approach - BFS","text":"<p>The problem is equivalent to finding out number of groups with connected <code>1</code>s. When encountering a <code>1</code> and not visited before, consider it as a root node and use breadth-first search (BFS) to find all connected <code>1</code>s and mark them as visited (either use <code>set</code> or mark them as <code>0</code>). Count the number of root nodes that trigger BFS. This number is the number of islands.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    DIRECTIONS = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n\n    def numIslands(self, grid: List[List[str]]) -&gt; int:\n        if not grid:\n            return 0\n        n_rows = len(grid)\n        n_cols = len(grid[0])\n        n_islands = 0\n        queue = deque()\n        visited = set()\n\n        for i_row in range(n_rows):\n            for j_col in range(n_cols):\n                if grid[i_row][j_col] == \"1\" and (i_row, j_col) not in visited:\n                    queue.append((i_row, j_col))\n                    visited.add((i_row, j_col))\n                    n_islands += 1\n\n                    # Visit connected 1s\n                    while queue:\n                        base_row, base_col = queue.popleft()\n                        for step_row, step_col in self.DIRECTIONS:\n                            next_row = base_row + step_row\n                            next_col = base_col + step_col\n                            if next_row &gt;= 0 and next_row &lt; n_rows and next_col &gt;= 0 and next_col &lt; n_cols \\\n                                and grid[next_row][next_col] == \"1\" and (next_row, next_col) not in visited:\n                                    queue.append((next_row, next_col))\n                                    visited.add((next_row, next_col))\n\n        return n_islands\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(mn)\\)   The worst case is to search all nodes for connected <code>1</code>s. The total number of nodes is \\(m \\times n\\), where \\(m\\) is number of rows and \\(n\\) is number of columns of the grid.</li> <li>Space complexity: \\(O(mn)\\)   In the worst case, the size of queue and visisted hold all nodes, \\(m \\times n\\).</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#approach-dfs","title":"Approach - DFS","text":"<p>This problem can also be solved use depth-first search.</p> python <pre><code>class Solution:\n    DIRECTIONS = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n\n    def numIslands(self, grid: List[List[str]]) -&gt; int:\n        if not grid:\n            return 0\n\n        n_islands = 0\n        visited = set()\n        for i_row in range(len(grid)):\n            for j_col in range(len(grid[0])):\n                if grid[i_row][j_col] == \"1\" and (i_row, j_col) not in visited:\n                    self.dfs(grid, i_row, j_col, visited)\n                    n_islands += 1\n        return n_islands\n\n    def dfs(self, grid, i_row, j_col, visited):\n        if i_row &gt;= 0 and i_row &lt; len(grid) and j_col &gt;= 0 and j_col &lt; len(grid[0]) \\\n            and grid[i_row][j_col] == \"1\" and (i_row, j_col) not in visited:\n                visited.add((i_row, j_col))\n                for step_row, step_col in self.DIRECTIONS:\n                    self.dfs(grid, i_row + step_row, j_col + step_col, visited)\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(mn)\\)   The worst case is to search all nodes for connected <code>1</code>s. </li> <li>Space complexity: \\(O(mn)\\)   In the worst case, the recursive function depth is \\(m \\times n\\) where the grid map is filled with lands.</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - BFS \\(O(mn)\\) \\(O(mn)\\) Approach - DFS \\(O(mn)\\) \\(O(mn)\\)","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0200-number-of-islands/#test","title":"Test","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/","title":"LC203. Remove Linked List Elements","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 203: Given the\u00a0<code>head</code>\u00a0of a linked list and an integer\u00a0<code>val</code>, remove all the nodes of the linked list that has\u00a0<code>Node.val == val</code>, and return\u00a0the new head.</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#clarification","title":"Clarification","text":"<ul> <li>the whole list could be removed</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#approach-iteration","title":"Approach - Iteration","text":"<p>The main idea is to use two pointers,  <code>prev</code>, and <code>curr</code>, and check the following two conditions while iterating over the list: - If <code>curr.val == val</code>, remove the current node by setting <code>prev.next = curr.next</code> - If <code>curr.val != val</code>, simply move the <code>prev</code> pointer to <code>curr</code> node since it is a valid node and move <code>curr</code> to the next one.</p> Python <pre><code>class Solution:\n    def removeElements(self, head: Optional[ListNode], val: int) -&gt; Optional[ListNode]:\n        dummy = ListNode(-1, head)\n        prev = dummy\n        curr = head\n\n        while curr:\n            if curr.val == val:\n                prev.next = curr.next\n            else:\n                prev = curr\n\n            curr = curr.next\n\n        return dummy.next\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Visit every node in the list</li> <li>Space complexity: \\(O(1)\\)     Just use limited variables for pointers and therefore constant space.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#approach-recursion","title":"Approach - Recursion","text":"<p>The problem can also be solved via recursion. The main idea to recursively call <code>removeElements(head.next, val)</code>. If the node contains the value, simply return <code>node.next</code>. Otherwise, return current node.</p> Python <pre><code>class Solution:\ndef removeElements(self, head: Optional[ListNode], val: int) -&gt; Optional[ListNode]:\n    if head is None:\n        return None\n\n    head.next = self.removeElements(head.next, val)\n\n    if head.val == val:\n        return head.next\n    else:\n        return head\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Takes \\(n\\) function calls to go through the whole list</li> <li>Space complexity: \\(O(n)\\)     Function recursive call takes \\(O(n)\\) space</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - iteration \\(O(n)\\) \\(O(1)\\) Approach - recursion \\(O(n)\\) \\(O(n)\\)","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0203-remove-linked-list-elements/#test","title":"Test","text":"<p>Consider some edge cases:</p> <ul> <li>The linked list is empty, i.e., the head node is None</li> <li>Multiple nodes with the target value in a row</li> <li>The head node has the target value</li> <li>All of the nodes have the target value</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/","title":"LC206. Reverse Linked List","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 206: Given the head of a singly linked list, reverse the list, and return the reversed list. For example, change <code>1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5</code> to <code>5 -&gt; 4 -&gt; 3 -&gt; 2 -&gt; 1</code>.</p>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#clarification","title":"Clarification","text":"<ul> <li>singly linked list</li> </ul>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#assumption","title":"Assumption","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#solution","title":"Solution","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#approach-iteration","title":"Approach - Iteration","text":"<p>The problem can be solved via iteration. For each node, switch pointing direction from right to left. @Ajna provides some good explanations.</p> <p></p> Python <pre><code>class Solution:\ndef reverseList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n    prev_node = None\n    while head is not None:\n        next_node = head.next\n        head.next = prev_node\n        prev_node = head\n        head = next_node\n\n    return prev_node\n</code></pre>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)   Go through the whole linked list of \\(n\\) nodes.</li> <li>Space complexity: \\(O(1)\\)   Only need to store previous, current and next nodes.</li> </ul>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#approach-recursion","title":"Approach - Recursion","text":"<p>The problem can be solved via recursive methods. There are two different ways:</p> <ol> <li>Create a new helper function and find that it is easy to understand and clear</li> <li>Re-use the existing function signature.</li> </ol> <p>Refer to @tusizi solution and comments from @christopherpace86</p> Python <pre><code>class Solution:\n    def reverseList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        return self._reverseList(head)\n\n    def _reverseList(self, curr: Optional[ListNode], prev: Optional[ListNode]=None) -&gt; Optional[ListNode]:\n        if not curr:\n            return prev\n\n        next = curr.next\n        curr.next = prev\n        return self._reverseList(next, curr)\n</code></pre> <p>function call</p> <pre><code>call #1: curr: 1, prev: None, next: 2, reverse [1, 2, 3, 4, 5]\n         reverse link from 1 -&gt; 2 to 1 -&gt; none\n         return 5\ncall #2: curr: 2, prev: 1, next: 3, reverse [2, 3, 4, 5]\n         reverse linke form 2 -&gt; 3 to 2 -&gt; 1\n         return 5\ncall #3: curr: 3, prev: 2, next 4, reverse [3, 4, 5]\n         reverse link from 3 -&gt; 4 to 3 -&gt; 2\n         return 5\ncall #4  curr: 4, prev: 3, next: 5, reverse [4, 5]\n        reverse link from 4 -&gt; 5 to 4 -&gt; 3\n        return 5\ncall #5  curr: 5, prev: 4, next: none, reverse [5]\n        reverse link from 5 -&gt; none to 5 -&gt; 4;\n        return 5\ncall #6 curr: none, prev: 5 base case\n        return 5\n</code></pre> Python - Recursion II <pre><code>class Solution:\n    def reverseList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        if not head or not head.next:\n            return head\n\n        node = self.reverseList(head.next)\n        head.next.next = head\n        head.next = None  # remove the old link.\n        return node\n</code></pre> <p>Function call</p> <pre><code>call #1: head: 1\n         node: 5\n         add link: 1 -&gt; &lt;- 2\n         remove link: 1 &lt;- 2\n         return 5\ncall #2: head: 2\n         node: 5\n         add link: 2 -&gt; &lt;- 3\n         remove link: 2 &lt;- 3\n         return 5\ncall #3: head: 3\n         node: 5\n         add link: 3 -&gt; &lt;- 4\n         remoe linke: 3 &lt;- 4\n         return 5\ncall #4: head: 4, \n        node: 5 (after return)\n        Add link &lt;-, so 4 -&gt; &lt;- 5  (&lt;- added)\n        remove link (-&gt;),  4 &lt;- 5\n        return 5\ncall #5: head: 5, return 5\n</code></pre>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   Go through the whole linked list and therefore is \\(O(n)\\) </li> <li>Space complexity: \\(O(n)\\)   Recursive function call stack stores function pointers for up to \\(n\\) calls.</li> </ul>","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Iteration \\(O(n)\\) \\(O(1)\\) Approach - Recursion \\(O(n)\\) \\(O(n)\\)","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0206-reverse-linked-list/#test","title":"Test","text":"","tags":["Linked List","Stack"]},{"location":"lc-solutions/lc0200-0299/lc0207-course-schedule/","title":"LC207. Course Schedule","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0207-course-schedule/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 207: There are a total of\u00a0<code>numCourses</code>\u00a0courses you have to take, labeled from\u00a0<code>0</code>\u00a0to <code>numCourses - 1</code>. You are given an array\u00a0<code>prerequisites</code>\u00a0where\u00a0 <code>prerequisites[i] = [ai, bi]</code>\u00a0indicates that you\u00a0must\u00a0take course\u00a0<code>bi</code>\u00a0first if you want to take course\u00a0<code>ai</code>.</p> <ul> <li>For example, the pair\u00a0<code>[0, 1]</code>, indicates that to take course\u00a0<code>0</code>\u00a0you have to first take course\u00a0<code>1</code>.</li> </ul> <p>Return\u00a0<code>true</code>\u00a0if you can finish all courses. Otherwise, return\u00a0<code>false</code>.</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0207-course-schedule/#clarification","title":"Clarification","text":"<ul> <li>0-based indexing</li> <li>[ai, bi], bi is the prerequisites</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0207-course-schedule/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0207-course-schedule/#solution","title":"Solution","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0207-course-schedule/#approach-topological-sort","title":"Approach - Topological Sort","text":"<p>We can solve the problem by using topological sort. It is similar to 210 Course Schedule II. Instead of find ordered courses, return whether all courses can finish.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def canFinish(self, numCourses: int, prerequisites: List[List[int]]) -&gt; bool:\n        # Build adjacent list and count in degrees\n        adj_list = defaultdict(list)\n        in_degrees = [0] * numCourses  # (1)\n        for course_after, course_before in prerequisites:\n            adj_list[course_before].append(course_after)\n            in_degrees[course_after] += 1\n\n        # Obtain zero in-degree list\n        zero_in_degree_list = [i for i in range(numCourses) if in_degrees[i] == 0]\n        zero_in_degree_queue = deque(zero_in_degree_list)\n\n        # Conduct topological sort\n        n_visited = 0\n        while zero_in_degree_queue:\n            curr_course = zero_in_degree_queue.popleft()\n            n_visited += 1\n\n            for next_course in adj_list[curr_course]:\n                in_degrees[next_course] -= 1\n                if in_degrees[next_course] == 0:\n                    zero_in_degree_queue.append(next_course)\n\n        # return whether finish all courses\n        return n_visited == numCourses\n</code></pre> <ol> <li>The courses are labeled from 0 to numCourses - 1.</li> </ol>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0207-course-schedule/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(V + E)\\) <ul> <li>Building adjacent list and computing in-degree takes \\(O(E)\\) since going through all prerequisites.</li> <li>Finding initial course with 0 in-degree takes \\(O(V)\\) time since going through all courses.</li> <li>For queue operations, it will process all \\(V\\) nodes and each queue operation takes \\(O(1)\\). So the queue operations take \\(O(V)\\).</li> <li>For neighboring exploration, it will explore all neighbor nodes of each node, the total number of exploration is \\(O(E)\\). So the total time complexity is \\(O(E) + O(V) + O(V) + O(E) = O(V + E)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Adjacent list takes \\(O(E)\\) since storing edges of all nodes.</li> <li>In-degree dictionary takes \\(O(V)\\) space in the worst case to store in-degree of all nodes.</li> <li>The queue may take \\(O(V)\\) space in the worst case. So the total space complexity is \\(O(E) + O(V) + O(V) = O(V + E)\\)</li> </ul> </li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0207-course-schedule/#test","title":"Test","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/","title":"LC209. Minimum Size Subarray Sum","text":"","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 209: Given an array of positive integers <code>nums</code> and a positive integer <code>target</code>, return the minimal length of a contiguous subarray <code>[numsl, numsl+1, ..., numsr-1, numsr]</code> of which the sum is greater than or equal to <code>target</code>. If there is no such subarray, return <code>0</code> instead.</p>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#clarification","title":"Clarification","text":"<ul> <li>Positive integer</li> </ul>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#assumption","title":"Assumption","text":"<ul> <li>Long int can store the sum values (i.e., sum doesn't exceed the limits of long integer)</li> </ul>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#solution","title":"Solution","text":"","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#approach-brute-force","title":"Approach - Brute Force","text":"<p>Use two for-loops to find sum of the subarrays and update the minimal length. There are several improvements implemented :</p> <ul> <li>Break the 2nd loop early if it is find the first index <code>j</code> for a given index <code>i</code>. Since finding the minimal length, any values after <code>j</code> will have a larger length</li> <li>Define a variable <code>sum</code> to store the sum values for subarray starting from index <code>i</code></li> <li>Initialize <code>length = n + 1 &gt; n = size of nums</code>. When <code>length = n + 1</code>, we know minimal length is not updated and therefore return zero in the end.  </li> </ul> <pre><code>class Solution {\npublic:\n    int minSubArrayLen(int target, vector&lt;int&gt;&amp; nums) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size n = nums.size();\n        long int sum;\n        vec_size length = n + 1; // length &gt;= 0\n\n        for (vec_size i = 0; i &lt; n; i++) {\n            sum = 0;\n            for (vec_size j = i; j &lt; n; j++) {\n                sum += nums[j];\n                if (sum &gt;= target) {\n                    if (j - i + 1 &lt; length) { // j &gt;= i, no need to worried about negative causing overflow of unsigned integer\n                        length = j - i + 1; \n                    }\n                    break;\n                }\n            }\n        }\n        return (length == n + 1) ? 0 : length;\n    }\n};\n</code></pre>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^2)\\)     Since using two for-loops to find the subarrays, the time complexity is \\(O(n^2)\\) </li> <li>Space complexity: \\(O(1)\\)     Only use several local variables with constant space complexity.</li> </ul>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#approach-binary-search","title":"Approach - Binary Search","text":"<p>We can improve the brute force approach by using the binary search in the 2nd for-loop. Instead of iterating linearly to find the sum that <code>&gt; target</code>, we can use binary search to find the lower bound  of the index with value that is <code>cusum[i-1] + target</code>. Note that we add zero as the first element of cusum to compare <code>cusum[i] - 0</code> besides compare <code>cusum[i] - cusum[j]</code>. So the index will be shifted by 1. </p> <pre><code>class Solution {\npublic:\n    int minSubArrayLen(int target, vector&lt;int&gt;&amp; nums) {\n        int n = nums.size();\n        if (n == 0) return 0;\n        int minLength = n + 1; // n + 1 is not achievable since the max length is n, which can be used to check whether valid subarray exists\n        int length;\n\n        vector&lt;int&gt; cusum(n+1); // cumulative sum [0, n+1] with additional 0 element at the beginning\n        // Compute cumulative sum\n        cusum[0] = 0; // add zero to the first element for checking individual cusum values\n        for (int i = 1; i &lt;= n; i++) {\n            cusum[i] = cusum[i-1] + nums[i-1];\n        }\n\n        // Find valid subarray via binary search and update minimal length\n        for (int i = 1; i &lt;= n; i++) {\n            int toFind = cusum[i-1] + target;\n            int bound = binary_search_lower_bound(cusum, i-1, n, toFind);\n\n            if (bound &gt; - 1) {\n               length = bound - (i - 1);\n                if (length &lt; minLength) {\n                    minLength = length;\n                } \n            }\n        }\n\n        return (minLength == n + 1) ? 0 : minLength;\n    }\n\nprivate:\n    int binary_search_lower_bound(vector&lt;int&gt;&amp; nums, int start, \n                                int end, int target) {\n        int left = start;\n        int right = end;\n        int mid;\n\n        // [0, 1], target = 1\n        //  l  r\n        //  m\n\n        while (left &lt; right) {\n            mid = left + (right - left)/2;  // while loop will ensure right &gt;= left\n\n            if (nums[mid] &lt; target) {\n                left = mid + 1;\n            }\n            else {\n                right = mid;\n            }\n        }\n\n        return (nums[left] &gt;= target) ? left : -1;\n    }\n};\n</code></pre>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\)     It takes \\(O(n)\\) time to compute cumulative sum and then followed by two for-loops--the first loop takes \\(O(n)\\) for iterating over the array and the second loop takes \\(O(\\log n)\\) to find the subarray for each index using binary search. Therefore, the total time complexity is \\(O(n) + O(n \\log n) = O(n \\log n)\\). </li> <li>Space complexity: \\(O(n)\\)     Additional \\(O(n)\\) space for <code>cusum</code> vector.</li> </ul>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#approach-slide-window","title":"Approach - Slide Window","text":"<p>Since the array contains only positive elements (with the same sign), the problem can be solved using a sliding window with changing size moves along the array, increasing window size when <code>sum &lt; target</code> and decreasing window size when <code>sum &gt;= target</code>. The objective is to find the smallest window size with sum of values inside the window &gt;= target. We can use two pointers to represent this slide window:</p> <ul> <li>The right pointer, <code>r</code>, represents the end position of the window. It will expand first by moving <code>r</code> forward</li> <li>The left pointer, <code>l</code>, represents the start position of the window. the window will be reduced by moving <code>l</code> forward until the sum inside the window is <code>&lt; target</code> The window size is <code>r - l + 1</code>. The minimal length will be update when the window expands and shrinks along the array. </li> </ul> PythonC++ <pre><code>class Solution:\ndef minSubArrayLen(self, target: int, nums: List[int]) -&gt; int:\n    min_length = len(nums) + 1\n    left = 0\n    subarray_sum = 0\n    for right in range(len(nums)):\n        subarray_sum += nums[right]\n\n        while subarray_sum &gt;= target:\n            min_length = min(min_length, right - left + 1)\n            subarray_sum -= nums[left]\n            left += 1\n\n    if min_length &gt; len(nums): # (1)\n        return 0\n    else:\n        return min_length\n</code></pre> <ol> <li>The <code>if/else</code> statement can be simplified as <code>return min_length % (len(nums) + 1)</code></li> </ol> <pre><code>class Solution {\npublic:\n    int minSubArrayLen(int target, vector&lt;int&gt;&amp; nums) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size l = 0;\n        vec_size r = 0;\n        vec_size n = nums.size();\n        long int sum = 0;\n        vec_size length = n + 1;\n\n        while (r &lt; n) {\n            sum += nums[r];\n\n            while (sum &gt;= target) {\n                if (r - l + 1 &lt; length) {\n                    length = r - l + 1; // r &gt;= l (always)\n                }\n                sum -= nums[l++];\n            }\n            r++;\n        }\n        return (length == n + 1) ? 0 : length; // length % (n + 1)\n    }\n};\n</code></pre>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#complexity-analysis_2","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Each element can be visited at most twice, once by the right pointer and at most once by the left pointer. </li> <li>Space complexity: \\(O(1)\\)     Only constant space is required for left, right, and sum.</li> </ul>","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Brute Force \\(O(n^2)\\) \\(O(1)\\) Approach - Binary Search \\(O(n \\log n)\\) \\(O(n)\\) Approach - Slide Window \\(O(n)\\) \\(O(1)\\)","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0209-minimum-size-subarray-sum/#test","title":"Test","text":"","tags":["Array","Two Pointers","Prefix Sum"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/","title":"LC210. Course Schedule II","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 210: There are a total of\u00a0<code>numCourses</code>\u00a0courses you have to take, labeled from\u00a0<code>0</code>\u00a0to <code>numCourses - 1</code>. You are given an array\u00a0<code>prerequisites</code>\u00a0where <code>prerequisites[i] = [ai, bi]</code>\u00a0indicates that you\u00a0must\u00a0take course\u00a0<code>bi</code>\u00a0first if you want to take course\u00a0<code>ai</code>.</p> <ul> <li>For example, the pair\u00a0<code>[0, 1]</code>, indicates that to take course\u00a0<code>0</code>\u00a0you have to first take course\u00a0<code>1</code>.</li> </ul> <p>Return\u00a0the ordering of courses you should take to finish all courses. If there are many valid answers, return\u00a0any\u00a0of them. If it is impossible to finish all courses, return\u00a0an empty array.</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#clarification","title":"Clarification","text":"<ul> <li><code>prerequisites[i] = [ai, bi]</code> order is bi --&gt; ai</li> <li>may contain cycle</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#solution","title":"Solution","text":"<p>We can represent the course information in the form of a directed and unweighted graph:</p> <ul> <li>Each course represents a vertex in the graph.</li> <li>Each prerequisite relationship, <code>prerequisites[i] = [ai, bi]</code>, represents a directed edge from <code>bi</code> to <code>ai</code>.</li> <li>The graph may be a cyclic graph.</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#approach-topological-sort","title":"Approach - Topological Sort","text":"<p>The ordering of courses based on prerequisites is a classic topological sorting problem.</p> <ul> <li>Build adj_list and compute in_degree for each course</li> <li>Go through each zero-in-degree vertex in a queue<ul> <li>move it to result list</li> <li>reduce neighbor vertex's in degree to 1</li> <li>if in degree is 0, add to the queue</li> </ul> </li> <li>if len(result) != numCourses, return empty array</li> </ul> Python <pre><code>from collections import defaultdict, deque\n\n\nclass Solution:\n    def findOrder(self, numCourses: int, prerequisites: List[List[int]]) -&gt; List[int]:\n        ordered_courses = []\n\n        # Build adjacent list and compute in-degree\n        course_in_degree = [0] * numCourses\n        adj_list = defaultdict(list)\n        for dependent_course, prerequisite_course in prerequisites:\n            adj_list[prerequisite_course].append(dependent_course)\n            course_in_degree[dependent_course] += 1\n\n        # Iterate zero in degree queue\n        zero_in_degree_list = [i for i in range(numCourses) if course_in_degree[i] == 0]\n        zero_in_degree_queue = deque(zero_in_degree_list)\n        while zero_in_degree_queue:\n            curr_course = zero_in_degree_queue.popleft()\n            ordered_courses.append(curr_course)\n\n            # Reduce in-degree of all the neighbors\n            for dependent_course in adj_list[curr_course]:\n                course_in_degree[dependent_course] -= 1\n                if course_in_degree[dependent_course] == 0:\n                    zero_in_degree_queue.append(dependent_course)\n\n        return ordered_courses if len(ordered_courses) == numCourses else []\n</code></pre>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(V + E)\\) <ul> <li>Building adjacent list and computing in-degree takes \\(O(E)\\) since going through all prerequisites.</li> <li>Finding initial course with 0 in-degree takes \\(O(V)\\) time since going through all courses.</li> <li>For queue operations, it will process all \\(V\\) nodes and each queue operation takes \\(O(1)\\). So the queue operations take \\(O(V)\\).</li> <li>For neighboring exploration, it will explore all neighbor nodes of each node, the total number of exploration is \\(O(E)\\). So the total time complexity is \\(O(E) + O(V) + O(V) + O(E) = O(V + E)\\).</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li>Adjacent list takes \\(O(E)\\) since storing edges of all nodes.</li> <li>In-degree dictionary takes \\(O(V)\\) space in the worst case to store in-degree of all nodes.</li> <li>The queue may take \\(O(V)\\) space in the worst case. So the total space complexity is \\(O(E) + O(V) + O(V) = O(V + E)\\)</li> </ul> </li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#approach-2-","title":"Approach 2 -","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0210-course-schedule-ii/#test","title":"Test","text":"<ul> <li>No prerequisites (<code>prerequisites = []</code>): Any order of courses is valid.</li> <li>Single course (<code>numCourses = 1</code>).</li> <li>Cycles in the graph (e.g.,\u00a0<code>[0,1]</code>,<code>[1,0]</code>): Return an empty list.</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/","title":"LC215. Kth Largest Element in an Array","text":"","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 215: Given an integer array\u00a0<code>nums</code>\u00a0and an integer\u00a0<code>k</code>, return\u00a0the <code>kth</code> largest element in the array.</p> <p>Note that it is the\u00a0<code>kth</code>\u00a0largest element in the sorted order, not the\u00a0<code>kth</code>\u00a0distinct element.</p> <p>Can you solve it without sorting?</p>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#clarification","title":"Clarification","text":"<ul> <li>Integer array with duplicates</li> <li>Return the kth position in the sorted order. Not kth distinct element</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#solution","title":"Solution","text":"","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#approach-min-heap","title":"Approach - Min-Heap","text":"<p>We can use min-heap to solve the problem. Push all the elements into a min-heap but pop from the heap when the size exceeds <code>k</code>. By limiting the heap's size to <code>k</code>, after handling all elements, the heap will contain exactly the <code>k</code> largest elements from the array.</p> Python <pre><code>import heapq\n\nclass Solution:\n    def findKthLargest(self, nums: List[int], k: int) -&gt; int:\n        k_largest_queue = []\n\n        for num in nums:\n            heapq.heappush(k_largest_queue, num)\n            if len(k_largest_queue) &gt; k:\n                heapq.heappop(k_largest_queue)\n\n        return k_largest_queue[0]\n</code></pre>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log k)\\) <ul> <li>We iterate <code>n</code> numbers and each iteration performs one or two heap operations. The heap operation takes \\(O(\\log k)\\) since the heap size is limited to <code>k</code>.</li> <li>So the total time complexity is \\(O(n \\log k)\\).</li> </ul> </li> <li>Space complexity: \\(O(k)\\)     The heap uses \\(O(k)\\) space.</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#approach-2-quickselect","title":"Approach 2 - Quickselect","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Min-Heap \\(O(n \\log k)\\) \\(O(k)\\) Approach - Quickselect \\(O(1)\\) \\(O(n)\\)","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0215-kth-largest-element-in-an-array/#test","title":"Test","text":"<ul> <li>Small arrays where\u00a0k=1k=1\u00a0or\u00a0k=nk=n.</li> <li>Arrays with all identical elements.</li> <li>Negative numbers.</li> <li>Arrays with only one element.</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/","title":"218. The Skyline Problem","text":"","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 218: A city's\u00a0skyline\u00a0is the outer contour of the silhouette formed by all the buildings in that city when viewed from a distance. Given the locations and heights of all the buildings, return\u00a0the\u00a0skyline\u00a0formed by these buildings collectively.</p> <p>The geometric information of each building is given in the array\u00a0<code>buildings</code> where\u00a0<code>buildings[i] = [lefti, righti, heighti]</code>:</p> <ul> <li><code>lefti</code>\u00a0is the x coordinate of the left edge of the\u00a0<code>ith</code>\u00a0building.</li> <li><code>righti</code>\u00a0is the x coordinate of the right edge of the\u00a0<code>ith</code>\u00a0building.</li> <li><code>heighti</code>\u00a0is the height of the\u00a0<code>ith</code>\u00a0building.</li> </ul> <p>You may assume all buildings are perfect rectangles grounded on an absolutely flat surface at height\u00a0<code>0</code>.</p> <p>The\u00a0skyline\u00a0should be represented as a list of \"key points\" sorted by their x-coordinate\u00a0in the form\u00a0<code>[[x1,y1],[x2,y2],...]</code>. Each key point is the left endpoint of some horizontal segment in the skyline except the last point in the list, which always has a y-coordinate\u00a0<code>0</code>\u00a0and is used to mark the skyline's termination where the rightmost building ends. Any ground between the leftmost and rightmost buildings should be part of the skyline's contour.</p> <p>Note:\u00a0There must be no consecutive horizontal lines of equal height in the output skyline. For instance,\u00a0<code>[...,[2 3],[4 5],[7 5],[11 5],[12 7],...]</code>\u00a0is not acceptable; the three lines of height 5 should be merged into one in the final output as such: <code>[...,[2 3],[4 5],[12 7],...]</code></p>","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#solution","title":"Solution","text":"","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#approach-1-sweep-line-with-max-heap","title":"Approach 1: Sweep Line with Max-Heap","text":"<p>The problem can be solved using sweep line algorithm combined with a max-heap. It processes building edges in order and tracks active building heights to determine the skyline.</p> Python <pre><code>import heapq\n\nclass Solution:\n    def getSkyline(self, buildings: list[list[int]]) -&gt; list[list[int]]:\n        # Step 1: Create all the critical points\n        events = []\n        for left, right, height in buildings:\n            events.append((left, -height))  # entering event (using negative height)\n            events.append((right, height))  # exiting event\n\n        # Step 2: Sort events\n        # Sort by x-coordinate; if tie, sort by height: entering before exiting\n        events.sort(key=lambda x: (x[0], x[1]))\n\n        # Step 3: Max-heap to keep track of active building heights\n        result = []\n        max_heap = [0]  # initial ground height\n        heap_counter = {0: 1}  # track occurrences\n        prev_max = 0\n\n        for x, h in events:\n            if h &lt; 0:  # entering a building\n                heapq.heappush(max_heap, h)\n                heap_counter[-h] = heap_counter.get(-h, 0) + 1\n            else:  # exiting a building\n                heap_counter[h] -= 1\n\n            # Clean up the heap (remove heights that are no longer active)\n            while max_heap and heap_counter[-max_heap[0]] == 0:\n                heapq.heappop(max_heap)\n\n            current_max = -max_heap[0]\n            if current_max != prev_max:\n                result.append([x, current_max])\n                prev_max = current_max\n\n        return result\n</code></pre>","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li>Sorting takes \\(O(n \\log n)\\) time for \\(n\\) events (twice the number of buildings). </li> <li>Go through \\(n\\) events and each iteration takes \\(O(\\log n)\\) heap operation. So the time complexity is \\(O(n \\log n)\\)</li> <li>So the overall time complexity is \\(O(n \\log n)\\)</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Sorting events takes \\(O(n)\\) space.</li> <li>The heap takes \\(O(n)\\) space.</li> <li>So the over space complexity is \\(O(n)\\).</li> </ul> </li> </ul>","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#approach-2","title":"Approach 2:","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0218-the-skyline-problem/#test","title":"Test","text":"","tags":["Heap","Line Sweep","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0221-maximal-square/","title":"221. lc0221 maximal square","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0221-maximal-square/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 221: Given an\u00a0<code>m x n</code>\u00a0binary\u00a0<code>matrix</code>\u00a0filled with\u00a0<code>0</code>'s and\u00a0<code>1</code>'s,\u00a0find the largest square containing only <code>1</code>'s\u00a0and return its area.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0221-maximal-square/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0221-maximal-square/#assumption","title":"Assumption","text":"<ul> <li>The matrix is not square</li> <li>Need to find the largest square</li> <li>Area (width x height)</li> <li>The matrix could be empty</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0221-maximal-square/#solution","title":"Solution","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0221-maximal-square/#approach-1-dynamic-programming","title":"Approach 1: Dynamic Programming","text":"<p>To form a square <code>k + 1</code> at <code>(i, j)</code>, we need to ensure that:</p> <ul> <li>A square of size <code>k</code> exists above, <code>(i - 1, j)</code></li> <li>A square of size <code>k</code> exists to the left, <code>(i, j - 1)</code></li> <li>A square of size <code>k</code> exists diagonally top-left, <code>(i - 1, j - 1)</code></li> </ul> <pre><code>1 1\n1 X   \u2190 we're at X = (i,j)\n\n\u2b09  \u2191\n\u2190  [i,j]\n</code></pre> <p>This problem can be solved using dynamic programming:</p> <ul> <li>State: <code>dp(i, j)</code> represents the side length of the largest square whose bottom-right corner is at <code>(i, j)</code> in the input matrix.</li> <li>State Transition:<ul> <li>If <code>matrix[i][j] == \"1\"</code>, then <code>dp(i, j)</code> is the minimum of the top, left, and top-left neighbors plus one: <code>dp(i, j) = min(dp(i-1, j), dp(i, j-1), dp(i-1, j-1)) + 1</code></li> <li>If <code>matrix[i][j] == \"0\"</code>, then: <code>dp(i, j) = 0</code></li> </ul> </li> <li>Base Case: If <code>i == 0</code> or <code>j == 0</code>, then <code>dp(i, j) = matrix[i][j]</code> (if it's \"1\") or <code>0</code> (if it's \"0\").</li> </ul> <p>For the space complexity optimization, we can</p> <ul> <li>Start from a 2D array of size <code>(m + 1) x (n + 1)</code> for better understanding</li> <li>Reduce it to two 1D arrays of size <code>n + 1</code>, one for the current row and one for the previous row</li> <li>Further reduce it to a single 1D array of size <code>n + 1</code>. It is tricky to understand and implement it correctly. </li> </ul> <pre><code>graph LR\n    2d[\"2D Array\"] --&gt; two1d[\"Two 1D Arrays\"] --&gt; 1d[\"1D Array\"]</code></pre> <pre><code>block-beta\ncolumns 14\n    block:2dArray:4\n        columns 2\n        topLeft2d[\"dp(i-1, j-1)\"] top2d[\"dp(i-1, j)\"]\n        left2d[\"dp(i, j-1)\"] bottomRight2d[\"dp(i, j)\"]\n    end\n    space\n    block:two1dArrays:4\n        columns 2\n        topLeft21d[\"prev[j-1]\"] top21d[\"prev[j]\"]\n        left21d[\"curr[j-1]\"] bottomRight21d[\"curr[j]\"]\n    end\n    space\n    block:1dArray:4\n        columns 2\n        topLeft1d[\"prev, old dp[i-1]\"] top1d[\"dp[i]\"]\n        left1d[\"dp[i-1]\"] bottomRight1d[\"new dp[i]\"]\n    end\n\n    2dArray --&gt; two1dArrays\n    two1dArrays --&gt; 1dArray\n\n    style bottomRight2d fill:orange,stroke:#333,stroke-width:2px\n    style bottomRight21d fill:orange,stroke:#333,stroke-width:2px\n    style bottomRight1d fill:orange,stroke:#333,stroke-width:2px</code></pre> Python - 2D ArrayPython - Two 1D Arrays <pre><code>class Solution:\n    def maximalSquare(self, matrix: List[List[str]]) -&gt; int:\n        n_rows = len(matrix)\n        n_cols = len(matrix[0]) if n_rows else 0\n        dp = [\n            [0] * (n_cols + 1) for _ in range(n_rows + 1)\n        ]  # Add extra rows and columns to facility dp computations for the first row and the first column in matrix\n        max_sq_len = 0\n        for i in range(n_rows):\n            for j in range(n_cols):\n                if matrix[i][j] == \"1\":\n                    dp[i + 1][j + 1] = (\n                        min([dp[i][j + 1], dp[i + 1][j], dp[i][j]]) + 1\n                    )  # Be careful of the indexing, (i, j) in matrix correspond to (i + 1, j + 1) in dp\n                    max_sq_len = max(max_sq_len, dp[i + 1][j + 1])\n\n        return max_sq_len * max_sq_len\n</code></pre> <pre><code>class Solution:\n     def maximalSquare(self, matrix: List[List[str]]) -&gt; int:\n         if not matrix or not matrix[0]:\n             return 0\n\n         n_rows, n_cols = len(matrix), len(matrix[0])\n         prev = [0] * (n_cols + 1)\n         max_side = 0\n\n         for i in range(1, n_rows + 1):\n             curr = [0] * (n_cols + 1)\n             for j in range(1, n_cols + 1):\n                 if matrix[i - 1][j - 1] == \"1\":\n                     curr[j] = min(prev[j - 1], prev[j], curr[j - 1]) + 1\n                     max_side = max(max_side, curr[j])\n             prev = curr\n\n         return max_side * max_side\n</code></pre> Python <pre><code>class Solution:\n    def maximalSquare(self, matrix: List[List[str]]) -&gt; int:\n        if not matrix:\n            return 0\n        n_rows, n_cols = len(matrix), len(matrix[0])\n\n        dp = [0] * (n_cols + 1)\n        max_sq_len = 0\n        prev = 0\n        for i in range(n_rows):\n            for j in range(n_cols):\n                temp = dp[j + 1]\n                if matrix[i][j] == \"1\":\n                    dp[j + 1] = min([dp[j + 1], dp[j], prev]) + 1\n                    max_sq_len = max(max_sq_len, dp[j + 1])\n                else:\n                    dp[j + 1] = 0\n                prev = temp\n\n        return max_sq_len * max_sq_len\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0221-maximal-square/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m \\times n)\\)   We need to iterate through each cell in the matrix once.</li> <li>Space complexity: \\(O(n)\\) for 1D array implementation, \\(O(m \\times n)\\) for 2D array implementation  <ul> <li>For 2D array implementation, we use a 2D array of size \\((m + 1) \\times (n + 1)\\).</li> <li>For two 1D arrays implementation, we use two 1D arrays of size \\(n + 1\\).</li> <li>For 1D array implementation, we use a 1D array of size \\(n + 1\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0221-maximal-square/#test","title":"Test","text":"<ul> <li>Test empty matrix</li> <li>Test matrix with single row or single column</li> <li>Test matrix with all \"0\"s</li> <li>Test matrix with all \"1\"s</li> <li>Test matrix with mixed \"0\"s and \"1\"s</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0225-implement-stack-using-queues/","title":"LC225. Implement Stack using Queues","text":"","tags":["Queue"]},{"location":"lc-solutions/lc0200-0299/lc0225-implement-stack-using-queues/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 225: Implement a last-in-first-out (LIFO) stack using only two queues. The implemented stack should support all the functions of a normal stack (<code>push</code>,\u00a0<code>top</code>,\u00a0<code>pop</code>, and\u00a0<code>empty</code>).</p> <p>Implement the\u00a0<code>MyStack</code>\u00a0class:</p> <ul> <li><code>void push(int x)</code>\u00a0Pushes element x to the top of the stack.</li> <li><code>int pop()</code>\u00a0Removes the element on the top of the stack and returns it.</li> <li><code>int top()</code>\u00a0Returns the element on the top of the stack.</li> <li><code>boolean empty()</code>\u00a0Returns\u00a0<code>true</code>\u00a0if the stack is empty,\u00a0<code>false</code>\u00a0otherwise.</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0200-0299/lc0225-implement-stack-using-queues/#clarification","title":"Clarification","text":"<ul> <li>Any time complexity requirement?</li> <li>What to return for pop/top operations when stack is empty?</li> <li>What about just using 1 queue?</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0200-0299/lc0225-implement-stack-using-queues/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Queue"]},{"location":"lc-solutions/lc0200-0299/lc0225-implement-stack-using-queues/#solution","title":"Solution","text":"","tags":["Queue"]},{"location":"lc-solutions/lc0200-0299/lc0225-implement-stack-using-queues/#approach-1-queue","title":"Approach - 1 queue","text":"<p>We can use 1 queue instead of 2 queues to achieve the stack functions. For <code>pop</code> operations, we need to pop the front elements out and append them back until the last element is at the front.</p> Python <pre><code>from collections import deque\n\nclass MyStack:\n\n    def __init__(self):\n        self.queue = deque()\n\n    def push(self, x: int) -&gt; None:\n        self.queue.append(x)\n\n    def pop(self) -&gt; int:\n        self.move()\n        return self.queue.popleft()\n\n    def top(self) -&gt; int:\n        return self.queue[-1]\n\n    def empty(self) -&gt; bool:\n        return not self.queue\n\n    def move(self) -&gt; bool:\n        n = len(self.queue)\n\n        for i in range(n - 1):\n            self.queue.append(self.queue.popleft())\n</code></pre>","tags":["Queue"]},{"location":"lc-solutions/lc0200-0299/lc0225-implement-stack-using-queues/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity:<ul> <li><code>push</code>: \\(O(1)\\) since the queue <code>append</code> function is \\(O(1)\\).</li> <li><code>pop</code>: \\(O(n)\\) since needs to move the elements using a for-loop.</li> <li><code>top</code>: \\(O(1)\\) since the queue's view operations is \\(O(1)\\).</li> <li><code>empty</code>: \\(O(1)\\)</li> </ul> </li> <li>Space complexity: \\(O(n)\\)   In the worst case, it will store all \\(n\\) elements.</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0200-0299/lc0225-implement-stack-using-queues/#test","title":"Test","text":"","tags":["Queue"]},{"location":"lc-solutions/lc0200-0299/lc0232-implement-queue-using-stacks/","title":"LC232. Implement Queue using Stacks","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0200-0299/lc0232-implement-queue-using-stacks/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 232: Implement a first in first out (FIFO) queue using only two stacks. The implemented queue should support all the functions of a normal queue (<code>push</code>,\u00a0<code>peek</code>,\u00a0<code>pop</code>, and\u00a0<code>empty</code>).</p> <p>Implement the\u00a0<code>MyQueue</code>\u00a0class:</p> <ul> <li><code>void push(int x)</code>\u00a0Pushes element x to the back of the queue.</li> <li><code>int pop()</code>\u00a0Removes the element from the front of the queue and returns it.</li> <li><code>int peek()</code>\u00a0Returns the element at the front of the queue.</li> <li><code>boolean empty()</code>\u00a0Returns\u00a0<code>true</code>\u00a0if the queue is empty,\u00a0<code>false</code>otherwise.</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0200-0299/lc0232-implement-queue-using-stacks/#clarification","title":"Clarification","text":"<ul> <li>Any requirement on time complexity of different operations? Still O(1)?</li> <li>What to return when stack is empty?</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0200-0299/lc0232-implement-queue-using-stacks/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Stack"]},{"location":"lc-solutions/lc0200-0299/lc0232-implement-queue-using-stacks/#solution","title":"Solution","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0200-0299/lc0232-implement-queue-using-stacks/#approach-2-stacks-with-move","title":"Approach - 2 Stacks with Move","text":"<ul> <li>Use one input stack for pushing new elements</li> <li>Use one output stack for peak/pop</li> <li>Move all elements from input stack to output stack when performing peep/po with empty output stack. So the order is reversed with the correct one for peep/pop.</li> </ul> Python <pre><code>from collections import deque\nclass MyQueue:\n\n    def __init__(self):\n        self.input_stack = deque()\n        self.output_stack = deque()\n\n    def push(self, x: int) -&gt; None:\n        self.output_stack.append(x)\n\n    def pop(self) -&gt; int:\n        self.move()\n        return self.input_stack.pop()\n\n    def peek(self) -&gt; int:\n        self.move()\n        return self.input_stack[-1]\n\n    def empty(self) -&gt; bool:\n        return not self.input_stack and not self.output_stack\n\n    def move(self):\n        if not self.input_stack:\n            while self.output_stack:\n                self.input_stack.append(self.output_stack.pop())\n</code></pre>","tags":["Stack"]},{"location":"lc-solutions/lc0200-0299/lc0232-implement-queue-using-stacks/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li> <p>Time complexity: \\(O(1)\\) or Amortized \\(O(1)\\)</p> <ul> <li><code>push</code>: \\(O(1)\\)</li> <li><code>pop</code>: Amortized \\(O(1)\\) Since this moving operation only happens once for each element (when it is about to be popped), the amortized time complexity for pop() is O(1)</li> <li><code>peek</code>: Amortized \\(O(1)\\)</li> <li><code>empty</code>: \\(O(1)\\)</li> </ul> </li> <li> <p>Space complexity: \\(O(n)\\)   In the worst case, store \\(n\\) elements</p> </li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0200-0299/lc0232-implement-queue-using-stacks/#test","title":"Test","text":"<ul> <li>Empty</li> <li>1 element</li> <li>normal queue</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/","title":"LC234. Palindrome Linked List","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 234: Given the\u00a0<code>head</code>\u00a0of a singly linked list, return\u00a0<code>true</code> if it is a palindrome or\u00a0<code>false</code> otherwise.</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#clarification","title":"Clarification","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#approach-use-array","title":"Approach - Use Array","text":"<p>Go through the linked list and create an array to store its values. Then compare the array to its reverse to find out if it's a palindrome.</p> Python <pre><code>class Solution:\n    def isPalindrome(self, head: Optional[ListNode]) -&gt; bool:\n        value_list = []\n        curr = head\n        while curr:\n            value_list.append(curr.val)\n            curr = curr.next\n\n        start = 0\n        end = len(value_list) - 1\n        while start != end and end &gt;= 0:\n            if value_list[start] != value_list[end]:\n                return False\n            start = start + 1\n            end = end - 1\n        return True\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Go through the whole linked list.  </li> <li>Space complexity: \\(O(n)\\)     Need an additional array store values of \\(n\\) nodes.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#approach-reverse-2nd-half","title":"Approach - Reverse 2nd half","text":"<p>Find the middle of the linked list and reverse the 2nd half of the linked list. Then compare two halves, one starts from the head and the other starts from the head of the reversed 2nd half. </p> Python <pre><code>class Solution:\n    def isPalindrome(self, head: Optional[ListNode]) -&gt; bool:\n        slow, fast = head, head\n\n        # Find the middle\n        while fast and fast.next:\n            slow = slow.next\n            fast = fast.next.next\n\n        # Reverse the 2nd half list\n        reversed_head_2nd_half = self.reverse(slow)\n\n        # Compare two halves for palindrome\n        is_palindrome = True\n        pointer_1st_half = head\n        pointer_2nd_half = reversed_head_2nd_half\n        while pointer_2nd_half:\n            if pointer_1st_half.val != pointer_2nd_half.val:\n                is_palindrome = False\n                break\n\n            pointer_1st_half = pointer_1st_half.next\n            pointer_2nd_half = pointer_2nd_half.next\n\n        # Reverse the 2nd half back\n        _ = self.reverse(reversed_head_2nd_half)\n\n        return is_palindrome\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It takes \\(n/2\\) steps to find the middle, and \\(n/2\\) steps to reverse the 2nd half, \\(n/2\\) steps to compare two halves, and then \\(n/2\\) steps to reverse the 2nd half back. So the time complexity is \\(O(n)\\)</li> <li>Space complexity: \\(O(1)\\)     Just use several pointers.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Use Array \\(O(n)\\) \\(O(n)\\) Approach - Reverse 2nd half \\(O(n)\\) \\(O(1)\\)","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0234-palindrome-linked-list/#test","title":"Test","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/","title":"LC236. Lowest Common Ancestor of a Binary Tree","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 236: Given a binary tree, find the lowest common ancestor (LCA) of two given nodes in the tree.</p> <p>According to the\u00a0definition of LCA on Wikipedia: \u201cThe lowest common ancestor is defined between two nodes\u00a0<code>p</code>\u00a0and\u00a0<code>q</code>as the lowest node in\u00a0<code>T</code>\u00a0that has both\u00a0<code>p</code>\u00a0and\u00a0<code>q</code>\u00a0as descendants (where we allow a node to be a descendant of itself).\u201d</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#clarification","title":"Clarification","text":"<ul> <li>lowest common ancestor definition:<ul> <li>the lowest node that has both <code>p</code> and <code>q</code> as descendants</li> <li>a node can be descendant of itself</li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#assumption","title":"Assumption","text":"<ul> <li><code>root</code>, <code>p</code>, and <code>q</code> are not None.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#approach-1-recursion","title":"Approach 1: Recursion","text":"<p>We can recursively traverse the left and right subtrees and determine whether <code>p</code> and <code>q</code> are located in relation to the current node (bottom-up approach):</p> <ol> <li>If either <code>p</code> or <code>q</code> is found at the current node, then this node could be an LCA.</li> <li>If both <code>p</code> and <code>q</code> are found in different subtrees of a node, then the node is the LCA.</li> <li>If <code>p</code> and <code>q</code> are found in the same subtree, the LCA is that subtree and the other subtree will return <code>None</code>.</li> </ol> Python <pre><code>class Solution:\n    def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode':\n        # Base case\n        if root is None or root == p or root == q:\n            return root\n\n        # Traverse left and right subtrees\n        left = self.lowestCommonAncestor(root.left, p, q)\n        right = self.lowestCommonAncestor(root.right, p, q)\n\n        # Nodes are in different subtrees, so the current root is the lowest common ancestor.\n        if left and right:\n            return root\n\n        # Handle two cases:\n        # - one node is the descendant of the other\n        # - not finding either p or q, return none\n        return left if left else right\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   In the worse case, each node is visited once.</li> <li>Space complexity: \\(O(n)\\)   In the worst case (e.g., skewed trees), the recursive function call stack depth is \\(O(n)\\).</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#approach-2-iteration-with-stack","title":"Approach 2: Iteration with Stack","text":"<p>We can use iterative solution by using a stack for tree traversal and a hash table to store parent relationships.</p> <ol> <li>Traverse the tree and store parent pointers for each node using a hash table.</li> <li>Find ancestors of <code>p</code> and store them in a set.</li> <li>Trace up from <code>q</code> until we find the first common ancestor in the set.</li> </ol> python <pre><code>class Solution:\n    def lowestCommonAncestor(self, root: 'TreeNode', p: 'TreeNode', q: 'TreeNode') -&gt; 'TreeNode':\n        stack = [root]  # stack for traversal\n        parent = {root: None}  # node -&gt; parent\n\n        # Use DFS to build parent dictionary until both nodes' parents are found\n        while p not in parent or q not in parent:\n            node = stack.pop()\n            if node.left:\n                parent[node.left] = node\n                stack.append(node.left)\n            if node.right:\n                parent[node.right] = node\n                stack.append(node.right)\n\n        # Ancestors of node p (remove duplicates)\n        ancestors = set()\n        curr = p\n        while curr:\n            ancestors.add(curr)\n            curr = parent[curr]  # Move up to the parent\n\n        # Find the first ancestor of q that appears in the p's ancestors,\n        # which is the lowest common ancestor.\n        curr = q\n        while curr not in ancestors:\n            curr = parent[curr]\n\n        return curr\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)<ul> <li>In the worse case, traverse the tree once to build the parent mapping, which takes \\(O(n)\\).</li> <li>Find ancestors of both <code>p</code> and <code>q</code>, at most \\(O(h)\\) (where \\(h\\) is the tree height). In the worst case it is \\(O(n)\\).</li> <li>So the overall time complexity is \\(O(n) + O(n) = O(n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\)<ul> <li>Stack: in the worst case, it holds \\(n\\) nodes (skewed tree).</li> <li>Ancestor set: stores \\(h\\) nodes, in the worst case, it stores \\(n\\) nodes.</li> <li>Parent hash table: stores at most \\(n\\) nodes.</li> <li>So the overall space complexity is \\(O(n) + O(n) + O(n) = O(n)\\).</li> </ul> </li> </ul> <p>Note that</p> <ul> <li>Parent hash table allows efficient look of parent nodes in \\(O(1)\\)</li> <li>Ancestor set ensures fast ancestor checking in \\(O(1)\\).</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Recursion \\(O(n)\\) \\(O(n)\\) Approach - Iteration \\(O(n)\\) \\(O(n)\\)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#test","title":"Test","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0236-lowest-common-ancestor-of-a-binary-tree/#references","title":"References","text":"<ul> <li>Lowest Common Ancestor Binary Tree - Tushar Roy Youtube Channel</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0237-delete-node-in-a-linked-list/","title":"LC237. Delete Node in a Linked List","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0237-delete-node-in-a-linked-list/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 237: There is a singly-linked list\u00a0<code>head</code>\u00a0and we want to delete a node\u00a0<code>node</code>\u00a0in it.</p> <p>You are given the node to be deleted\u00a0<code>node</code>. You will\u00a0not be given access\u00a0to the first node of\u00a0<code>head</code>.</p> <p>All the values of the linked list are\u00a0unique, and it is guaranteed that the given node\u00a0<code>node</code>\u00a0is not the last node in the linked list.</p> <p>Delete the given node. Note that by deleting the node, we do not mean removing it from memory. We mean:</p> <ul> <li>The value of the given node should not exist in the linked list.</li> <li>The number of nodes in the linked list should decrease by one.</li> <li>All the values before\u00a0<code>node</code>\u00a0should be in the same order.</li> <li>All the values after\u00a0<code>node</code>\u00a0should be in the same order.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0237-delete-node-in-a-linked-list/#clarification","title":"Clarification","text":"<ul> <li>Give <code>node</code> to be deleted but not the head</li> <li>Not remove it from memory just remove the value from the list</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0237-delete-node-in-a-linked-list/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0237-delete-node-in-a-linked-list/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0237-delete-node-in-a-linked-list/#approach-delete-value","title":"Approach - Delete value","text":"<p>Without knowing the previous node, it is not possible to delete the current node. Since the given node is not a tail node and all node values are unique, we can delete the next node instead and coping its value to the current node.</p> Note <p>Remember to delete the node from memory.</p> Python <pre><code>class Solution:\n    def deleteNode(self, node):\n        \"\"\"\n        :type node: ListNode\n        :rtype: void Do not return anything, modify node in-place instead.\n        \"\"\"\n\n        if node.next:\n            next_node = node.next\n            node.val = next_node.val\n            node.next = next_node.next\n\n            next_node.next = None\n            del next_node\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0237-delete-node-in-a-linked-list/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(1)\\)     Since only 1 node is to be deleted. </li> <li>Space complexity: \\(O(1)\\)     Use constant space to track the next node.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0237-delete-node-in-a-linked-list/#test","title":"Test","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/","title":"LC240. Search a 2D Matrix II","text":"","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 240: Write an efficient algorithm that searches for a value\u00a0<code>target</code>\u00a0in an\u00a0<code>m x n</code>\u00a0integer matrix <code>matrix</code>. This matrix has the following properties:</p> <ul> <li>Integers in each row are sorted in ascending from left to right.</li> <li>Integers in each column are sorted in ascending from top to bottom.</li> </ul> <p></p> <p>Input: <code>matrix = [[1,4,7,11,15],[2,5,8,12,19],[3,6,9,16,22],[10,13,14,17,24],[18,21,23,26,30]]</code>, <code>target = 5</code> Output: <code>true</code> </p>","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#clarification","title":"Clarification","text":"<ul> <li>Search target in matrix</li> <li>row-wise and column-wise ascending</li> <li>return index or true/false</li> </ul>","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#assumption","title":"Assumption","text":"","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#solution","title":"Solution","text":"","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#approach-1-binary-search-by-row","title":"Approach 1 - Binary Search by Row","text":"<p>Go through each row and search each row by using binary search since it is sorted.</p> <p>Or we can go diagonally from top-right corner to bottom-left corner and then binary search row and column to find the target.</p> Python <pre><code>class Solution:\n    def searchMatrix(self, matrix: List[List[int]], target: int) -&gt; bool:\n        m, n = len(matrix), len(matrix[0])\n\n        for i_row in range(m):\n            left = 0\n            right = n - 1\n            while left &lt;= right:\n                mid = (left + right) // 2\n                if matrix[i_row][mid] == target:\n                    return True\n                elif target &lt; matrix[i_row][mid]:\n                    right = mid - 1\n                else:\n                    left = mid + 1\n\n        return False\n</code></pre>","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m \\log n)\\)   There are \\(m\\) rows and search each row takes at most \\(\\log n\\) steps using binary search.   In the worst case, it will search all rows, \\(m \\log n\\).</li> <li>Space complexity: \\(O(1)\\)   Use several variables to search</li> </ul>","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#approach-2-staircase-traversal","title":"Approach 2 - Staircase Traversal","text":"<p>Based on the sorted properties, we can use staircase traversal to search the target.</p> <p>Starting from bottom-left corner (top-right corner also works):</p> <ul> <li>if target == value, return true</li> <li>if target &gt; value, skip the current column</li> <li>if target &lt; value, skip the current row</li> </ul> Python <pre><code>class Solution:\n    def searchMatrix(self, matrix: List[List[int]], target: int) -&gt; bool:\n        m, n = len(matrix), len(matrix[0])\n\n        i_row, j_col = m - 1, 0\n\n        while i_row &gt;= 0 and j_col &lt; n:\n            if matrix[i_row][j_col] == target:\n                return True\n            elif matrix[i_row][j_col] &lt; target:\n                j_col += 1  # Remove the current column\n            else:\n                i_row -= 1  # Remove the current row\n\n        return False\n</code></pre>","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(m + n)\\)   Each step we skip one row or one column. In the worst case, we will search all rows   and all columns. So the time complexity is \\(O(m + n)\\).</li> <li>Space complexity: \\(O(1)\\)   Use several variables to search. No extra space is needed.</li> </ul>","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#approach-3-binary-search-by-sub-matrix","title":"Approach 3 - Binary Search by Sub Matrix","text":"<p>We can use a recursive divide-and-conquer approach, slicing the matrix into 4 quadrants based on a middle point:</p> <ul> <li>if target &lt; center element, bottom right quadrants can be excluded;</li> <li>if target &gt; center element, top left quadrants can be excluded; Continue to search the rest of 3 quadrants.</li> </ul> <pre><code>   zone 1      zone 2\n*  *  *  * | *  *  *  *\n*  *  *  * | *  *  *  *\n*  *  *  * | *  *  *  *\n*  *  *  * | *  *  *  *\n-----------------------\n*  *  *  * | *  *  *  *\n*  *  *  * | *  *  *  *\n*  *  *  * | *  *  *  *\n*  *  *  * | *  *  *  *\n  zone 3      zone 4\n</code></pre> PythonC++ <pre><code>class Solution:\n    def searchMatrix(self, matrix: List[List[int]], target: int) -&gt; bool:\n        return self.searchSubMatrix(matrix, target, 0, len(matrix) - 1, 0, len(matrix[0]) - 1)\n\n    def searchSubMatrix(self, matrix: list[list[int]], target: int, row_start: int, row_end: int, col_start: int, col_end: int) -&gt; bool:\n        # Base case\n        if row_start &gt; row_end or col_start &gt; col_end:\n            return False\n\n        # Find value in the middle of sub matrix\n        row_middle = row_start + (row_end - row_start) // 2\n        col_middle = col_start + (col_end - col_start) // 2\n        value_middle = matrix[row_middle][col_middle]\n\n        # Compare and recursively search 4 quadrants\n        if value_middle == target:\n            return True\n        elif value_middle &gt; target:\n            # Exclude quadrant 4, search quadrant 1 and 2, and quadrant 3\n            return self.searchSubMatrix(matrix, target, row_start, row_middle - 1, col_start, col_end) or \\\n                self.searchSubMatrix(matrix, target, row_middle, row_end, col_start, col_middle - 1)\n        else:\n            # Exclude quadrant 1, search quadrant 2, and quadrant 3 and 4\n            return self.searchSubMatrix(matrix, target, row_start, row_middle, col_middle + 1, col_end) or \\\n                self.searchSubMatrix(matrix, target, row_middle + 1, row_end, col_start, col_end)\n</code></pre> <pre><code>class Solution {\npublic:\n    bool searchMatrix(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int target) {\n        if (matrix.empty() || matrix[0].empty()) return false;\n\n        int nRow = matrix.size(); // number of rows\n        int nCol = matrix[0].size(); // number of columns\n\n        return searchSubMatrix(matrix, target, 0, nRow - 1, 0, nCol - 1);\n\n    }\n\n    bool searchSubMatrix(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int target, int rStart, int rEnd, int cStart, int cEnd) {\n        if ((rStart &gt; rEnd) || (cStart &gt; cEnd)) return false;\n\n        int rMid = rStart + (rEnd - rStart)/2;\n        int cMid = cStart + (cEnd - cStart)/2;\n        int midVal = matrix[rMid][cMid];\n\n        if (target == midVal) {\n            return true;\n        }\n        else if (target &lt; midVal) {\n            // Exclude zone 4; search zone 1 + zone 2 and zone 3\n            return searchSubMatrix(matrix, target, rStart, rMid - 1, cStart, cEnd)\n                || searchSubMatrix(matrix, target, rMid, rEnd, cStart, cMid - 1);\n        }\n        else {\n            // Exclude zone 1; search zone 3 + zone 4 and zone 2\n            return searchSubMatrix(matrix, target, rMid + 1, rEnd, cStart, cEnd)\n                || searchSubMatrix(matrix, target, rStart, rMid, cMid + 1, cEnd);\n        }\n    }\n};\n</code></pre>","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log (mn))\\)   Every step it excludes \\(1/4\\) quadrant and search the rest \\(1/2\\) and \\(1/4\\) sub matrices.   When formulate this search path as a tree, the worst path is search \\(1/2\\) the space   each step and the best path is search \\(1/4\\) space each step. In the worst case, the   search space is reduced by half each time. So the time complexity is   \\(O(\\log (mn))\\).</li> </ul> <pre><code>                1\n            /       \\\n          1/2       1/4\n         /   \\     /   \\\n       1/2   1/4 1/2   1/4\n</code></pre> <ul> <li>Space complexity: \\(O(\\log (mn))\\)   Need to recursive call functions at most \\(\\log (mn)\\) times and need to store function   call stack.</li> </ul>","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Binary Search by Row \\(O(m \\log n)\\) \\(O(1)\\) Approach - Staircase Traversal \\(O(m + n)\\) \\(O(1)\\) Approach - Binary Search by Sub Matrix \\(O(\\log (mn))\\) \\(O(\\log (mn))\\)","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0240-search-a-2d-matrix-ii/#test","title":"Test","text":"","tags":["Binary Search","Matrix","Divide and Conquer"]},{"location":"lc-solutions/lc0200-0299/lc0250-count-univalue-subtrees/","title":"LC250. Count Univalue Subtrees","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0250-count-univalue-subtrees/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 250: Given the\u00a0<code>root</code>\u00a0of a binary tree, return\u00a0the number of\u00a0uni-value subtrees.</p> <p>A\u00a0uni-value subtree\u00a0means all nodes of the subtree have the same value.</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0250-count-univalue-subtrees/#clarification","title":"Clarification","text":"<ul> <li>Not only direct children but all children to have the same values.</li> <li>Leaf nodes are uni-value subtree.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0250-count-univalue-subtrees/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0250-count-univalue-subtrees/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0250-count-univalue-subtrees/#approach-recursion","title":"Approach - Recursion","text":"<p>Bases on the definition, a univalue subtree meets the following criteria:</p> <ol> <li>The children are also uni-value subtrees.</li> <li>The children have the same value as the current node.</li> </ol> <p>Leaf nodes automatically meets above two conditions since it contains only that node.</p> <p>We can recursively iterate through left and right children of each node to see if the children from uni-value subtrees. We can increase the count if all children are from uni-value subtrees and have the same value as the current node.</p> <p>To facility recursively check and count, the function will return <code>(count, is_univalue_subtree)</code>.</p> Python <pre><code>class Solution:\n    def countUnivalSubtrees(self, root: Optional[TreeNode]) -&gt; int:\n        count, is_univalue = self.count_check_univalue_tree(root)\n        return count\n\n    def count_check_univalue_tree(self, root: Optional[TreeNode]) -&gt; tuple[int, bool]:\n        if root is None:\n            return (0, True)\n\n        if root.left is None and root.right is None:\n            return (1, True)\n\n        left_count, is_left_univalue = self.count_check_univalue_tree(root.left)\n        right_count, is_right_univalue = self.count_check_univalue_tree(root.right)\n\n        if (\n            is_left_univalue\n            and is_right_univalue\n            and (root.left is None or root.val == root.left.val)\n            and (root.right is None or root.val == root.right.val)\n        ):\n            return (left_count + right_count + 1, True)\n        else:\n            return (left_count + right_count, False)\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0250-count-univalue-subtrees/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Each node is visited once. The total number of nodes is \\(n\\).</li> <li>Space complexity: \\(O(n)\\)   The maximum recursive function call stack would be the tree's height, which in the   worst case would be \\(O(n)\\) when the tree is a straight line.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0250-count-univalue-subtrees/#test","title":"Test","text":"<ul> <li>Empty tree (<code>[]</code>)\u00a0\u2192 Should return\u00a0<code>0</code>.</li> <li>Single-node tree (<code>[1]</code>)\u00a0\u2192 Should return\u00a0<code>1</code>.</li> <li>All nodes same (<code>[5,5,5,5,5]</code>)\u00a0\u2192 Should return the total number of nodes.</li> <li>Test normal uni-value tree.</li> <li>Test a tree not a uni-value tree.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/","title":"253. Meeting Rooms II","text":"","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 253: Given an array of meeting time intervals\u00a0<code>intervals</code>\u00a0where <code>intervals[i] = [starti, endi]</code>, return\u00a0the minimum number of conference rooms required.</p> <p>Example 1:</p> <p>Input: intervals = [[0,30],[5,10],[15,20]] Output: 2</p> <p>Example 2:</p> <p>Input: intervals = [[7,10],[2,4]] Output: 1</p>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#clarification","title":"Clarification","text":"<ul> <li>Explain more on minimum number of conference rooms --&gt; most number of overlapped intervals?</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#solution","title":"Solution","text":"","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#approach-heap","title":"Approach - Heap","text":"<ul> <li>Like normal meetings, allocate rooms for meetings from earlier to later. So we first sort intervals by start time.</li> <li>The first room (don't care which room) gets freed up based on their end times can be used for the new meeting.</li> <li>We can use a min-heap to store the end times of the meetings in various rooms. It dynamically grows until reaching the minimum number of conference rooms:<ul> <li>Check the top element of the heap (end time), indicating the room that would be get free the earliest.<ul> <li>If it is not free, allocate a new room.</li> <li>If it is free, no need to allocate a new room.</li> </ul> </li> </ul> </li> </ul> Python <pre><code>import heapq\nfrom operator import itemgetter\n\nclass Solution:\n    def minMeetingRooms(self, intervals: List[List[int]]) -&gt; int:\n        # Sort intervals by start time.\n        intervals_sorted = sorted(intervals, key=itemgetter(0))\n\n        # Use a min heap to track the end times of ongoing meetings.\n        # (1)\n        min_heap = [intervals_sorted[0][1]]  # (2)\n        for start_time, end_time in intervals_sorted[1:]:\n            # (3)\n            if min_heap[0] &lt;= start_time:\n                heapq.heappop(min_heap)\n\n            # (4)\n            heapq.heappush(min_heap, end_time)\n\n        return len(min_heap)  #(5)\n</code></pre> <ol> <li>The heap represents active meeting rooms, with the earliest ending meeting time at the top.</li> <li>Add the end time of the first meeting.</li> <li>If the earliest ending meeting has already finished before the current one starts, remove it from the heap (freeing up a room).</li> <li>Add the current meeting's end time to heap.<ul> <li>If a room was freed in a previous step, the heap size remains the same.</li> <li>If no room was free,  a new room is allocated, increasing the heap size.</li> </ul> </li> <li>The heap size represents the number of rooms needed.</li> </ol>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li>Sorting the intervals takes \\(O(n \\log n)\\) time.</li> <li>Iterate all \\(n\\) intervals. For each iteration, it takes at least 1 heap operation, which takes \\(O(\\log s)\\) time where \\(s\\) is the size of the heap. In the worst case, the heap size could be \\(n\\). So the time complexity is \\(O(n \\log n)\\).</li> <li>So the total time complexity is \\(O(n \\log n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Sorting in Python takes \\(O(n)\\) space.</li> <li>Heap takes \\(O(n)\\) space in the worst case.</li> <li>So the total space complexity is \\(O(n)\\).</li> </ul> </li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#approach-2-separate-start-and-end-times","title":"Approach 2 - Separate Start and End Times","text":"<p>The start and end times don't need to be together. When start time of one meeting &gt; end time of any meeting, it indicates a room is available. We don't need to know which room is available.</p> <p>With separation of start and end times and sort them individually, we can track them separately:</p> <ul> <li>if start time &gt;= end time, the room is available and increase the end pointer;</li> <li>if start time &lt; end time, no room is available and allocate a new room.</li> </ul> python <pre><code>class Solution:\n    def minMeetingRooms(self, intervals: List[List[int]]) -&gt; int:\n        # Separate start and end times and sort them individually.\n        start_times_sorted = sorted([i[0] for i in intervals])\n        end_times_sorted = sorted([i[1] for i in intervals])\n\n        # Go through start times\n        n_rooms_needed = 0\n        end_pointer = 0\n        for start_time in start_times_sorted:\n            if start_time &gt;= end_times_sorted[end_pointer]:\n                end_pointer += 1\n            else:\n                n_rooms_needed += 1\n\n        return n_rooms_needed\n</code></pre>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li>Sorting start times takes \\(O(n \\log n)\\) time.</li> <li>Sorting end times takes \\(O(n \\log n)\\) time.</li> <li>Iterate all start times, which takes \\(O(n)\\).</li> <li>So the total time complexity is \\(O(n \\log n) + O(n \\log n) + O(n) = O(n \\log n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Start and end times take \\(O(n)\\) space.</li> <li>Sorting in Python takes \\(O(n)\\) space.</li> <li>So the total space complexity is \\(O(n) + O(n) + O(n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Heap \\(O(n \\log n)\\) \\(O(n)\\) Approach - \\(O(n \\log n)\\) \\(O(n)\\)","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0253-meeting-rooms-ii/#test","title":"Test","text":"<ul> <li>Non-overlapping meetings\u00a0\u2192 Needs only one room.</li> <li>Meetings that all overlap\u00a0\u2192 Requires\u00a0<code>n</code>\u00a0rooms.</li> <li>Large input size\u00a0\u2192 Sorting dominates runtime complexity.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/","title":"LC261. Graph Valid Tree","text":"","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 261: You have a graph of\u00a0<code>n</code>\u00a0nodes labeled from\u00a0<code>0</code>\u00a0to\u00a0<code>n - 1</code>. You are given an integer n and a list of <code>edges</code>\u00a0where\u00a0<code>edges[i] = [ai, bi]</code>indicates that there is an undirected edge between nodes\u00a0<code>ai</code>\u00a0and\u00a0<code>bi</code>\u00a0in the graph.</p> <p>Return\u00a0<code>true</code> if the edges of the given graph make up a valid tree, and <code>false</code> otherwise.</p>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#clarification","title":"Clarification","text":"<ul> <li>Undirected graph</li> <li>Definition of valid tree</li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#solution","title":"Solution","text":"<p>There are different solutions based on the definition of a valid tree. In general, there are two kinds of definitions:</p> <ul> <li>Basic<ul> <li>The graph is fully connected.</li> <li>The graph contains no cycle.</li> </ul> </li> <li>Advanced<ul> <li>The graph is fully connected.</li> <li>The graph has exactly \\(n - 1\\) edges. Any less, it can't possibly be fully connected. Any more, it contains cycles.</li> </ul> </li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#approach-1-basic-graph-theory-dfsbfs","title":"Approach 1 - Basic Graph Theory + DFS/BFS","text":"<p>Start from the basic definition,</p> <ul> <li>Check whether the graph is fully connected, <code>len(visited) == n</code></li> <li>Detect a cycle<ul> <li>Since it is an undirected graph, we need to exclude a trivia cycle, <code>A - B - A</code>. Check whether <code>next_node == parent of current node</code></li> <li>Detect a real cycle, <code>next node is in visited</code></li> </ul> </li> </ul> <p>We can use depth-first search (DFS) or breadth-first search (BFS) to traverse the graph and mark visited node. If detect a cycle or not able to visited all nodes, return False.</p> Python - DFSPython - DFS - VisitedPython - BFSPython - BFS - Visited <pre><code>class Solution:\n    def validTree(self, n: int, edges: List[List[int]]) -&gt; bool:\n\n        adjacent_list = [[] for _ in range(n)]\n        for edge in edges:\n            adjacent_list[edge[0]].append(edge[1])\n            adjacent_list[edge[1]].append(edge[0])\n        parent = {0: -1}  # (1)\n\n        return self.dfs(0, adjacent_list, parent) and len(parent) == n\n\n    def dfs(self, current_node: int, adjacent_list: List[List[int]], \n            parent: Dict[int, int]) -&gt; bool:\n        for next_node in adjacent_list[current_node]:\n            if next_node == parent[current_node]:  # (2)\n                continue\n            if next_node in parent:  # (3)\n                return False\n            # The node is not visited or parent node\n            parent[next_node] = current_node\n            if not self.dfs(next_node, adjacent_list, parent):  #(4)\n                return False\n\n        return True\n</code></pre> <ol> <li>key: current node, value: parent node.</li> <li>Exclude trivia cycle <code>A -&gt; B -&gt; A</code>. The key, current_node, is already in the parent before calling dfs function. Otherwise, need to use <code>parent.get(current_node, -1)</code>.</li> <li>If the node is visited, there is a cycle.</li> <li>Early termination.</li> </ol> <pre><code>class Solution:\ndef validTree(self, n: int, edges: List[List[int]]) -&gt; bool:\n\n    adjacent_list = [[] for _ in range(n)]\n    for edge in edges:\n        adjacent_list[edge[0]].append(edge[1])\n        adjacent_list[edge[1]].append(edge[0])\n    visited = set([0])\n    return self.dfs(0, -1, adjacent_list, visited) and len(visited) == n\n\ndef dfs(self, current_node: int, parent_node: int, adjacent_list: List[List[int]], \n        visited: Set[int]) -&gt; bool:  # (1)\n    for next_node in adjacent_list[current_node]:\n        if next_node == parent_node:\n            continue\n        if next_node in visited:\n            return False\n        # The node is not visited or parent node\n        visited.add(next_node)\n        if not self.dfs(next_node, current_node, adjacent_list, visited):\n            return False\n\n    return True\n</code></pre> <ol> <li>Use two parameters, <code>visited</code> and <code>parent_node</code>, instead of one <code>parent</code> dictionary</li> </ol> <pre><code>from collections import deque\n\nclass Solution:\n    def validTree(self, n: int, edges: List[List[int]]) -&gt; bool:\n\n        adjacent_list = [[] for _ in range(n)]\n        for edge in edges:\n            adjacent_list[edge[0]].append(edge[1])\n            adjacent_list[edge[1]].append(edge[0])\n        parent = {}\n        return self.bfs(0, adjacent_list, parent) and len(parent) == n\n\n    def bfs(self, node: int, adjacent_list: List[List[int]], \n            parent: Dict[int, int]) -&gt; bool:\n        queue = deque([node])\n        parent[node] = -1  # (1)\n        while queue:\n            current_node = queue.popleft()\n            for next_node in adjacent_list[current_node]:\n                if next_node == parent[current_node]:  # (2)\n                    continue\n                if next_node in parent:  # (3)\n                    return False\n                # The node is not visited or parent node\n                parent[next_node] = current_node\n                queue.append(next_node)\n\n        return True\n</code></pre> <ol> <li>Set parent of root node to <code>-1</code>, indicating no parent node.</li> <li>Exclude trivia cycle <code>A -&gt; B -&gt; A</code>. The key, current_node, is already in the  parent before calling dfs function. Otherwise, need to use <code>parent.get(current_node, -1)</code>.</li> <li>If the node is visited, there is a cycle.</li> </ol> <pre><code>from collections import deque\n\nclass Solution:\n    def validTree(self, n: int, edges: List[List[int]]) -&gt; bool:\n\n        adjacent_list = [[] for _ in range(n)]\n        for edge in edges:\n            adjacent_list[edge[0]].append(edge[1])\n            adjacent_list[edge[1]].append(edge[0])\n        visited = set()\n        return self.bfs(0, adjacent_list, visited) and len(visited) == n\n\n    def bfs(self, node: int, adjacent_list: List[List[int]], visited: Set[int]) -&gt; bool:\n        queue = deque([(node, -1)])  # (1)\n        visited.add(node)\n        while queue:\n            current_node, parent_node = queue.popleft()\n            for next_node in adjacent_list[current_node]:\n                if next_node == parent_node:\n                    continue\n                if next_node in visited:\n                    return False\n                # The node is not visited or parent node\n                visited.add(next_node)\n                queue.append((next_node, current_node))\n\n        return True\n</code></pre> <ol> <li>Store <code>(current_node, parent_node)</code> pair in the queue and therefore can use  <code>visited</code> set instead of <code>parent</code> dictionary.</li> </ol>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(V + E)\\) where \\(V\\) is number of vertices and \\(E\\) is number of edges   The total time complexity consists of<ul> <li>Initialize the adjacent list, taking \\(O(V)\\)</li> <li>Convert from edges to adjacent list, taking \\(O(E)\\)</li> <li>For traversing, the outer loop will run \\(V\\) times to go through each node exact once even the node has no neighbors. The inner loop, it iterates over the adjacent edges once. In total, all \\(E\\) edges are iterated over once by the inner loop. Therefore, this gives \\(O(V + E)\\) for traversing.     so the total time complexity is \\(O(V) + O(E) + O(V + E) = O(V + E)\\).</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li>The adjacent list is a list of length \\(V\\) (stores all nodes) with inner lists with lengths that are added to a total of \\(E\\) (edges), which takes \\(O(V + E)\\).</li> <li><code>visited</code> or <code>parent</code> stores all nodes in the worst takes, taking \\(O(V)\\)</li> <li>The recursive <code>dfs</code> calls takes at most \\(V\\) times or the <code>queue</code> stores all \\(V\\) nodes in the worst case, which takes \\(O(V)\\).   So the total space complexity is \\(O(V + E) + O(V) + O(V) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#approach-2-advanced-graph-theory-dfsbfs","title":"Approach 2 - Advanced Graph Theory + DFS/BFS","text":"<p>Start from advanced definition of tree:</p> <ul> <li>The graph is fully connected -&gt; check whether traverse all nodes from one node</li> <li>The graph has exactly \\(n - 1\\) edges -&gt; Check whether there are \\(n - 1\\) edges</li> </ul> <p>We can use either DFS or BFS to traverse the graph to check the connectivity.</p> Python - DFSPython - BFS <pre><code>class Solution:\ndef validTree(self, n: int, edges: List[List[int]]) -&gt; bool:\n    if len(edges) != n - 1:  # (1)\n        return False\n\n    adjacent_list = [[] for _ in range(n)]\n    for edge in edges:\n        adjacent_list[edge[0]].append(edge[1])\n        adjacent_list[edge[1]].append(edge[0])\n    visited = set()\n    self.dfs(0, adjacent_list, visited)\n    return len(visited) == n\n\ndef dfs(self, node: int, adjacent_list: List[List[int]], visited: Set[int]) -&gt; None:\n    visited.add(node)\n    for next_node in adjacent_list[node]:\n        if next_node in visited:  # (2)\n            continue\n        self.dfs(next_node, adjacent_list, visited)\n</code></pre> <ol> <li>Check the condition 2 of advanced conditions</li> <li>prevent from stucking in an infinite loop if there are indeed cycles (or prevent from looping on the trivial cycles)</li> </ol> <pre><code>from collections import deque\n\nclass Solution:\n    def validTree(self, n: int, edges: List[List[int]]) -&gt; bool:\n        if len(edges) != n - 1:  # (1)\n            return False\n\n        adjacent_list = [[] for _ in range(n)]\n        for edge in edges:\n            adjacent_list[edge[0]].append(edge[1])\n            adjacent_list[edge[1]].append(edge[0])\n        visited = set()\n        self.bfs(0, adjacent_list, visited)\n        return len(visited) == n\n\n    def bfs(self, node: int, adjacent_list: List[List[int]], visited: Set[int]) -&gt; None:\n        queue = deque([node])\n        visited.add(node)\n        while queue:\n            current_node = queue.popleft()\n            for next_node in adjacent_list[current_node]:\n                if next_node in visited:  # (2)\n                    continue\n                visited.add(next_node)\n                queue.append(next_node)\n</code></pre> <ol> <li>Check the condition 2 of advanced conditions</li> <li>prevent from stucking in an infinite loop if there are indeed cycles (or prevent from looping on the trivial cycles)</li> </ol>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(V)\\) where \\(V\\) is the number of nodes   Note that \\(O(E) = O(V)\\) this time since <code>number of edges == number of nodes - 1</code>.   The total time complexity consists of<ul> <li>Initialize the adjacent list, taking \\(O(V)\\)</li> <li>Convert from edges to adjacent list, taking \\(O(E) = O(V)\\).</li> <li>For traversing, the outer loop will run \\(V\\) times to go through each node exact once even the node has no neighbors. The inner loop, it iterates over the adjacent  edges once. In total, all \\(E\\) edges are iterated over once by the inner loop.  Therefore, this gives \\(O(V + E) = O(V)\\) for traversing.    so the total time complexity is \\(O(V) + O(V) + O(V + V) = O(V)\\).</li> </ul> </li> <li>Space complexity: \\(O(V)\\) <ul> <li>The adjacent list is a list of length \\(V\\) (stores all nodes) with inner lists with lengths that are added to a total of \\(E\\) (edges), which takes \\(O(V + E) = O(V)\\).</li> <li><code>visited</code> or <code>parent</code> stores all nodes in the worst takes, taking \\(O(V)\\)</li> <li>The <code>queue</code> will store all nodes (total number of \\(V\\)) or <code>dfs</code> recursive function calls \\(V\\) times in the worse case, taking \\(O(V)\\) space.   So the total space complexity is \\(O(V) + O(V) + O(V) = O(V)\\).</li> </ul> </li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#approach-3-advanced-graph-theory-union-find","title":"Approach 3 - Advanced Graph Theory + Union Find","text":"<p>Based on the advanced definition, we can also use union find to check whether a single connected component is formed (indicating connectivity).</p> python <pre><code>class UnionFind:\ndef __init__(self, size):\n    self.root = [i for i in range(size)]\n    self.rank = [0 for _ in range(size)]\n    self.count = size\n\ndef find(self, x):\n    if x == self.root[x]:\n        return x\n\n    self.root[x] = self.find(self.root[x])\n    return self.root[x]\n\ndef union(self, x, y):\n    root_x = self.find(x)\n    root_y = self.find(y)\n\n    if root_x != root_y:\n        if self.rank[root_x] &gt; self.rank[root_y]:\n            self.root[root_y] = root_x\n        elif self.rank[root_x] &lt; self.rank[root_y]:\n            self.root[root_x] = root_y\n        else:\n            self.root[root_y] = root_x\n            self.rank[root_x] += 1\n        self.count -= 1\n\n\nclass Solution:\n    def validTree(self, n: int, edges: List[List[int]]) -&gt; bool:\n        if len(edges) != n - 1:\n            return False\n\n        uf = UnionFind(n)\n        for edge in edges:\n            uf.union(edge[0], edge[1])\n\n        return uf.count == 1\n</code></pre>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(V \\alpha(V))\\)   In the worst case, the number of edges equals the number of vertices. Then, go through   each of the \\(E\\) edges (\\(E = V\\)) and add them to the <code>UnionFind</code> data structure by   using the <code>union</code> function. The union function takes amortized \\(O(\\alpha(n))\\),   where \\(\\alpha\\) is the Inverse Ackermann Function.   So the total time complexity is \\(O(E \\alpha(E)) = O(V \\alpha(V))\\).</li> <li>Space complexity: \\(O(V)\\)   The <code>UnionFind</code> data structure requires \\(O(V)\\) space to store the <code>root</code> and <code>rank</code>.</li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Basic + DFS/BFS \\(O(V + E)\\) \\(O(V + E)\\) Approach - Advance + DFS/BFS \\(O(V)\\) \\(O(V)\\) Approach - Advance + Union Find \\(O(V \\alpha(V))\\) \\(O(V)\\)","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0261-graph-valid-tree/#test","title":"Test","text":"","tags":["Breadth-First Search","Depth-First Search","Union Find","Graph"]},{"location":"lc-solutions/lc0200-0299/lc0269-alien-dictionary/","title":"LC269. Alien Dictionary","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0269-alien-dictionary/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 269: There is a new alien language that uses the English alphabet. However, the order of the letters is unknown to you.</p> <p>You are given a list of strings\u00a0<code>words</code>\u00a0from the alien language's dictionary. Now it is claimed that the strings in\u00a0<code>words</code>\u00a0are\u00a0sorted lexicographically by the rules of this new language.</p> <p>If this claim is incorrect, and the given arrangement of string in\u00a0<code>words</code>\u00a0cannot correspond to any order of letters,\u00a0return\u00a0<code>\"\".</code></p> <p>Otherwise, return\u00a0a string of the unique letters in the new alien language sorted in lexicographically increasing order by the new language's rules. If there are multiple solutions, return\u00a0any of them.</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0269-alien-dictionary/#clarification","title":"Clarification","text":"<ul> <li>The order is unknown.</li> <li>The order could be in correct in <code>words</code></li> <li>When it is correct, return unique letters in order by the new rule</li> <li>Are letters in lower case or capital one?</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0269-alien-dictionary/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0269-alien-dictionary/#solution","title":"Solution","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0269-alien-dictionary/#approach-topological-sort","title":"Approach - Topological Sort","text":"<p>The problem can be viewed as a graph:</p> <ul> <li>Each character is a vertex.</li> <li>Order of letters (a in front of b) is a directed edge from a to b.</li> </ul> <p>To solve the problem, we need to</p> <ol> <li>Build the graph based on the order of words.<ul> <li>Compare adjacent words to find edges.<ul> <li>If two words differ at the first mismatched letter, add a directed edge from the letter in the first word to the letter in the second.</li> <li>If a word is a prefix of another, the input is invalid (e.g., <code>[\"abc\", \"ab\"]</code>. The correct order should be <code>[\"ab\", \"abc\"]</code>).</li> </ul> </li> <li>Count the in-degree (number of incoming edges) for each nod.</li> </ul> </li> <li>Perform topological sort to find the order of letters.<ul> <li>Use a queue to perform a BFS for topological sorting:<ul> <li>Start with all nodes that have zero in-degree.</li> <li>Remove edges from the graph as nodes are visited.</li> </ul> </li> <li>If the graph has a cycle, the topological sort will fail (not all nodes will be visited).</li> </ul> </li> </ol> Python <pre><code>from collections import defaultdict, deque\n\n\nclass Solution:\n    def alienOrder(self, words: List[str]) -&gt; str:\n\n        # (1)\n        adj_list = defaultdict(set)\n        in_degree = {char: 0 for word in words for char in word}  #(2)\n\n        # (3)\n        for word1, word2 in zip(words, words[1:]):\n            for char1, char2 in zip(word1, word2):\n                # Find the first difference and create an edge\n                if char1 != char2:\n                    if char2 not in adj_list[char1]:\n                        adj_list[char1].add(char2)\n                        in_degree[char2] += 1\n                    break\n            else:\n                # (4)\n                if len(word2) &lt; len(word1):\n                    return \"\"\n\n        # (5)\n        ordered_chars = []\n        zero_in_degree_chars = [char for char in in_degree if in_degree[char] == 0]\n        zero_in_degree_queue = deque(zero_in_degree_chars)\n        while zero_in_degree_queue:\n            curr_char = zero_in_degree_queue.popleft()\n            ordered_chars.append(curr_char)\n\n            for next_char in adj_list[curr_char]:\n                in_degree[next_char] -= 1\n                if in_degree[next_char] == 0:\n                    zero_in_degree_queue.append(next_char)\n\n        if len(ordered_chars) == len(in_degree):\n            return \"\".join(ordered_chars)\n        else:\n            return \"\"  # (6)\n</code></pre> <ol> <li>Initialize adjacent list and in-degree dictionary.</li> <li>Initialize all letters with default in-degree <code>0</code>. Later, when building adjacent list no need to check all letters to set them to 0.</li> <li>Build adjacent list and count in-degrees.</li> <li>Check for invalid input (prefix case), where second word isn't a prefix of first word.</li> <li>Perform topological sort.</li> <li>There is a cycle.</li> </ol>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0269-alien-dictionary/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(C + V + E)\\) where \\(C\\) is the total number of letters in all words, \\(V\\) is the number of unique letters, and \\(E\\) is the total number of edges.<ul> <li>Loop through all letters in all words to initialize in-degree dictionary takes \\(O(C)\\), where \\(C\\) is the total number of letters in all words.</li> <li>Build adjacent list may go through all letters in the worst case, which takes \\(O(C)\\).</li> <li>Topological sort initialization iterates over the nodes (unique letters) in <code>in_degree</code>, which takes \\(O(V)\\), where \\(V\\) is the number of unique letters. Then enqueue all nodes with zero in-degree, which takes time less than \\(O(V)\\). So the initialization takes \\(O(V)\\).</li> <li>Topological sort execution takes \\(O(V + E)\\):<ul> <li>For queue operations, each node is dequeued and processed exactly once, which takes \\(O(V)\\).</li> <li>For neighboring explorations, the outgoing edges of each dequeued node are traversed to update the in-degrees of its neighbors. The total number of outgoing edges processed is \\(O(E)\\), as each edge is processed exactly once.</li> </ul> </li> <li>So the total time complexity is \\(O(C) + O(C) + O(V) + O(V + E) = O(C + V + E)\\)</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\)<ul> <li>In-degree dictionary tracks the in degree of all \\(V\\) nodes, takes \\(O(V)\\) space.</li> <li>The adjacent list stores all \\(V\\) nodes and all \\(E\\) edges, which takes \\(O(V + E)\\) space.</li> <li>The queue in the worst case may store all \\(V\\) nodes, which takes \\(O(V)\\) space.</li> <li>The result list holds all \\(V\\) nodes, taking \\(O(V)\\) space.</li> <li>So the total space complexity is \\(O(V) + O(V + E) + O(E) + O(V) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0269-alien-dictionary/#test","title":"Test","text":"<ul> <li>Single word (<code>words=[\"abc\"]</code>): Order is the word\u2019s characters (<code>\"abc\"</code>).</li> <li>No valid order due to cycles (<code>words=[\"z\",\"x\",\"z\"]</code>).</li> <li>Completely independent characters (<code>words=[\"a\",\"b\",\"c\"]</code>): Any order works (<code>\"abc\"</code>, <code>\"bac\"</code>, etc.).</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/","title":"LC274. H-Index","text":"","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 274: Given an array of integers\u00a0<code>citations</code>\u00a0where\u00a0<code>citations[i]</code>\u00a0is the number of citations a researcher received for their\u00a0<code>ith</code>\u00a0paper, return\u00a0the researcher's h-index.</p> <p>According to the\u00a0definition of h-index on Wikipedia: The h-index is defined as the maximum value of\u00a0<code>h</code>\u00a0such that the given researcher has published at least\u00a0<code>h</code>\u00a0papers that have each been cited at least\u00a0<code>h</code>\u00a0times.</p>","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#clarification","title":"Clarification","text":"","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#assumption","title":"Assumption","text":"","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#solution","title":"Solution","text":"","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#approach-sort-binary-search","title":"Approach - Sort + Binary Search","text":"<p>We can sort the <code>citations</code> first. Then problem is the same as LC275 H-Indx II. We can use binary search to find the solution</p> Python <pre><code>class Solution:\n    def hIndex(self, citations: List[int]) -&gt; int:\n        citations_sorted = sorted(citations)\n\n        n = len(citations)\n        left, right = 0, len(citations) - 1\n\n        while left &lt; right:\n            mid = (left + right) // 2\n            if citations_sorted[mid] &gt;= n - mid:\n                right = mid\n            else:\n                left = mid + 1\n\n        if citations_sorted[right] &gt;= n - right:\n            return n - right\n        else:\n            return 0\n</code></pre>","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) The sorting time complexity is \\(O(n \\log n)\\) and the binary search after sorting is \\(O(\\log n)\\). So the total time complexity is \\(O(\\log n)\\)</li> <li>Space complexity: \\(O(1)\\) Only use several variables.</li> </ul>","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#approach-counting-sort","title":"Approach - Counting Sort","text":"<p>The result is within the range <code>[0, len(citations)]</code>, since we can't h-index &gt; the total number of papers published from definition. So we can create an array <code>count</code> to store the counts:</p> <ul> <li>For any paper with <code>citations == i</code>, increase <code>count[i]</code> by 1</li> <li>For any paper with <code>citations &gt; n</code>, increase <code>count[n]</code> by 1</li> </ul> <p>Then iterate backwards from the highest index of <code>count</code> and add total counts. When total counts exceed the <code>index</code> of the <code>count</code>, it means that we have the <code>index</code> number of papers that have <code>citations &gt;= index</code>.</p> Python <pre><code>class Solution:\n    def hIndex(self, citations: List[int]) -&gt; int:\n        n = len(citations)\n        count = [0] * (n + 1)\n\n        for c in citations:\n            if c &gt; n:\n                count[n] += 1\n            else:\n                count[c] += 1\n\n        total = 0\n        for idx in range(n, -1, -1):\n            total += count[idx]\n            if total &gt;= idx:\n                return idx\n\n        return 0\n</code></pre>","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\) It takes \\(n\\) steps to fill the <code>count</code> array and at most \\(n + 1\\) steps to go through <code>count</code>. So the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) It needs <code>count</code> array with \\(n + 1\\) elements.</li> </ul>","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Sort + Binary Search \\(O(n \\log n)\\) \\(O(1)\\) Approach - Counting Sort \\(O(n)\\) \\(O(n)\\)","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0274-h-index/#test","title":"Test","text":"","tags":["Sorting"]},{"location":"lc-solutions/lc0200-0299/lc0275-h-index-ii/","title":"LC275. H-Index II","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0275-h-index-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 275: Given an array of integers\u00a0<code>citations</code>\u00a0where\u00a0<code>citations[i]</code>\u00a0is the number of citations a researcher received for their\u00a0<code>ith</code>\u00a0paper and\u00a0<code>citations</code>\u00a0is sorted in\u00a0ascending order, return\u00a0the researcher's h-index.</p> <p>According to the\u00a0definition of h-index on Wikipedia: The h-index is defined as the maximum value of\u00a0<code>h</code>\u00a0such that the given researcher has published at least\u00a0<code>h</code>\u00a0papers that have each been cited at least\u00a0<code>h</code>\u00a0times.</p> <p>You must write an algorithm that runs in logarithmic time.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0275-h-index-ii/#clarification","title":"Clarification","text":"<ul> <li>citations is sorted in ascending order</li> <li>h-index definition</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0275-h-index-ii/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0275-h-index-ii/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0275-h-index-ii/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since the citation array is sorted in ascending order, for index <code>i</code> (0-based), it has <code>citations[i]</code> and <code>n - i</code> (if <code>i</code> is 1-based index, it will be <code>n - i + 1</code>) papers with <code>citations[j] &gt;= citations[i]</code>, where <code>j &gt;= i</code>. Essentially, the problem is to find the first index where </p> \\[\\text{citations}[i] &gt;= n - i\\] <p>Note that if \\(\\text{citations}[i] &gt;= n - i\\), then any <code>j</code> with <code>j &gt; i</code> also satisfies the equation, \\(\\text{citations}[j] &gt;= \\text{citations}[j] &gt;= n - i &gt; n - j\\).</p> Python <pre><code>class Solution:\n    def hIndex(self, citations: List[int]) -&gt; int:\n        n = len(citations)\n        left, right = 0, n - 1\n\n        '''\n        1 2 3 4 5\n        0 1 2 3 4\n        [0 1 3 5 6]\n            l\n            r \n                r\n        '''\n        while left &lt; right:\n            mid = (left + right) // 2\n            if citations[mid] &gt;= n - mid:\n                right = mid\n            else:\n                left = mid + 1\n\n        if n - right &lt;= citations[right]:\n            return n - right\n        else:\n            return 0\n</code></pre> <ol> <li>Handle empty array or array with only 1 element</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0275-h-index-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) Since using the binary search, so the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\) Only use two index variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0275-h-index-ii/#test","title":"Test","text":"<ul> <li>Empty array</li> <li>Array with 1 element</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/","title":"276. lc0276 paint fence","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 276: You are painting a fence of\u00a0<code>n</code>\u00a0posts with\u00a0<code>k</code>\u00a0different colors. You must paint the posts following these rules:</p> <ul> <li>Every post must be painted\u00a0exactly one\u00a0color.</li> <li>There\u00a0cannot\u00a0be three or more\u00a0consecutive\u00a0posts with the same color.</li> </ul> <p>Given the two integers\u00a0<code>n</code>\u00a0and\u00a0<code>k</code>, return\u00a0the\u00a0number of ways\u00a0you can paint the fence.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#assumption","title":"Assumption","text":"<ul> <li>k &gt; 1 for n &gt; 2</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#solution","title":"Solution","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#approach-1-dynamic-programming","title":"Approach 1: Dynamic Programming","text":"<p>The problem can be solved using dynamic programming:</p> <ul> <li>State: <code>total_ways[i]</code> represents the number of ways to paint the first <code>i</code> posts.</li> <li>Transition: there are two scenarios to consider.<ul> <li>If using a different color than the previous post, there are <code>k - 1</code> options for the current post. So there are <code>(k - 1) * total_ways[i - 1]</code> ways to paint <code>i</code> posts for this scenario.</li> <li>If using the same color as the previous post, there is only one color to use, so there are <code>1 * total_ways[i - 1]</code> ways to paint the <code>ith</code> post. However the restriction is \"cannot be three or more consecutive posts with the same color.\" The number of ways to paint the <code>(i-1)th</code> post a different color from the <code>(i-2)th</code> post is <code>(k - 1) * total_ways[i - 2]</code>. So there are <code>1 * total_ways[i - 1] (different color from i - 2) = (k - 1) * total_ways[i - 2]</code> to paint <code>i</code> posts for this scenario.</li> <li>Add above two scenarios together: <code>total_ways[i] = (k - 1) * total_ways[i - 1] + (k - 1) * total_ways[i - 2]</code></li> </ul> </li> <li>Base Case:<ul> <li><code>total_ways[1] = k</code> (the first post)</li> <li><code>total_ways[2] = k * k</code> (the first two posts, which can have the same color)</li> </ul> </li> </ul> Python <pre><code>class Solution:\n    def numWays(self, n: int, k: int) -&gt; int:\n        if n == 1:\n            return k\n\n        total_ways_prev_prev = k\n        total_ways_prev = k * k\n        for i in range(3, n + 1):\n            total_ways_curr = (k - 1) * total_ways_prev + (k - 1) * total_ways_prev_prev\n            total_ways_prev, total_ways_prev_prev = total_ways_curr, total_ways_prev\n\n        return total_ways_prev\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Need to iterate over <code>n</code> posts and each iteration takes \\(O(1)\\) time. So the total time   complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(1)\\)   Only use 3 local variables to store values which are independent of input size.</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#approach-2","title":"Approach 2:","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0276-paint-fence/#test","title":"Test","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0200-0299/lc0278-first-bad-version/","title":"LC278. First Bad Version","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0278-first-bad-version/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 278: You are a product manager and currently leading a team to develop a new product. Unfortunately, the latest version of your product fails the quality check. Since each version is developed based on the previous version, all the versions after a bad version are also bad.</p> <p>Suppose you have\u00a0<code>n</code>\u00a0versions\u00a0<code>[1, 2, ..., n]</code>\u00a0and you want to find out the first bad one, which causes all the following ones to be bad.</p> <p>You are given an API\u00a0<code>bool isBadVersion(version)</code>\u00a0which returns whether\u00a0<code>version</code>\u00a0is bad. Implement a function to find the first bad version. You should minimize the number of calls to the API.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0278-first-bad-version/#clarification","title":"Clarification","text":"<ul> <li>[1, 2, ..., n] versions</li> <li>find out the first bad version</li> <li>requirement: minimize the number of calls to the API</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0278-first-bad-version/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0278-first-bad-version/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0278-first-bad-version/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Each version in [1, 2, ..., n] has its status in good (\\(0\\)) or bad (\\(1\\)):</p> \\[\\begin{bmatrix}1 &amp; 2 &amp; \\cdots &amp; i &amp; i + 1 &amp; \\cdots n \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 1 &amp; \\cdots &amp; 1 \\end{bmatrix}\\] <p>The status array consists of just two statuses and is sorted. So we can use binary search to find the first bad version effectively.</p> Python <pre><code>class Solution:\n    def firstBadVersion(self, n: int) -&gt; int:\n        left, right = 0, n\n\n        while left &lt; right:\n            mid = (left + right) // 2\n\n            if isBadVersion(mid):\n                right = mid\n            else:\n                left = mid + 1\n\n        return left\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0278-first-bad-version/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)     Since using binary search, the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\)     Only use two index variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0278-first-bad-version/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0200-0299/lc0279-perfect-squares/","title":"LC279. Perfect Squares","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0279-perfect-squares/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 279: Given an integer\u00a0<code>n</code>, return\u00a0the least number of perfect square numbers that sum to <code>n</code>.</p> <p>A\u00a0perfect square\u00a0is an integer that is the square of an integer; in other words, it is the product of some integer with itself. For example,\u00a0<code>1</code>,\u00a0<code>4</code>,\u00a0<code>9</code>, and\u00a0<code>16</code>\u00a0are perfect squares while\u00a0<code>3</code>\u00a0and\u00a0<code>11</code>\u00a0are not.</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0279-perfect-squares/#clarification","title":"Clarification","text":"<ul> <li>definition of perfect square number</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0279-perfect-squares/#assumption","title":"Assumption","text":"<ul> <li>integer is positive</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0279-perfect-squares/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0279-perfect-squares/#approach-bfs","title":"Approach - BFS","text":"<p>Add the current node to the graph and go through all perfect square &lt; node, add remain value (node - square value) to the queue. Then go layer by layer until find a number that is perfect square. The number of steps is the least number of perfect squares</p> <p></p> <p>The above image is from editorial solution.</p> Python <pre><code>from collections import deque\nimport math\n\nclass Solution:\n    def numSquares(self, n: int) -&gt; int:\n        queue = deque()\n        visited = set()\n\n        queue.append(n)\n        visited.add(n)\n        count = 1\n\n        while queue:\n            current_level_node_count = len(queue)\n            for _ in range(current_level_node_count):\n                value = queue.popleft()\n                sqrt_value = math.isqrt(value)\n                if value == sqrt_value ** 2:\n                    return count\n\n                for i_sqrt in range(1, sqrt_value + 1):\n                    remain_value = value - i_sqrt ** 2\n                    if remain_value not in visited:\n                        queue.append(remain_value)\n            count += 1\n\n        return 0\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0279-perfect-squares/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li> <p>Time complexity: \\(O(n \\sqrt{n})\\) or \\(O(n)\\)     In the worst case, it will explore \\(n\\) nodes. So time complexity is \\(O(n)\\). Additional information:</p> <ul> <li>4-Square theorem: Every natural no is sum of 4 squares.</li> <li>Python <code>math.isqrt</code> run time is \\(O((\\log(n))^(\\log(3)/\\log(2)))\\), as explained in this article.</li> </ul> </li> <li> <p>Space complexity: \\(O(\\sqrt{n})\\)     In the worst case, both queue and set will store values of number, \\(\\sqrt{n}\\).</p> </li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0279-perfect-squares/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/","title":"LC286. Walls and Gates","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 286: You are given an\u00a0<code>m x n</code>\u00a0grid\u00a0<code>rooms</code>\u00a0initialized with these three possible values.</p> <ul> <li><code>-1</code>\u00a0A wall or an obstacle.</li> <li><code>0</code>\u00a0A gate.</li> <li><code>INF</code>\u00a0Infinity means an empty room. We use the value\u00a0<code>231 - 1 = 2147483647</code>\u00a0to represent\u00a0<code>INF</code>\u00a0as you may assume that the distance to a gate is less than\u00a0<code>2147483647</code>.</li> </ul> <p>Fill each empty room with the distance to\u00a0its nearest gate. If it is impossible to reach a gate, it should be filled with\u00a0<code>INF</code>.</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#clarification","title":"Clarification","text":"<ul> <li>There are multiple gates. Room value is the steps to the nearest gate.</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#assumption","title":"Assumption","text":"<ul> <li>If the room can be reached, steps to the gate &lt; <code>Inf</code></li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#approach-bfs-1-gate","title":"Approach - BFS 1 Gate","text":"<p>Find gate one at a time and use breadth-first search to search all rooms the gate can reach and update room value if is smaller.</p> <p>Note that no need to store visited rooms since room value reflects whether it is visited. Another trick is to update the room value based on last room and no need to stop step value.</p> Python <pre><code>class Solution:\ndef wallsAndGates(self, rooms: List[List[int]]) -&gt; None:\n    \"\"\"\n    Do not return anything, modify rooms in-place instead.\n    \"\"\"\n    queue = deque()\n    n_row = len(rooms)\n    n_col = len(rooms[0])\n\n    for i_row in range(n_row):\n        for j_col in range(n_col):\n            if rooms[i_row][j_col] == 0:                \n                queue.append((i_row, j_col))\n\n                # Use BFS to travers roomsa and update the room value\n                # for the gate\n                while queue:\n                    size = len(queue)\n                    for i in range(size):\n                        base_row, base_col = queue.popleft()\n                        for row_step, col_step in [(-1, 0), (0, 1), (0, -1), (1, 0)]:\n                                curr_row = base_row + row_step\n                                curr_col = base_col + col_step\n                                if curr_row &gt;= 0 and curr_row &lt; n_row \\\n                                    and curr_col &gt;= 0 and curr_col &lt; n_col \\\n                                    and rooms[curr_row][curr_col] &gt; rooms[base_row][base_col] + 1:\n                                        rooms[curr_row][curr_col] = rooms[base_row][base_col] + 1\n                                        queue.append((curr_row, curr_col))\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(kmn)\\)     If there is ONLY one gate, the breadth-first search takes at most m\u00d7n steps to reach all rooms, therefore the time complexity is \\(O(mn)\\). When there are <code>k</code> gates, on average the space will be essentially divided by <code>k</code> subspaces since each BFS will only search rooms with larger value. So the time complexity is \\(O(\\frac{k}{k}mn) + O(\\frac{k-1}{k}mn) + \\cdots + O(\\frac{1}{k}mn) = O(\\frac{1+k}{2} mn)\\). So in worth case, the time complexity is \\(O(kmn)\\).</li> <li>Space complexity: \\(O(mn)\\)     The space complexity depends on the queue's size. We insert at most \\(m \\times n\\) points into the queue.</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#approach-bfs-all-gates","title":"Approach - BFS All Gates","text":"<p>Add all gates to the queue first and then check the same layer of each node and add empty rooms to the queue. Essentially, always check the same layer of all gates, when checking 1st layer, if room is empty, update with <code>1</code> and add it to the queue. When checking <code>kth</code> layer, if the room is empty, update the room with value <code>k</code> and add it to the queue. For <code>kth</code> layer, if room is updated for one gate with <code>k</code>, no need to update it for another gate since it will be update by the same value.</p> python <pre><code>from collections import deque\n\nclass Solution:\n    EMPTY = 2**31 - 1\n    GATE = 0\n    DIRECTIONS = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n\n    def wallsAndGates(self, rooms: List[List[int]]) -&gt; None:\n        \"\"\"\n        Do not return anything, modify rooms in-place instead.\n        \"\"\"\n        n_row = len(rooms)\n        if n_row == 0:\n            return\n        n_col = len(rooms[0])\n        queue = deque()\n\n        for i_row in range(n_row):\n            for i_col in range(n_col):\n                if rooms[i_row][i_col] == self.GATE:\n                    queue.append((i_row, i_col))\n\n        while queue:\n            current_row, current_col = queue.popleft()\n            for step_row, step_col in self.DIRECTIONS:\n                next_row = current_row + step_row\n                next_col = current_col + step_col\n                if next_row &gt;= 0 and next_row &lt; n_row \\\n                    and next_col &gt;= 0 and next_col &lt; n_col \\\n                    and rooms[next_row][next_col] == self.EMPTY:\n                        rooms[next_row][next_col] = rooms[current_row][current_col] + 1\n                        queue.append((next_row, next_col))\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(mn)\\)     Since it is only check non-empty rooms once, so in worth case, the time complexity is \\(O(mn)\\).</li> <li>Space complexity: \\(O(mn)\\)     The space complexity depends on the queue's size. We insert at most \\(m \\times n\\) points into the queue.</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - BFS 1 gate \\(O(kmn)\\) \\(O(mn)\\) Approach - BFS all gates \\(O(mn)\\) \\(O(mn)\\)","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0286-walls-and-gates/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/","title":"LC295. Find Median from Data Stream","text":"","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 295: The\u00a0median\u00a0is the middle value in an ordered integer list. If the size of the list is even, there is no middle value, and the median is the mean of the two middle values.</p> <ul> <li>For example, for\u00a0<code>arr = [2,3,4]</code>, the median is\u00a0<code>3</code>.</li> <li>For example, for\u00a0<code>arr = [2,3]</code>, the median is\u00a0<code>(2 + 3) / 2 = 2.5</code>.</li> </ul> <p>Implement the MedianFinder class:</p> <ul> <li><code>MedianFinder()</code>\u00a0initializes the\u00a0<code>MedianFinder</code>\u00a0object.</li> <li><code>void addNum(int num)</code>\u00a0adds the integer\u00a0<code>num</code>\u00a0from the data stream to the data structure.</li> <li><code>double findMedian()</code>\u00a0returns the median of all elements so far. Answers within\u00a0<code>10-5</code> of the actual answer will be accepted.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#clarification","title":"Clarification","text":"<ul> <li>Only add number, no remove?</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#solution","title":"Solution","text":"","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#approach-two-heaps","title":"Approach - Two Heaps","text":"<p>The idea is to divide numbers into 2 balanced halves: one half <code>small</code> stores smaller numbers and the other half <code>large</code> stores larger numbers.</p> <p>Then, we can use</p> <ul> <li>max heap to store a half of smaller numbers. The top of the max heap is the largest number among small numbers.</li> <li>min heap to store a half of larger numbers. The top of the min heap is the lowest number among large numbers.</li> </ul> <p>When adding numbers, we need to balance the size between the max heap and min heap. After adding <code>i</code> elements:</p> <ul> <li>if <code>i</code> is even, then <code>len(small) == len(large)</code></li> <li>if <code>i</code> is odd, then <code>len(small) == len(large) + 1</code></li> </ul> <p>Since the both trees are balanced, the median will be either the top of max heap or average of tops of both heaps.</p> Python <pre><code>import heapq\n\nclass MedianFinder:\n\n    def __init__(self):\n        self.left_max_heap = []\n        self.right_min_heap = []\n\n    def addNum(self, num: int) -&gt; None:\n        heapq.heappush(self.left_max_heap, -num)  # (1)\n        heapq.heappush(self.right_min_heap, -heapq.heappop(self.left_max_heap))  # (2)\n        if len(self.right_min_heap) &gt; len(self.left_max_heap):  # (3)\n            heapq.heappush(self.left_max_heap, -heapq.heappop(self.right_min_heap))\n\n    def findMedian(self) -&gt; float:\n        if len(self.left_max_heap) == len(self.right_min_heap):\n            return (-self.left_max_heap[0] + self.right_min_heap[0]) / 2\n        else:\n            return -self.left_max_heap[0]\n</code></pre> <ol> <li>Always push to the left heap first.</li> <li>Balance heap values: smaller numbers in the left max heap and larger numbers in the right min heap.</li> <li>Maintain size property: <code>max heap size == min heap size</code> or <code>max heap size == min heap size + 1</code>.</li> </ol>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity:<ul> <li>Constructor takes \\(O(1)\\) time.</li> <li><code>addNum</code> takes \\(O(\\log n)\\) where \\(n\\) is the size of heap. When adding number, it takes at most 5 heap operations and each heap operation takes \\(O(\\log n)\\) time.</li> <li><code>findMedian</code> takes \\(O(1)\\) since it simply retrieves the top values from two heaps.</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Need to store all \\(n\\) numbers in two heaps.</li> </ul> </li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#approach-2-","title":"Approach 2 -","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Two Heaps \\(O(1)\\), \\(O(\\log n)\\), \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0295-find-median-from-data-stream/#test","title":"Test","text":"<ul> <li>Only one number is added\u00a0\u2192 Return that number as median.</li> <li>Even and odd number of elements\u00a0\u2192 Correctly handle averaging when needed.</li> <li>All numbers are the same\u00a0\u2192 Median should return that same number.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/","title":"LC297. Serialize and Deserialize Binary Tree","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 297: Serialization is the process of converting a data structure or object into a sequence of bits so that it can be stored in a file or memory buffer, or transmitted across a network connection link to be reconstructed later in the same or another computer environment.</p> <p>Design an algorithm to serialize and deserialize a binary tree. There is no restriction on how your serialization/deserialization algorithm should work. You just need to ensure that a binary tree can be serialized to a string and this string can be deserialized to the original tree structure.</p> <p>Clarification: The input/output format is the same as how LeetCode serializes a binary tree. You do not necessarily need to follow this format, so please be creative and come up with different approaches yourself.</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#solution","title":"Solution","text":"","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#approach-1-preorderpostorder-traversal","title":"Approach 1: Preorder/Postorder Traversal","text":"<p>We can use either preorder or postorder method to traverse the tree and encode its values as well as its structure (adding <code>None</code> nodes) into a string.</p> <p>This is different from LC105 construct binary tree from preorder and inorder traversal and LC106 construct binary tree from inorder and postorder traversal where lists don't preserve the <code>None</code> node information, so we don't have an indicator to check if a node is in the left subtree or right subtree and 2 traversals are needed.</p> Python <pre><code>class Codec:\n\n    spliter = \",\"\n    none_str = \"x\"\n\n    def serialize(self, root):\n        \"\"\"Encodes a tree to a single string.\n\n        :type root: TreeNode\n        :rtype: str\n        \"\"\"\n        str_list = []\n        self.build_string(root, str_list)\n\n        return Codec.spliter.join(str_list)\n\n    def deserialize(self, data):\n        \"\"\"Decodes your encoded data to tree.\n\n        :type data: str\n        :rtype: TreeNode\n        \"\"\"\n        val_str_list = data.split(Codec.spliter)\n        queue = deque(val_str_list)\n        return self.build_tree(queue)\n\n    def build_tree(self, data_str_queue):\n        curr_val_str = data_str_queue.popleft()  # (1)\n        if curr_val_str == Codec.none_str:\n            return None\n\n        node = TreeNode(int(curr_val_str))\n        node.left = self.build_tree(data_str_queue)\n        node.right = self.build_tree(data_str_queue)  # (2)\n\n        return node\n\n    def build_string(self, node, str_list):\n        if not node:\n            str_list.append(Codec.none_str)\n        else:\n            str_list.append(str(node.val))  # (3)\n            self.build_string(node.left, str_list)\n            self.build_string(node.right, str_list)\n</code></pre> <ol> <li>For postorder, change <code>popleft()</code> to <code>pop()</code>, since the root of postorder is the last node.</li> <li>For post order, move building right tree above building left tree. The postorder list is <code>left -&gt; right -&gt; root</code>. Since we go through the list in a reversed direction, it should be <code>left &lt;- right &lt;- root</code>.</li> <li>For postorder, move adding the root value to the bottom after building the right subtree to match the postorder <code>left -&gt; right -&gt; root</code>.</li> </ol>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\) for serialization and deserialization  <ul> <li>Serialization takes \\(O(n)\\)<ul> <li><code>build_string</code> traverse all nodes exactly once, which takes \\(O(n)\\) time.</li> <li>Convert string list to string takes \\(O(n)\\) time.</li> </ul> </li> <li>Deserialization takes \\(O(n)\\)<ul> <li>string split takes \\(O(n)\\) time.</li> <li>Add string list to queue takes \\(O(n)\\) time.</li> <li><code>build_tree</code> goes through all strings, which takes \\(O(n)\\).</li> </ul> </li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Serialization takes \\(O(n)\\) space<ul> <li><code>str_list</code> stores all \\(n\\) nodes' values and additional \\(n - 1\\) null values, taking \\(O(n)\\) space. Each missing child gets an explicit null value. For a full binary tree with \\(n\\) nodes, the total number of positions is \\(2 n - 1\\). So the number of nulls is \\(2 n - 1 - n = n - 1\\).</li> </ul> </li> <li>Deserialization takes \\(O(n)\\)<ul> <li>Convert string to list takes \\(O(n)\\) space.</li> <li>Add strings to queue takes \\(O(n)\\) space.</li> </ul> </li> </ul> </li> </ul> Why does a full binary tree with \\(n\\) nodes have \\(2 n - 1\\) positions? <ul> <li>Each node occupies one position.</li> <li>Each node creates 2 child positions (except the root node).</li> <li>So the total number of positions is \\(2 n - 1\\). <code>-1</code> is for the root.</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#approach-2-level-order","title":"Approach 2: Level Order","text":"<p>We can also use level order traversal for serialization/deserialization. Similarly, we will preserve <code>None</code> nodes to encode structure information.</p> python <pre><code>class Codec:\n\n    def serialize(self, root):\n        \"\"\"Encodes a tree to a single string.\n\n        :type root: TreeNode\n        :rtype: str\n        \"\"\"\n        if not root:\n            return \"\"\n\n        values = []\n        values.append(str(root.val))\n        queue = deque([root])\n        while queue:\n            curr_node = queue.popleft()\n\n            if curr_node.left:\n                queue.append(curr_node.left)\n                values.append(str(curr_node.left.val))\n            else:\n                values.append(\"null\")\n\n            if curr_node.right:\n                queue.append(curr_node.right)\n                values.append(str(curr_node.right.val))\n            else:\n                values.append(\"null\")\n\n        return \",\".join(values)\n\n    def deserialize(self, data):\n        \"\"\"Decodes your encoded data to tree.\n\n        :type data: str\n        :rtype: TreeNode\n        \"\"\"\n\n        # Empty string\n        if not data:\n            return None\n\n        value_str_list = data.split(\",\")\n        root = TreeNode(value_str_list[0])\n        idx = 1  # index of value string list, starting from the 2nd element since the first one is created for root\n        prev_level = deque([root])\n        while prev_level:\n            prev_node = prev_level.popleft()\n            left_value_str = value_str_list[idx]\n            if left_value_str != \"null\":\n                left_node = TreeNode(int(left_value_str))\n                prev_node.left = left_node\n                prev_level.append(left_node)\n\n            idx += 1\n            right_value_str = value_str_list[idx]\n            if right_value_str != \"null\":\n                right_node = TreeNode(int(right_value_str))\n                prev_node.right = right_node\n                prev_level.append(right_node)\n\n            idx += 1\n\n        return root\n</code></pre>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\) <ul> <li>Serialization: \\(O(n)\\)<ul> <li>Using queue to go through all \\(n\\) nodes exactly once, which takes \\(O(n)\\).</li> <li>string join takes \\(O(n)\\).</li> </ul> </li> <li>Deserialization: \\(O(n)\\)<ul> <li>string split takes \\(O(n)\\) time.</li> <li>Go through all \\(n\\) nodes to build tree which takes \\(O(n)\\) time.</li> </ul> </li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Serialization: \\(O(n)\\)<ul> <li>value list stores values of \\(n\\) nodes and \\(n - 1\\) <code>None</code> nodes, takes \\(O(n)\\) space.</li> <li>the queue size reaches the peak when storing the last level of nodes. For a full binary tree, the last level has \\(n / 2\\) nodes.</li> </ul> </li> <li>Deserialization: \\(O(n)\\)<ul> <li>Storing slitted strings takes \\(O(n)\\) space.</li> <li>The <code>prev_queue</code> stores at most \\(n / 2\\) nodes, taking \\(O(n)\\) space.</li> </ul> </li> </ul> </li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Preorder/Postorder \\(O(n)\\) \\(O(n)\\) Approach - Level Order \\(O(n)\\) \\(O(n)\\)","tags":["Binary Tree"]},{"location":"lc-solutions/lc0200-0299/lc0297-serialize-and-deserialize-binary-tree/#test","title":"Test","text":"<ul> <li>Tree is empty (None).</li> <li>Tree contains only one node.</li> <li>Tree is highly unbalanced (linked list-like structure).</li> </ul>","tags":["Binary Tree"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/","title":"LC300. Longest Increasing Subsequence","text":"","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 300: Given an integer array\u00a0<code>nums</code>, return\u00a0_the length of the longest\u00a0strictly increasing subsequence.</p>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#clarification","title":"Clarification","text":"<ul> <li>strictly increasing? &gt; not &gt;=</li> <li>is it continuous subsequence?</li> </ul>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#assumption","title":"Assumption","text":"","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#solution","title":"Solution","text":"","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#approach-dynamic-programming","title":"Approach - Dynamic Programming","text":"<p>The problem can be solved using dynamic programming:</p> <ul> <li>State: let <code>dp[i]</code> be the length of the longest increase subsequence that ends with the i-th element, <code>nums[0], nums[k], ..., nums[i]</code>.</li> <li>Transition: for each <code>i</code>, we can find the longest increasing subsequence that ends with <code>nums[i]</code> by checking all previous elements <code>j</code> (where <code>j &lt; i</code>) and updating <code>dp[i]</code> as follows: <code>dp[i] = max(dp[i], dp[j] + 1)</code> for all <code>j &lt; i</code> where <code>nums[j] &lt; nums[i]</code>.</li> <li>Base case: <code>dp[i]</code> will be initialized to 1 since we can always pick a single element for the sequence.</li> </ul> Python <pre><code>class Solution:\n    def lengthOfLIS(self, nums: List[int]) -&gt; int:\n        n = len(nums)\n        dp = [1] * n\n        for i in range(n):\n            for j in range(i):\n                if nums[i] &gt; nums[j] and dp[i] &lt; dp[j] + 1:\n                    dp[i] = dp[j] + 1\n        return max(dp)\n</code></pre>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li> <p>Time complexity: \\(O(n^2)\\) Use two nested for-loops, resulting in \\(1 + 2 + ... + n = \\frac{n(n+1)}{2}\\) operations.</p> </li> <li> <p>Space complexity: \\(O(n)\\) <code>dp</code> array to store values.</p> </li> </ul>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#approach-binary-search","title":"Approach - Binary Search","text":"<p>@hiepit provides a good explanations. He also mention another useful document for better understanding.</p> <p>The idea is to build an increasing subsequence by:</p> <ul> <li>If the current number is larger than the last number in the subsequence, append it.</li> <li>If it is smaller, find the first number in the subsequence that is larger than or equal to the current number and replace it with the current number. The replacement maintains the existing length and allows for a potentially longer subsequence in the future.</li> </ul> <p>For example, with the input <code>[1, 7, 8, 3, 4, 5, 2]</code>, the subsequence will be built as follows:</p> <pre><code>block-beta\n    columns 1\n    block\n        columns 4\n        1 7 8 space\n    end\n    space\n    block\n        columns 4\n        n1[\"1\"] 3 4 5\n    end\n    space\n    block\n        columns 4\n        nn1[\"1\"] 2 n4[\"4\"] n5[\"5\"]\n    end\n    1 --&gt; n1\n    7 --&gt; 3\n    8 --&gt; 4\n    3 --&gt; 2</code></pre> <p>Note that this approach does not actually build a valid subsequence, but the length of the subsequence is always equal the length of the longest increasing subsequence. As shown in the above example, the final subsequence is <code>[1, 2, 4, 5]</code> but the correct sequence is <code>[1, 3, 4, 5]</code>.  Both have the same length.</p> Python <pre><code>class Solution:\n    def lengthOfLIS(self, nums: List[int]) -&gt; int:\n        sub = []\n        for x in nums:\n            if len(sub) == 0 or sub[-1] &lt; x:\n                sub.append(x)\n            else:\n                idx = bisect_left(sub, x)  # Find the index of the first element &gt;= x\n                sub[idx] = x  # Replace that number with x\n        return len(sub)\n</code></pre>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li> <p>Time complexity: \\(O(n \\log n)\\) Iterate the array \\(n\\) times and each iteration takes \\(O(\\log n)\\) by using binary search.</p> </li> <li> <p>Space complexity: \\(O(n)\\) Need space to store sub array.</p> </li> </ul>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Dynamic Programming \\(O(n^2)\\) \\(O(n)\\) Approach - Binary Search \\(O(n \\log n)\\) \\(O(n)\\)","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0300-longest-increasing-subsequence/#test","title":"Test","text":"<ul> <li>Test normal cases</li> <li>Test edge cases:<ul> <li>Empty array</li> <li>Single element array</li> <li>All elements are the same</li> <li>Already sorted array</li> <li>Reverse sorted array</li> </ul> </li> </ul>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0310-minimum-height-trees/","title":"LC310. Minimum Height Trees","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc0300-0399/lc0310-minimum-height-trees/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 310: A tree is an undirected graph in which any two vertices are connected by\u00a0exactly\u00a0one path. In other words, any connected graph without simple cycles is a tree.</p> <p>Given a tree of\u00a0<code>n</code>\u00a0nodes\u00a0labelled from\u00a0<code>0</code>\u00a0to\u00a0<code>n - 1</code>, and an array of\u00a0<code>n - 1</code> <code>edges</code> where\u00a0<code>edges[i] = [ai, bi]</code>\u00a0indicates that there is an undirected edge between the two nodes\u00a0<code>ai</code>\u00a0and\u00a0<code>bi</code>\u00a0in the tree,\u00a0you can choose any node of the tree as the root. When you select a node\u00a0<code>x</code>\u00a0as the root, the result tree has height\u00a0<code>h</code>. Among all possible rooted trees, those with minimum height (i.e.\u00a0<code>min(h)</code>)\u00a0 are called minimum height trees\u00a0(MHTs).</p> <p>Return\u00a0a list of all\u00a0MHTs'\u00a0root labels.\u00a0You can return the answer in\u00a0any order.</p> <p>The\u00a0height\u00a0of a rooted tree is the number of edges on the longest downward path between the root and a leaf.</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0300-0399/lc0310-minimum-height-trees/#clarification","title":"Clarification","text":"<ul> <li>A tree is an undirected graph with\u00a0n\u00a0nodes and\u00a0n\u22121\u00a0edges.</li> <li>The height of a tree is the number of edges in the longest path from the root to a leaf.</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0300-0399/lc0310-minimum-height-trees/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0300-0399/lc0310-minimum-height-trees/#solution","title":"Solution","text":"<p>A straight-forward (brutal force) way to solve the problem is to</p> <ul> <li>Start from each node and find the maximum distance between the root and the leaf node using either BFS or DFS.</li> <li>Filter out the roots that have the minimum height.</li> </ul> <p>Yet, the time complexity of this brutal force method is \\(O(n^2)\\) where \\(n\\) is the number of nodes in the tree. It will results in Time Limit Exceeded exception.</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0300-0399/lc0310-minimum-height-trees/#approach-topological-sort","title":"Approach - Topological Sort","text":"<p>The problem can be efficiently solved using a topological sort-like approach bases on the observation: the roots of minimum height trees are at the centers of the tree. The center divide the treen into subtree of approximately equal height, which helps minimize the height of the tree. We can also prove it by contradiction. If move away from center in any direction, it will cause the heigh increase, which won't be the minimum height tree.</p> <p>By iteratively removing leaves, the tree \"shrinks\" inward toward its centers. The process stops when 1 or 2 nodes remain, which are the centers of the tree.</p> <p>Here are diagrams to show the \"shrinks\" process:</p> <pre><code>graph LR\n    node0((0))\n    node1((1))\n    node2((2))\n    node3((3))\n    node4((4))\n    node5((5))\n\n    node0---node3\n    node1---node4\n    node2---node5\n    subgraph \"degree &gt; 1\"\n    node0---node1\n    node0---node2\n    end</code></pre> <pre><code>graph LR\n    node0((0))\n    node1((1))\n    node2((2))\n\n    node0---node1\n    node0---node2\n    subgraph \"degree &gt; 1\"\n    node0\n    end</code></pre> Python <pre><code>from collections import defaultdict, deque\n\nclass Solution:\n    def findMinHeightTrees(self, n: int, edges: List[List[int]]) -&gt; List[int]:\n        # Edge cases\n        if n &lt;= 2:\n            return [i for i in range(n)]\n\n        # Build adjacent list and n_connections\n        adj_list = defaultdict(set)\n        n_connections = [0] * n  # (1)\n        for node_a, node_b in edges:\n            if node_b not in adj_list[node_a]:\n                adj_list[node_a].add(node_b)\n                adj_list[node_b].add(node_a)\n                n_connections[node_a] += 1\n                n_connections[node_b] += 1\n\n        # Find all leaf nodes\n        # Since it is a tree, every node has at least 1 connection.\n        leaf_nodes = [i for i in range(n) if n_connections[i] == 1]\n        leaf_nodes_queue = deque(leaf_nodes)\n\n        # Trim leaf nodes iteratively\n        n_processed_nodes = n\n        while leaf_nodes_queue:\n            if n_processed_nodes &lt;= 2:\n                return list(leaf_nodes_queue)\n\n            size = len(leaf_nodes_queue)\n            n_processed_nodes -= size\n\n            for i in range(size):\n                curr_node = leaf_nodes_queue.popleft()\n                for next_node in adj_list[curr_node]:\n                    n_connections[next_node] -= 1\n                    if n_connections[next_node] == 1:\n                        leaf_nodes_queue.append(next_node)\n\n        return []  # not a tree\n</code></pre> <ol> <li>We can use list here since the nodes are labeled from <code>0</code> to <code>n - 1</code>.</li> </ol>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0300-0399/lc0310-minimum-height-trees/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\) <ul> <li>Building adjacent list takes \\(O(E)\\) since iterating through all \\(E\\) edges.</li> <li>Finding leaf nodes takes \\(O(V)\\) since going through all \\(V\\) nodes and checking their degrees.</li> <li>For queue operations, it will go through \\(V - 2\\) nodes, taking \\(O(V)\\) time.</li> <li>For neighboring explorations, it will go through at most \\(E\\) edges in the worst case, taking \\(O(E)\\) time.</li> <li>For a tree, \\(V = n\\) and \\(E = n - 1\\).</li> <li>So the total time complexity is \\(O(E) + O(V) + O(V) + O(E) = O(n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Adjacent list takes \\(O(V + E)\\) since store all nodes and their associate edges.</li> <li>n_connection array takes \\(O(V)\\) space since store degrees for all nodes.</li> <li>The queue may store \\(V - 2\\) nodes in the worst case, which takes \\(O(V)\\) space.</li> <li>So the total space complexity is \\(O(V + E) + O(V) + O(V) = O(n)\\).</li> </ul> </li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0300-0399/lc0310-minimum-height-trees/#test","title":"Test","text":"<ul> <li>Single node (<code>n=1</code>,<code>edges=[]</code>): Output is\u00a0<code>[0]</code>.</li> <li>Linear tree (<code>n=4</code>,<code>edges=[[0,1],[1,2],[2,3]]</code>): Output is\u00a0<code>[1,2]</code>.</li> <li>Completely balanced tree (<code>n=7</code>,<code>edges=[[0,1],[0,2],[1,3],[1,4],[2,5],[2,6]]</code>): Output is\u00a0<code>[0]</code>.</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/","title":"LC323. Number of Connected Components in an Undirected Graph","text":"","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 323: You have a graph of\u00a0<code>n</code>\u00a0nodes. You are given an integer\u00a0<code>n</code>\u00a0and an array\u00a0<code>edges</code>\u00a0where <code>edges[i] = [ai, bi]</code>\u00a0indicates that there is an edge between\u00a0<code>ai</code>\u00a0and\u00a0<code>bi</code>\u00a0in the graph.</p> <p>Return\u00a0the number of connected components in the graph.</p>","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#clarification","title":"Clarification","text":"<ul> <li>Undirected graph</li> </ul>","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#assumption","title":"Assumption","text":"<ul> <li>node values range from 0 to n - 1</li> </ul>","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#solution","title":"Solution","text":"","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#approach-1-union-find","title":"Approach 1 - Union Find","text":"<p>We can use union find to count the number of connected components in the graph.</p> Python <pre><code>class UnionFind:\n    def __init__(self, n):\n        self.root = [i for i in range(n)]\n        self.rank = [0] * n\n        self.count = n\n\n    def find(self, x):\n        if x == self.root[x]:\n            return x\n        self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x, y):\n        root_x = self.find(x)\n        root_y = self.find(y)\n\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = root_x\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = root_y\n            else:\n                self.root[root_y] = root_x\n                self.rank[root_x] += 1\n            self.count -= 1\n\nclass Solution:\n    def countComponents(self, n: int, edges: List[List[int]]) -&gt; int:\n        uf = UnionFind(n)\n\n        for edge in edges:\n            uf.union(edge[0], edge[1])\n\n        return uf.count\n</code></pre>","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(V + E \\alpha(V))\\)  where \\(V\\) is number of vertices and \\(E\\) is number of edges  <ul> <li>Initialize <code>root</code> and <code>rank</code> arrays take \\(O(V)\\) time</li> <li>The for-loop requires \\(O(E)\\) operations to iterating all edges. Each iteration calls <code>union</code> function and takes \\(O(\\alpha(V))\\). So the total time complexity is \\(O(V + E \\alpha(V))\\).</li> </ul> </li> <li>Space complexity: \\(O(V)\\)   The union find takes \\(O(V)\\) space to stores <code>root</code> and <code>rank</code>.</li> </ul>","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#approach-2-dfsbfs","title":"Approach 2 - DFS/BFS","text":"<p>The problem can also be solved using either BFS or DFS. Start from a vertex and traverse the sub-graph (connected components) using either BFS or DFS and mark nodes visited. For the next node not visited, traverse and mark visited again. In the meantime, increase count by 1 since it doesn't belong to previous connected components.</p> Python - DFSPython - BFS <pre><code>class Solution:\n    def countComponents(self, n: int, edges: List[List[int]]) -&gt; int:\n        count = 0\n\n        # Convert edge list to adjacent list for easy traversing later\n        adj_list = [[] for _ in range(n)]\n        for edge in edges:\n            adj_list[edge[0]].append(edge[1])\n            adj_list[edge[1]].append(edge[0])\n\n        visited = set()\n        for node in range(n):\n            if node not in visited:\n                count += 1\n                self.dfs(node, adj_list, visited)\n\n        return count\n\n    def dfs(self, node: int, adj_list: List[List[int]], visited: Set[int]) -&gt; None:\n        visited.add(node)\n\n        for neighbor in adj_list[node]:\n            if neighbor not in visited:\n                self.dfs(neighbor, adj_list, visited)\n</code></pre> <pre><code>class Solution:\n    def countComponents(self, n: int, edges: List[List[int]]) -&gt; int:\n        count = 0\n\n        # Convert edge list to adjacent list for easy traversing later\n        adj_list = [[] for _ in range(n)]\n        for edge in edges:\n            adj_list[edge[0]].append(edge[1])\n            adj_list[edge[1]].append(edge[0])\n\n        visited = set()\n        for node in range(n):\n            if node not in visited:\n                count += 1\n                self.bfs(node, adj_list, visited)\n\n        return count\n\n    def bfs(self, node: int, adj_list: List[List[int]], visited: Set[int]) -&gt; None:\n        visited.add(node)\n        queue = deque([node])\n\n        while queue:\n            curr_node = queue.popleft()\n            for neighbor in adj_list[curr_node]:\n                if neighbor not in visited:\n                    queue.append(neighbor)\n                    visited.add(neighbor)\n</code></pre>","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(V + E)\\) <ul> <li>Initialize <code>adj_list</code> takes \\(O(V)\\) time</li> <li>Convert edge list to <code>adj_list</code> takes \\(O(E)\\) time</li> <li>During DFS/BFS traversal, each vertex will only be visited once, taking \\(O(V)\\) time. For each vertex, we iterate its edge list once. In total, takes \\(O(E)\\) time to go through all edges. So the time complexity for traversing is \\(O(V + E)\\). So the total time complexity is \\(O(V) + O(E) + O(V + E) = O(V + E)\\).</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li><code>adj_list</code> takes \\(O(V + E)\\) space since store all nodes and their edges.</li> <li><code>visited</code> takes \\(O(V)\\) space to track nodes</li> <li>The call stack of DFS or queue of BFS takes \\(O(V)\\) space in the worst case. So the total space complexity is \\(O(V + E) + O(V) + O(V) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Union Find \\(O(V + E \\alpha(V))\\) \\(O(V)\\) Approach 2 - BFS/DFS \\(O(V + E)\\) \\(O(V + E)\\)","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0323-number-of-connected-components-in-an-undirected-graph/#test","title":"Test","text":"","tags":["Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0325-maximum-size-subarray-sum-equals-k/","title":"LC325. Maximum Size Subarray Sum Equals k","text":"","tags":["Array","Two Pointers","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0300-0399/lc0325-maximum-size-subarray-sum-equals-k/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 325: Given an integer array <code>nums</code> and an integer <code>k</code>, return the maximum length of a subarray that sums to <code>k</code>. If there is not one, return <code>0</code> instead.</p>","tags":["Array","Two Pointers","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0300-0399/lc0325-maximum-size-subarray-sum-equals-k/#clarification","title":"Clarification","text":"<ul> <li>Find the maximum length of subarray with <code>sum == k</code></li> <li>If doesn't exist, return 0</li> <li>Include both positive and negative values</li> </ul>","tags":["Array","Two Pointers","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0300-0399/lc0325-maximum-size-subarray-sum-equals-k/#assumption","title":"Assumption","text":"<ul> <li>Sum of subarray won't cause integer overflow</li> </ul>","tags":["Array","Two Pointers","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0300-0399/lc0325-maximum-size-subarray-sum-equals-k/#solution","title":"Solution","text":"<p>The general idea is to - detect subarrays with sum <code>k</code>  - find the length of the longest subarray with sum <code>k</code> -  The straightforward solution is using brute force with two for-loops to find all possible subarrays, which has \\(O(n^2)\\) time complexity. A better approach is to use prefix sum and hash map to detect subarray with sum <code>k</code> more efficiently, which will reduce time complexity to \\(O(n)\\) but will use \\(O(n)\\) space. </p>","tags":["Array","Two Pointers","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0300-0399/lc0325-maximum-size-subarray-sum-equals-k/#approach-prefix-sum-hash-map","title":"Approach - Prefix Sum + Hash Map","text":"<p>A better approach to solve this problem is to use prefix sum and hash map. The prefix sum is the cumulative sum. The original array <code>nums = [1, 2, 2, 3]</code> can be converted to the prefix sum array <code>prefix = [1, 3, 5, 8]</code>. The prefix sum has the following properties: - <code>prefix[j] - prefix[i]</code> represents the sum of the subarray from <code>i+1</code> to <code>j</code> , where <code>prefix[i]</code> is the sum of all the elements from <code>0</code> to <code>i</code> (inclusive).  - If <code>prefixSum[i] == prefixSum[j]</code>, then the sum of subarray from <code>i+1</code> to <code>j</code> equals <code>0</code>  With above mentioned property, we can - Store previously seen prefix sums and their indices in a hash map, <code>map&lt;prefixSum, index&gt;</code>      - No need to create a prefix sum array. Instead, use an integer variable to keep track of the prefix sum     - If running into duplicates (due to negative numbers), only update the index in the hash map when it doesn't exist (i.e., <code>maps.find(prefixSum) == map.end()</code>), which keep the index as far to the left as possible, since we want the longest subarray.  - Check if <code>prefix[i] == k</code>, then the sum of the subarray from <code>0</code> to <code>i</code> is <code>k</code>     - Check it directly using if statement     - Or initialize the hash map with a key (prefix sum) of <code>0</code> corresponding to a value of <code>-1</code> (index) - Check if <code>prefix[i] - k</code> has already been seen. If so (e.g., <code>prefix[i] - k = prefix[j]</code>), the sum of the subarray from <code>i+1</code> to <code>j</code> is <code>k</code> - Find the length of subarray using the stored index and current index and update longest length</p> <p>Note: it's better replace integer with <code>vector&lt;int&gt;::size_type</code> for indexing.</p> <pre><code>class Solution {\npublic:\n    vector&lt;int&gt;::size_type maxSubArrayLen(vector&lt;int&gt;&amp; nums, int k) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        unordered_map&lt;long, vec_size&gt; sumIndexMap; \n\n        long int sum = 0;\n        vec_size length = 0;\n        vec_size maxLength = 0;\n\n        for (vec_size i = 0; i &lt; nums.size(); i++) {\n            sum += nums[i];\n\n            // Check if cumulative sum == k\n            if (sum == k) {\n                if (i + 1 &gt; maxLength) {\n                    maxLength = i + 1;\n                }\n            }\n\n            // If any subarry with summmation == sum - k, update maxlenght\n            if (sumIndexMap.find(sum - k) != sumIndexMap.end()) {\n                length = i - sumIndexMap[sum - k];\n                if (length &gt; maxLength) {\n                    maxLength = length;\n                }\n            }\n\n            // Add the first appeared sum to hashmap for computing max length later\n            if (sumIndexMap.find(sum) == sumIndexMap.end()) {\n                sumIndexMap[sum] = i;\n            }\n        }\n\n        return maxLength;\n\n    }\n};\n</code></pre>","tags":["Array","Two Pointers","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0300-0399/lc0325-maximum-size-subarray-sum-equals-k/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     We iterate the array with one pass. Inside the for-loop, each code block is \\(O(1)\\). All hash map operators are \\(O(1)\\).  </li> <li>Space complexity: \\(O(n)\\)     The hash map can potential hold as many key-value pairs as numbers in <code>nums</code>. An example of this when there are NO negative numbers in the array.</li> </ul>","tags":["Array","Two Pointers","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/","title":"LC344. Reverse String","text":"","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 344: Write a function that reverses a string. The input string is given as an array of characters\u00a0<code>s</code>.</p> <p>You must do this by modifying the input array\u00a0in-place with\u00a0<code>O(1)</code>\u00a0extra memory.</p>","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#solution","title":"Solution","text":"","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#approach-1-iteration-with-two-pointers","title":"Approach 1: Iteration with Two Pointers","text":"<p>Use two pointers, one start from the beginning of the array and the other from the end. Move two pointers from two ends to the center and swap two values during the moving.</p> Python <pre><code>class Solution:\ndef reverseString(self, s: List[str]) -&gt; None:\n    \"\"\"\n    Do not return anything, modify s in-place instead.\n    \"\"\"\n\n    idx_begin, idx_end = 0, len(s) - 1\n\n    while idx_begin &lt; idx_end:\n        s[idx_begin], s[idx_end] = s[idx_end], s[idx_begin]\n        idx_begin += 1\n        idx_end -= 1\n</code></pre>","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Every execution two pointers together move 2 steps. So it takes \\(n/2\\) executions. So   the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(1)\\)   Only use limited index variables.</li> </ul>","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#approach-2-recursion","title":"Approach 2: Recursion","text":"<p>We can also use two pointer to solve the problem recursively by passing updated the begin and end indices as arguments.</p> python <pre><code>class Solution:\n  def reverseString(self, s: List[str]) -&gt; None:\n      \"\"\"\n      Do not return anything, modify s in-place instead.\n      \"\"\"\n      self.reverse(s, 0, len(s) - 1)\n\n  def reverse(self, s: list[str], idx_begin: int, idx_end: int) -&gt; None:\n      # Base case: 0 or 1 character, no need to swap\n      if idx_begin &gt;= idx_end:\n          return\n\n      # Swap two ends\n      s[idx_begin], s[idx_end] = s[idx_end], s[idx_begin]\n\n      # Recursive call a smaller string without two ends.\n      self.reverse(s, idx_begin + 1, idx_end - 1)\n</code></pre>","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   It performs \\(n/2\\) swaps with recursive function calls.</li> <li>Space complexity: \\(O(n)\\)   The recursive function call stack depth is up to \\(n/2\\).</li> </ul>","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Iteration \\(O(n)\\) \\(O(1)\\) Approach - Recursion \\(O(n)\\) \\(O(n)\\)","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0344-reverse-string/#test","title":"Test","text":"<ul> <li>Test empty array.</li> <li>Test array with 1 or 2 elements.</li> </ul>","tags":["Two Pointers","String"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/","title":"LC346. Moving Average from Data Stream","text":"","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 346: Given a stream of integers and a window size, calculate the moving average of all integers in the sliding window.</p> <p>Implement the\u00a0<code>MovingAverage</code>\u00a0class:</p> <ul> <li><code>MovingAverage(int size)</code>\u00a0Initializes\u00a0the object with the size of the window\u00a0<code>size</code>.</li> <li><code>double next(int val)</code>\u00a0Returns the moving average of the last\u00a0<code>size</code>\u00a0values of the stream.</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#clarification","title":"Clarification","text":"<ul> <li><code>next</code> function will do two things: add val to the moving window and return the moving average.</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#solution","title":"Solution","text":"","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#approach-deque","title":"Approach - deque","text":"<p>From moving window definition, at each step, add a new element to the window, and at the same time remove the oldest element from the window.</p> <ul> <li>We can use queue data structure to implement the moving window, which has the constant time complexity (\\(O(1)\\)) to add or remove an element from both ends.</li> <li>To compute the new sum, we keep the sum of the previous moving window and add the new element and subtract the oldest element.</li> </ul> Python <pre><code>from collections import deque\n\n\nclass MovingAverage:\n\n    def __init__(self, size: int):\n        self.count = 0\n        self.queue = deque([], size)\n        self.size = size\n        self.sum = 0\n\n    def next(self, val: int) -&gt; float:\n        self.count += 1\n        if self.count &gt; self.size:\n            tail = self.queue.popleft()\n        else:\n            tail = 0\n\n        self.queue.append(val)  # (1)\n\n        self.sum = self.sum + val - tail\n        return self.sum / min(self.count, self.size)\n</code></pre> <ol> <li>Since queue is defined with the fix size, append value here (not early). Otherwise, it will automatically popleft.</li> </ol>","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(1)\\) <ul> <li>Two queue operations are \\(O(1)\\).</li> <li>New sum calculation is based on previous sum, new value, and the oldest value, which takes \\(O(1)\\).</li> <li>So the total time complexity is \\(O(1)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\), where \\(n\\) is the size of moving window     The queue will store at most \\(n\\) elements.</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#approach-2-circular-queue-with-array","title":"Approach 2 - Circular Queue with Array","text":"<p>We can also use circular queue data structure to implement the moving window. The circular queue is basically a queue with the circular shape.</p> <p>we can implement a circular queue with a fixed-size array. The key to the implementation is to find the relationship between the index of <code>head</code> and <code>tail</code> elements, <code>tail = (head + 1) % size</code>. The <code>tail</code> element is right next to the <code>head</code> element. Once moving the <code>head</code> forward, the previous <code>tail</code> will be overwritten.</p> python <pre><code>class MovingAverage:\n\n    def __init__(self, size: int):\n        self.size = size\n        self.queue = [0] * size\n        self.head = 0\n        self.window_sum = 0\n        self.count = 0\n\n    def next(self, val: int) -&gt; float:\n        self.count = min(self.count + 1, self.size)\n        tail = (self.head + 1) % self.size  # (1)\n        self.window_sum = self.window_sum - self.queue[tail] + val\n        self.head = (self.head + 1) % self.size  # (2)\n        self.queue[self.head] = val  # (3)\n        return self.window_sum / self.count\n</code></pre> <ol> <li>Find the index of the <code>tail</code> element since <code>head</code> is update in the last execution.</li> <li>Find the index of the <code>head</code> element.</li> <li>Update the <code>head</code>. The old <code>tail</code> will be overwritten.</li> </ol>","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Find the indices and calculations take \\(O(1)\\).</li> <li>Space complexity: \\(O(n)\\)   The circular queue will take at most \\(n\\) elements.</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - deque \\(O(1)\\) \\(O(n)\\) Approach - circular queue \\(O(1)\\) \\(O(n)\\)","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0346-moving-average-from-data-stream/#test","title":"Test","text":"","tags":["Queue"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/","title":"LC347. Top K Frequent Elements","text":"","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 347: Given an integer array\u00a0<code>nums</code>\u00a0and an integer\u00a0<code>k</code>, return\u00a0the <code>k</code> most frequent elements. You may return the answer in\u00a0any order.</p>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#clarification","title":"Clarification","text":"<ul> <li>Most frequent elements --&gt; top number of appearances</li> <li>What to return, when k &gt; len(num)</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#solution","title":"Solution","text":"","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#approach-heap","title":"Approach - Heap","text":"<p>First, count number of appearances for each number. Then push <code>(number of appearances, num)</code> to a min heap with size <code>k</code>. After pushing all pairs, the heap stores top <code>k</code> frequent elements.</p> Python <pre><code>import heapq\nfrom collections import defaultdict\n\n\nclass Solution:\n    def topKFrequent(self, nums: List[int], k: int) -&gt; List[int]:\n        # Count number of appearances for each number.\n        num_appearances = defaultdict(lambda: 0)\n        for num in nums:\n            num_appearances[num] += 1\n\n        # Use Min Heap to store top k (number of appearances, num)\n        min_heap = []\n        for num, n_appearances in num_appearances.items():\n            heapq.heappush(min_heap, (n_appearances, num))\n            if len(min_heap) &gt; k:\n                heapq.heappop(min_heap)\n\n        # Return k most frequent num\n        return [heapq.heappop(min_heap)[1] for i in range(len(min_heap))]\n</code></pre>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log k)\\) <ul> <li>Counting number of appearances takes \\(O(n)\\) time since iterating the array <code>nums</code>.</li> <li>For min heap operations, iterate \\(n\\) pairs and each iteration perform one or two heap operations. The heap operations takes \\(O(\\log k)\\) since the heap size is <code>k</code>. The time complexity is \\(O(n \\log k)\\).</li> <li>Return a list from heap takes \\(O(k)\\) since go through all <code>k</code> elements in the heap.</li> <li>The total time complexity is \\(O(n) + O(n \\log k) + O(k) = O(n \\log k)\\)</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>The dictionary to store number of appearances for each number takes \\(O(n)\\) space.</li> <li>Min heap takes \\(O(k)\\) space since stores <code>k</code> elements.</li> <li>The total space complexity is \\(O(n) + O(k) = O(n)\\).</li> </ul> </li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#approach-2-","title":"Approach 2 -","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Heap \\(O(n \\log k)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0347-top-k-frequent-elements/#test","title":"Test","text":"","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0300-0399/lc0354-russian-doll-envelopes/","title":"LC354. Russian Doll Envelopes","text":"","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc0300-0399/lc0354-russian-doll-envelopes/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 354: You are given a 2D array of integers\u00a0<code>envelopes</code>\u00a0where\u00a0<code>envelopes[i] = [wi, hi]</code>\u00a0represents the width and the height of an envelope.</p> <p>One envelope can fit into another if and only if both the width and height of one envelope are greater than the other envelope's width and height.</p> <p>Return\u00a0the maximum number of envelopes you can Russian doll (i.e., put one inside the other).</p> <p>Note:\u00a0You cannot rotate an envelope.</p>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc0300-0399/lc0354-russian-doll-envelopes/#clarification","title":"Clarification","text":"<ul> <li>2d array</li> <li>fit, w_i &lt; w_i_out and h_i &lt; h_i_out and no rotation</li> <li>return max number of envelops</li> </ul>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc0300-0399/lc0354-russian-doll-envelopes/#assumption","title":"Assumption","text":"<ul> <li>width and height &gt; 0</li> </ul>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc0300-0399/lc0354-russian-doll-envelopes/#solution","title":"Solution","text":"","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc0300-0399/lc0354-russian-doll-envelopes/#approach-sorting-binary-search","title":"Approach - Sorting + Binary Search","text":"<p>Since the problem involves a 2D array, the general idea is to sort the array and reduce the problem into a 1D array, which is similar to LC300 - Longest Increasing Subsequences.</p> <ol> <li>Sort the array in increasing order of width. And if two widths are the same, sort height in decreasing order. The reason to sort height in decreasing order to handle unfit cases where widths are the same. For example, <code>[[3, 3], [3, 4], [3, 5]]</code> vs. <code>[[3, 5], [3, 4], [3, 3]]</code>. Refer to @rhythm_varshney's explanations.</li> <li>Find longest increasing subsequence along the height. Similar to LC300 - Longest Increasing Subsequences.</li> </ol> Python <pre><code>class Solution:\n    def maxEnvelopes(self, envelopes: List[List[int]]) -&gt; int:\n        envelopes.sort(key=lambda x: (x[0], -x[1]))  # (1)\n        sub = []\n        for (w, h) in envelopes:\n            if not sub or sub[-1] &lt; h:\n                sub.append(h)\n            else:\n                idx = bisect_left(sub, h)\n                sub[idx] = h\n        return len(sub) \n</code></pre> <ol> <li>Sorted by width and then by height. Since <code>height &gt; 0</code>, use <code>-height</code> will sort height decreasingly. </li> </ol>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc0300-0399/lc0354-russian-doll-envelopes/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) Go through all envelops and use binary search for each step. </li> <li>Space complexity: \\(O(n)\\) Use an array to store longest increasing subsequences. The worst case could be the whole array.</li> </ul>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc0300-0399/lc0354-russian-doll-envelopes/#test","title":"Test","text":"","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/","title":"LC367. Valid Perfect Square","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem xx: Given a positive integer num, return\u00a0<code>true</code> if <code>num</code> is a perfect square or <code>false</code> otherwise.</p> <p>A\u00a0perfect square\u00a0is an integer that is the square of an integer. In other words, it is the product of some integer with itself. For example, \\(16 = 4 \\times 4\\).</p> <p>You must not use any built-in library function, such as\u00a0<code>sqrt</code>.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#clarification","title":"Clarification","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#approach-binary-search","title":"Approach - Binary Search","text":"<p>The problem can be transformed to find an integer <code>i</code> in the search space <code>[1, num]</code> such that <code>i * i == num</code>.</p> <ul> <li>If <code>i * i &gt; num</code>, no need to search right (i.e., i+1, i+2, \u00b7\u00b7\u00b7), since square of these values will also be larger than num.</li> <li>If <code>i * i &lt; num</code>, no need to search left, since square of these values will also be smaller than num.</li> <li>If <code>i * i == num</code>, find the answer</li> </ul> <p>With these properties, we can use binary search. Due to potential overflow of using <code>i * i == num</code> in C++ or Java, we convert it into integer division <code>i == num/i</code>. In order to check the equality of integer division, we need to check both division (<code>i == num/i</code>) and reminder (<code>num%i == 0</code>) since multiple integers may satisfy the equality condition <code>i == num/i</code> (e.g., <code>3 == 9/3</code>, <code>3 == 10/3</code>).</p> PythonJava <pre><code>class Solution:\n    def isPerfectSquare(self, num: int) -&gt; bool:\n        left, right = 0, num\n\n        while left &lt;= right:\n            mid = (left + right) // 2\n            mid_square = mid * mid\n            if num == mid_square:\n                return True\n            elif num &gt; mid_square:\n                left = mid + 1\n            else:\n                right = mid - 1\n\n        return False\n</code></pre> <pre><code>class Solution {\n    public boolean isPerfectSquare(int num) {\n        int left = 1;\n        int right = num;\n        int mid;\n        int res;\n        int remain;\n\n        while (left &lt;= right) {\n            mid = left + (right - left)/2;\n            res = num / mid;\n            remain = num % mid;\n\n            if (res == mid &amp;&amp; remain == 0)\n                return true;\n            else if (res &gt; mid)  // (1)\n                left = mid + 1;\n            else\n                right = mid - 1;\n        }\n\n        return false;\n    }\n}\n</code></pre> <ol> <li>Due to integer division, 16, 17 may satisfy <code>num/mid == mid</code>. Due to integer round down, none perfect square will always &gt; the perfect square</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) The time complexity is \\(O(\\log n)\\) with the binary search. </li> <li>Space complexity: \\(O(1)\\) Only use limited variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#math","title":"Math","text":"<p>\\(1 + 3 + \\cdots + (2n - 1) = (2n - 1 + 1) * n / 2 = n^2\\)</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0367-valid-perfect-square/#references","title":"References","text":"<ul> <li>multiple solutions from @fhqpizj</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0374-guess-number-higher-or-lower/","title":"LC374. Guess Number Higher or Lower","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0374-guess-number-higher-or-lower/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 374: We are playing the Guess Game. The game is as follows:</p> <p>I pick a number from\u00a0<code>1</code>\u00a0to\u00a0<code>n</code>. You have to guess which number I picked.</p> <p>Every time you guess wrong, I will tell you whether the number I picked is higher or lower than your guess.</p> <p>You call a pre-defined API\u00a0<code>int guess(int num)</code>, which returns three possible results:</p> <ul> <li><code>-1</code>: Your guess is higher than the number I picked (i.e.\u00a0<code>num &gt; pick</code>).</li> <li><code>1</code>: Your guess is lower than the number I picked (i.e.\u00a0<code>num &lt; pick</code>).</li> <li><code>0</code>: your guess is equal to the number I picked (i.e.\u00a0<code>num == pick</code>).</li> </ul> <p>Return\u00a0the number that I picked.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0374-guess-number-higher-or-lower/#clarification","title":"Clarification","text":"<ul> <li>picked number is between 1 to n number</li> <li>call guess to return guess results</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0374-guess-number-higher-or-lower/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0374-guess-number-higher-or-lower/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0374-guess-number-higher-or-lower/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Essentially, the problem is to find the target in an array of 1 to n (sorted). We can use binary search to find the picked number by using the guess results from the api function.</p> Python <pre><code>class Solution:\n    def guessNumber(self, n: int) -&gt; int:\n        left, right = 1, n\n\n        while left &lt;= right:\n            mid = (left + right) // 2\n\n            res = guess(mid)\n            if res == 0:\n                return mid\n            elif res == -1:\n                right = mid - 1\n            else:\n                left = mid + 1\n\n        return -1  # if not found\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0374-guess-number-higher-or-lower/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)     Since using binary search, the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\)     Just use two index variables. </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0374-guess-number-higher-or-lower/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/","title":"LC378. Kth Smallest Element in a Sorted Matrix","text":"","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 378: Given an\u00a0<code>n x n</code> <code>matrix</code>\u00a0where each of the rows and columns is sorted in ascending order, return\u00a0the <code>kth</code> smallest element in the matrix.</p> <p>Note that it is the\u00a0<code>kth</code>\u00a0smallest element\u00a0in the sorted order, not the\u00a0<code>kth</code> distinct\u00a0element.</p> <p>You must find a solution with a memory complexity better than\u00a0<code>O(n2)</code>.</p>","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#clarification","title":"Clarification","text":"<ul> <li>Each row and column is sorted in ascending order. It doesn't mean 1D array from this matrix is sorted. For example, <code>matrix = [[1,5,9],[10,11,13],[12,13,15]]</code>.</li> <li>Find kth smallest element, not the kth distinct element.</li> </ul>","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#solution","title":"Solution","text":"","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#approach-heap","title":"Approach - Heap","text":"<p>Push matrix elements into max heap with size of k. In the end, the top of the heap is the <code>kth</code> smallest element</p> Python <pre><code>import heapq\n\nclass Solution:\n    def kthSmallest(self, matrix: List[List[int]], k: int) -&gt; int:\n        max_heap = []\n\n        for row in matrix:\n            for element in row:\n                heapq.heappush(max_heap, -element)  # (1)\n\n                if len(max_heap) &gt; k:\n                    heapq.heappop(max_heap)\n\n        return -max_heap[0]  # (2)\n</code></pre> <ol> <li>Store negative elements to achieve max heap.</li> <li><code>Kth</code> smallest element is the top of the max heap. Need to revert negative value to normal.</li> </ol>","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n^2 \\log k)\\)<ul> <li>Iterate all \\(n^2\\) elements in the matrix. Each iteration will take at most two heap operations. The heap operation takes \\(O(\\log k)\\) since the heap size is \\(k\\).</li> <li>So the total time complexity is \\(O(n^2 \\log k)\\).</li> </ul> </li> <li>Space complexity: \\(O(k)\\)     The heap size is \\(k\\).</li> </ul>","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#approach-2-binary-search","title":"Approach 2 - Binary Search","text":"<p>Since each row and column of the matrix is sorted, we can use binary search on the number range to find the kth smallest number.</p> <ul> <li>At the beginning, the number range is between the smallest number at the top left corner of the matrix and the largest number at the bottom right corner.</li> <li>Then find the middle number. The middle number is not necessarily an element in the matrix.</li> <li>To decide whether to move left or right, we need to count numbers smaller than or equal to middle in the matrix.</li> <li>When counting, we need to track the smallest number greater than the middle and the largest number less than or equal to the middle. Use these values to set the new range.</li> </ul> python <pre><code>class Solution:\n    def kthSmallest(self, matrix: List[List[int]], k: int) -&gt; int:\n        left, right = matrix[0][0], matrix[-1][-1]\n        while left &lt; right:\n            mid = (left + right) // 2\n            smaller, larger = matrix[0][0], matrix[-1][-1]\n\n            count_smaller, smaller, larger = self.countLessEqual(\n                matrix, mid, smaller, larger\n            )\n\n            if count_smaller == k:\n                return smaller\n\n            if count_smaller &lt; k:\n                left = larger\n            else:\n                right = smaller\n\n        return left\n\n    def countLessEqual(\n        self, matrix: list[list[int]], mid: int, smaller: int, larger: int\n    ) -&gt; tuple[int, int, int]:\n        count_smaller, n = 0, len(matrix)\n\n        # (1)\n        i_row, i_col = (\n            n - 1,\n            0,\n        )  # (2)\n        while i_row &gt;= 0 and i_col &lt; n:\n            if matrix[i_row][i_col] &gt; mid:\n                larger = min(\n                    larger, matrix[i_row][i_col]\n                )  # (3)\n                i_row -= 1\n            else:\n                smaller = max(\n                    smaller, matrix[i_row][i_col]\n                )  # (4)\n                count_smaller += i_row + 1\n                i_col += 1\n\n        return count_smaller, smaller, larger\n</code></pre> <ol> <li>Use stair case traversal.</li> <li>Start from the first column last row (important to choose this!).</li> <li>Track the smallest number that is larger than the mid.</li> <li>Track the biggest number less than or equal to the mid.</li> </ol>","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n \\log (\\max - \\min))\\) <ul> <li>Binary search between smallest (min) and largest value (max) takes \\(O(\\log (\\max - \\min))\\) iterations.</li> <li>Each iteration takes \\(O(n)\\) to count the size of the left half.</li> <li>So the overall time complexity is \\(O(n \\log (\\max - \\min))\\).</li> </ul> </li> <li>Space complexity: \\(O(1)\\)     Only fixed number of variables are used for binary search.</li> </ul>","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Heap \\(O(n^2 \\log k)\\) \\(O(k)\\) Approach - Binary Search \\(O(n \\log (\\max - \\min))\\) \\(O(1)\\)","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0378-kth-smallest-element-in-a-sorted-matrix/#test","title":"Test","text":"","tags":["Heap","Binary Search"]},{"location":"lc-solutions/lc0300-0399/lc0394-decode-string/","title":"LC394. Decode String","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0300-0399/lc0394-decode-string/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 394: Given an encoded string, return its decoded string.</p> <p>The encoding rule is:\u00a0<code>k[encoded_string]</code>, where the\u00a0<code>encoded_string</code>\u00a0inside the square brackets is being repeated exactly\u00a0<code>k</code>\u00a0times. Note that\u00a0<code>k</code>\u00a0is guaranteed to be a positive integer.</p> <p>You may assume that the input string is always valid; there are no extra white spaces, square brackets are well-formed, etc. Furthermore, you may assume that the original data does not contain any digits and that digits are only for those repeat numbers,\u00a0<code>k</code>. For example, there will not be input like\u00a0<code>3a</code>\u00a0or\u00a0<code>2[4]</code>.</p> <p>The test cases are generated so that the length of the output will never exceed\u00a0<code>105</code>.</p>","tags":["Stack"]},{"location":"lc-solutions/lc0300-0399/lc0394-decode-string/#clarification","title":"Clarification","text":"<ul> <li>Go through encoded rule</li> <li>Always have a valid input?</li> <li>Only contains english letters, digits, and square brackets <code>[]</code>?</li> <li>So no <code>3a</code>. Instead, <code>3[a]</code></li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0300-0399/lc0394-decode-string/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Stack"]},{"location":"lc-solutions/lc0300-0399/lc0394-decode-string/#solution","title":"Solution","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0300-0399/lc0394-decode-string/#approach-stack","title":"Approach - Stack","text":"<p>Uses a stack to handle nested patterns in the encoded string. It loops through the characters of the string,</p> <ul> <li>when encountering open bracket <code>[</code>, push the current string and number onto the stack.</li> <li>when encountering a closing bracket <code>]</code>, it pops the stack to retrieve the previous string and repeats the current string according to the last number, then concatenates it.</li> <li>digits are processed to form numbers.</li> <li>regular characters are appended directly to the current string.</li> </ul> Python <pre><code>class Solution:\ndef decodeString(self, s: str) -&gt; str:\n    stack = deque()\n    curr_string = \"\"\n    curr_num = 0\n\n    for c in s:\n        if c == \"[\":\n            stack.append(curr_string)\n            stack.append(curr_num)\n            curr_string = \"\"\n            curr_num = 0\n        elif c == \"]\":\n            num = stack.pop()\n            prev_string = stack.pop()\n            curr_string = prev_string + curr_string * num\n        elif c.isdigit():\n            curr_num = curr_num * 10 + int(c)\n        else:\n            curr_string += c\n    return curr_string\n</code></pre>","tags":["Stack"]},{"location":"lc-solutions/lc0300-0399/lc0394-decode-string/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   The algorithm processes each character in the input string exactly once, when \\(n\\) is the length of the input string. For stack pushing and pop, the time complexity is \\(O(1)\\). For string concatenation, it concatenates at most \\(n\\) letters, so the time complexity is within \\(O(n)\\).</li> <li>Space complexity: \\(O(m)\\), where \\(m\\) is the size of the expanded string, which can be larger than \\(n\\) if there are many repeated segments.</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0300-0399/lc0394-decode-string/#test","title":"Test","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/","title":"LC399. Evaluate Division","text":"","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 399: You are given an array of variable pairs\u00a0<code>equations</code>\u00a0and an array of real numbers <code>values</code>, where\u00a0<code>equations[i] = [Ai, Bi]</code>\u00a0and\u00a0<code>values[i]</code>\u00a0represent the equation\u00a0 <code>Ai / Bi = values[i]</code>. Each\u00a0<code>Ai</code>\u00a0or\u00a0<code>Bi</code>\u00a0is a string that represents a single variable.</p> <p>You are also given some\u00a0<code>queries</code>, where\u00a0<code>queries[j] = [Cj, Dj]</code>\u00a0represents the\u00a0<code>jth</code> query where you must find the answer for\u00a0<code>Cj / Dj = ?</code>.</p> <p>Return\u00a0the answers to all queries. If a single answer cannot be determined, return <code>-1.0</code>.</p> <p>Note:\u00a0The input is always valid. You may assume that evaluating the queries will not result in division by zero and that there is no contradiction.</p> <p>Note:\u00a0The variables that do not occur in the list of equations are undefined, so the answer cannot be determined for them.</p>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#clarification","title":"Clarification","text":"<ul> <li>A single answer for one query?</li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#assumption","title":"Assumption","text":"<ul> <li>No contradiction</li> <li>No division by zero</li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#solution","title":"Solution","text":"<p>We can transform the equations into directed weighted graph, where each variable is a vertex and the division relationship between variables is edge with direction and weight. The direction of edge indicates the order of division and the weight of edge indicates the result of division.</p> <p>For example, the equations \\(a / b = 2\\) and \\(b / c = 3\\) can be represented in the following graph.</p> <pre><code>    graph LR\n        a((a))\n        b((b))\n        c((c))\n        a -- \"a/b = 2\" --&gt; b -- \"b/c = 3\" --&gt; c\n        c -- \"c/b = 1/3\" --&gt; b -- \"b/a = 1/2\" --&gt; a</code></pre> <p>To evaluate a query is equivalent to perform two task:</p> <ol> <li>find if there exists a path between the two vertices;</li> <li>If exists, calculate the cumulative product along the path.</li> </ol>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#approach-1-bfsdfs","title":"Approach 1 - BFS/DFS","text":"<p>First build the directed weighted graph from equations. Then we can use either Breadth-First Search (BFS) or Depth-First Search (DFS) to find the path between two nodes and calculate the cumulative product along the path if exists.</p> Python - BFSPython - DFS <pre><code>from collections import defaultdict, deque\n\n\nclass Solution:\n    def calcEquation(\n        self, equations: List[List[str]], values: List[float], queries: List[List[str]]\n    ) -&gt; List[float]:\n\n        #  (1)\n        graph = defaultdict(list)\n        for (num, den), value in zip(equations, values):\n            graph[num].append((den, value))\n            graph[den].append((num, 1.0 / value))\n\n        results = [-1] * len(queries)\n        for i, (num, den) in enumerate(queries):\n            if num in graph and den in graph:\n                results[i] = self.bfs(num, den, graph)\n\n        return results\n\n    def bfs(self, start_node: str, end_node: str, graph: dict[dict]) -&gt; float:\n        visited = set([None, start_node])\n        queue = deque([(start_node, 1.0)])  #  (2)\n\n        while queue:\n            curr_node, cum_product = queue.popleft()\n            if curr_node == end_node:\n                return cum_product\n\n            for next_node, next_value in graph[curr_node]:\n                if (curr_node, next_node) not in visited:\n                    visited.add((curr_node, next_node))\n                    queue.append((next_node, cum_product * next_value))\n\n        return -1.0  #  (3)\n</code></pre> <ol> <li>Build directional graph with weights from the equations. Use dict of list to store node to node connections and weights.</li> <li>Store <code>(node, cumulative product)</code>.</li> <li>Not find end node</li> </ol> <pre><code>from collections import defaultdict, deque\n\n\nclass Solution:\n    def calcEquation(\n        self, equations: List[List[str]], values: List[float], queries: List[List[str]]\n    ) -&gt; List[float]:\n\n        #  (1)\n        graph = defaultdict(list)\n        for (num, den), value in zip(equations, values):\n            graph[num].append((den, value))\n            graph[den].append((num, 1.0 / value))\n\n        results = [-1] * len(queries)\n        for i, (num, den) in enumerate(queries):\n            if num in graph and den in graph:\n                visited = set([(None, num)])\n                results[i] = self.dfs(num, den, graph, visited, 1.0)\n\n        return results\n\n    def dfs(\n        self,\n        curr_node: str,\n        target_node: str,\n        graph: dict[dict],\n        visited: set,\n        cum_product: float,\n    ) -&gt; float:\n        if curr_node == target_node:\n            return cum_product\n\n        for next_node, next_value in graph[curr_node]:\n            if (curr_node, next_node) not in visited:\n                visited.add((curr_node, next_node))\n                result = self.dfs(\n                    next_node, target_node, graph, visited, cum_product * next_value\n                )\n                if result &gt; -1.0:\n                    return result\n\n        return -1.0  #  (2)\n</code></pre> <ol> <li>Build directional graph with weights from the equations. Use dict of list to store node to node connections and weights.</li> <li>Not find end node</li> </ol>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(Q (V + E))\\) where \\(Q\\) is the number of queries, \\(V\\) is the number of variables (vertices) and \\(E\\) is the number of divisions (edges)  <ul> <li>Build directed weighted graph takes \\(O(E)\\) since it goes through all equations (i.e., edges);</li> <li>When iterating the \\(Q\\) queries:<ul> <li>if conditions check with dict access takes \\(O(1)\\);</li> <li>In the worst case, BFS/DFS visit all nodes exact once by exploring all neighboring edges, which takes \\(O(V + E)\\); So the total time complexity is \\(O(E) + O(Q (V + E)) = O(Q (V + E))\\).</li> </ul> </li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li>The directed weighted graph dictionary takes \\(O(V + E)\\) space</li> <li><code>visited</code> takes \\(O(V)\\) in the worst case</li> <li>DFS call stack or BFS queue take \\(O(V)\\) space in the worst case So the total space complexity is \\(O(V + E) + O(V) + O(V) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#approach-2-union-find","title":"Approach 2 - Union Find","text":"<p>The problem can also be solved by customized union-find data structure. We can use union-find data structure to easily determine whether there is a path between two vertices. But we need some customization to calculate the cumulative product along the path:</p> <ul> <li>Build a map between <code>node</code> as a key and <code>(root, weight)</code> as a value. The <code>weight</code> is a ratio between <code>node</code> and <code>root</code>, i.e., <code>weight = node / root</code></li> <li>In the <code>find(x)</code> function, update the new <code>weight</code> element besides updating <code>root</code> normally. We can still use path compression and recursively update all the root node in the path to root. The weight between the current node <code>x</code> and <code>root</code>, <code>x / root</code> is calculated using, <code>x / root = (x / parent) * (parent / root)</code>. Note that <code>find(parent)</code> will return updated weight between <code>parent</code> and <code>root</code>, <code>parent / root</code>.</li> <li>In the <code>union(x, y, x_y_weight)</code> function, merge <code>root[x]</code> into <code>root[y]</code> branches by making <code>root[root[x]] = root[y]</code> and calculating the weight between <code>root[x]</code> and <code>root[y]</code>, <code>root[x] / root[y] = (x / y) * (y / root[y]) / (x / root[x])</code>. Note that when merging <code>root[y]</code> into <code>root[x]</code>, the weight is between <code>root[y]</code> and <code>root[x]</code>, <code>root[y] / root[x] = (x / root[x]) / ((x / y) * (y / root[y]))</code>. Refer to diagrams below for illustrations.</li> </ul> <pre><code>    graph LR\n        x((x))\n        p((parent))\n        r((root))\n        x -- \"x / parent\" --&gt; p -- \"parent / root\" --&gt; r\n        x == \"x / root\" ==&gt; r</code></pre> <pre><code>    graph LR\n        x((x))\n        r_x((\"root[x]\"))\n        y((y))\n        r_y((\"root[y]\"))\n        x -- \"x / root[x]\" --&gt; r_x\n        x -- \"x / y \" --&gt; y\n        y -- \"y / root[y]\" --&gt; r_y\n        r_x == \"root_x / root_y\"  ==&gt; r_y</code></pre> <pre><code>    graph LR\n        x((x))\n        r_x((\"root[x]\"))\n        y((y))\n        r_y((\"root[y]\"))\n        x -- \"x / root[x]\" --&gt; r_x\n        x -- \"x / y \" --&gt; y\n        y -- \"y / root[y]\" --&gt; r_y\n        r_y == \"root_y / root_x\"  ==&gt; r_x</code></pre> <p>With the customized union-find structure, we can</p> <ol> <li>iterate through each equation and union them with divisions</li> <li>evaluate the query one by one. If both variables, <code>x</code> and <code>y</code>, have the same <code>root</code>. Then we can calculate <code>x / y = (x / root) / (y / root)</code>.</li> </ol> pythonPython - Union by Rank <pre><code>class UnionFind:\n    def __init__(self):\n        self.root = {}  # (1)\n\n    def find(self, x: str) -&gt; tuple[str, float]:\n        if x not in self.root:\n            self.root[x] = (x, 1.0)  # (2)\n        parent, x_parent_weight = self.root[x]\n        if x != parent:  # with path compression\n            root, parent_root = self.find(parent)\n            self.root[x] = (root, x_parent_weight * parent_root)\n        return self.root[x]\n\n    def union(self, x, y, x_y_weight):\n        root_x, x_rootx_weight = self.find(x)\n        root_y, y_rooty_weight = self.find(y)\n        if root_x != root_y:\n            self.root[root_x] = (root_y, x_y_weight * y_rooty_weight / x_rootx_weight)\n\n    def exist(self, x) -&gt; bool:\n        return x in self.root\n\n\nclass Solution:\n    def calcEquation(self, equations: List[List[str]], values: List[float],\n    queries: List[List[str]]) -&gt; List[float]:\n        uf = UnionFind()\n        for (num, den), value in zip(equations, values):\n            uf.union(num, den, value)\n\n        results = [-1.0] * len(queries)\n        for i, (num, den) in enumerate(queries):\n            if not uf.exist(num) or not uf.exist(den):\n                results[i] = -1.0\n            else:\n                num_id, num_weight = uf.find(num)\n                den_id, den_weight = uf.find(den)\n                if num_id != den_id:\n                    results[i] = -1.0  # not connected\n                else:\n                    results[i] = num_weight / den_weight\n\n        return results\n</code></pre> <ol> <li>Dictionary of key: node, value: (root, weight).</li> <li>Default root is itself, weight is 1.0 (x / root[x] = x / x = 1.0)</li> </ol> <pre><code>class UnionFind:\n    def __init__(self):\n        self.root = {}\n        self.rank = {}  # (1)\n\n    def find(self, x: str) -&gt; tuple[str, float]:\n        if x not in self.root:\n            self.root[x] = (x, 1.0)\n            self.rank[x] = 0\n        parent, x_parent_weight = self.root[x]\n        if x != parent:  # with path compression\n            root, parent_root = self.find(parent)\n            self.root[x] = (root, x_parent_weight * parent_root)\n        return self.root[x]\n\n    def union(self, x, y, x_y_weight):\n        root_x, x_rootx_weight = self.find(x)\n        root_y, y_rooty_weight = self.find(y)\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = (root_x, x_rootx_weight / (x_y_weight * y_rooty_weight))  # (2)\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = (root_y, x_y_weight * y_rooty_weight / x_rootx_weight)  # (3)\n            else:\n                self.root[root_y] = (root_x, x_rootx_weight / (x_y_weight * y_rooty_weight))\n                self.rank[root_x] += 1\n</code></pre> <ol> <li>Dictionary of key: node, value: rank</li> <li>Calculate weight <code>root[y] / root[x]</code></li> <li>Calculate weight <code>root[x] / root[y]</code></li> </ol>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O((Q + E) \\alpha(V))\\) where \\(Q\\) is number of queries, \\(E\\) is the number of equations (i.e., edges), and \\(V\\) is the number of variables (i.e., vertices)  <ul> <li>For union all equations, it takes \\(O(E)\\) iterations to go through all equations. Each iteration calls <code>union</code> function and takes \\(O(\\alpha(V))\\) time complexity. So union all equations take \\(O(E \\alpha(V))\\);</li> <li>For evaluating all queries, it takes \\(O(Q)\\) iterations to go through all queries. Each iteration may call <code>find</code> function and take \\(O(\\alpha(V))\\) in the worst case. So evaluation queries take \\(O(Q \\alpha(V))\\);</li> <li>Build result array takes \\(O(Q)\\); So the total time complexity is \\(O(E \\alpha(V)) + O(Q \\alpha(V)) + O(Q) = O((Q + E) \\alpha(V))\\).</li> </ul> </li> <li>Space complexity: \\(O(V)\\)   The union find structure takes \\(O(V)\\) space to store <code>root</code> and <code>rank</code></li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - BFS/DFS \\(O(Q (V + E))\\) \\(O(V + E)\\) Approach 2 - Union Find \\(O((Q + E) \\alpha(V))\\) \\(O(V)\\)","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0300-0399/lc0399-evaluate-division/#test","title":"Test","text":"","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc0400-0499/lc0410-split-array-largest-sum/","title":"LC410. Split Array Largest Sum","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0410-split-array-largest-sum/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 410: Given an integer array\u00a0<code>nums</code>\u00a0and an integer\u00a0<code>k</code>, split\u00a0<code>nums</code>\u00a0into\u00a0<code>k</code>\u00a0non-empty subarrays such that the largest sum of any subarray is\u00a0minimized.</p> <p>Return\u00a0the minimized largest sum of the split.</p> <p>A\u00a0subarray\u00a0is a contiguous part of the array.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0410-split-array-largest-sum/#clarification","title":"Clarification","text":"<ul> <li>split <code>nums</code> into <code>k</code> subarrays</li> <li>subarray is not empty and a contiguous part</li> <li>the largest sum is minimized. what does it mean?</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0410-split-array-largest-sum/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0410-split-array-largest-sum/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0410-split-array-largest-sum/#approach-binary-search","title":"Approach - Binary Search","text":"<p>The problem can be considered as searching the  minimum largest subarray sum, that can split the array at most <code>k</code> subarrays. For a given minimum largest subarray sum, <code>m</code>,</p> <ul> <li>If the array can be split into <code>k</code> or fewer subarrays, there could be a potential solution. For fewer subarrays, we can always split them to increase the count. </li> <li>If the array can be split more than <code>k</code> subarrays, it means <code>m</code> value is too small.</li> </ul> <p>Based on these properties, we can use binary search. The search space is between maximum value of the array and sum of the array.</p> Python <pre><code>class Solution:\n    def splitArray(self, nums: List[int], k: int) -&gt; int:\n        ans = -1\n        low, high = max(nums), sum(nums)\n        while low &lt;= high:\n            mid = (low + high) // 2\n            if self.is_valid(nums, k, mid):  # (1)\n                ans = mid\n                high = mid - 1\n            else:\n                low = mid + 1\n        return ans\n\n    def is_valid(self, nums: List[int], k: int, max_sum_allowed: int):\n        n_splits, curr_sum = 0, 0\n        for num in nums:\n            if curr_sum + num &lt;= max_sum_allowed:\n                curr_sum += num\n            else:\n                n_splits += 1  # (2)\n                curr_sum = num\n        n_subarray = n_splits + 1  # (3)\n        return n_subarray &lt;= k\n</code></pre> <ol> <li>Can cut into <code>m</code> sub-arrays with maximum sum of <code>mid</code></li> <li>Increase the number of splits</li> <li>Number of subarrays is the number of splits + 1</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0410-split-array-largest-sum/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log s)\\) where \\(n\\) is the array length and \\(s\\) is the array sum. The binary search space is \\(s\\), which takes \\(O(\\log s)\\) time. During each iteration, it takes \\(O(n)\\) time to compute number of subarrays. So the total time complexity is \\(O(n \\log s)\\).</li> <li>Space complexity: \\(O(1)\\) Just limited number of variables. Therefore, constant extra space. </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0410-split-array-largest-sum/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/","title":"426. Convert Binary Search Tree to Sorted Doubly Linked List","text":"","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 426: Convert a\u00a0Binary Search Tree\u00a0to a sorted\u00a0Circular Doubly-Linked List\u00a0in place.</p> <p>You can think of the left and right pointers as synonymous to the predecessor and successor pointers in a doubly-linked list. For a circular doubly linked list, the predecessor of the first element is the last element, and the successor of the last element is the first element.</p> <p>We want to do the transformation\u00a0in place. After the transformation, the left pointer of the tree node should point to its predecessor, and the right pointer should point to its successor. You should return the pointer to the smallest element of the linked list.</p>","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#solution","title":"Solution","text":"","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#approach-1-standard-in-order-traversal","title":"Approach 1: Standard In-order Traversal","text":"<p>This problem can be solved using the standard in-order traversal. The in-order traversal of a binary search tree (BST) visits the nodes in sorted order. We can use this property to build a doubly linked list.</p> <p>Following the in-order traversal (<code>left -&gt; node -&gt; right</code>), we can explore the left -&gt; build links between prev and curr -&gt; explore the right.</p> <p>To facilitate the link building:</p> <ul> <li>Use a <code>dummy</code> node to keep track of the head of the doubly linked list.</li> <li>Use a <code>prev</code> pointer to keep track of the previous node in the traversal. This will be used to connect the current node with the previous node.</li> </ul> <p>After the in-order traversal, connect the head (<code>dummy.right</code>) and tail (<code>prev</code>) of the doubly linked list to make it circular.</p> Python <pre><code>class Solution:\n    def treeToDoublyList(self, root: 'Optional[Node]') -&gt; 'Optional[Node]':\n        if root is None:\n            return None\n\n        dummy = Node(-1)\n        self.prev = dummy\n        self._inorder_conversion(root)\n\n        # Connect head (dummy.right) and tail (self.prev)\n        self.prev.right = dummy.right\n        dummy.right.left = self.prev\n\n        return dummy.right\n\n    def _inorder_conversion(self, curr: 'Optional[Node]') -&gt; None:\n        if curr is None:\n            return\n\n        # Explore left subtree\n        self._inorder_conversion(curr.left)\n\n        # Build connections between prev and curr\n        self.prev.right = curr\n        curr.left = self.prev\n        self.prev = curr\n\n        # Explore right subtree\n        self._inorder_conversion(curr.right)\n</code></pre>","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   The algorithm visits each node exactly once for total \\(n\\) nodes.</li> <li>Space complexity: \\(O(n)\\)   The space complexity is due to the recursion stack, which can go as deep as the   height of the tree. In the worst case (for example, every node only has left child),   the recursion stack takes \\(O(n)\\) space. In the best case (a balanced binary tree),   the recursion stack takes \\(O(\\log n)\\) space.</li> </ul>","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#approach-2-morris-in-order-traversal","title":"Approach 2: Morris In-order Traversal","text":"<p>This problem can be solved using Morris in-order traversal. The Morris traversal adds a link from the rightmost node of the left subtree to the current node. By leveraging this:</p> <ul> <li>Keep this link (not remove it like the original Morris traversal)</li> <li>Add a link from the current node to the rightmost node of the left subtree. So we can build the doubly linked list in place.</li> <li>Store <code>prev</code> node whenever we move to the right subtree. This will be used to connect the leftmost node of the right subtree to the current node.</li> </ul> python <pre><code>class Solution:\n    def treeToDoublyList(self, root: 'Optional[Node]') -&gt; 'Optional[Node]':\n        if root is None:\n            return root\n\n        # Find head\n        node = root\n        while node.left is not None:\n            node = node.left\n        head = node\n\n        # Find tail\n        node = root\n        while node.right is not None:\n            node = node.right\n        tail = node\n\n        # Use morris in-order traversal to build links\n        prev = None\n        curr = root\n        while curr is not None:\n            if curr.left is None:\n                # Finish exploring the left tree, explore the right\n                if prev is not None:\n                    curr.left, prev.right = prev, curr\n                prev = curr  # Update prev when moving to right\n                curr = curr.right\n            else:\n                predecessor = curr.left\n\n                # Find the right most node of the left subtree\n                while predecessor.right is not None and predecessor.right is not curr:\n                    predecessor = predecessor.right\n\n                # Two conditions after while loop\n                # 1) predecessor.right is None\n                # 2) left subtree is explored\n\n                if predecessor.right is None:\n                    predecessor.right = curr\n                    curr = curr.left\n                else:\n                    prev = curr  # store this node and will be connected with left most node of right subtree\n                    curr.left = predecessor  # Keep predecessor.right link and add link back from the current\n                    curr = curr.right\n\n        # Build connection between head and tail\n        head.left, tail.right = tail, head\n\n        return head\n</code></pre>","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   We visit each node twice, once for establishing the link and once for exploring it.   Therefore, the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(1)\\)   We use constant space for the pointers <code>prev</code>, <code>curr</code>, and <code>predecessor</code> to build the   list in place.</li> </ul>","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Standard In-order Traversal \\(O(n)\\) \\(O(n)\\) Approach 2 - Morris In-Order Traversal \\(O(n)\\) \\(O(1)\\)","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0426-convert-binary-search-tree-to-sorted-doubly-linked-list/#test","title":"Test","text":"<ul> <li>Test empty tree</li> <li>Test single node tree</li> <li>Test two nodes tree</li> <li>Test normal tree with more than two nodes and both left and right subtrees</li> <li>Test normal tree with more than two nodes and only left subtree</li> <li>Test normal tree with more than two nodes and only right subtree</li> </ul>","tags":["Binary Search Tree","Doubly-Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0429-n-ary-tree-level-order-traversal/","title":"LC429. N-ary Tree Level Order Traversal","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0429-n-ary-tree-level-order-traversal/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 429: Given an n-ary tree, return the\u00a0level order\u00a0traversal of its nodes' values.</p> <p>Nary-Tree input serialization is represented in their level order traversal, each group of children is separated by the null value (See examples).</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0429-n-ary-tree-level-order-traversal/#clarification","title":"Clarification","text":"<ul> <li>Does the node always have a valid value?</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0429-n-ary-tree-level-order-traversal/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0429-n-ary-tree-level-order-traversal/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0429-n-ary-tree-level-order-traversal/#approach-bfs","title":"Approach - BFS","text":"<p>Use Breadth-First Search (BFS) to traverse the n-ary tree. No need to use visited since it is a n-ary tree and traversing level by level.</p> Python <pre><code>class Solution:\n    def levelOrder(self, root: 'Node') -&gt; List[List[int]]:\n        results = []\n        if not root:\n            return results\n\n        queue = deque([root])\n        while queue:\n            level = []\n            for _ in range(len(queue)):\n                node = queue.popleft()\n                level.append(node.val)\n                queue.extend(node.children)\n\n            results.append(level)  # (1)\n\n        return results\n</code></pre> <ol> <li>Can also use for-loop as well. <pre><code>for child in node.children:\n    queue.append(child)\n</code></pre></li> </ol>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0429-n-ary-tree-level-order-traversal/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Process total \\(n\\) nodes exact once and each node takes \\(O(1)\\) time. So the total time complexity is \\(O(n)\\). </li> <li>Space complexity: \\(O(n)\\)   In the worst case, most of nodes (\\(n-1\\)) are in one level, so the time complexity is \\(O(n)\\).</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0429-n-ary-tree-level-order-traversal/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0436-find-right-interval/","title":"LC436. Find Right Interval","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0436-find-right-interval/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 436: You are given an array of\u00a0<code>intervals</code>, where\u00a0<code>intervals[i] = [starti, endi]</code>\u00a0and each\u00a0<code>starti</code>\u00a0is\u00a0unique.</p> <p>The\u00a0right interval\u00a0for an interval\u00a0<code>i</code>\u00a0is an interval\u00a0<code>j</code>\u00a0such that\u00a0<code>startj &gt;= endi</code>\u00a0and\u00a0<code>startj</code>\u00a0is\u00a0minimized. Note that\u00a0<code>i</code>\u00a0may equal\u00a0<code>j</code>.</p> <p>Return\u00a0an array of\u00a0right interval\u00a0indices for each interval\u00a0<code>i</code>. If no\u00a0right interval\u00a0exists for interval\u00a0<code>i</code>, then put\u00a0<code>-1</code>\u00a0at index\u00a0<code>i</code>.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0436-find-right-interval/#clarification","title":"Clarification","text":"<ul> <li>an array of [start_i, end_i]</li> <li>start_i is unique</li> <li>Right interval?</li> <li>Can end_i &lt; start_i?</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0436-find-right-interval/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0436-find-right-interval/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0436-find-right-interval/#approach-sort-binary-search","title":"Approach - Sort + Binary Search","text":"<p>From intervals, take <code>(start_i, i)</code> to formulate a new list. Sort the list based on <code>start_i</code> value. Then find <code>start_i</code> that meets the right interval requirement and return index <code>i</code></p> Python <pre><code>class Solution:\n    def findRightInterval(self, intervals: List[List[int]]) -&gt; List[int]:\n        l = sorted((e[0], i) for i, e in enumerate(intervals))\n        n = len(l)\n        res = []\n        for e in intervals:\n            r = bisect.bisect_left(l, (e[1],))  # (1)\n            res.append(l[r][1] if r &lt; n else -1)\n        return res\n</code></pre> <ol> <li>Or use key function, <code>bisect_left(l, e[1], key=lambda value: value[0])</code></li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0436-find-right-interval/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\)     Sort takes \\(O(n \\log n)\\) and for-loop with binary search takes another \\(O(n \\log n)\\). So overall time complexity is \\(O(n \\log n)\\)</li> <li>Space complexity: \\(O(n)\\)     Need to store a list of <code>(start_i, i)</code> and therefore use \\(O(n)\\) space</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/","title":"LC441. Arranging Coins","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 441: You have\u00a0<code>n</code>\u00a0coins and you want to build a staircase with these coins. The staircase consists of\u00a0<code>k</code>\u00a0rows where the\u00a0<code>ith</code>\u00a0row has exactly\u00a0<code>i</code>coins. The last row of the staircase\u00a0may be\u00a0incomplete.</p> <p>Given the integer\u00a0<code>n</code>, return\u00a0the number of\u00a0complete rows\u00a0of the staircase you will build.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#clarification","title":"Clarification","text":"<ul> <li>ith row contains i coins</li> <li>the last row may or may be incomplete</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#assumption","title":"Assumption","text":"<ul> <li>n &gt;= 1</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#approach-brutal-force","title":"Approach - Brutal Force","text":"<p>Follow the problem descriptions, add coins along each row until <code>sum &gt;= n</code>.</p> Python <pre><code>class Solution:\n    def arrangeCoins(self, n: int) -&gt; int:\n        sum = 0\n        for i_row in range(1, n + 1):\n            sum += i_row\n            if sum == n:\n                return i_row\n\n            if sum &gt; n:\n                return i_row - 1\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\sqrt{n})\\) We will go trough \\(k\\) rows, \\(k \\leq \\sqrt{2n + 0.25}- 0.5\\). Refer to the math section below.</li> <li>Space complexity: \\(O(1)\\) Use two variables, <code>sum</code> and <code>i_row</code></li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#approach-binary-search","title":"Approach - Binary Search","text":"<p>The problem can be expressed by the following equation:</p> \\[1 + 2 + 3 + \\dots + k + x = n\\] <p>where \\(x\\) represents the last incomplete row with range \\(0 &lt;= x &lt; (k + 1)\\).</p> <p>Essentially, we are trying to find \\(k\\) that satisfies:</p> \\[1 + 2 + 3 + \\dots + k \\leq n\\] <p>which means</p> \\[k * (k + 1) \\leq 2n\\] <p>Then we can use binary search to find \\(k\\) effectively.</p> Python <pre><code>class Solution:\n    def arrangeCoins(self, n: int) -&gt; int:\n        left, right = 0, n\n\n        while left &lt; right - 1:\n            mid = (left + right) // 2\n            num = mid * (mid + 1)\n\n            if num == 2 * n:\n                return mid\n            elif num &lt; 2 * n:\n                left = mid\n            else:\n                right = mid - 1\n\n        if right * (right + 1) &lt;= 2 * n:\n            return right\n        else:\n            return left\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) Since using the binary search to find \\(k\\) from space <code>[0, n]</code>, the time complexity is \\(O(\\log n)\\)</li> <li>Space complexity: \\(O(1)\\) Use 3 variables, <code>left</code>, <code>mid</code>, <code>right</code>.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#approach-math","title":"Approach - Math","text":"<p>The equation \\(k * (k + 1) \\leq 2n\\) can be further reduced to:</p> \\[\\begin{align} k^2 + k &amp;\\leq 2n \\\\ (k + 0.5)^2 &amp;\\leq 2n + 0.25 \\\\ k &amp;\\leq \\sqrt{2n + 0.25}- 0.5 \\end{align}\\] <p>Since we want the row has full coins, we just find the floor value of \\(k\\) in the above equation.</p> Python <pre><code>class Solution:\n    def arrangeCoins(self, n: int) -&gt; int:\n        return math.floor(math.sqrt(2 * n + 0.25) - 0\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#complexity-analysis_2","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(1)\\) Just solve the equation directly. So the time complexity is \\(O(1)\\).</li> <li>Space complexity: \\(O(1)\\) </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Brutal Force \\(O(\\sqrt{n})\\) \\(O(1)\\) Approach - Binary Search \\(O(\\log n)\\) \\(O(1)\\) Approach - Math \\(O(1)\\) \\(O(1)\\)","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0441-arranging-coins/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/","title":"LC445. Add Two Numbers II","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 445: You are given two\u00a0non-empty\u00a0linked lists representing two non-negative integers. The most significant digit comes first and each of their nodes contains a single digit. Add the two numbers and return the sum as a linked list.</p> <p>You may assume the two numbers do not contain any leading zero, except the number 0 itself.</p>","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#clarification","title":"Clarification","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#approach-reverse","title":"Approach - Reverse","text":"<p>For the list, the most significant digit comes first and each node includes a single digit. A basic addition of two numbers start with the least significant digits. So we need to </p> <ol> <li>Reverse the given lists to get the least significant digits first same as LC206 reverse linked list. </li> <li>Then we can iterate over the reversed lists to perform the addition same as LC2 Add two numbers.  Once get the result list, reverse it.</li> <li>Reverse the result list since the required result start with the most significant digit</li> </ol> Python <pre><code>class Solution:\n    def addTwoNumbers(self, l1: Optional[ListNode], l2: Optional[ListNode]) -&gt; Optional[ListNode]:\n        l1_reversed = self.reverseList(l1)\n        l2_reversed = self.reverseList(l2)\n\n        sum_list = self.addTwoNumbersInternal(l1_reversed, l2_reversed)\n        return self.reverseList(sum_list)\n\n    def reverseList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        prev = None\n        curr = head\n\n        while curr:\n            nxt = curr.next\n            curr.next = prev\n            prev = curr\n            curr = nxt\n\n        return prev\n\n    def addTwoNumbersInternal(self, l1: Optional[ListNode], l2: Optional[ListNode]) -&gt; Optional[ListNode]:\n        dummy_head = ListNode(-1, None)\n        carry = 0\n        tail = dummy_head\n\n        while l1 or l2 or carry:\n            if l1:\n                digit1 = l1.val\n                l1 = l1.next\n            else:\n                digit1 = 0\n\n            if l2:\n                digit2 = l2.val\n                l2 = l2.next\n            else:\n                digit2 = 0\n\n            total = digit1 + digit2 + carry\n            digit = total % 10\n            carry = total // 10\n\n            new_node = ListNode(digit, None)\n            tail.next = new_node\n            tail = tail.next\n\n        return dummy_head.next\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Assume \\(n_1\\) and \\(n_2\\) are the number of nodes in <code>l1</code> and <code>l2</code> respectively. It takes \\(n_1\\) steps to reverse l1 list, \\(n_2\\) steps to reverse l2 list, at most \\(\\max(n_1, n_2) + 1\\) steps to do addition, and another \\(\\max(n_1, n_2) + 1\\) steps for reversing the list. So total steps is \\(n_1 + n_2 + 2 \\max(n_1, n_2)\\).</li> <li>Space complexity: \\(O(n)\\)     Need to create a new list with at most \\(\\max(n_1, n_2) + 1\\) nodes. Except that, just use several pointers with \\(O(1)\\) space. </li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#approach-stack","title":"Approach - Stack","text":"<p>In the previous approach, we reverse the linked lists to access the least significant digits first. We can also use stacks to access the least significant digits first, pushing the most significant digit to the bottom and the least significant digit to the top. Then perform digit-wise addition by popping up values from stack and considering any carry-over.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def addTwoNumbers(self, l1: Optional[ListNode], l2: Optional[ListNode]) -&gt; Optional[ListNode]:\n        stack1 = deque()\n        stack2 = deque()\n\n        curr = l1\n        while curr:\n            stack1.append(curr.val)\n            curr = curr.next\n\n        curr = l2\n        while curr:\n            stack2.append(curr.val)\n            curr = curr.next\n\n        carry = 0\n        prev = None\n        while stack1 or stack2 or carry &gt; 0:\n            if stack1:\n                digit1 = stack1.pop()\n            else:\n                digit1 = 0\n\n            if stack2:\n                digit2 = stack2.pop()\n            else:\n                digit2 = 0\n\n            total = digit1 + digit2 + carry\n            digit = total % 10\n            carry = total // 10\n\n            curr = ListNode(digit, prev)\n            prev = curr\n\n        return curr\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It takes \\(n_1\\) steps to push l1 list to stack, \\(n_2\\) steps to push l2 list to stack, and at most \\(\\max(n_1, n_2) + 1\\) to do addition.  So the total steps are \\(n_1 + n_2 + \\max(n_1, n_2)\\)</li> <li>Space complexity: \\(O(n)\\)     Besides new list with at most \\(\\max(n_1, n_2) + 1\\) nodes and two stacks to store \\(n_1\\) and \\(n_2\\) nodes respectively.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Reverse \\(O(n)\\) \\(O(1)\\) except result Approach - Stack \\(O(n)\\) \\(O(n)\\) except result","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0445-add-two-numbers-ii/#test","title":"Test","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/","title":"LC448. Find All Numbers Disappeared in an Array","text":"","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 448: Given an array <code>nums</code> of <code>n</code> integers where <code>nums[i]</code> is in the range <code>[1, n]</code>, return an array of all the integers in the range <code>[1, n]</code> that do not appear in <code>nums</code>.</p>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#clarification","title":"Clarification","text":"<ul> <li>Can the input array be modified? Different solutions</li> </ul>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#assumption","title":"Assumption","text":"","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#solution","title":"Solution","text":"<p>@archit91 shares a good summary on different ways to solve this problem. There are two general approaches to solve this problem:   </p> <ul> <li>Use additional data structure (e.g. hashset or bool array) to store the information of whether number appears  </li> <li>Modify original array (e.g. swap or negation) to store the information of whether numbers appear  </li> </ul>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#approach-hashset","title":"Approach - Hashset","text":"<p>Initialize a hashset with all elements from <code>nums</code> and then iterate over the range <code>[1, n]</code> and only add elements that are not present in the hashset to the <code>ans</code>. </p> PythonC++ <pre><code>class Solution:\ndef findDisappearedNumbers(self, nums: List[int]) -&gt; List[int]:\n    nums_unique = set(nums)\n    return [i for i in range(1, len(nums) + 1) if i not in nums_unique]\n</code></pre> <pre><code>class Solution {\npublic:\n    vector&lt;int&gt; findDisappearedNumbers(vector&lt;int&gt;&amp; nums) {\n        unordered_set&lt;int&gt; s(nums.begin(), nums.end());\n        vector&lt;int&gt; ans(nums.size() - s.size());\n\n        // Note check range [1, n] so i strarts from 1 not 0, and &lt;= n not &lt; n\n        for (int i = 1, j = 0; i &lt;= nums.size(); i++) {\n            if (s.count(i) == 0) {\n                ans[j++] = i;\n            }\n        }\n        return ans;\n    }\n};\n</code></pre>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It requires \\(O(n)\\) time to insert all elements into hashset and another \\(O(n)\\) time to iterate over range, check whether element in the hashset and insert elements not present into <code>ans</code>. Note that the average time complexity of checking existence in a hashset is O(1). So the total time complexity of \\(O(n) = O(n) + O(n)\\).  </li> <li>Space complexity: \\(O(n)\\)     Store at most \\(n\\) elements in the hashset. </li> </ul>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#approach-mark-as-seen-by-negation","title":"Approach - Mark as Seen by Negation","text":"<p>We can map each element of the range <code>[1, n]</code> to the indices of <code>nums</code> from <code>[0, n-1]</code>.  Then making the element <code>nums[nums[i] - 1]</code> negative to indicate <code>nums[i]</code> exist. Need to take care that some elements may already be negative.</p> PythonC++ <pre><code>class Solution:\ndef findDisappearedNumbers(self, nums: List[int]) -&gt; List[int]:\n    # index: 0, 1, 2, ..., n - 1\n    # value: 1, 2, 3, ..., n\n    for i in range(len(nums)):\n        idx = abs(nums[i]) - 1 # (1)\n        if nums[idx] &gt; 0:\n            nums[idx] *= -1\n\n    return [i + 1 for i in range(len(nums)) if nums[i] &gt; 0]\n</code></pre> <ol> <li>Add `abs`` since the value may be flipped before and negative</li> </ol> <pre><code>class Solution {\npublic:\n    vector&lt;int&gt; findDisappearedNumbers(vector&lt;int&gt;&amp; nums) {\n        vector&lt;int&gt; ans;\n\n        for (int c : nums) {\n            int i = abs(c) - 1;\n            if (nums[i] &gt; 0) nums[i] *= -1;\n        }\n\n        for (int i = 0; i &lt; nums.size(); i++) {\n            if (nums[i] &gt; 0) ans.push_back(i+1);  // nums[i] &gt; 0 means i+1 isn't present\n        }\n\n        return ans;\n    }\n};\n</code></pre>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Iterate nums twice and each takes \\(O(n)\\) time. </li> <li>Space complexity: \\(O(1)\\)     Only constant extra space is used except for the output <code>ans</code>. The original array can be easily restored by changing negative values to positive ones. </li> </ul>","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Hashset \\(O(n)\\) \\(O(n)\\) Approach - Masrk as Seen by Negation \\(O(n)\\) \\(O(1)\\)","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0448-find-all-numbers-disappeared-in-an-array/#test","title":"Test","text":"","tags":["Array","Hash Table"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/","title":"LC485. Max Consecutive Ones","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 485: Given a binary array <code>nums</code>, return the maximum number of consecutive <code>1</code>'s in the array.</p>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/#similar-questions","title":"Similar questions","text":"<ul> <li>lc0487-max-consecutive-ones-ii</li> <li>lc1004-max-consecutive-ones-iii</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/#clarification","title":"Clarification","text":"<ul> <li>Binary array: bool or int data type? - Find the maximum number of consecutive 1's</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/#assumption","title":"Assumption","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/#solution","title":"Solution","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/#approach-one-pass","title":"Approach - One Pass","text":"<p>We keep a count of the number of 1's encountered. - Increase the count when encountering 1 - Reset to 0 when encountering 0 update max count accordingly.</p> PythonC++ <pre><code>class Solution:\ndef findMaxConsecutiveOnes(self, nums: List[int]) -&gt; int:\n    n_consecutive_1s = 0\n    max_n_consecutive_1s = 0\n\n    for num in nums:\n        if num == 1:\n            n_consecutive_1s += 1\n        else:\n            n_consecutive_1s = 0\n\n        max_n_consecutive_1s = max(max_n_consecutive_1s, n_consecutive_1s)\n\n    return max_n_consecutive_1s\n</code></pre> <pre><code>class Solution {\npublic:\n    int findMaxConsecutiveOnes(vector&lt;int&gt;&amp; nums) {\n        int count = 0;\n        int maxCount = 0;\n\n        for (int num : nums) {\n            if (num == 1) {\n                count++;\n            }\n            else {\n                count = 0;\n            }\n            maxCount = max(count, maxCount);\n        }\n\n        return maxCount;\n    }\n};\n</code></pre>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/#approach-sliding-window","title":"Approach - Sliding Window","text":"PythonC++ <pre><code>class Solution:\ndef findMaxConsecutiveOnes(self, nums: List[int]) -&gt; int:\n    idx_left = 0\n    max_n_consecutive_1s = 0\n\n    for idx_right in range(len(nums)):\n        if nums[idx_right] == 1:\n            n_consective_1s = idx_right - idx_left + 1\n            max_n_consecutive_1s = max(n_consective_1s, max_n_consecutive_1s)\n        else:\n            idx_left = idx_right + 1\n\n    return max_n_consecutive_1s\n</code></pre> <pre><code>class Solution {\npublic:\n    int findMaxConsecutiveOnes(vector&lt;int&gt;&amp; nums) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size n = nums.size();\n        vec_size left = 0; // left pointer of the sliding window\n        vec_size right = 0;  // right pointer of the sliding window\n        vec_size nZeroInWindow = 0; // number of zeros in the window \n        vec_size count = 0; // number of consecutive 1s in a sliding window\n        vec_size maxCount = 0; // max number of consecutive 1s\n\n        while (right &lt; n) {\n            if (nums[right] == 0) {\n                nZeroInWindow++;\n            }\n\n            while (nZeroInWindow &gt; 0) {\n                if (nums[left] == 0) {\n                    nZeroInWindow--;\n                }\n                left++;\n            }\n\n            if (right &gt;= left) {\n                count = right - left + 1;\n                if (count &gt; maxCount) {\n                    maxCount = count;\n                }\n            }\n\n            right++;\n        }\n\n        return maxCount;\n\n    }\n};\n</code></pre>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0485-max-consecutive-ones/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Iterate the array once.  </li> <li>Space complexity: \\(O(1)\\)     Only use two variables</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/","title":"LC487. Max Consecutive Ones II","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 487: Given a binary array <code>nums</code>, return the maximum number of consecutive <code>1</code>'s in the array if you can flip at most one <code>0</code>.</p> <p>Follow up: What if the input numbers come in one by one as an infinite stream? In other words, you can't store all numbers coming from the stream as it's too large to hold in memory. Could you solve it efficiently?</p>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#similar-questions","title":"Similar questions","text":"<ul> <li>lc0485-max-consecutive-ones</li> <li>lc1004-max-consecutive-ones-iii</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#clarification","title":"Clarification","text":"<ul> <li>Binary array: data type is bool or integer?</li> <li>Re-phrase the question: find the sequence with most 1s but with at most one 0</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#assumption","title":"Assumption","text":"<ul> <li>The maximum number of consecutive 1 can be represented by an integer instead of unsigned integer.  </li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#solution","title":"Solution","text":"<p>There are two different ways to solve the problem efficiently:  - Use two number, one stores number of consecutive 1s and the other store a sequence with at most 1 zero, and update them to find the largest value. - Use sliding window to find the longest sequence with at most 1 zero. - </p>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#approach-two-number","title":"Approach - Two Number","text":"<p>@sunnyleevip shared a method using two numbers: - One stores the current consecutive 1s  - The other stores the case of only a 0 between 1s Update these two numbers: - When <code>num == 1</code>,  increase both numbers - When <code>num == 0</code>, set <code>nOnesAndZero = nOnes + 1</code> and reset <code>nOnes</code>. This is a really smart way to do. My initial submission has to use two addition bool variables and logics to achieve the similar results.</p> <pre><code>class Solution {\npublic:\n    int findMaxConsecutiveOnes(vector&lt;int&gt;&amp; nums) {\n        int nOnesMax = 0;\n        int nOnes = 0; // number of consecutive ones\n        int nOnesAndZero = 0; // number of consecutive ones + 1 zero\n\n        for (int num : nums) {\n            if (num == 1) {\n                nOnes++;\n                nOnesAndZero++;\n            }\n            else {\n                nOnesAndZero = nOnes + 1;\n                nOnes = 0;\n            }\n\n            if (nOnesAndZero &gt; nOnesMax) {\n                nOnesMax = nOnesAndZero;\n            }\n        }\n        return nOnesMax;\n    }\n};\n</code></pre> <p>My initial submission achieves the similar results but using a little complicated logics using two bool variables.  <pre><code>class Solution {\npublic:\n    int findMaxConsecutiveOnes(vector&lt;int&gt;&amp; nums) {\n        int nMaxOne = 0;\n        int nOneP1 = 0;\n        int nOneP2 = 0;\n        bool flipP1 = true; // true: flip from zero to one for pointer 1\n        bool flipP2 = false; // true: flip from zero to one for pointer 2\n\n        for (int num : nums) {\n            if (num == 1) {\n                nOneP1++;\n                nOneP2++;\n            }\n            else {\n                if (flipP1) {\n                    // 0 --&gt; 1\n                    nOneP1++;\n                }\n                else {\n                    if (nOneP1 &gt; nMaxOne) {\n                        nMaxOne = nOneP1;\n                    }\n                    nOneP1 = 0; \n                }\n\n                if (flipP2) {\n                    // 0 --&gt; 1\n                    nOneP2++;\n                }\n                else {\n                    if (nOneP2 &gt; nMaxOne) {\n                        nMaxOne = nOneP2;\n                    }\n                    nOneP2 = 0;\n                }\n\n                flipP1 = !flipP1;\n                flipP2 = !flipP2;\n            }\n        }\n\n        if (nOneP1 &gt; nMaxOne) {\n            nMaxOne = nOneP1;\n        }\n\n        if (nOneP2 &gt; nMaxOne) {\n            nMaxOne = nOneP2;\n        }\n\n        return nMaxOne;\n    }\n};\n</code></pre></p>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Iterate all elements of the array once.   </li> <li>Space complexity: \\(O(1)\\)     Only use 3 local variables and therefore constant space complexity. </li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#approach-sliding-window","title":"Approach - Sliding Window","text":"<p>Use a sliding window (left and right pointers) to find the longest sequence with at most 1 zero: - Expand the window by moving the right pointer forward until reaching invalid window, more than one zero in the current window - Shrink the window by moving the left pointer forward until having a valid window, one of fewer 0's in the current window</p> PythonC++ <pre><code>class Solution:\ndef findMaxConsecutiveOnes(self, nums: List[int]) -&gt; int:\n    idx_left = 0\n    n_max = 0\n    n_zero = 0\n\n    for idx_right in range(len(nums)):\n        if nums[idx_right] == 0:\n            n_zero += 1\n\n        while n_zero &gt;= 2:\n            if nums[idx_left] == 0:\n                n_zero -= 1\n\n            idx_left += 1\n\n        n_max = max(n_max, idx_right - idx_left + 1)\n\n    return n_max\n</code></pre> <pre><code>class Solution {\npublic:\n    int findMaxConsecutiveOnes(vector&lt;int&gt;&amp; nums) {\n        int nMaxOnes = 0;\n        int left = 0;\n        int right = 0;\n        int nZerosWindow = 0; // number of zeros within a window\n        int nElementsWindow = 0;\n\n        // Keep window in bounds\n        while (right &lt; nums.size()) {\n\n            // When expanding to right, update number of zeros in the window\n            if (nums[right] == 0) {\n                nZerosWindow++;\n            }\n\n            // If window is invalid, contract from left\n            while (nZerosWindow == 2) {\n                if (nums[left] == 0) {\n                    nZerosWindow--;\n                }\n                left++;\n            }\n\n            // Update result\n            nElementsWindow = right - left + 1;\n            if (nElementsWindow &gt; nMaxOnes) {\n                nMaxOnes = nElementsWindow;\n            }\n\n            // Expand window to right\n            right++;\n        }\n        return nMaxOnes;\n    }\n};\n</code></pre>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Both left and right pointers only move forward and traverse at most \\(n\\) steps. Therefore, the time complexity is \\(O(n)\\).  </li> <li>Space complexity: \\(O(1)\\)     Only use several variables (pointers and variables to store numbers). The number of variables are constant and do not change with the size of the input.</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - two number \\(O(n)\\) \\(O(1)\\) Approach - sliding window \\(O(n)\\) \\(O(1)\\)","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0487-max-consecutive-ones-ii/#test","title":"Test","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0400-0499/lc0489-robot-room-cleaner/","title":"489. Robot Room Cleaner","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0400-0499/lc0489-robot-room-cleaner/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 489: You are controlling a robot that is located somewhere in a room. The room is modeled as an\u00a0<code>m x n</code>\u00a0binary grid where\u00a0<code>0</code>represents a wall and\u00a0<code>1</code>\u00a0represents an empty slot.</p> <p>The robot starts at an unknown location in the room that is guaranteed to be empty, and you do not have access to the grid, but you can move the robot using the given API\u00a0<code>Robot</code>.</p> <p>You are tasked to use the robot to clean the entire room (i.e., clean every empty cell in the room). The robot with the four given APIs can move forward, turn left, or turn right. Each turn is\u00a0<code>90</code>\u00a0degrees.</p> <p>When the robot tries to move into a wall cell, its bumper sensor detects the obstacle, and it stays on the current cell.</p> <p>Design an algorithm to clean the entire room using the following APIs:</p> <pre><code>interface Robot {\n  // returns true if next cell is open and robot moves into the cell.\n  // returns false if next cell is obstacle and robot stays on the current cell.\n  boolean move();\n\n  // Robot will stay on the same cell after calling turnLeft/turnRight.\n  // Each turn will be 90 degrees.\n  void turnLeft();\n  void turnRight();\n\n  // Clean the current cell.\n  void clean();\n}\n</code></pre> <p>Note\u00a0that the initial direction of the robot will be facing up. You can assume all four edges of the grid are all surrounded by a wall.</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0400-0499/lc0489-robot-room-cleaner/#clarification","title":"Clarification","text":"<ul> <li>0: wall; 1: empty</li> <li>All empty cells are reachable?</li> <li>Does the robot need to return to its original position?</li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0400-0499/lc0489-robot-room-cleaner/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Backtracking"]},{"location":"lc-solutions/lc0400-0499/lc0489-robot-room-cleaner/#solution","title":"Solution","text":"","tags":["Backtracking"]},{"location":"lc-solutions/lc0400-0499/lc0489-robot-room-cleaner/#approach-1-backtracking","title":"Approach 1: Backtracking","text":"<p>Since we don't know the coordinates or layout, we simulate the robot's position using coordinates relative to the start <code>(0, 0)</code>. We can use a depth-first search (DFS) approach to explore all possible paths the robot can take.</p> <p>The robot can move in four directions: up, right, down, and left. When moving, we will check</p> <ul> <li>if the next cell is empty and not visited. If it is, we will move the robot to that cell, clean it, and continue exploring from there.</li> <li>if we reach a dead end (i.e., all adjacent cells are either walls or already visited), we will backtrack to the previous cell and try another direction.</li> </ul> Python <pre><code>class Solution:\n    def cleanRoom(self, robot):\n        \"\"\"\n        :type robot: Robot\n        :rtype: None\n        \"\"\"\n        self.DIRECTIONS = [(-1, 0), (0, 1), (1, 0), (0, -1)]  # up, right, down, left\n        self.visited = set()\n        self.dfs(robot, 0, 0, 0)\n\n    def dfs(self, robot, i_row: int, i_col: int, i_d: int) -&gt; None:\n        self.visited.add((i_row, i_col))\n        robot.clean()\n\n        # Iterate all 4 directions, starting from the current direction,\n        # keep turning right (or left) until all directions explored\n        for i in range(4):\n            i_d_next = (i_d + i) % 4\n            i_row_next = i_row + self.DIRECTIONS[i_d_next][0]\n            i_col_next = i_col + self.DIRECTIONS[i_d_next][1]\n\n            if (i_row_next, i_col_next) not in self.visited and robot.move():\n                self.dfs(robot, i_row_next, i_col_next, i_d_next)\n                self.go_back(robot)\n\n            # Try another direction by turning right (we can also turn left here)\n            robot.turnRight()\n\n    def go_back(self, robot):\n        # Turn 180 degrees to face the opposite direction\n        robot.turnRight()\n        robot.turnRight()\n\n        # Move back to the previous cell\n        robot.move()\n\n        # Turn 180 degrees again to restore the original direction\n        robot.turnRight()\n        robot.turnRight()\n</code></pre>","tags":["Backtracking"]},{"location":"lc-solutions/lc0400-0499/lc0489-robot-room-cleaner/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n - m)\\) where \\(n\\) is the number of cells and \\(m\\) is the number of obstacles.   The robot will visit each empty cell once. At each cell, it will check 4 directions,   resulting in \\(4(n - m)\\) operations.</li> <li>Space complexity: \\(O(n - m)\\) <ul> <li>The <code>visited</code> hashset will store up to \\(n - m\\) cells.</li> <li>The recursion stack can go as deep as \\(n - m\\) in the worst case.</li> <li>So the overall space complexity of the algorithm is \\(O(n - m)\\).</li> </ul> </li> </ul>","tags":["Backtracking"]},{"location":"lc-solutions/lc0400-0499/lc0489-robot-room-cleaner/#test","title":"Test","text":"<ol> <li> <p>Single Cell Room    Input: A room with only one empty cell.    Output: The robot cleans the single cell.</p> </li> <li> <p>Room with Obstacles    Input: A room with walls blocking some cells.    Output: The robot cleans all reachable cells.</p> </li> <li> <p>Large Empty Room    Input: A large room with no obstacles.    Output: The robot cleans all cells.</p> </li> <li> <p>Edge Case: All Walls    Input: A room where all cells are walls.    Output: The robot does nothing.</p> </li> </ol>","tags":["Backtracking"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/","title":"LC494. Target Sum","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 494: You are given an integer array\u00a0<code>nums</code>\u00a0and an integer\u00a0<code>target</code>.</p> <p>You want to build an\u00a0expression\u00a0out of nums by adding one of the symbols\u00a0<code>'+'</code>\u00a0and\u00a0<code>'-'</code>\u00a0before each integer in nums and then concatenate all the integers.</p> <ul> <li>For example, if\u00a0<code>nums = [2, 1]</code>, you can add a\u00a0<code>'+'</code>\u00a0before\u00a0<code>2</code>\u00a0and a\u00a0<code>'-'</code>\u00a0before\u00a0<code>1</code>and concatenate them to build the expression\u00a0<code>\"+2-1\"</code>.</li> </ul> <p>Return the number of different\u00a0expressions\u00a0that you can build, which evaluates to\u00a0<code>target</code>.</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#approach-1-brutal-force","title":"Approach 1 - Brutal Force","text":"<p>Recursively calling the find function until reach the end of array. It will return <code>1</code> if <code>sum == target</code> or 0 otherwise in the end. At each node, return values from function calls of <code>+</code> and <code>-</code> elements will be added.</p> <p>A small trick: instead of add an argument of <code>sum</code>, send <code>remain_target</code> by adding or subtracting values from <code>target</code> in each recursive function call.</p> Python <pre><code>class Solution:\n    def findTargetSumWays(self, nums: List[int], target: int) -&gt; int:\n        return self.find(nums, 0, target)\n\n    def find(self, nums: List[int], depth: int, remain_target: int) -&gt; int:\n        if depth == len(nums):\n            return remain_target == 0\n\n        return self.find(nums, depth + 1, remain_target + nums[depth]) \\\n            + self.find(nums, depth + 1, remain_target - nums[depth])\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(2^n)\\)   Each recursive call will leads two sub-recursive call. Since the recursive call depth is \\(n\\) (number of array elements), so the time complexity is \\(O(2^n)\\).</li> <li>Space complexity: \\(O(n)\\)   The function recursive call stack with the depth of \\(n\\).</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#approach-2-memoization","title":"Approach 2 - Memoization","text":"<p>In the brutal force method, there are many redundant functional call during the recursion for the same <code>(indx, sum)</code> pair. These values can be stored and re-used.</p> python <pre><code>class Solution:\ndef findTargetSumWays(self, nums: List[int], target: int) -&gt; int:\n    mem = {}\n    return self.find(nums, 0, target, mem)\n\ndef find(self, nums: List[int], depth: int, remain_target: int, mem: dict[int, int]) -&gt; int:\n    if depth == len(nums):\n        return remain_target == 0\n\n    if (depth, remain_target) in mem:\n        return mem[(depth, remain_target)]\n\n    mem[(depth, remain_target)] = self.find(nums, depth + 1, remain_target + nums[depth], mem) \\\n        + self.find(nums, depth + 1, remain_target - nums[depth], mem)\n\n    return mem[(depth, remain_target)]\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n \\times \\text{sum}(\\text{nums}))\\)   Each state\u00a0<code>(index, sum)</code>\u00a0is computed only once. The number of unique states is proportional to\u00a0\\(O(\\)n \\times \\text{sum}(\\text{nums}))$, where\u00a0<code>n</code>\u00a0is the length of\u00a0<code>nums</code>\u00a0and\u00a0<code>sum(nums)</code>\u00a0is the maximum possible absolute sum.</li> <li> <p>Space complexity: \\(O(n \\times \\text{sum}(\\text{nums}))\\)   The total space complexity is combination of memoization table and recursion stack space, \\(O(n \\times \\text{sum}(\\text{nums})) + O(n) = O(n \\times \\text{sum}(\\text{nums}))\\).  </p> <ul> <li>Recursion stack space due to recursion function call of depth \\(n\\), which requires \\(O(n)\\) space</li> <li>Memoization table: stores results of each pair <code>(index, sum)</code> where <code>index</code> ranges from <code>0</code> to <code>n</code> with \\(n + 1\\) possible values and <code>sum</code> ranges from \\(-\\text{sum}(\\text{nums})\\) to $\\text{sum}(\\text{nums}) with \\(2 \\times \\text{sum}(\\text{nums}) + 1\\) possible values. </li> </ul> </li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#approach-3-dp","title":"Approach 3 - DP","text":"<p>The problem can be solved using bottom-up (iterative) dynamic programming. Each step is to compute the number of ways to achieve new sum based on <code>sum_so_far</code> and <code>count</code> in previous step. A list of dictionaries, <code>dp</code>, is introduced. <code>dp[i]</code> keeps track of number of ways to achiever different sums using the first <code>i</code> numbers of the <code>nums</code> array.</p> <p>Note that, the DP array has aa size of <code>n + 1</code> instead of <code>n</code> to account for the base case where no elements from the <code>nums</code> array have been processed yet (i.e., the \"0-th\" step).</p> <ul> <li><code>dp[i]</code> represents the possible sums you can get by using the first <code>i</code> numbers of <code>nums</code>.</li> <li><code>dp[0]</code> represents the base case before processing any numbers. <code>dp[0][0] = 1</code> indicates there is exactly 1 way to have a sum of <code>0</code> before processing any numbers.</li> </ul> Python <pre><code>class Solution:\ndef findTargetSumWays(self, nums: List[int], target: int) -&gt; int:\n    n = len(nums)\n    # dp[i] stores the number of ways to make a sum with the first i elements\n    dp = [{} for _ in range(n + 1)]\n    dp[0][0] = 1  # there is one way to get sum of 0 using 0 element\n\n    for i in range(n):\n        for sum_so_far, count in dp[i].items():\n            if sum_so_far + nums[i] not in dp[i+1]:\n                dp[i+1][sum_so_far + nums[i]] = 0\n            if sum_so_far - nums[i] not in dp[i+1]:\n                dp[i+1][sum_so_far - nums[i]] = 0\n\n            dp[i+1][sum_so_far + nums[i]] += count\n            dp[i+1][sum_so_far - nums[i]] += count\n\n    if target in dp[n]:\n        return dp[n][target]\n    else:\n        return 0\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n \\times \\text{sum}(\\text{nums}))\\) </li> <li>Outer loop: we iterate through each element in <code>nums</code>, so the outer loop runs \\(n\\) times.</li> <li>Inner loop: at each step <code>i</code>, go through every possible sums that can be achieved using the first <code>i</code> elements. The number of possible sums at step <code>i</code> is constrained by \\(-\\text{sum}(\\text{nums})\\) and \\(+\\text{sum}(\\text{nums})\\) and up to \\(2 \\times \\text{sum}(\\text{nums}) + 1\\). So the total time complexity is \\(O(n \\times (2 \\times \\text{sum}(\\text{nums}))) = O(n \\times \\text{sum}(\\text{nums}))\\).</li> <li>Space complexity: \\(O(n \\times \\text{sum}(\\text{nums}))\\)   We define a list of hashmaps <code>dp</code> with size of \\(n + 1\\). Each <code>dp[i]</code> is a dictionary that can store up to \\(2 \\times \\text{sum}(\\text{nums}) + 1\\).</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#approach-4-dp-with-linear-space","title":"Approach 4 - DP with Linear Space","text":"<p>In the DP approach, we only need to use the results for the current and previous states. The space can be optimized to use only two such dictionaries instead of the full list.</p> Python <pre><code>class Solution:\ndef findTargetSumWays(self, nums: List[int], target: int) -&gt; int:\n    n = len(nums)\n    # dp stores the number of ways to make a sum with the first i elements in previous step i\n    dp_prev = {} \n    dp_prev[0] = 1 # base case: there is one way to get sum of 0 using 0 element \n\n    for i in range(n):\n        dp_curr = {}\n        for sum_so_far, count in dp_prev.items():\n            if sum_so_far + nums[i] not in dp_curr:\n                dp_curr[sum_so_far + nums[i]] = 0\n            if sum_so_far - nums[i] not in dp_curr:\n                dp_curr[sum_so_far - nums[i]] = 0\n\n            dp_curr[sum_so_far + nums[i]] += count\n            dp_curr[sum_so_far - nums[i]] += count\n\n        dp_prev = dp_curr.copy()\n\n    if target in dp_curr:\n        return dp_curr[target]\n    else:\n        return 0\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#complexity-analysis-of-approach-4","title":"Complexity Analysis of Approach 4","text":"<ul> <li>Time complexity: \\(O(n \\times \\text{sum}(\\text{nums}))\\)   See previous analysis of DP approach.</li> <li>Space complexity: \\(O(\\text{sum}(\\text{nums}))\\)   The previous or current dictionary stores at most \\(2 \\times \\text{sum}(\\text{nums}) + 1\\) entries. So the space complexity is \\(O(2 \\times \\text{sum}(\\text{nums}) + 1) = O(\\text{sum}(\\text{nums})\\).</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - \\(O(2^n)\\) \\(O(n)\\) Approach 2 - \\(O(n \\times \\text{sum}(\\text{nums}))\\) \\(O(n \\times \\text{sum}(\\text{nums}))\\) Approach 3 - \\(O(n \\times \\text{sum}(\\text{nums}))\\) \\(O(n \\times \\text{sum}(\\text{nums}))\\) Approach 4 - \\(O(n \\times \\text{sum}(\\text{nums}))\\) \\(O(\\text{sum}(\\text{nums}))\\)","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0400-0499/lc0494-target-sum/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/","title":"509. Fibonacci Number","text":"","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 509: The\u00a0Fibonacci numbers, commonly denoted\u00a0<code>F(n)</code>\u00a0form a sequence, called the Fibonacci sequence, such that each number is the sum of the two preceding ones, starting from\u00a0<code>0</code>\u00a0and\u00a0<code>1</code>. That is,</p> <pre><code>F(0) = 0, F(1) = 1\nF(n) = F(n - 1) + F(n - 2), for n &gt; 1.\n</code></pre> <p>Given\u00a0<code>n</code>, calculate\u00a0<code>F(n)</code>.</p>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#clarification","title":"Clarification","text":"<ul> <li>Input data type is int</li> </ul>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#assumption","title":"Assumption","text":"<ul> <li>\\(n &gt;= 0\\)</li> </ul>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#solution","title":"Solution","text":"<p>Overview of different solutions:</p> <pre><code>graph TD;\n    iteration(\"Iteration ($$O(n), O(1))$$\")\n    recursionBasic(\"Recursion Basic ($$O(2^n), O(n))$$\")\n    recursionMemo(\"Recursion + Memoization ($$O(n), O(n))$$\")\n    recursionOpt(\"Recursion Optimized ($$O(\\log n), O(\\log n))$$\")\n    matrixBasic(\"Matrix Basic ($$O(n), O(1))$$\")\n    matrixFast(\"Matrix Fast ($$O(\\log n), O(1))$$\")\n    math(\"Math (Golden Ratio) ($$O(\\log n), O(1))$$\")\n\n    recursionBasic --&gt; recursionMemo --&gt; recursionOpt\n    matrixBasic --&gt; matrixFast</code></pre>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#approach-1-recursion-memoization","title":"Approach 1: Recursion + Memoization","text":"<p>Since <code>F(n) = F(n - 1) + F(n - 2), for n &gt; 1</code>, we can use recursion to compute the Fibonacci number. Note that many intermediate calculations are repeated and we can use memoization to restore these intermediate results and re-use them later.</p> <p>For example, to compute <code>F(4)</code>, <code>F(4) = F(3) + F(2) = (F(2) + F(1)) + F(2)</code>, it computes <code>F(2)</code> twice, <code>F(1)</code> 3 times, and <code>f(0)</code> twice.</p> <pre><code>graph TD\n    f3_f2_f0((\"f(0)\"))\n    f3_f2_f1((\"f(1)\"))\n    f4_f2_f0((\"f(0)\"))\n    f4_f2_f1((\"f(1)\"))\n    f3_f1((\"f(1)\"))\n    f3_f2((\"f(2)\"))\n    f3((\"f(3)\"))\n    f4_f2((\"f(2)\"))\n    f4((\"f(4)\"))\n    f4 --&gt; f3\n    f4 --&gt; f4_f2\n    f4_f2 --&gt; f4_f2_f1\n    f4_f2 --&gt; f4_f2_f0\n    f3 --&gt; f3_f2\n    f3 --&gt; f3_f1\n    f3_f2 --&gt; f3_f2_f1\n    f3_f2 --&gt; f3_f2_f0\n\n    style f4_f2 fill:#F2D2BD\n    style f3_f2 fill:#F2D2BD\n    style f3_f1 fill:#FFBF00\n    style f3_f2_f1 fill:#FFBF00\n    style f4_f2_f1 fill:#FFBF00\n    style f4_f2_f0 fill:#FFE5B4\n    style f3_f2_f0 fill:#FFE5B4</code></pre> Python <pre><code>class Solution:\n    def __init__(self):\n        self.cache = {}\n\n    def fib(self, n: int) -&gt; int:\n        # Base case\n        if n &lt; 2:\n            return n\n        elif n in self.cache:\n            return self.cache[n]\n        else:\n            self.cache[n] = self.fib(n - 1) + self.fib(n - 2)\n            return self.cache[n]\n</code></pre>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Each number is visited once from 1 to \\(n\\). Each visit is either computed or retrieved   from cache for \\(n &gt;= 2\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>Recursion function call takes \\(n\\) times, taking \\(O(n)\\) space.</li> <li>Cache stores \\(n - 2\\) intermediate results, taking \\(O(n)\\) space.</li> </ul> </li> </ul>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#approach-2-recursion-optimized","title":"Approach 2: Recursion Optimized","text":"<p>Prof. Edsger W. Dijkstra proposed an optimized recursive approach in note EWD654 \"In honor of Fibonacci\" to computing Fibonacci numbers using fast doubling recursion.</p> <p>Note that Dijkstra's series begins F(1)=0 and F(2)=1 so, using our index system which has F(0)=0 and F(1)=1, we have:</p> \\[\\begin{eqnarray} F(2n - 1) = F(n - 1)^2 + F(n)^2 \\\\ F(2n) = (2 F(n - 1) + F(n)) F(n)  \\end{eqnarray}\\] <p>There are two different ways to implement this fast doubling recursion:</p> <ul> <li>Use cache to store intermediate results.</li> <li>Return tuple <code>(f_n, f_n1)</code> instead of cache since higher Fibonacci number calculation just need two numbers.</li> </ul> pythonpython - no cache <pre><code>class Solution:\n    def __init__(self):\n        self.cache = {}\n\n    def fib(self, n: int) -&gt; int:\n        # Base case\n        if n &lt; 2:\n            return n\n        elif n in self.cache:\n            return self.cache[n]\n        else:\n            if n % 2 == 0:\n                m = n // 2\n                self.cache[n] = (2 * self.fib(m - 1) + self.fib(m)) * self.fib(m)\n            else:\n                m = (n + 1) // 2\n                self.cache[n] = self.fib(m - 1) * self.fib(m - 1) + self.fib(m) * self.fib(m)\n            return self.cache[n]\n</code></pre> <pre><code>class Solution:\n    def fib(self, n: int) -&gt; int:\n        return fibonacci(n)[0]\n\ndef fibonacci(n):\n    if n == 0:\n        return (0, 1)\n\n    f_k, f_k1 = fibonacci(n // 2)\n\n    f_2k = f_k * (2 * f_k1 - f_k)\n    f_2k1 = f_k1 * f_k1 + f_k * f_k\n\n    if n % 2 == 0:\n        return (f_2k, f_2k1)\n    else:\n        return (f_2k1, f_2k + f_2k1)\n</code></pre>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)   To compute \\(n\\), it need to compute intermediate results by half each time, i.e.,   \\(n \\rightarrow n/2 \\rightarrow n/4 \\rightarrow \\cdots 1\\). So the time complexity is   \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(\\log n)\\) <ul> <li>The recursive function call takes \\(\\log n\\) times.</li> <li>If using cache, the cache doesn't need to store all \\(n\\) values and just need to store \\(2 \\log n\\) values.</li> <li>The overall time complexity is \\(O(\\log n)\\) with or without cache.</li> </ul> </li> </ul>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#approach-3-iteration","title":"Approach 3: Iteration","text":"<p>The problem can also be solve using iterative method by following Fibonacci number calculation.</p> python <pre><code>class Solution:\n    def fib(self, n: int) -&gt; int:\n        if n &lt; 2:\n            return n\n\n        f_n_2 = 0\n        f_n_1 = 1\n        for i in range(2, n + 1):\n            f_n = f_n_1 + f_n_2\n            f_n_2, f_n_1 = f_n_1, f_n\n\n        return f_n\n</code></pre>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n)\\)   Compute all \\(n\\) numbers iteratively.</li> <li>Space complexity: \\(O(1)\\)   Only use limited number of variables.</li> </ul>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#approach-4-matrix-exponentiation","title":"Approach 4: Matrix Exponentiation","text":"<p>The Fibonacci sequence follows:</p> \\[F_n = F_{n - 1} + F_{n - 2}\\] <p>This can be rewritten in matrix form:</p> \\[\\begin{bmatrix} F_n \\\\ F_{n - 1} \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} F_{n - 1} \\\\ F_{n - 2} \\end{bmatrix}\\] <p>Expanding this recurrence, we obtain</p> \\[\\begin{bmatrix} F_n \\\\ F_{n - 1} \\end{bmatrix} = \\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}^{n - 1} \\begin{bmatrix} F_1 \\\\ F_0 \\end{bmatrix}\\] <p>Since \\(F_1 = 1\\) and \\(F_0 = 0\\), we only need to extract the top-left element of the matrix exponentiation result.</p> <p>To compute Fibonacci efficiently, we perform fast exponentiation by squaring on the transformation matrix \\(\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}\\), which takes \\(O(\\log n)\\) time.</p> pythonpython - recursion <pre><code>class Solution:\n    def fib(self, n: int) -&gt; int:\n        if n &lt;= 1:\n            return n\n\n        M = [[1, 1], [1, 0]]\n        result = matrix_exponentiation(M, n - 1)\n        return result[0][0]\n\n\ndef matrix_mult(A, B):\n    \"\"\"Multiply two 2x2 matrices.\"\"\"\n    return [\n        [A[0][0] * B[0][0] + A[0][1] * B[1][0], A[0][0] * B[0][1] + A[0][1] * B[1][1]],\n        [A[1][0] * B[0][0] + A[1][1] * B[1][0], A[1][0] * B[0][1] + A[1][1] * B[1][1]],\n    ]\n\n\ndef matrix_exponentiation(M, exp):\n    \"\"\"Computes M^exp using fast exponentiation.\"\"\"\n\n    # Only consider square matrix\n    if not M or len(M) != len(M[0]):\n        return []\n\n    res = [[1, 0], [0, 1]]  # Identity matrix\n    # Base case\n    if exp == 0:\n        return res\n    if exp == 1:\n        return M\n\n    base = M\n\n    while exp:\n        if exp % 2 == 1:\n            # If odd, multiply result by base\n            # If exp starts with odd, it will execute twice, one at the beginning and the other at the end.\n            # If exp starts with even, it will execute once at the end.\n            res = matrix_mult(res, base)\n        base = matrix_mult(base, base)  # square the base\n        exp //= 2\n\n    return res\n</code></pre> <pre><code>class Solution:\n    def fib(self, n: int) -&gt; int:\n        if n &lt;= 1:\n            return n\n\n        M = [[1, 1], [1, 0]]\n        result = matrix_exponentiation(M, n - 1)\n        return result[0][0]\n\n\ndef matrix_mult(A, B):\n    \"\"\"Multiply two 2x2 matrices.\"\"\"\n    return [\n        [A[0][0] * B[0][0] + A[0][1] * B[1][0], A[0][0] * B[0][1] + A[0][1] * B[1][1]],\n        [A[1][0] * B[0][0] + A[1][1] * B[1][0], A[1][0] * B[0][1] + A[1][1] * B[1][1]],\n    ]\n\n\ndef matrix_exponentiation(M, exp):\n    \"\"\"Computes M^exp using fast exponentiation.\"\"\"\n\n    # Only consider square matrix\n    if not M or len(M) != len(M[0]):\n        return []\n\n    # Base case\n    if exp == 0:\n        return [[1, 0], [0, 1]]  # Identity matrix\n    if exp == 1:\n        return M\n\n    half = matrix_exponentiation(M, exp // 2)\n    half_square = matrix_mult(half, half)\n    if exp % 2 == 0:\n        return half_square\n    else:\n        return matrix_mult(half_square, M)\n</code></pre>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#complexity-analysis-of-approach-4","title":"Complexity Analysis of Approach 4","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) <ul> <li>Matrix multiplication is \\(O(1)\\) for fixed \\(2 \\times 2\\) matrix.</li> <li>Matrix exponentiation uses exponentiation by squaring, which takes \\(O(\\log n)\\).</li> <li>So the overall time complexity is \\(O(\\log n)\\).</li> </ul> </li> <li>Space complexity: \\(O(1)\\) for iteration or \\(O(\\log n)\\) for recursion  <ul> <li>For iteration, we only use several \\(2 \\times 2\\) matrices. So it's \\(O(1)\\) space.</li> <li>For recursion, the recursion call stack takes \\(O(\\log n)\\) space since the function recursively calls \\(\\log n\\) times.</li> </ul> </li> </ul>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#approach-5-math","title":"Approach 5: Math","text":"<p>The limit of ratio of consecutive Fibonacci numbers converges to the golden ration \\(\\varphi = \\frac{1 + \\sqrt{5}}{2}\\):</p> \\[\\lim_{n \\rightarrow \\infty} \\frac{F_{n+1}}{F_n} = \\varphi\\] <p>The Fibonacci sequence has a closed-form solution using the Golden Ratio \\(\\varphi\\). The Fibonaaci number at index \\(n\\) can be computed as:</p> \\[F_n = \\frac{\\varphi^n - \\psi^n}{\\sqrt{5}}\\] <p>where:</p> <ul> <li>\\(\\varphi = \\frac{1+\\sqrt{5}}{2} \\approx 1.6180339887\\) (Golden ratio)</li> <li>\\(\\psi = \\frac{1 - \\sqrt{5}}{2} \\approx -0.6180339887\\) (Conjugate of the Golden Ratio)</li> <li>\\(\\sqrt{5}\\) is a normalization factor</li> </ul> <p>since \\(\\psi^n = (-0.62)^n\\) quickly approaches zero for large \\(n\\), the formula simplifies to:</p> \\[F_n = \\frac{\\varphi^n}{\\sqrt{5}}\\] <p>Note that</p> <ul> <li>the eigenvalues of the Fibonacci transformation matrix are \\(\\varphi\\) and \\(\\psi\\).</li> <li>Python\u2019s floating-point arithmetic is precise enough that rounding the result gives the correct answer up to n \u2248 70.</li> <li>Beyond n \u2248 70, floating-point errors can accumulate, making this method unreliable for very large Fibonacci numbers.</li> </ul> python <pre><code>import math\n\nclass Solution:\n    def fib(self, n: int) -&gt; int:\n        phi = (1 + math.sqrt(5)) / 2\n        return round(phi**n / math.sqrt(5))\n</code></pre>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#complexity-analysis-of-approach-5","title":"Complexity Analysis of Approach 5","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)   In Python, the <code>**</code> operator (or <code>pow(a, b)</code>) internally uses exponentiation by   squaring, which takes \\(O(\\log n)\\) time.</li> <li>Space complexity: \\(O(1)\\)   Only a few variables used.</li> </ul>","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Accuracy Approach 1 - Recursion + Memoization \\(O(n)\\) \\(O(n)\\) Accurate Approach 2 - Recursion optimized \\(O(\\log n)\\) \\(O(\\log n)\\) Accurate Approach 3 - Iteration \\(O(n)\\) \\(O(1)\\) Accurate Approach 4 - Matrix \\(O(\\log n)\\) \\(O(1)\\) Accurate Approach 5 - Math \\(O(\\log n)\\) \\(O(1)\\) Accurate up to \\(n \\approx 70\\)","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0509-fibonacci-number/#test","title":"Test","text":"","tags":["Math","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/","title":"518. Coin Change II","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 518: You are given an integer array\u00a0<code>coins</code>\u00a0representing coins of different denominations and an integer\u00a0<code>amount</code>\u00a0representing a total amount of money.</p> <p>Return\u00a0the number of combinations that make up that amount. If that amount of money cannot be made up by any combination of the coins, return\u00a0<code>0</code>.</p> <p>You may assume that you have an infinite number of each kind of coin.</p> <p>The answer is\u00a0guaranteed\u00a0to fit into a signed\u00a032-bit\u00a0integer.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#solution","title":"Solution","text":"<p>There are two main ways to solve the program:</p> <ol> <li>View problem as a graph problem. The node is the remaining amount and the edge is coin value. We can use BFS to find all possible and unique path leads to 0 amount. Note that the combinations <code>[1 2 2]</code>, <code>[2 1 2]</code>, and <code>[2, 2, 1]</code> are the same.</li> <li>Use dynamic programming<ul> <li>State: <code>dp(i, amount)</code> represents the number of ways for the current coin i (index) with the remaining amount.</li> <li>State transition:<ul> <li><code>Coins[i] &gt; amount</code> skip this coin since it is too large: <code>dp(i, amount) = dp(i + 1, amount)</code></li> <li>Combination of two cases:<ul> <li>Take this coin (can repeatedly use the same coin): <code>dp(i, amount - coins[i])</code></li> <li>Not take this coin: <code>dp(i + 1, amount)</code></li> <li>Sum of two cases: <code>dp(i, amount) = dp(i, amount - coins[i]) + dp(i + 1, amount)</code></li> </ul> </li> </ul> </li> <li>Base case:<ul> <li><code>dp(i, 0) = 1</code>, since we can always make up 0 amount by not taking any coins That is one way.</li> <li><code>dp(n, amount) = 0</code> where n is the number of coins. No coin left to make up the amount.</li> </ul> </li> </ul> </li> </ol>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#approach-1-top-down-dynamic-programming","title":"Approach 1: Top-Down Dynamic Programming","text":"<p>We can use top-down dynamic programming to solve the problem. We can use a recursive function to find the number of ways to make up the amount using the coins up to the current coin index <code>i</code> and the remaining amount <code>amount</code>.</p> Python <pre><code>class Solution:\n    def change(self, amount: int, coins: List[int]) -&gt; int:\n        self._cache = {}\n        return self._count_combination(0, amount, coins)\n\n    def _count_combination(self, i: int, amount: int, coins: List[int]) -&gt; int:\n        # Base case\n        if amount == 0:  # not take coin for 0 (1 way)\n            return 1\n        if i == len(coins):  # no more coin left\n            return 0\n\n        if (i, amount) in self._cache:\n            return self._cache[(i, amount)]\n\n        if coins[i] &gt; amount:\n            num_ways = self._count_combination(i + 1, amount, coins)\n        else:\n            num_ways = self._count_combination(i, amount - coins[i], coins) + self._count_combination(i + 1, amount, coins)\n\n        self._cache[(i, amount)] = num_ways\n        return num_ways\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\cdot m)\\) where \\(n\\) is number of coins and \\(m\\) is the amount.<ul> <li>The total number of states are combination of coin index, <code>i</code>, and remaining amount, <code>amount</code>.<ul> <li><code>i</code>: the current coin index --&gt; range from <code>0</code> to <code>len(coins)</code> --&gt; n states</li> <li><code>amount</code>: the remaining amount --&gt; range from <code>0</code> to <code>amount</code> --&gt; m states. Note that in the worst case, when coins contain 1, we will go through \\(0, 1, \\cdots, \\text{amount}\\).</li> </ul> </li> <li>Calculation per state: due to memoization, each state is computed only once and each calculation takes \\(O(1)\\).</li> <li>Total time complexity is \\(O(n \\cdot m)\\).</li> </ul> </li> <li>Space complexity: \\(O(n \\cdot m)\\) <ul> <li>Cache stores results for each <code>(i, amount)</code> --&gt; \\(O(n \\cdot m)\\).</li> <li>Recursion call goes as deep as \\(n + m\\), moving <code>i</code> forward one at a time and reduce coin one by one.</li> <li>The total time complexity is \\(O(n \\cdot m) + O(n + m) = O(n \\cdot m)\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#approach-2-bottom-up-dynamic-programming","title":"Approach 2: Bottom-Up Dynamic Programming","text":"<p>We can also use a bottom-up approach to solve the problem by using a 2D list <code>dp[i][a]</code> to store the number of ways to make <code>j</code> amount <code>a</code> using first <code>i</code> coins where <code>i</code> ranges from 0 to <code>len(coins)</code> and <code>a</code> ranges from 0 to <code>amount</code>.</p> <p>Here is the 2D array for the example <code>amount = 5, coins = [1,2,5]</code>:</p> <pre><code>block-beta\n  columns 8\n  space space space blockArrowId&lt;[\"Amount j\"]&gt;(right) space space space space\n  space space     j0((\"0\")) j1((\"1\")) j2((\"2\")) j3((\"3\")) j4((\"4\")) j5((\"5\"))\n  space i0((\"0\")) ij00[\"1\"] ij01[\"1\"] ij02[\"2\"] ij03[\"2\"] ij04[\"3\"] ij05[\"4\"]\n  space i1((\"1\")) ij10[\"1\"] ij11[\"0\"] ij12[\"1\"] ij13[\"0\"] ij14[\"1\"] ij15[\"1\"]\n  blockArrowId3&lt;[\"\\nIndex i\\n\"]&gt;(up) i2((\"2\")) ij20[\"1\"] ij21[\"0\"] ij22[\"0\"] ij23[\"0\"] ij24[\"0\"] ij25[\"1\"]\n  space i3((\"3\")) ij30[\"0\"] ij31[\"0\"] ij32[\"0\"] ij33[\"0\"] ij34[\"0\"] ij35[\"0\"]</code></pre> python <pre><code>class Solution:\n    def change(self, amount: int, coins: List[int]) -&gt; int:\n        n = len(coins)\n        dp = [[0] * (amount + 1) for _ in range(n + 1)]\n        for i in range(n):\n            dp[i][0] = 1\n\n        for i in range(n - 1, -1, -1):\n            for j in range(1, amount + 1):\n                if coins[i] &gt; j:\n                    dp[i][j] = dp[i + 1][j]\n                else:\n                    dp[i][j] = dp[i + 1][j] + dp[i][j - coins[i]]\n\n        return dp[0][amount]\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n \\cdot m)\\) where \\(n\\) is number of coins and \\(m\\) is the amount.<ul> <li>Initializing the <code>dp</code> array takes \\(O(n \\cdot m)\\).</li> <li>Run two nested for-loops to fill the entire <code>dp</code> array. Each iteration takes \\(O(1)\\) time. So it takes \\(O(n \\cdot m)\\) time to fill the <code>dp</code>.</li> <li>The total time complexity is \\(O(n \\cdot m) + O(n \\cdot m) = O(n \\cdot m)\\).</li> </ul> </li> <li>Space complexity: \\(O(n \\cdot m)\\)     The <code>dp</code> array takes \\(O(n \\cdot m)\\) space.</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#approach-3-bottom-up-dynamic-programming-with-space-optimization","title":"Approach 3: Bottom-Up Dynamic Programming with Space Optimization","text":"<p>From the state transition: <code>dp[i][j] = dp[i + 1][j] + dp[i][j - coins[i]]</code>, we just need values from current row and previous row in 2D array and the value on the current row won't be overwritten by future calculations. We can use 1D array to conduct the calculation:</p> <ul> <li>Before calculating <code>dp[j]</code>, <code>dp[j]</code> stores the previous calculated value (i.e. <code>d[[i + 1][j]</code> in 2D array.</li> <li><code>dp[j - coins[i]]</code> values are updated before <code>j</code> and can be used for calculating <code>dp[j]</code>.</li> </ul> <p>In previous 2D example, <code>dp[0][5]</code> is calculated from <code>dp[0][4]</code> and <code>dp[1][5]</code></p> <pre><code>block-beta\n  columns 8\n  space space space blockArrowId&lt;[\"Amount j\"]&gt;(right) space space space space\n  space space     j0((\"0\")) j1((\"1\")) j2((\"2\")) j3((\"3\")) j4((\"4\")) j5((\"5\"))\n  blockArrowId3&lt;[\"\\nIndex i\\n\"]&gt;(up) i0((\"0\")) ij00[\"1\"] ij01[\"1\"] ij02[\"2\"] ij03[\"2\"] ij04[\"3\"] ij05[\"4\"]\n  space i1((\"1\")) ij10[\"1\"] ij11[\"0\"] ij12[\"1\"] ij13[\"0\"] ij14[\"1\"] ij15[\"1\"]\n\n  style ij05 stroke:#333,stroke-width:4px\n  style ij04 stroke:#f66,stroke-width:2px,stroke-dasharray: 5 5\n  style ij15 stroke:#f66,stroke-width:2px,stroke-dasharray: 5 5</code></pre> python <pre><code>class Solution:\n    def change(self, amount: int, coins: List[int]) -&gt; int:\n        n = len(coins)\n        dp = [0] * (amount + 1)\n        dp[0] = 1\n\n        for i in range(n - 1, -1, -1):\n            for j in range(coins[i], amount + 1):\n                dp[j] += dp[j - coins[i]]\n\n        return dp[amount]\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n \\cdot m)\\) where \\(n\\) is number of coins and \\(m\\) is the amount.<ul> <li>Initializing the <code>dp</code> array takes \\(O(n \\cdot m)\\).</li> <li>Run two nested for-loops to fill the entire <code>dp</code> array. Each iteration takes \\(O(1)\\) time. So it takes \\(O(n \\cdot m)\\) time to fill the <code>dp</code>.</li> <li>The total time complexity is \\(O(n \\cdot m) + O(n \\cdot m) = O(n \\cdot m)\\).</li> </ul> </li> <li>Space complexity: \\(O(m)\\)   The <code>dp</code> array takes \\(O(m)\\) space.</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#approach-4-breadth-first-search","title":"Approach 4: Breadth-First Search","text":"<p>We can view the problem as a graph problem. Each node is the remaining amount, and each edge represents using a coin with coin value. We can use BFS to explore all possible combinations of coins.</p> <p>We want the number of combinations (order doesn't matter) of coins that sum to <code>amount</code>. That means <code>{1, 2, 2}</code> is the same as <code>{2, 1, 2}</code> and <code>{2, 2, 1}</code>. So we need to enforce a canonical order in our search.</p> <p>If we represent a state as <code>(remaining, index)</code> where <code>remaining</code> is the remaining amount and <code>index</code> is the coin index we are allowed to use from here forward. Then at each state <code>(remaining, index)</code>, we can either:</p> <ol> <li>Use the coin at <code>index</code>, which reduces the <code>remaining</code> amount by <code>coins[index]</code> and keeps the <code>index</code> the same (since we can use the same coin again).</li> <li>Skip the coin at <code>index</code>, which keeps the <code>remaining</code> amount the same and moves to the next coin by incrementing <code>index</code>.</li> </ol> <p>Storing <code>(remaining, index)</code> ensures non-decreasing order of indices. Any valid combination <code>{c1, c2, \u2026, ck}</code> can be sorted in ascending order. That sorted sequence corresponds to exactly one path through (remaining, index)</p> python <pre><code>from collections import deque\n\nclass Solution:\n    def change(self, amount: int, coins: List[int]) -&gt; int:\n        n = len(coins)\n        queue = deque([(amount, 0)])  # remaining amount, index\n        num_ways = 0\n\n        while queue:\n            remaining, i = queue.popleft()\n\n            if remaining == 0:\n                num_ways += 1\n                continue\n\n            for j in range(i, n):\n                if coins[j] &lt;= remaining:\n                    queue.append((remaining - coins[j], j))\n\n        return num_ways\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#complexity-analysis-of-approach-4","title":"Complexity Analysis of Approach 4","text":"<ul> <li>Time complexity: \\(O(n \\cdot m)\\) where \\(n\\) is number of coins and \\(m\\) is the amount.   Each state is visited at most once. There are \\(O(n \\cdot m)\\) possible states.</li> <li>Space complexity: \\(O(n \\cdot m)\\)   Each state can be stored in the queue, and the maximum number of states is \\(O(n \\cdot m)\\).</li> </ul> <p>### Approach 5: Backtracking</p> python <pre><code>code\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#complexity-analysis-of-approach-5","title":"Complexity Analysis of Approach 5","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Top-Down DP \\(O(n \\cdot m)\\) \\(O(n \\cdot m)\\) Approach 2 - Bottom-Up DP \\(O(n \\cdot m)\\) \\(O(n \\cdot m)\\) Approach 3 - Bottom-Up DP Space Optimization \\(O(n \\cdot m)\\) \\(O(m)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0518-coin-change-ii/#test","title":"Test","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0528-random-pick-with-weight/","title":"LC528. Random Pick with Weight","text":"","tags":["Prefix Sum","Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0528-random-pick-with-weight/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 528: You are given a\u00a00-indexed\u00a0array of positive integers\u00a0<code>w</code>\u00a0where\u00a0<code>w[i]</code>\u00a0describes the\u00a0weight\u00a0of the\u00a0<code>ith</code>\u00a0index.</p> <p>You need to implement the function\u00a0<code>pickIndex()</code>, which\u00a0randomly\u00a0picks an index in the range\u00a0<code>[0, w.length - 1]</code>\u00a0(inclusive) and returns it. The\u00a0probability\u00a0of picking an index\u00a0<code>i</code>\u00a0is\u00a0<code>w[i] / sum(w)</code>.</p> <ul> <li>For example, if\u00a0<code>w = [1, 3]</code>, the probability of picking index\u00a0<code>0</code>\u00a0is\u00a0<code>1 / (1 + 3) = 0.25</code>\u00a0(i.e.,\u00a0<code>25%</code>), and the probability of picking index\u00a0<code>1</code>\u00a0is\u00a0<code>3 / (1 + 3) = 0.75</code>\u00a0(i.e.,\u00a0<code>75%</code>).</li> </ul>","tags":["Prefix Sum","Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0528-random-pick-with-weight/#clarification","title":"Clarification","text":"<ul> <li>positive integer</li> <li>return the index?</li> <li>Ensure returned index meets the probability of picking</li> </ul>","tags":["Prefix Sum","Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0528-random-pick-with-weight/#assumption","title":"Assumption","text":"","tags":["Prefix Sum","Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0528-random-pick-with-weight/#solution","title":"Solution","text":"","tags":["Prefix Sum","Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0528-random-pick-with-weight/#approach-prefix-sum-binary-search","title":"Approach - Prefix Sum + Binary Search","text":"<p>After converting array to cumulative sum array, the width of each range represents the original value. The larger the original value is, the wider range is. For wider range, the random pick will falls into that range with higher probability.</p> Python <pre><code>import random\n\n\nclass Solution:\n\n    def __init__(self, w: List[int]):\n        self.w_cusum = w\n        for i in range(1, len(w)):\n            self.w_cusum[i] = self.w_cusum[i - 1] + w[i]\n\n    def pickIndex(self) -&gt; int:\n        rand_val = random.randint(1, self.w_cusum[-1])  # inclusive on two ends\n\n        left, right = 0, len(self.w_cusum) - 1\n        while left &lt; right:\n            mid = (left + right) // 2\n            if self.w_cusum[mid] == rand_val:\n                return mid\n            elif self.w_cusum[mid] &lt; rand_val:\n                left = mid + 1\n            else:\n                right = mid\n\n        return left\n</code></pre>","tags":["Prefix Sum","Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0528-random-pick-with-weight/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\) for <code>init</code>, \\(O(\\log n)\\) for <code>pickIndex</code> In <code>init</code> function, it takes \\(O(n)\\) to compute cumulative summation. In <code>pickIndex</code>, it uses binary search to find target index. So the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(n)\\) Storing cumulative sum array using \\(O(n)\\) space.</li> </ul>","tags":["Prefix Sum","Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0528-random-pick-with-weight/#test","title":"Test","text":"","tags":["Prefix Sum","Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0540-single-element-in-a-sorted-array/","title":"LC540. Single Element in a Sorted Array","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0540-single-element-in-a-sorted-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 540: You are given a sorted array consisting of only integers where every element appears exactly twice, except for one element which appears exactly once.</p> <p>Return\u00a0the single element that appears only once.</p> <p>Your solution must run in\u00a0<code>O(log n)</code>\u00a0time and\u00a0<code>O(1)</code>\u00a0space.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0540-single-element-in-a-sorted-array/#clarification","title":"Clarification","text":"<ul> <li>sorted array with integers</li> <li>only one element appears once</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0540-single-element-in-a-sorted-array/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0540-single-element-in-a-sorted-array/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0540-single-element-in-a-sorted-array/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Based on the definition, the total number of elements is odd and the last index is an even number with zero-based indexing. The target number (appears exactly once) can only appear in even indices, e.g., <code>nums[0]</code>, <code>nums[2]</code>, ..., <code>nums[2*n]</code>. We can search array in paris, i.e., numbers with index <code>[2 * i, 2 * i - 1]</code>. For any given pair,</p> <ul> <li>If elements in a pair are the same, the single element is on the right half of the array</li> <li>Otherwise, the single element is either in the current pair or on the left half of the array</li> </ul> <p>With this property, we can use binary search to speed up the search. The search space is the index of pairs, <code>[0, n/2]</code>. We want to find the first even-index number not followed by the same number. </p> Note <p>The last pair of <code>n/2</code> only has one element. In the code, use while condition <code>left &lt; right</code> to prevent out-of-bound access using <code>nums[2 * mid + 1]</code>. When it reaches the last pair, <code>left == right</code>, it will jump out of the while loop</p> Python <pre><code>class Solution:\n    def singleNonDuplicate(self, nums: List[int]) -&gt; int:\n        left, right = 0, len(nums) // 2\n\n        while left &lt; right:\n            mid = (left + right) // 2\n\n            if nums[2 * mid] == nums[2 * mid + 1]:\n                left = mid + 1\n            else:\n                right = mid\n\n        return nums[2 * left]\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0540-single-element-in-a-sorted-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)  Since using binary search, the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\) Only limited variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0540-single-element-in-a-sorted-array/#test","title":"Test","text":"<ul> <li>Empty array</li> <li>Array with 1 element</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/","title":"LC542. 01 Matrix","text":"","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 542: Given an\u00a0<code>m x n</code> binary matrix\u00a0<code>mat</code>, return\u00a0the distance of the nearest <code>0</code>for each cell.</p> <p>The distance between two adjacent cells is\u00a0<code>1</code>.</p>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#solution","title":"Solution","text":"","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#approach-bfs","title":"Approach - BFS","text":"<p>Use BFS to search starting from all <code>0</code>s. Note that starting from <code>1</code> leads to redundant calculation and visiting.  Check <code>matrix</code> value to indicate whether it is visited without using a dedicated set to track.</p> <p>When updating distance, we can either update it based on the parent node since it is visited or update based on the number of layers of BFS.</p> PythonPython 2 <pre><code>class Solution:\ndef updateMatrix(self, mat: List[List[int]]) -&gt; List[List[int]]:\n    m, n = len(mat), len(mat[0])\n    dist_mat = [[-1 for_ in range(n)] for _ in range(m)]\n    DIRECTIONS = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n\n    q = deque()\n    for r in range(m):\n        for c in range(n):\n            if mat[r][c] == 0:\n                dist_mat[r][c] = 0\n                q.append((r, c))\n\n    while q:\n        r, c = q.popleft()\n        for dx, dy in DIRECTIONS:\n            nr, nc = r + dx, c + dy\n            if 0 &lt;= nr &lt; m and 0 &lt;= nc &lt; n and dist_mat[nr][nc] == -1:\n                dist_mat[nr][nc] = dist_mat[r][c] + 1  #(1)\n                q.append((nr, nc))\n\n    return dist_mat\n</code></pre> <ol> <li>Update the distance based on the parent node which has been visited.</li> </ol> <pre><code>class Solution:\ndef updateMatrix(self, mat: List[List[int]]) -&gt; List[List[int]]:\n    m, n = len(mat), len(mat[0])\n    dist_mat = [[-1 for_ in range(n)] for _ in range(m)]\n    DIRECTIONS = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n\n    q = deque()\n    for r in range(m):\n        for c in range(n):\n            if mat[r][c] == 0:\n                dist_mat[r][c] = 0\n                q.append((r, c))\n\n    dist = 1\n    while q:\n        size = len(q)\n        for _ in range(size):\n            r, c = q.popleft()\n            for dx, dy in DIRECTIONS:\n                nr, nc = r + dx, c + dy\n                if 0 &lt;= nr &lt; m and 0 &lt;= nc &lt; n and dist_mat[nr][nc] == -1:\n                    dist_mat[nr][nc] = dist\n                    q.append((nr, nc))\n        dist += 1\n\n    return dist_mat\n</code></pre>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m \\times n)\\)   The BFS visits all nodes, \\(m \\times n\\), just once.</li> <li>Space complexity: \\(O(m \\times n)\\)   In the worst case, the queue will add all nodes, \\(m \\times n\\).</li> </ul>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#approach-2-dp","title":"Approach 2 - DP","text":"<p>The problem can be solved using dynamic programming with some tweaks. For a cell with 4 neighbors, we  can't directly use dynamic programming to compute the distance of the current cell based on 4 neighbors since distance of neighboring cells may not be computed yet.</p> <p>Instead, we use dynamic programming with two passes:</p> <ol> <li>Start from top left corner, calculate minimum distance based on only two directions: left and top neighbors, which has been visited</li> <li>Start from bottom right corner, calculate the minimum distance based on the current cell + only two directions: right and bottom, which has been visited</li> </ol> <p>For example, assume only one <code>0</code> in the middle and the other is <code>1</code>.</p> <ul> <li>After the 1st pass, the top left half will be filled with <code>inf</code> and bottom right half after <code>0</code> will have correct distance.</li> <li>After the 2nd pass, the top left half will the corrected</li> </ul> <p>Refer to explanations from @hiepit</p> <p></p> python <pre><code>class Solution:\ndef updateMatrix(self, mat: List[List[int]]) -&gt; List[List[int]]:\n    dp = [row[:] for row in mat]\n    m, n = len(mat), len(mat[0])\n\n    for row in range(m):\n        for col in range(n):\n            if dp[row][col] != 0:\n                top = dp[row - 1][col] if row &gt; 0 else math.inf\n                left = dp[row][col - 1] if col &gt; 0 else math.inf\n                dp[row][col] = min(top, left) + 1\n\n    for row in range(m - 1, -1, -1):\n        for col in range(n - 1, -1, -1):\n            if dp[row][col] != 0:\n                bottom = dp[row + 1][col] if row &lt; m - 1 else math.inf\n                right = dp[row][col + 1] if col &lt; n - 1 else math.inf\n                dp[row][col] = min(dp[row][col], bottom + 1, right + 1)  # (1)\n\n    return dp\n</code></pre> <ol> <li>Need to include the current cell since it is updated from the first pass</li> </ol>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(m \\times n)\\)   Iterate over matrix twice with constant work on each iteration. So the time complexity   is \\(O(2 \\times m \\times n) = O(m \\times n)\\).</li> <li>Space complexity: \\(O(m \\times n)\\)   The <code>dp</code> matrix contains \\(m \\times n\\) elements.</li> </ul>","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 -  BFS \\(O(m \\times n)\\) \\(O(m \\times n)\\) Approach 2 -  DP \\(O(m \\times n)\\) \\(O(m \\times n)\\)","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0542-01-matrix/#test","title":"Test","text":"","tags":["Breadth-First Search","Dynamic Programming"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/","title":"LC547. Number of Provinces","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 547: There are\u00a0<code>n</code> cities. Some of them are connected, while some are not. If city\u00a0<code>a</code>\u00a0is connected directly with city\u00a0<code>b</code>, and city\u00a0<code>b</code>\u00a0is connected directly with city\u00a0<code>c</code>, then city\u00a0<code>a</code> is connected indirectly with city\u00a0<code>c</code>.</p> <p>A\u00a0province\u00a0is a group of directly or indirectly connected cities and no other cities outside of the group.</p> <p>You are given an\u00a0<code>n x n</code>\u00a0matrix\u00a0<code>isConnected</code>\u00a0where\u00a0<code>isConnected[i][j] = 1</code>\u00a0if the\u00a0<code>ith</code> city and the\u00a0<code>jth</code>\u00a0city are directly connected, and\u00a0<code>isConnected[i][j] = 0</code>\u00a0otherwise.</p> <p>Return\u00a0the total number of\u00a0provinces.</p>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#clarification","title":"Clarification","text":"<ul> <li>What does \"no other cities outside of the group\" mean?</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#solution","title":"Solution","text":"<p>Go through each city, and use either DFS or BFS to find all connected cities and also mark visited city in the meantime. Once done, increase number of provinces by 1. If the city is visited, skip.</p>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#approach-bfs","title":"Approach - BFS","text":"<p>Use breadth-first search to traverse the graph.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def findCircleNum(self, isConnected: List[List[int]]) -&gt; int:\n        visited = set()\n        n_provinces = 0\n        n_cities = len(isConnected)\n        for i_city in range(n_cities):\n            if i_city not in visited:\n                self.bfs(isConnected, i_city, visited)\n                n_provinces +=1\n\n        return n_provinces\n\n    def bfs(self, isConnected: List[List[int]], i_city: int, visited: Set[int]) -&gt; None:\n        queue = deque([i_city])\n        visited.add(i_city)\n        n_cities = len(isConnected[0])\n        while queue:\n            curr_city = queue.popleft()\n            for next_city in range(n_cities):\n                if next_city not in visited and isConnected[curr_city][next_city]:\n                    queue.append(next_city)\n                    visited.add(next_city)\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n^2)\\)   In the worst case, it will visit \\(n\\) cities once. when visiting each city, it will   check \\(n\\) edges (including no connection edge) for the next city. So the time   complexity is \\(O(n^2)\\).</li> <li>Space complexity: \\(O(n)\\)   In the worst case, the queue and visited will store all cities, which takes \\(O(n)\\) space.</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#approach-2-dfs","title":"Approach 2 - DFS","text":"<p>Use depth-first search to traverse the cities.</p> python <pre><code>class Solution:\n    def findCircleNum(self, isConnected: List[List[int]]) -&gt; int:\n        n_provinces = 0\n        visited = set()\n        for i_city in range(len(isConnected)):\n            if i_city not in visited:\n                self.dfs(i_city, isConnected, visited)\n                n_provinces += 1\n\n        return n_provinces\n\n    def dfs(self, curr_city: int, isConnected: List[List[int]], visited: set[int]) -&gt; None:\n        visited.add(curr_city)\n        for next_city in range(len(isConnected[curr_city])):\n            if next_city not in visited and isConnected[curr_city][next_city] == 1:\n                self.dfs(next_city, isConnected, visited)\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n^2)\\)   In the worst case, it will visit \\(n\\) cities once. when visiting each city, it will   check \\(n\\) edges (including no connection edge) for the next city. So the time   complexity is \\(O(n^2)\\).</li> <li>Space complexity: \\(O(n)\\)   In the worst case, recursive function is called \\(n\\) times and recursion call stack   uses \\(O(n)\\) space.</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#approach-3-union-find","title":"Approach 3 - Union Find","text":"<p>We can solve the problem using union-find:</p> <ul> <li><code>union</code> two cities if they are not in the same disjoined set (i.e. provinces)</li> <li><code>find</code> whether any two cities are in the same disjoin set (i.e., province)</li> </ul> <p>We can initialize the <code>n_provinces</code> as total number of cities. Whenever conducting <code>union</code> operations, reduce <code>n_provinces</code> by 1.</p> python <pre><code>class UnionFind:\n    def __init__(self, size: int) -&gt; None:\n        self.root = [i for i in range(size)]  # (1)\n        self.rank = [0] * size\n        self.count = size\n\n    def find(self, x: int) -&gt; int:\n        if x == self.root[x]:\n            return x\n        self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x: int, y: int) -&gt; None:\n        root_x = self.find(x)\n        root_y = self.find(y)\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = root_x\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = root_y\n            else:  # equal rank\n                self.root[root_y] = root_x\n                self.rank[root_x] += 1\n            self.count -= 1\n\n    def getCount(self) -&gt; int:\n        return self.count\n\nclass Solution:\n    def findCircleNum(self, isConnected: List[List[int]]) -&gt; int:\n        if not isConnected or len(isConnected) == 0:\n            return 0\n\n        n_cities = len(isConnected)\n        uf = UnionFind(n_cities)\n\n        for i_city in range(n_cities):\n            for j_city in range(i_city + 1, n_cities):\n                if isConnected[i_city][j_city] == 1:\n                    uf.union(i_city, j_city)\n\n        return uf.getCount()\n</code></pre> <ol> <li>It's better set <code>root</code>, <code>rank</code>, and <code>count</code> as private attributes, <code>__root</code>, <code>__rank</code>, and <code>__count</code>.</li> </ol>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n^2 \\alpha(n))\\) where \\(\\alpha(n)\\) is the inverse Ackermann function.   The time complexity is dominated by two for-loops:<ul> <li>two for-loops take \\(n^2/2\\) operations</li> <li>within the for-loop, <code>union</code> function takes \\(\\alpha(n)\\).   So the total time complexity is \\(n^2 \\alpha(n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\)   The <code>UnionFind</code> use <code>root</code> and <code>rank</code> arrays. Each stores \\(n\\) elements   uses \\(O(n)\\) space.</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - BFS \\(O(n^2)\\) \\(O(n)\\) Approach 2 - DFS \\(O(n^2)\\) \\(O(n)\\) Approach 3 - Union Find \\(O(n^2 \\alpha(n))\\) \\(O(n)\\)","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0547-number-of-provinces/#test","title":"Test","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/","title":"LC560. Subarray Sum Equals K","text":"","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 560: Given an array of integers <code>nums</code> and an integer <code>k</code>, return the total number of continuous subarrays whose sum equals to <code>k</code>.</p>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#clarification","title":"Clarification","text":"<ul> <li>Subarray size could be 1 to len(nums)</li> <li>Array element could be negative</li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#assumption","title":"Assumption","text":"<ul> <li>Sum of subarray won't cause integer overflow</li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#solution","title":"Solution","text":"","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#approach-brute-force","title":"Approach - Brute Force","text":"Python <pre><code>class Solution:\ndef subarraySum(self, nums: List[int], k: int) -&gt; int:\n    n_sub_sum_k = 0\n    for i in range(len(nums)):\n        sum_sub = 0\n        for j in range(i, len(nums)):\n            sum_sub += nums[j]\n            if sum_sub == k:\n                # Even find one, will continue since there may be more\n                n_sub_sum_k += 1\n\n    return n_sub_sum_k\n</code></pre>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#approach-hashmap","title":"Approach - Hashmap","text":"<p>The problem can be solved more efficiently in terms of cumulative sum. For the cumulative sum (running sum or prefix sum), we will have the following properties:</p> <ul> <li>\\(\\text{runningSum}_x + \\text{targetSum} = \\text{runningSum}_y\\), i.e., \\(\\text{runningSum}_x = \\text{runningSum}_y - \\text{targetSum}\\) for subarray sum equals k<ul> <li>\\(\\text{runningSum}_y - \\text{runningSum}_x\\) is the sum of the subarray from index \\(x+1\\) to \\(y\\)</li> </ul> </li> <li>potentially multiple \\(runningSum_{x_1}, runningSum_{x_2}, \\cdots, runningSum_{x_i}\\) may satisfy the above equation since sum of subarray could be zero</li> </ul> <p>The solution is to find any \\(\\text{runningSum}_x\\) for position y that satisfies the equation \\(\\text{runningSum}_x = \\text{runningSum}_y - \\text{targetSum}\\). We can use the hashmap to store the cumulative sum and associated number of occurrence to quickly find the number of subarrays whose sum satisfy the equation.  </p> <p> </p> <p>The figure is from the book, \"Cranking the coding interview\" </p> PythonC++ <pre><code>class Solution:\ndef subarraySum(self, nums: List[int], k: int) -&gt; int:\n    count = 0\n    prefix_sum = 0\n    sum_count_dict = {0:1} # (1)\n\n    for num in nums:\n        prefix_sum = prefix_sum + num\n\n        if prefix_sum - k in sum_count_dict:\n            count += sum_count_dict[prefix_sum - k]\n\n        if prefix_sum not in sum_count_dict: # (2)\n            sum_count_dict[prefix_sum] = 1\n        else:\n            sum_count_dict[prefix_sum] += 1\n\n    return count\n</code></pre> <ol> <li>Initialize with <code>{0:1}</code> for <code>prefix_sum == k</code> cases where <code>prefix_sum - k == 0</code></li> <li><code>if/else</code> statement can be simplified as one line <code>sum_count_dict[prefix_sum] = sum_count_dict.get(prefix_sum, 0) + 1</code></li> </ol> <pre><code>class Solution {\npublic:\n    int subarraySum(vector&lt;int&gt;&amp; nums, int k) {\n        unordered_map&lt;long int, int&gt; sum_map;\n        long int sum = 0;\n        int count = 0;\n\n        for (int num : nums) {\n            sum += num;\n\n            if (sum == k) {\n                count++;\n            }\n\n            if (sum_map.find(sum - k) != sum_map.end()) {\n                count += sum_map[sum - k];\n            }\n\n            sum_map[sum]++;\n        }\n        return count;\n    }\n};\n</code></pre>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Traverse the array once.  </li> <li>Space complexity: \\(O(n)\\)     The hash map may contain up to \\(n\\) distinct entries in the worst case.</li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Brute force \\(O(n^2)\\) \\(O(1)\\) Approach - Hashmap \\(O(n)\\) \\(O(n)\\)","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0500-0599/lc0560-subarray-sum-equals-k/#test","title":"Test","text":"<ul> <li><code>nums</code>: <code>[1]</code>, <code>k</code>: 0, it will test where to put map update <code>sum_map[sum]++</code>. It should be in the end of for-loop (not before the two if conditions). Otherwise, the count update will be wrong.</li> <li><code>nums</code>: <code>[1, 2]</code>, <code>k</code>: 3, <code>prefix_sum == k</code></li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0600-0699/lc0611-valid-triangle-number/","title":"LC611. Valid Triangle Number","text":"","tags":["Sorting","Count"]},{"location":"lc-solutions/lc0600-0699/lc0611-valid-triangle-number/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 611: Given an integer array\u00a0<code>nums</code>, return\u00a0the number of triplets chosen from the array that can make triangles if we take them as side lengths of a triangle.</p>","tags":["Sorting","Count"]},{"location":"lc-solutions/lc0600-0699/lc0611-valid-triangle-number/#clarification","title":"Clarification","text":"<ul> <li>meaning of triplets to make triangles</li> <li>contains 0s?</li> </ul>","tags":["Sorting","Count"]},{"location":"lc-solutions/lc0600-0699/lc0611-valid-triangle-number/#assumption","title":"Assumption","text":"<ul> <li>No negative values</li> </ul>","tags":["Sorting","Count"]},{"location":"lc-solutions/lc0600-0699/lc0611-valid-triangle-number/#solution","title":"Solution","text":"","tags":["Sorting","Count"]},{"location":"lc-solutions/lc0600-0699/lc0611-valid-triangle-number/#approach-sorting-count","title":"Approach - Sorting + Count","text":"<p>@hiepit provides good explanations</p> <p>In a triangle, the length of any side is less than the sum of the other two sides, i.e., the following 3 conditions all need to be satisfied:</p> <ol> <li><code>a + b &gt; c</code></li> <li><code>a + c &gt; b</code></li> <li><code>b + c &gt; a</code>.</li> </ol> <p>If <code>c</code> is the longest side, we just need to check <code>a + b &gt; c</code> since the other two conditions are satisfied. It also excludes <code>a = 0</code> or <code>b = 0</code>. Since <code>0 + b &gt; c</code> contradicts the condition <code>c</code> is the longest side.</p> <p>First, sort <code>nums</code> in increase order. Then fix <code>k</code> and select <code>i</code>, <code>j</code> such that <code>i &lt; j &lt; k</code> where <code>nums[i]</code> is the smallest element and <code>nums[k]</code> is the largest element. Start with <code>i = 0</code> and <code>j = k - 1</code></p> <ul> <li>if <code>nums[i] + nums[j] &gt; nums[k]</code><ul> <li>elements in <code>i</code>, <code>i + 1</code>, ..., <code>j - 1</code> will satisfied this equation and form a triangles. There are total <code>j - i</code> triplets.</li> <li>next step: try another <code>nums[j]</code> by reducing <code>j</code> by 1</li> </ul> </li> <li>else <code>nums[i] + nums[j] &lt;= nums[k]</code>, need to increase sum of <code>nums[i] + nums[j]</code> by increase <code>i</code> by 1</li> </ul> <p></p> Python <pre><code>class Solution:\n    def triangleNumber(self, nums: List[int]) -&gt; int:\n        nums.sort()\n        n = len(nums)\n        count = 0\n        for k in range(2, n):\n            i = 0\n            j = k - 1\n            while i &lt; j:\n                if nums[i] + nums[j] &gt; nums[k]:\n                    count += j - i\n                    j -= 1\n                else:\n                    i += 1\n        return count\n</code></pre>","tags":["Sorting","Count"]},{"location":"lc-solutions/lc0600-0699/lc0611-valid-triangle-number/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^2)\\) In the worst case, for each <code>k</code>, it goes through 0 ~ k - 1 elements. </li> <li>Space complexity: \\(O(sorting)\\) Space used by sorting algorithm</li> </ul>","tags":["Sorting","Count"]},{"location":"lc-solutions/lc0600-0699/lc0611-valid-triangle-number/#test","title":"Test","text":"<ul> <li>array contains 0</li> </ul>","tags":["Sorting","Count"]},{"location":"lc-solutions/lc0600-0699/lc0622-design-circular-queue/","title":"LC622. Design Circular Queue","text":"","tags":["Queue"]},{"location":"lc-solutions/lc0600-0699/lc0622-design-circular-queue/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 622: Design your implementation of the circular queue. The circular queue is a linear data structure in which the operations are performed based on FIFO (First In First Out) principle, and the last position is connected back to the first position to make a circle. It is also called \"Ring Buffer\".</p> <p>Implement the\u00a0<code>MyCircularQueue</code>\u00a0class:</p> <ul> <li><code>MyCircularQueue(k)</code>\u00a0Initializes the object with the size of the queue to be\u00a0<code>k</code>.</li> <li><code>int Front()</code>\u00a0Gets the front item from the queue. If the queue is empty, return\u00a0<code>-1</code>.</li> <li><code>int Rear()</code>\u00a0Gets the last item from the queue. If the queue is empty, return\u00a0<code>-1</code>.</li> <li><code>boolean enQueue(int value)</code>\u00a0Inserts an element into the circular queue. Return\u00a0<code>true</code> if the operation is successful.</li> <li><code>boolean deQueue()</code>\u00a0Deletes an element from the circular queue. Return\u00a0<code>true</code>\u00a0if the operation is successful.</li> <li><code>boolean isEmpty()</code>\u00a0Checks whether the circular queue is empty or not.</li> <li><code>boolean isFull()</code>\u00a0Checks whether the circular queue is full or not.</li> </ul> <p>You must solve the problem without using the built-in queue data structure in your programming language.</p>","tags":["Queue"]},{"location":"lc-solutions/lc0600-0699/lc0622-design-circular-queue/#clarification","title":"Clarification","text":"<ul> <li>Implement circular queue without using built-in queue structure.</li> <li>What to return when deQueue an empty queue? Return false.</li> <li>When to return when enQueue a full queue? Return false.</li> <li>Which is front? The first enter element</li> <li>Which is tail? The last enter element</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0600-0699/lc0622-design-circular-queue/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Queue"]},{"location":"lc-solutions/lc0600-0699/lc0622-design-circular-queue/#solution","title":"Solution","text":"","tags":["Queue"]},{"location":"lc-solutions/lc0600-0699/lc0622-design-circular-queue/#approach-array","title":"Approach - Array","text":"<p>We can use an array with a fixed size and two pointers (head and tail) to implement circular queue. Note that if we know the head pointer, count of items, and array size, we can use the following equations to get the tail pointer</p> <pre><code>idx_tail = (idx_head + count - 1) % size\n</code></pre> <p>The insert index of the new item is the one after the tail pointer, we can use the equation <code>idx_insert = (idx_head + count) % size</code>. Note that we increase from <code>count - 1</code> to <code>count</code>.</p> <pre><code>block-beta\n  columns 5\n  head space space tail insert\n  space space space space space\n  0 1 2 3 4\n\n  head --&gt; 0\n  tail --&gt; 3\n  insert --&gt; 4\n\n  style 0 fill:#f8cecc\n  style 1 fill:#f8cecc\n  style 2 fill:#f8cecc\n  style 3 fill:#f8cecc</code></pre> <pre><code>block-beta\n  columns 5\n  tail insert space head space\n  space space space space space\n  0 1 2 3 4\n\n  head --&gt; 3\n  tail --&gt; 0\n  insert --&gt; 1\n\n  style 0 fill:#f8cecc\n  style 1 fill:#f8cecc\n  style 3 fill:#f8cecc\n  style 4 fill:#f8cecc</code></pre> Python <pre><code>class MyCircularQueue:\n\n    def __init__(self, k: int):\n        self.array = [0] * k\n        self.idx_head = 0\n        self.count = 0\n        self.size = k\n\n    def enQueue(self, value: int) -&gt; bool:\n        if self.isFull():\n            return False\n\n        # (1)\n        idx_insert= (self.idx_head + self.count)\n        self.array[idx_insert] = value\n        self.count += 1\n        return True\n\n    def deQueue(self) -&gt; bool:\n        if self.isEmpty():\n            return False\n\n        self.idx_head = (self.idx_head + 1) % self.size\n        self.count -= 1\n        return True\n\n    def Front(self) -&gt; int:\n        if self.isEmpty():\n            return -1\n\n        return self.array[self.idx_head]\n\n    def Rear(self) -&gt; int:\n        if self.isEmpty():\n            return -1\n\n        # (2)\n        idx_tail = (self.idx_head + self.count - 1) % self.size\n        return self.array[idx_tail]\n\n    def isEmpty(self) -&gt; bool:\n        return self.count == 0\n\n    def isFull(self) -&gt; bool:\n        return self.count == self.size\n</code></pre> <ol> <li>Use the following equation to find the insert index: <code>idx_insert = (head + count) % size</code>. Examples: <pre><code>index:  0  1  2  3\nvalue: [1, 2, 3, _]\nidx_head = 0, count = 3, size = 4, idx_insert = (0 + 3) % 4 = 3\nindex:  0  1  2  3\nvalue: [_, 2, 3, 4]\nidx_head = 1, count = 3, size = 4, idx_insert = (1 + 3) % 4 = 0\n</code></pre></li> <li>Use the following equation to find the tail index, <code>idx_tail = (head + count - 1) % size</code>. Note that <code>count - 1</code> used here instead of <code>count</code>. Examples: <pre><code>index:  0  1  2  3\nvalue: [1, 2, 3, _]\nidx_head = 0, count = 3, size = 4, idx_insert = (0 + 3 - 1) % 4 = 2\nindex:  0  1  2  3\nvalue: [_, 2, 3, 4]\nidx_head = 1, count = 3, size = 4, idx_insert = (1 + 3 - 1) % 4 = 3\n</code></pre></li> </ol>","tags":["Queue"]},{"location":"lc-solutions/lc0600-0699/lc0622-design-circular-queue/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(1)\\)     All methods use constant time complexity.</li> <li>Space complexity: \\(O(n)\\)     The array stores \\(n\\) items.</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0600-0699/lc0622-design-circular-queue/#test","title":"Test","text":"<ul> <li>When the circular queue is empty (should return\u00a0<code>-1</code>\u00a0for\u00a0<code>Front()</code>\u00a0and\u00a0<code>Rear()</code>).</li> <li>When the queue becomes full, additional enQueue operations should be rejected.</li> <li>Wrap-around behavior when\u00a0<code>rear</code>\u00a0reaches the end of the array.</li> </ul>","tags":["Queue"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/","title":"LC658. Find K Closest Elements","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 658: Given a sorted\u00a0integer array\u00a0<code>arr</code>, two integers\u00a0<code>k</code>\u00a0and\u00a0<code>x</code>, return the\u00a0<code>k</code>\u00a0closest integers to\u00a0<code>x</code>\u00a0in the array. The result should also be sorted in ascending order.</p> <p>An integer\u00a0<code>a</code>\u00a0is closer to\u00a0<code>x</code>\u00a0than an integer\u00a0<code>b</code>\u00a0if:</p> <ul> <li><code>|a - x| &lt; |b - x|</code>, or</li> <li><code>|a - x| == |b - x|</code>\u00a0and\u00a0<code>a &lt; b</code>\u00a0space.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#clarification","title":"Clarification","text":"<ul> <li>Find k elements vs. k-th element?</li> <li>Range of k? K &lt;= 0 or k &gt; arr.length?</li> <li>Sorted vs unsorted?</li> <li>Exact target my not exit and target may be out of array range</li> <li>Duplicate elements (target, or any element in the result) handling?</li> <li>Deal with tie case?</li> <li>return data - sorted or unsorted? sorted in ascending order or based on distance from x? what about empty?</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#assumptions","title":"Assumptions","text":"<ul> <li><code>k &lt;= arr.length</code></li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#solution","title":"Solution","text":"<ol> <li>For unsorted array, sort the element first by absolute difference values to the target (e.g., using Collection.sort). The result is in the first k elements.</li> <li> <p>For sorted array, we can use binary search to speed up the search. There are two different ways to achieve that:</p> <ul> <li>Binary search with two pointers: Use binary search to find two closest elements around the target and move to left or right using two pointers to find k closet elements.</li> <li>Binary search of a window @lee215: using binary search to find index i such that the window <code>[i, i+k-1]</code> (inclusive) contains the k closest elements</li> </ul> </li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#approach-sorting","title":"Approach - Sorting","text":"<p>Sort the element first by absolute difference values to the target. The result is in the first k elements. Before return, sort the k elements so the result is in ascending order as required. This approach can be used for both sorted and unsorted array.</p> <ul> <li>To use <code>Collections.sort</code>, the input array is copied to an array list.</li> <li><code>Collection.sort</code> is used twice -- 1) sort the whole array based on distance from target and 2) sort the k elements in the result based on the value</li> <li><code>Collection.sort</code> uses mergesort and has \\(n \\log n\\) comparison for general case.</li> <li>The <code>subList</code> function of ArrayList return a view of the portion of original list. Any operations on the sub list is actually happening on the original list.</li> <li>The total number of executions (including array copy and sort): \\(n + n \\log n + k \\log k\\)</li> </ul> Java <pre><code>class Solution {\n    public List&lt;Integer&gt; findClosestElements(int[] arr, int k, int x) {\n\n        List&lt;Integer&gt; arrList = new ArrayList&lt;Integer&gt;();\n\n        // Add array values to list\n        for (int i=0; i &lt; arr.length; i++)\n            arrList.add(arr[i]);\n\n        // Sort with compare funciont defined with lambda expression\n        Collections.sort(arrList, (a, b) -&gt; Math.abs(a - x) - Math.abs(b - x));\n\n        // The k closest elements\n        arrList = arrList.subList(0, k);\n\n        // Sort again before return so the result in ascending order\n        Collections.sort(arrList);\n        return arrList;\n    }\n}\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <code>Collections.sort()</code> uses merge sort and has \\(n \\log n\\) comparison for general case. The total number of executions (including array copy and sort): \\(n + n \\log n + k \\log k\\). Therefore, \\(O(n + n \\log n + k \\log k) \\rightarrow O (n \\log n)\\)</li> <li>Space complexity: \\(O(n)\\) The in-place sorting does not consume any extra space. However, converting array to list takes additional space. If the input is the list, it will be \\(O(1)\\) since <code>subList</code> returns a view, not a separate copy.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#approach-binary-search-with-two-pointers","title":"Approach - Binary Search with two pointers","text":"<p>Since the original array is sorted, we can use binary search to speed up the search with the following two steps:</p> <ol> <li>Use binary search to find the index of the target or the index of a smaller element that is closest to target (if target not exists)</li> <li>Move to left or right (inside-out) using two pointers to find k closet elements. Alternative way: shrink the range [index-k-1, index+k+1] where the desired k elements must in.</li> </ol> <p>Improvement on step 2: use binary search idea again If <code>arr[pointLeft - k/2]</code> is closer to target compared with <code>arr[pointLeft + k/2]</code>, then all elements from <code>pointLeft - k/2</code> to <code>pointLeft</code> should be included in the result. Next step compare <code>arr[pointLeft - k/2 - k/4]</code> and <code>arr[pointRight + k/4]</code> Using recursion will be <code>k, (p1, p1+1, k)</code> <code>k/2, (p1 - k/2, p2 + 1, k - k/2)</code>, This method can achieve \\(O(\\log n + \\log k)\\) time complexity on find indices but still need \\(O(\\log n + k)\\) to return elements since generating k length list needs some time.</p> PythonJava <pre><code>class Solution:\n    def findClosestElements(self, arr: List[int], k: int, x: int) -&gt; List[int]:\n        if k &lt;= 0 or k &gt; len(arr):\n            return [0]\n\n        left = self.binarySearch(arr, x)\n        right = left + 1\n        # Expand to left and right to find the k sub array\n        for count in range(k):\n            if left &lt; 0:\n                right += 1\n            elif right &gt; len(arr) - 1:\n                left -= 1\n            else:\n                if abs(arr[left] - x) &lt;= abs(arr[right] - x):\n                    left -= 1\n                else:\n                    right += 1\n\n        return arr[left + 1: right]\n\n    def binarySearch(self, arr: List[int], x: int) -&gt; int:\n        left, right = 0, len(arr) - 1\n\n        while left &lt; right - 1:\n            mid = (left + right) // 2\n\n            if arr[mid] == x:\n                return mid\n            elif arr[mid] &lt; x:\n                left = mid\n            else:\n                right = mid\n\n        return left\n</code></pre> <pre><code>class Solution {\n    public List&lt;Integer&gt; findClosestElements(int[] arr, int k, int x) {\n        List&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;();\n\n        if (arr == null || arr.length == 0)\n            return result; // return array\n\n        // Corner cases for k\n        // could return all elements if k &gt; arr.length\n        if (k &lt;= 0 || k &gt; arr.length)\n            return result; // return new int[0]\n\n        // binary search first\n        // then find closest elements from target to left and to right\n\n        int idxLeft = binarySearch(arr, x); // index for the left half, left closet element or equal element\n        int idxRight = idxLeft + 1; // index for the right half\n\n        for (int count = 0; count &lt; k; count++){\n            if (idxRight &gt;= arr.length  || (idxLeft &gt;= 0 &amp;&amp; Math.abs(arr[idxLeft] - x) &lt;= Math.abs(arr[idxRight] - x)))\n                idxLeft--;\n            else\n                idxRight++;\n        }\n\n        for (int idx = idxLeft+1; idx &lt; idxRight; idx++)\n            result.add(arr[idx]);\n\n        return result;\n    }\n\n    private int binarySearch(int[] arr, int target){\n        // return index of the left closest element to the target\n        int left = 0;\n        int right = arr.length - 1;\n        int middle;\n\n        while (left &lt; right - 1){\n            middle = left + (right - left)/2;\n            if (target &lt; arr[middle])\n                right = middle;\n            else if (target &gt; arr[middle])\n                left = middle;\n            else // target == arr[middle]\n                return middle;\n        }\n\n        // No need postprocessing, just return the left element\n        return left;\n    }\n}\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#complexity-analysis_1","title":"Complexity analysis","text":"<ul> <li>Time complexity: \\(O(\\log n + k)\\). \\(O(\\log n)\\) is for the time of binary search, while \\(O(k)\\) is for moving two pointers to find the range.</li> <li>Space complexity: \\(O(k)\\) for generating a list with k elements from an array.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#approach-binary-search-of-a-window","title":"Approach: Binary search of a window","text":"<p>A smart solutions from @lee215: using binary search to find index <code>i</code> such that the window <code>[i, i+k-1]</code> (inclusive) contains the k closest elements. Move the window to left or right by comparing the distance between <code>x - arr[mid]</code> and <code>arr[mid + k] - x</code>.</p> <ul> <li>case 1: x is outside of window and on the left (<code>x - A[mid] &lt; A[mid + k] - x</code>), move window to left -----x----A[mid]------------A[mid+k]--------</li> <li>case 2: x is in the window and close to the left (<code>x - A[mid] &lt; A[mid + k] - x</code>), move window to left again ----A[mid]-----x------------A[mid+k]--------</li> <li>case 3: x is in the window close to the right (<code>x - A[mid] &gt; A[mid + k] - x</code>), move window to right ----A[mid]------------x-----A[mid+k]--------</li> <li>case 3: x is outside of window and on the right (<code>x - A[mid] &gt; A[mid + k] - x</code>), move window to right ----A[mid]------------------A[mid+k]---x----</li> </ul> <pre><code>block-beta\n  block:ID\n    left_out_more[\"\u2022\u2022\u2022\"]\n    target[\"x\"]\n    left_out[\"\u2022\u2022\u2022\"]\n    left[\"mid\"]\n    middle[\"\u2022\u2022\u2022\"]\n    right[\"mid + k\"]\n    right_out[\"\u2022\u2022\u2022\"]\n  end</code></pre> <pre><code>block-beta\n  block:ID\n    left_out[\"\u2022\u2022\u2022\"]\n    left[\"mid\"]\n    middle_less[\"\u2022\"]\n    target[\"x\"]\n    middle[\"\u2022\u2022\u2022\"]\n    right[\"mid + k\"]\n    right_out[\"\u2022\u2022\u2022\"]\n  end</code></pre> <pre><code>block-beta\n  block:ID\n    left_out[\"\u2022\u2022\u2022\"]\n    left[\"mid\"]\n    middle[\"\u2022\u2022\u2022\"]\n    target[\"x\"]\n    middle_less[\"\u2022\"]\n    right[\"mid + k\"]\n    right_out[\"\u2022\u2022\u2022\"]\n  end</code></pre> <pre><code>block-beta\n  block:ID\n    left_out[\"\u2022\u2022\u2022\"]\n    left[\"mid\"]\n    middle[\"\u2022\u2022\u2022\"]\n    right[\"mid + k\"]\n    right_out[\"\u2022\u2022\u2022\"]\n    target[\"x\"]\n    right_out_more[\"\u2022\u2022\u2022\"]\n  end</code></pre> <p>Important points for implementation:</p> <ul> <li>Initialize <code>right = arr.length - k</code>, so <code>right + k - 1</code> will not exceed <code>arr.length</code></li> <li> <p>When updating left and right indices, using <code>mid + 1</code>, <code>mid</code>, or <code>mid - 1</code>?</p> <ul> <li>if <code>x - A[mid] &gt; A[mid + k] - x</code>, it means <code>A[mid + k]</code> is closer to x and the window <code>A[mid + 1] - A[mid + k]</code> is better than the window <code>A[mid] - A[mid + k - 1]</code>. Therefore update <code>left = mid + 1</code></li> <li>if <code>x - A[mid] &lt; A[mid + k] - x</code>, it means <code>A[mid]</code> is closer to x and the current window <code>A[mid] - A[mid + k - 1]</code> or potentially some window on the left is better. Therefore update <code>right = mid</code>. Note that it is NOT <code>mid - 1</code>, since from the comparison we only know the current window is better and don't know whether the window on the left is better.</li> <li>if <code>x - A[mid] == A[mid + k] - x</code>, don't stop here and continue to check the left see whether there is a better window. In the problem description, it requires \"If there is a tie, the smaller elements are always preferred.\" Therefore, update <code>right = mid</code> to search smaller elements.</li> <li>When to end the while loop for binary search? <code>left == right</code></li> <li>For comparison, using absolute value <code>abs(x - A[mid]</code> or relative value with sign <code>x - A[mid]</code>? If <code>A[mid] == A[mid + k]</code>, we don't know either to move left or right using absolute value (need additional check). Relative values can tell the direction based on the sign of the value. The absolute value comparison method fails at cases like <code>A = [1,1,2,2,2,2,2,3,3]</code>, <code>x = 3</code>, <code>k = 2</code>.</li> <li>For comparison, <code>A[mid]</code> vs. <code>A[mid + k]</code>, or <code>A[mid]</code> vs. <code>A[mid + k - 1]</code>? Use <code>A[mid]</code> vs. <code>A[mid + k]</code>, since we are trying to comparing two windows (A[mid] ~ A[mid + k - 1] vs. A[mid + 1] ~ A[mid + k]) to see which one is better.  </li> </ul> </li> </ul> PythonJava <pre><code>class Solution:\n    def findClosestElements(self, arr: List[int], k: int, x: int) -&gt; List[int]:\n        left, right = 0, len(arr) - k\n\n        while left &lt; right:\n            mid = (left + right) // 2\n            if x - arr[mid] &gt; arr[mid + k] - x:\n                left = mid + 1\n            else:\n                right = mid\n\n        return arr[left: left + k]\n</code></pre> <pre><code>class Solution {\n    public List&lt;Integer&gt; findClosestElements(int[] arr, int k, int x) {\n        List&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;();\n\n        // Input validation\n        if (arr == null || arr.length == 0)\n            return result;\n\n        if (k &lt;= 0 || k &gt; arr.length)\n            return result;\n\n        int left = 0;\n        int right = arr.length - k; // -k here with window consideration\n        int mid;\n\n        while (left &lt; right) {\n            mid = left + (right - left)/2;\n\n            // compare mid and mid+k not mid+k-1 to see which window is better\n            // current window (mid ~ mid+k-1) or next window (mid+1 ~ mid+k)\n            if (x - arr[mid] &gt; arr[mid + k] - x)\n                left = mid + 1;\n            // else if (x - arr[mid] &lt; arr[mid + k] - x)\n            //     right = mid;\n            else\n                right = mid;  // for tie case: not return, continue to check the left see whether there is a better window\n        }\n\n        // postprocessing left == right\n        // window left ~ left + k - 1\n        for (int i = left; i &lt; left + k; i++)\n            result.add(arr[i]);\n\n        return result;\n\n        // return Arrays.stream(arr, left, left + k).boxed().collect(Collectors.toList());\n\n    }\n}\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#complexity-analysis_2","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log (n - k))\\) for finding indices and \\(O(\\log (n - k) + k)\\) for returning elements. Since the search space of binary search of window is \\(n-k\\) elements, therefore the complexity for finding indices is \\(O(\\log (n - k))\\). However to return the elements, it involves k-times copy and therefore time complexity is changed to \\(O(\\log (n - k) + k)\\).</li> <li>Space complexity: \\(O(k)\\) for generating a list with k elements from an array.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"Approach Time Complexity Space Complexity Approach - sorting \\(O(n\\log n)\\) \\(O(n)\\) Approach - binary search with two pointers \\(O(\\log n + k)\\) \\(O(k)\\) Approach - binary search of a window \\(O(\\log (n-k) + k)\\) for returning elements \\(O(k)\\) \\(O(\\log (n-k))\\) for returning indices","tags":["Binary Search"]},{"location":"lc-solutions/lc0600-0699/lc0658-find-k-closest-elements/#test","title":"Test","text":"<ul> <li>Test corner cases: zero array, invalid k, array with 0, 1, and 2 elements</li> <li>Test general cases  </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/","title":"700. Search in a Binary Search Tree","text":"","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 700: You are given the\u00a0<code>root</code>\u00a0of a binary search tree (BST) and an integer\u00a0<code>val</code>.</p> <p>Find the node in the BST that the node's value equals\u00a0<code>val</code>and return the subtree rooted with that node. If such a node does not exist, return\u00a0<code>null</code>.</p>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#clarification","title":"Clarification","text":"<ul> <li>BST Definition</li> </ul>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#solution","title":"Solution","text":"<p>Implemented solutions based on binary search tree property</p> <ul> <li>smaller keys in the left subtree</li> <li>larger keys in the right subtree</li> </ul>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#approach-1-recursion","title":"Approach 1: Recursion","text":"<p>We can solve the problem using recursion.</p> Python <pre><code>class Solution:\ndef searchBST(self, root: Optional[TreeNode], val: int) -&gt; Optional[TreeNode]:\n    # Base case\n    if root is None or root.val == val:\n        return root\n\n    # Recursively serach either left or right subtree\n    if root.val &lt; val:\n        return self.searchBST(root.right, val)\n    else:\n        return self.searchBST(root.left, val)\n</code></pre>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   The time complexity is \\(O(h)\\), depends on the tree height, \\(h\\). In the worst case, it   is \\(O(n)\\). On average, it could be \\(O(\\log n)\\) since every search only search half of   the tree.</li> <li>Space complexity: \\(O(n)\\)   The recursion call stack takes \\(O(h)\\) space. In the worst case, it is \\(O(n)\\).</li> </ul>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#approach-2-iteration","title":"Approach 2: Iteration","text":"<p>The problem can be solved using iteration, which will reduce space complexity to \\(O(1)\\).</p> python <pre><code>class Solution:\n    def searchBST(self, root: Optional[TreeNode], val: int) -&gt; Optional[TreeNode]:\n        curr_node = root\n\n        while curr_node:\n            if curr_node.val == val:\n                return curr_node\n            elif curr_node.val &lt; val:\n                curr_node = curr_node.right\n            else:\n                curr_node = curr_node.left\n\n        return None  # not find the target value\n</code></pre>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   Similar to recursion, the time complexity in the worst case is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\)   Only use <code>curr_node</code>.</li> </ul>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Recursion \\(O(n)\\) \\(O(n)\\) Approach - Iteration \\(O(n)\\) \\(O(1)\\)","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0700-search-in-a-binary-search-tree/#test","title":"Test","text":"<ul> <li>Test empty root.</li> <li>Test <code>val</code> in the tree.</li> <li>Test <code>val</code> not in the tree.</li> </ul>","tags":["Binary Search Tree"]},{"location":"lc-solutions/lc0700-0799/lc0702-search-in-a-sorted-array-of-unknown-size/","title":"LC702. Search in a Sorted Array of Unknown Size","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0702-search-in-a-sorted-array-of-unknown-size/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 702: This is an\u00a0interactive problem.</p> <p>You have a sorted array of\u00a0unique\u00a0elements and an\u00a0unknown size. You do not have an access to the array but you can use the\u00a0<code>ArrayReader</code>\u00a0interface to access it. You can call\u00a0<code>ArrayReader.get(i)</code>\u00a0that:</p> <ul> <li>returns the value at the\u00a0<code>ith</code>\u00a0index (0-indexed) of the secret array (i.e.,\u00a0<code>secret[i]</code>), or</li> <li>returns\u00a0<code>231 - 1</code>\u00a0if the\u00a0<code>i</code>\u00a0is out of the boundary of the array.</li> </ul> <p>You are also given an integer\u00a0<code>target</code>.</p> <p>Return the index\u00a0<code>k</code>\u00a0of the hidden array where\u00a0<code>secret[k] == target</code>\u00a0or return\u00a0<code>-1</code>\u00a0otherwise.</p> <p>You must write an algorithm with\u00a0<code>O(log n)</code>\u00a0runtime complexity.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0702-search-in-a-sorted-array-of-unknown-size/#clarification","title":"Clarification","text":"<ul> <li>Data type? integer</li> <li>Sorted vs. unsorted?</li> <li>Ascending order or descending order?</li> <li>ArrayReader question:<ul> <li>What value to return when element doesn't exist?</li> <li>zero-based indexing?</li> </ul> </li> <li>How large the array size could be? Exceed the max value allowed of integer?</li> <li>Any duplicates? what to return if target has duplicates</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0702-search-in-a-sorted-array-of-unknown-size/#assumption","title":"Assumption","text":"<ul> <li>the array size &lt; Integer.MAX_VALUE;</li> <li>zero-based indexing</li> <li>target &lt; 2^31 - 1</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0702-search-in-a-sorted-array-of-unknown-size/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0702-search-in-a-sorted-array-of-unknown-size/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since the array is sorted, we can  </p> <ol> <li>Define search limits, i.e., left and right boundaries If target is outside the boundaries, then it should be on the right and extend the boundaries <code>left = right</code> and <code>right = right * 2</code>. Some considerations:  <ul> <li>End the search when <code>reader.get(right) &gt;= target</code></li> <li><code>right = right * 2</code> vs. <code>right = right * 10</code> (both work for elements with duplicates)</li> <li>tricky method: since all the elements are unique, there are at most <code>right = target - reader.get(0)</code> elements from index 0 to the index of target. If the element at the upper bound index does not exist, the search array will contain some <code>2^31 - 1</code> in the end. For example, <code>[-1, 2, 5, 8, 2^31 - 1, 2^31 - 1]</code>.</li> </ul> </li> <li>Perform classic binary search within the boundaries  </li> </ol> PythonJava <pre><code>class Solution:\n    def search(self, reader: 'ArrayReader', target: int) -&gt; int:\n        left, right = 0, 1\n\n        while reader.get(right) &lt; target:\n            left, right = right, right * 2\n\n        while left &lt;= right:\n            mid = (left + right) // 2\n            value = reader.get(mid)\n            if value == target:\n                return mid\n            elif target &lt; value:\n                right = mid - 1\n            else:\n                left = mid + 1\n\n        return -1\n</code></pre> <pre><code>class Solution {\n    public int search(ArrayReader reader, int target) {\n        int left = 0;\n        int right = 1;\n\n        // Search boundaries [Left, Right] to include target\n        while ((reader.get(right) &lt; target)) {\n            if (reader.get(right) == 2147483647)\n                return -1;\n\n            left = right;\n            if (right &lt; Integer.MAX_VALUE/2)\n                right *= 2;  // or right &lt;&lt;= 1, double right until finding the right boundary (i.e., right &gt; target)\n            else{\n                right = Integer.MAX_VALUE;\n                break;\n            }\n        }\n        // left = right/2;\n\n        int mid;\n        int val;  // value of reader.get(mid)\n        // classic binary search\n        while (left &lt;= right) {\n            mid = left + (right - left)/2;\n\n            val = reader.get(mid);\n            if (val == 2147483647)\n                right = mid - 1;\n            else if (target &lt; val)\n                right = mid - 1;\n            else if (target &gt; val)\n                left = mid + 1;\n            else\n                return mid;\n        }\n\n        return -1;\n    }\n}\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0702-search-in-a-sorted-array-of-unknown-size/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li> <p>Time complexity: \\(\\mathcal{O}(\\log T)\\), where \\(T\\) is an index of target value  There are two operations:</p> </li> <li> <p>Find search boundaries: the boundary is \\(2^k &lt; T \\leq 2^{k+1}\\) and needs \\(k = \\log T\\) steps to find the boundaries </p> </li> <li> <p>Binaries search within the boundaries: There are \\(2^{k+1} - 2^k = 2^k = 2^{\\log T} = T\\) elements. It takes \\(\\log T\\) steps for binary search. The total steps are \\(\\log T + \\log T\\). Therefore, the time complexity is \\(\\mathcal{O}(\\log T)\\) </p> </li> <li> <p>Space complexity: \\(\\mathcal{O}(1)\\), since it only update several variables in finding boundaries and performing binary search. </p> </li> </ul> <p>Alternative: use <code>right *= 10</code> instead of <code>right *= 2</code> - Find search boundaries: the boundary is \\(10^k &lt; T \\leq 10^{k+1}\\) and needs \\(k = \\log_{10} T\\) steps to find the boundaries   - Binaries search within the boundaries: There are \\(10^{k+1} - 10^k = 9*10^k = 9*10^{\\log_{10} T} = 9T\\) elements. It takes \\(\\log_2 9T\\) steps for bineary search.  </p> <p>Comparison between <code>right *= 2</code> and <code>right *= 10</code>:  </p> Find Boundaries Binary Search right *= 2 \\(\\log_2 T\\) \\(\\log_2 T\\) right *= 10 \\(\\log_{10} T\\) \\(\\log_2 9T\\) <p>Which one is better? When \\(T &gt; 23\\), 10 times update is faster. However, even T is really big (e.g. \\(10^{30}\\)), the  difference between 10 times and 2 times is still small (69 steps less). So using either one in implementation is fine.</p> <p>10 times - 2 times  = \\(\\log_{10} T + log_2 9T - \\log_2T - \\log_2 T\\) = \\(\\log_{10} T - \\log_2T + log_2 9T - \\log_2 T\\) = \\(\\log_{10} T - \\log_2T + log_2 9\\)</p> <p>\\(\\log_{10} 24 - \\log_2 24 + log_2 9 = - 0.035\\) \\(\\log_{10} 10^{30} - \\log_2 10^{30} + log_2 9 = - 68.81\\)</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0702-search-in-a-sorted-array-of-unknown-size/#test","title":"Test","text":"<ul> <li>Test corner cases: empty array, array size &gt; Integer.MAX_VALUE, target doesn't exist</li> <li>Test general case</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0703-kth-largest-element-in-a-stream/","title":"LC703. Kth Largest Element in a Stream","text":"","tags":["Heap"]},{"location":"lc-solutions/lc0700-0799/lc0703-kth-largest-element-in-a-stream/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 703: You are part of a university admissions office and need to keep track of the\u00a0<code>kth</code> highest test score from applicants in real-time. This helps to determine cut-off marks for interviews and admissions dynamically as new applicants submit their scores.</p> <p>You are tasked to implement a class which, for a given integer\u00a0<code>k</code>, maintains a stream of test scores and continuously returns the\u00a0<code>k</code>th highest test score\u00a0after\u00a0a new score has been submitted. More specifically, we are looking for the\u00a0<code>k</code>th highest score in the sorted list of all scores.</p> <p>Implement the\u00a0<code>KthLargest</code>\u00a0class:</p> <ul> <li><code>KthLargest(int k, int[] nums)</code>\u00a0Initializes the object with the integer\u00a0<code>k</code>\u00a0and the stream of test scores\u00a0<code>nums</code>.</li> <li><code>int add(int val)</code>\u00a0Adds a new test score\u00a0<code>val</code>\u00a0to the stream and returns the element representing the\u00a0<code>kth</code> largest element in the pool of test scores so far.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0700-0799/lc0703-kth-largest-element-in-a-stream/#clarification","title":"Clarification","text":"<ul> <li>Track the kth highest test score real time</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0700-0799/lc0703-kth-largest-element-in-a-stream/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap"]},{"location":"lc-solutions/lc0700-0799/lc0703-kth-largest-element-in-a-stream/#solution","title":"Solution","text":"","tags":["Heap"]},{"location":"lc-solutions/lc0700-0799/lc0703-kth-largest-element-in-a-stream/#approach-heap","title":"Approach - Heap","text":"<p>Use min heap to track the top k test scores.</p> Python <pre><code>import heapq\n\n\nclass KthLargest:\n\n    def __init__(self, k: int, nums: List[int]):\n        self.min_heap = []\n        self.min_heap_size = k\n        for num in nums:\n            self.add(num)\n\n    def add(self, val: int) -&gt; int:\n        heapq.heappush(self.min_heap, val)\n        if len(self.min_heap) &gt; self.min_heap_size:\n            heapq.heappop(self.min_heap)\n\n        return self.min_heap[0]  # (1)\n</code></pre> <ol> <li>The smallest value in the heap is the <code>kth</code> largest element.</li> </ol>","tags":["Heap"]},{"location":"lc-solutions/lc0700-0799/lc0703-kth-largest-element-in-a-stream/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log k)\\) where \\(n\\) is the total number of values including initial values in <code>nums</code> and later added ones.<ul> <li>The <code>add</code> function is called total \\(n\\) times. Each <code>add</code> performs one or two heap operations. Each operation takes \\(O(\\log k)\\) for the heap size \\(k\\).</li> <li>The total time complexity is \\(O(n \\log k)\\).</li> </ul> </li> <li>Space complexity: \\(O(k)\\)     The min heap stores at most \\(k\\) elements.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc0700-0799/lc0703-kth-largest-element-in-a-stream/#test","title":"Test","text":"","tags":["Heap"]},{"location":"lc-solutions/lc0700-0799/lc0704-binary-search/","title":"LC704. Binary Search","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0704-binary-search/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 704: Given an array of integers\u00a0<code>nums</code>\u00a0which is sorted in ascending order, and an integer\u00a0<code>target</code>, write a function to search\u00a0<code>target</code>\u00a0in\u00a0<code>nums</code>. If\u00a0<code>target</code>\u00a0exists, then return its index. Otherwise, return\u00a0<code>-1</code>.</p> <p>You must write an algorithm with\u00a0<code>O(log n)</code>\u00a0runtime complexity.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0704-binary-search/#clarification","title":"Clarification","text":"<ul> <li>sorted, ascending order</li> <li>target may not exist</li> <li>O(logn)</li> <li>return index</li> <li>what about duplicates</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0704-binary-search/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0704-binary-search/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0704-binary-search/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since the array is sorted, we can use the standard binary search to find the target. Each execution cuts one half that is guaranteed not to contain <code>target</code>.</p> Python <pre><code>class Solution:\n    def search(self, nums: List[int], target: int) -&gt; int:\n        left, right = 0, len(nums) - 1\n\n        while left &lt;= right:\n            mid = (left + right) // 2\n            if target == nums[mid]:\n                return mid\n            elif target &lt; nums[mid]:\n                right = mid - 1\n            else:\n                left = mid + 1\n\n        return -1\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0704-binary-search/#complexity-analysis","title":"Complexity Analysis","text":"<p>Assume array <code>nums</code> size is <code>n</code> </p> <ul> <li>Time complexity: \\(O(\\log n)\\)     The search space is divided by half each time. In the worse case, we need to cut <code>nums</code> until no more element, which takes \\(\\log n\\) steps.</li> <li>Space complexity: \\(O(1)\\)     Only need three indices, <code>left</code>, <code>right</code>, and <code>mid</code>, which take constant space.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0704-binary-search/#test","title":"Test","text":"<ul> <li>Test target on two ends</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0713-subarray-product-less-than-k/","title":"LC713. Subarray Product Less Than K","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0700-0799/lc0713-subarray-product-less-than-k/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 713: Given an array of integers <code>nums</code> and an integer <code>k</code>, return the number of contiguous subarrays where the product of all the elements in the subarray is strictly less than <code>k</code>.</p>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0700-0799/lc0713-subarray-product-less-than-k/#clarification","title":"Clarification","text":"<ul> <li>integer array</li> <li>find number of subarrays with product &lt; k</li> <li>positive elements</li> <li>positive k? <code>k==0</code>?</li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0700-0799/lc0713-subarray-product-less-than-k/#assumption","title":"Assumption","text":"<ul> <li>Product of subarray won't cause overflow of long long int</li> <li>Array elements are positive</li> <li><code>k &gt;= 0</code></li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0700-0799/lc0713-subarray-product-less-than-k/#solution","title":"Solution","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0700-0799/lc0713-subarray-product-less-than-k/#approach-sliding-window","title":"Approach - Sliding Window","text":"<p>The problem can be solved using a sliding window method with two pointers:</p> <ul> <li>Expand the sliding window by adding a new number on the right (right pointer, <code>j</code>)</li> <li>If <code>product &gt;= k</code>, shrink the window by removing the number from the left (left pointer, <code>i</code>) until the subarray with <code>product &lt; k</code> again<ul> <li>Note subarray could be empty and therefore needs add condition <code>left &lt;= right</code>. So the while loop ends at <code>left == right + 1</code> when no subarray satisfies the condition</li> </ul> </li> <li>Each step introduces <code>x</code> new subarrays, where <code>x</code>  is the size of the current window <code>j - i + 1</code><ul> <li>For example, for window (5, 2), when 6 is introduced, it adds 3 new subarray<ul> <li>(6)</li> <li>(2, 6)</li> <li>(5, 2, 6)</li> </ul> </li> <li>Then in nexts step when 3 is introduce, it may add 4 new subarrays<ul> <li>(3)</li> <li>(6, 3)</li> <li>(2, 6, 3)</li> <li>(5, 2, 6, 3) : depending k, may not satisfy the condition, </li> </ul> </li> </ul> </li> </ul> PythonC++ <pre><code>class Solution:\ndef numSubarrayProductLessThanK(self, nums: List[int], k: int) -&gt; int:\n    product = 1\n    count = 0\n    left = 0\n\n    for right in range(len(nums)):\n        product *= nums[right]\n\n        while product &gt;= k and left &lt;= right:\n            product = product // nums[left]\n            left += 1\n\n        count += right - left + 1 # (1)\n\n    return count\n</code></pre> <ol> <li>When subarray is empty, <code>left = right + 1</code> and therefore <code>right - left + 1 = 0</code></li> </ol> <pre><code>class Solution {\npublic:\n    int numSubarrayProductLessThanK(vector&lt;int&gt;&amp; nums, int k) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size left = 0;\n        long long int product = 1;\n        int count = 0;\n\n        for (vec_size right = 0; right &lt; nums.size(); right++) {\n            product *= nums[right];\n\n            while (product &gt;= k &amp;&amp; left &lt;= right) {\n                product /= nums[left++];\n            }\n\n            count += right + 1 - left;\n        }\n\n        return count;\n    }\n};\n</code></pre> <p>When product of subarray is too large, we can use <code>log</code> function to convert <code>A*B*C &gt;= k</code> to <code>log(A*B*C) = log(A) + log(B) + log(C) &gt;= log(k)</code>. Yet, due to numerical issue of floating point, we need to use <code>math.isclose</code> to check whether the summation is equal to <code>log(k)</code>.</p> <pre><code>import math\n\nclass Solution:\n    def numSubarrayProductLessThanK(self, nums: List[int], k: int) -&gt; int:\n        if k == 0:\n            return 0\n\n        prefix_sum = 0\n        count = 0\n        left = 0\n        log_k = math.log(k)\n\n        for right in range(len(nums)):\n            prefix_sum += math.log(nums[right])\n\n            while (prefix_sum &gt; log_k or math.isclose(prefix_sum, log_k)) and left &lt;= right:\n                prefix_sum -= math.log(nums[left])\n                left += 1\n\n            count += right - left + 1\n\n        return count\n</code></pre>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0700-0799/lc0713-subarray-product-less-than-k/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     The <code>right</code> pointers is increased by \\(n\\) times </li> <li>Space complexity: \\(O(1)\\)     Use limit local variables with constant space. </li> </ul>","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0700-0799/lc0713-subarray-product-less-than-k/#test","title":"Test","text":"","tags":["Array","Two Pointers","Sliding Window"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/","title":"LC733. Flood Fill","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 733: You are given an image represented by an\u00a0<code>m x n</code>\u00a0grid of integers\u00a0<code>image</code>, where\u00a0<code>image[i][j]</code>\u00a0represents the pixel value of the image. You are also given three integers\u00a0<code>sr</code>,\u00a0<code>sc</code>, and\u00a0<code>color</code>. Your task is to perform a\u00a0flood fillon the image starting from the pixel\u00a0<code>image[sr][sc]</code>.</p> <p>To perform a\u00a0flood fill:</p> <ol> <li>Begin with the starting pixel and change its color to\u00a0<code>color</code>.</li> <li>Perform the same process for each pixel that is\u00a0directly adjacent(pixels that share a side with the original pixel, either horizontally or vertically) and shares the\u00a0same color\u00a0as the starting pixel.</li> <li>Keep\u00a0repeating\u00a0this process by checking neighboring pixels of the\u00a0updated\u00a0pixels\u00a0and modifying their color if it matches the original color of the starting pixel.</li> <li>The process\u00a0stops\u00a0when there are\u00a0no more\u00a0adjacent pixels of the original color to update.</li> </ol> <p>Return the\u00a0modified\u00a0image after performing the flood fill.</p>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#clarification","title":"Clarification","text":"<ul> <li>Flood fill: fill the same color of directly adjacent pixels</li> <li>Adjacent: share a side with the original pixel</li> <li>Modify existing image directly?</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#assumption","title":"Assumption","text":"<ul> <li>Image is valid and sr and sc are within the image range</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#solution","title":"Solution","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#approach-bfs","title":"Approach - BFS","text":"<p>Using BFS (breadth-first search) to find all adjacent pixels with the same color and fill with target color. No need to use a visited variable since the color change indicates the pixel visited.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def floodFill(self, image: List[List[int]], sr: int, sc: int, color: int) -&gt; List[List[int]]:\n        start_pixel_color = image[sr][sc]\n\n        # No need to proceed if the start pixel already has the target color\n        if start_pixel_color == color:\n            return image\n\n        # Step direction: up, down, left, right\n        steps = [(1, 0), (-1, 0), (0, -1), (0, 1)]\n\n        n_row, n_col = len(image), len(image[0])\n        queue = deque([(sr, sc)])\n\n        while queue:\n            curr_row, curr_col = queue.popleft()\n\n            # Fill the current pixel with the new color\n            image[curr_row][curr_col] = color\n\n            # Check all 4 possible directions\n            for step_row, step_col in steps:\n                next_row, next_col = curr_row + step_row, curr_col + step_col\n                if 0 &lt;= next_row &lt; n_row and 0 &lt;= next_col &lt; n_col and image[next_row][next_col] == start_pixel_color:\n                    queue.append((next_row, next_col))\n\n        return image\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m \\times n)\\) where \\(m\\) is the number of rows and \\(n\\) is the number of columns in the <code>image</code> matrix   In the worst case, all the pixels in the <code>image</code> are visited (exactly once).   Explanation</li> <li>Space complexity: \\(O(m + n)\\) where \\(m\\) is the number of rows and \\(n\\) is the number of columns in the <code>image</code> matrix   In the worst case, the maximum number of pixels is proportional to the perimeter of the region rather than the area. For a full rectangular region, the perimeter is \\(O(m + n)\\).</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#approach2-dfs","title":"Approach2 - DFS","text":"<p>We can use DFS (depth-first search) to fill the adjacent pixels.</p> python <pre><code>class Solution:\n    def floodFill(self, image: List[List[int]], sr: int, sc: int, color: int) -&gt; List[List[int]]:\n        start_pixel_color = image[sr][sc]\n\n        # If the starting pixel already has the target color, no need to proceed\n        if start_pixel_color == color:\n            return image\n\n        self. dfs(image, sr, sc, color, start_pixel_color)\n        return image\n\n    def dfs(self, image: List[List[int]], r: int, c: int, color: int, start_color:int) -&gt; None:\n        n_row, n_col = len(image), len(image[0])\n        steps = [(1, 0), (-1, 0), (0, -1), (0, 1)]\n\n        if 0 &lt;= r &lt; n_row and 0 &lt;= c &lt; n_col and image[r][c] == start_color:\n            image[r][c] = color\n            for step_row, step_col in steps:\n                self.dfs(image, r + step_row, c + step_col, color, start_color)\n</code></pre>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(m \\times n)\\)   In the worst case, it may visit all pixels exact once when all pixels are connected with the same color.</li> <li>Space complexity: \\(O(\\max(m, n))\\)   The space complexity is determined by the depth of the call stack. The max depth is the max distance from a pixel to 4 edges.</li> </ul>","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - BFS \\(O(m \\times n)\\) \\(O(m + n)\\) Approach - DFS \\(O(m \\times n)\\) \\(O(\\max(m, n))\\)","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0733-flood-fill/#test","title":"Test","text":"","tags":["Breadth-First Search","Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/","title":"LC739. Daily Temperatures","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 739: Given an array of integers\u00a0<code>temperatures</code>\u00a0represents the daily temperatures, return\u00a0an array <code>answer</code> such that<code>answer[i]</code> is the number of days you have to wait after the <code>ith</code> day to get a warmer temperature. If there is no future day for which this is possible, keep\u00a0<code>answer[i] == 0</code>\u00a0instead.</p>","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#clarification","title":"Clarification","text":"<ul> <li>answer[i]: number of days to wait until a warmer temperature</li> <li>if don't exist, set 0</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#solution","title":"Solution","text":"","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#approach-stack","title":"Approach - Stack","text":"<p>Observation: the temperatures in descending order can share the same \"warmer\" day. So we can delay finding the answer for temperatures in descending order until finding a warmer day. Then we can move backward to calculate the answers. This process matches the behavior of a stack.</p> <p>We can use <code>monotonic stack</code> to store indices of temperatures so temperatures are in monotonic decreasing order. Note that for a given index, we can use <code>temperatures[i]</code> to find the temperature of the <code>ith</code> day. So only indexes are stored in the stack.</p> <p>On each day, there are two possibilities:</p> <ul> <li>If the current day's temperature is not warmer, just push the current day onto the stack since it is not warmer (equal or smaller). This will maintain the sorted property.</li> <li>If the current temperature is warmer than the temperature on top of the stack, it means that the current day is the first day with a warmer temperature than the day on top of the stack. Then update answers and pop up lower temperatures until no lower temperature or stack is empty. After that, push the current index to the stack. After this, the sorted property is still maintained.</li> </ul> Python <pre><code>from collections import deque\nclass Solution:\n    def dailyTemperatures(self, temperatures: List[int]) -&gt; List[int]:\n        n_days = len(temperatures)\n        answer = [0] * n_days\n        stack = deque()\n        for curr_day in range(n_days):\n            # (1)\n            while stack and temperatures[stack[-1]] &lt; temperatures[curr_day]:\n                prev_day = stack.pop()\n                answer[prev_day] = curr_day - prev_day\n            stack.append(curr_day)\n\n        return answer\n</code></pre> <ol> <li>Pop until the current temperature is not warmer than the temperature at the top.</li> </ol>","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)   Each element can only be added to the stack once. In the worst case, every element   will be pushed and popped once. This gives a time complexity of \\(O(2n) = O(n)\\).</li> <li>Space complexity: \\(O(n)\\)   If the input is non-increasing, then all \\(n\\) elements will add to the stack.</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#approach-2-array-optimized-space","title":"Approach 2 - Array, Optimized Space","text":"<p>For the monotonic stack, we iterated forward trough the array and move backwards when finding a warmer day. Can we find answers in an opposite way? iterate backwards through the array and move forwards to find the number of days until a warmer day.</p> <p>Yes, we can find the next warmer day by using the information from answers. For example, for <code>temperature[i]</code>,</p> <ul> <li>If <code>temperature[i + 1]</code> &lt;= <code>temperature[i]</code>, we can skip to temperature at <code>j = i + 1 + answers[i + 1]</code> since we just need to find the next warmer temperature after <code>i + 1</code> and answers store that information since moving backwards.</li> <li>if <code>temperature[j]</code> &lt;= <code>temperature[i]</code>, continue to just ahead based on the information in the answer.</li> </ul> <p>Note that, we need to track the hottest temperature seen so far. If <code>current temperature &gt; hottest temperature</code>, no need to search since no warmer temperatures available.</p> python <pre><code>class Solution:\n    def dailyTemperatures(self, temperatures: List[int]) -&gt; List[int]:\n        n = len(temperatures)\n        hottest = 0\n        answer = [0] * n\n\n        # Go though days in a reversed order\n        for idx_curr_day in range(n - 1, -1, -1):\n            curr_temp = temperatures[idx_curr_day]\n\n            # (1)\n            if curr_temp &gt;= hottest:\n                hottest = curr_temp\n                continue\n\n            # Find number of days to reach warmer temperature in forward order\n            days = 1\n            while temperatures[idx_curr_day + days] &lt;= curr_temp:\n                days += answer[idx_curr_day + days] (2)\n            answer[idx_curr_day] = days\n\n        return answer\n</code></pre> <ol> <li>If current temperature &gt; hottest temp seen so far, no need to check warmer temperature since it doesn't exist.</li> <li>Use information from answer to search for the next warmer day.</li> </ol>","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   The outer loop goes through \\(n\\) temperatures and the inner loop will skip some indices,   which leads to amortized time complexity \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\)   The answer store \\(n\\) values.</li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0739-daily-temperatures/#test","title":"Test","text":"<ul> <li>Strictly decreasing temperatures\u00a0\u2192\u00a0<code>[90, 80, 70, 60]</code>\u00a0\u2192 Output:\u00a0<code>[0, 0, 0, 0]</code></li> <li>Strictly increasing temperatures\u00a0\u2192\u00a0<code>[60, 70, 80, 90]</code>\u00a0\u2192 Output:\u00a0<code>[1, 1, 1, 0]</code></li> <li>Single element\u00a0\u2192\u00a0<code>[75]</code>\u00a0\u2192 Output:\u00a0<code>[0]</code></li> </ul>","tags":["Stack"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/","title":"740. Delete And Earn","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 740: You are given an integer array\u00a0<code>nums</code>. You want to maximize the number of points you get by performing the following operation any number of times:</p> <ul> <li>Pick any\u00a0<code>nums[i]</code>\u00a0and delete it to earn <code>nums[i]</code>\u00a0points. Afterwards, you must delete\u00a0every\u00a0element equal to\u00a0<code>nums[i] - 1</code> and\u00a0every\u00a0element equal to\u00a0<code>nums[i] + 1</code>.</li> </ul> <p>Return\u00a0the\u00a0maximum number of points\u00a0you can earn by applying the above operation some number of times.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#solution","title":"Solution","text":"<p>This problem can be solved using dynamic programming. It's really tricky to break down the problem.</p> <ul> <li>State: <code>max_points[num]</code>, the max points collected when at a given <code>num</code>.</li> <li>Recurrence relation: sorted the array and go through <code>num</code> in order,<ul> <li>Choose it indicates we can't take points from <code>num - 1</code> and have to use points from <code>num - 2</code>. So it is <code>max_points[num - 2] + num</code>.</li> <li>Skip it indicates it is the same as <code>max_points[num - 1]</code></li> <li>After the array sorted, no need to check <code>num + 1</code> since it will be evaluated later.</li> </ul> </li> <li>Base case:<ul> <li>max_points[0] = 0</li> <li>max_points[1] = nums[1] * occurence(nums[1])</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#approach-1-iteration","title":"Approach 1: Iteration","text":"<p>Once figuring out the recurrence relation, we can use iteration method to solve it.</p> Python <pre><code>from collections import Counter\n\nclass Solution:\n\n    def deleteAndEarn(self, nums: List[int]) -&gt; int:\n        points = Counter(nums)\n        prev1 = 0\n        prev2 = 0\n\n        # Go through number from 0 to max(nums) in order (some of them may not exist in numbers)\n        for value in range(max(points.keys()) + 1):\n            curr = max(prev2 + value * points[value], prev1)  # points[value] return 0 if value doesn't exist\n            prev1, prev2 = curr, prev1\n\n        return curr\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n + m)\\) where \\(n\\) is the length of <code>nums</code> and \\(m\\) is the max element in <code>nums</code>,<ul> <li><code>Counter</code> takes \\(O(n)\\) time since iterates over all \\(n\\) elements in <code>nums</code></li> <li>The <code>for</code> loop iterates over all possible values of <code>num</code> from 0 to <code>max(nums)</code> and each iteration takes \\(O(1)\\) time. So the whole for-loop takes \\(O(m)\\) time.</li> <li>So the total time complexity is \\(O(n + m)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>We use a dictionary <code>points</code> to store the points for each number in <code>nums</code>, which takes \\(O(n)\\) space.</li> <li>The 3 variables <code>prev1</code>, <code>prev2</code>, and <code>curr</code> used in for-loop take \\(O(1)\\) space.</li> <li>So the total space complexity is \\(O(n)\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#approach-2-recursion","title":"Approach 2: Recursion","text":"<p>The problem can be solved using recursion.</p> python <pre><code>from collections import Counter\n\n\nclass Solution:\n    def deleteAndEarn(self, nums: List[int]) -&gt; int:\n        self.cache = {}\n        points = Counter(nums)\n        max_number = max(points.keys())\n        return self.max_points(points, max_number)\n\n    def max_points(self, points: dict[int, int], num: int) -&gt; int:\n        # Base case\n        if num == 0:\n            return 0\n        if num == 1:\n            return points[1] * 1\n\n        if num in self.cache:\n            return self.cache[num]\n\n        # Apply recurrence relation\n        self.cache[num] = max(\n            self.max_points(points, num - 1),\n            self.max_points(points, num - 2) + points[num] * num,\n        )\n        return self.cache[num]\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n + m)\\)<ul> <li><code>Counter</code> takes \\(O(n)\\) time since iterates over all \\(n\\) elements in <code>nums</code></li> <li>The recursive function call starts from <code>max(nums)</code> and down to base case 0. Each function call takes \\(O(1)\\) time. So it takes \\(O(m)\\) time.</li> <li>So the total time complexity is \\(O(n + m)\\).</li> </ul> </li> <li>Space complexity: \\(O(n + m)\\) <ul> <li>We use a dictionary <code>points</code> to store the points for each number in <code>nums</code>, which takes \\(O(n)\\) space.</li> <li>The recursion call stack will grow up to  <code>max(nums)</code>, which takes \\(O(m)\\) space.</li> <li>so the total space complexity is \\(O(n + m)\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Iteration \\(O(n + m)\\) \\(O(n)\\) Approach 2 - Recursion \\(O(n + m)\\) \\(O(n + m)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0740-delete-and-earn/#test","title":"Test","text":"<ul> <li>Test inputs with just one element</li> <li>Test inputs with multiple elements and duplicates</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/","title":"LC743. Network Delay Time","text":"","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 743: You are given a network of\u00a0<code>n</code>\u00a0nodes, labeled from\u00a0<code>1</code>\u00a0to\u00a0<code>n</code>. You are also given <code>times</code>, a list of travel times as directed edges\u00a0<code>times[i] = (ui, vi, wi)</code>, where\u00a0<code>ui</code> is the source node,\u00a0<code>vi</code>\u00a0is the target node, and\u00a0<code>wi</code>\u00a0is the time it takes for a signal to travel from source to target.</p> <p>We will send a signal from a given node\u00a0<code>k</code>. Return\u00a0the\u00a0minimum\u00a0time it takes for all the <code>n</code> nodes to receive the signal. If it is impossible for all the\u00a0<code>n</code>\u00a0nodes to receive the signal, return\u00a0<code>-1</code>.</p>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#clarification","title":"Clarification","text":"<ul> <li>Find minimum time between a given node k and the rest of nodes</li> <li>May not reach all nodes</li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#solution","title":"Solution","text":"<p>The problem is to find the shortest time for each node to receive the signal and then find the maximum of shortest time of all nodes.</p>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#approach-shortest-path-faster-algorithm","title":"Approach - Shortest Path Faster Algorithm","text":"<p>Starting from node <code>k</code>, use a queue to track the signal along the directed edges with cumulative time. This is similar to breadth-first search but allowing nodes visited multiple times. We will update the shortest time between node <code>k</code> and any node <code>i</code> during the search process. We will add node to the queue if the next node has less time.</p> <p>Note that this algorithm can also works with negative weight but need to detect negative edge cycle.</p> Python <pre><code>import math\nfrom collections import defaultdict, deque\n\n\nclass Solution:\n    def networkDelayTime(self, times: List[List[int]], n: int, k: int) -&gt; int:\n        # Build adj_list with directed edge and weight\n        adj_list = defaultdict(list)\n        for source, target, time in times:\n            adj_list[source].append((target, time))\n\n        # Find shortest time from k to each node\n        shortest_time_map = self.find_shortest_time(k, adj_list)\n\n        # Return time to reach all nodes\n        if len(shortest_time_map) == n:\n            return max(shortest_time_map.values())\n        else:\n            return -1\n\n    def find_shortest_time(\n        self, source: int, adj_list: dict[int, list]\n    ) -&gt; dict[int, int]:\n        shortest_time = defaultdict(lambda: math.inf)  # (1)\n        shortest_time[k] = 0  # (2)\n        queue = deque([k])  # (node)\n        while queue:\n            curr_node = queue.popleft()\n            curr_time = shortest_time[curr_node]\n            for next_node, time in adj_list[curr_node]:\n                next_time = curr_time + time\n                if next_time &lt; shortest_time_map[next_node]:\n                    shortest_time_map[next_node] = next_time\n                    queue.append(next_node)\n</code></pre> <ol> <li>Store shortest time from k to each node.</li> <li>For starting node k, the shortest time from k to k is 0.</li> </ol>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(V E)\\) where \\(V\\) is the number of nodes and \\(E\\) is the number of edges  <ul> <li>Build adjacent list takes \\(O(E)\\) time since going through all times (i.e. edges);</li> <li><code>find_shortest_time</code> function goes through multiple paths between node <code>k</code> and the rest of nodes. It may reach each node multiple times. In the worst case (a complete graph), each node will be visited \\(E\\) times (number of edges). So the time complexity is \\(O(V E)\\);</li> <li>The <code>max</code> function takes \\(O(V)\\) time; The total time complexity is \\(O(E) + O (V E) + O(V) = O(V E)\\).</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li>Build adjacent list takes \\(O(V + E)\\) space to store nodes and edges;</li> <li>The queue may store all nodes, taking \\(O(V)\\) space;</li> <li>Shortest time map takes \\(O(V)\\) space to store shortest time for each node; So the total space complexity is \\(O(V + E) + O(V) + O(V) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#approach-2-dijkstras-algorithm","title":"Approach 2 - Dijkstra's Algorithm","text":"<p>This algorithm similar to approach 1 but replacing queue with a priority queue.</p> python <pre><code>import math\nimport heapq\nfrom collections import defaultdict\n\n\nclass Solution:\n    def networkDelayTime(self, times: List[List[int]], n: int, k: int) -&gt; int:\n        # Build adj_list with directed edge and weight\n        adj_list = defaultdict(list)\n        for source, target, time in times:\n            adj_list[source].append((target, time))\n\n        # Find shortest time from k to each node\n        shortest_time_map = self.find_shortest_time(k, adj_list)\n\n        # Return max value of shortest_time of all nodes\n        if len(shortest_time_map) == n:\n            return max(shortest_time_map.values())\n        else:\n            return -1\n\n    def find_shortest_time(\n        self, source: int, adj_list: dict[int, list]\n    ) -&gt; dict[int, int]:\n        shortest_time_map = defaultdict(lambda: math.inf)  # (1)\n        pq = [(0, source)]\n\n        while pq:\n            curr_time, curr_node = heapq.heappop(pq)\n            if curr_node not in shortest_time_map:  # (2)\n                shortest_time_map[curr_node] = curr_time\n\n                for next_node, time in adj_list[curr_node]:\n                    heapq.heappush(pq, (curr_time + time, next_node))\n</code></pre> <ol> <li>Store shortest time from k to each node.</li> <li>Just check existing and no need to compare whether time is the shortest since the priority queue will return the smallest value. This assumes non-negative weight.</li> </ol>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(E + V \\log V)\\) <ul> <li>Build adjacent list takes \\(O(E)\\) time since going through all times (i.e. edges);</li> <li><code>find_shortest_time</code> function in the worst case goes through all nodes, \\(V\\). For each node, push and pop from priority queue takes \\(\\log V\\). So the time complexity is \\(V \\log V\\);</li> <li>The <code>max</code> function takes \\(O(V)\\) time; The total time complexity is \\(O(E) + O (V \\log V) + O(V) = O(E + V \\log V)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Build adjacent list takes \\(O(V + E)\\) space to store nodes and edges;</li> <li>The priority queue may store all nodes, taking \\(O(V)\\) space;</li> <li>Shortest time map takes \\(O(V)\\) space to store shortest time for each node; So the total space complexity is \\(O(V + E) + O(V) + O(V) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - SPFA \\(O(V E)\\) \\(O(V + E)\\) Approach - Dijkstra \\(O(E + V \\log V)\\) \\(O(V + E)\\)","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0743-network-delay-time/#test","title":"Test","text":"<ul> <li>Single node (<code>n = 1</code>): The result is always \\(0\\).</li> <li>Disconnected nodes: Return \\(-1\\) if not all nodes are reachable.</li> <li>Multiple paths between nodes: Ensure the algorithm finds the shortest path.</li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0744-find-smallest-letter-greater-than-target/","title":"LC744. Find Smallest Letter Greater Than Target","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0744-find-smallest-letter-greater-than-target/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 744: You are given an array of characters\u00a0<code>letters</code>\u00a0that is sorted in\u00a0non-decreasing order, and a character\u00a0<code>target</code>. There are\u00a0at least two different\u00a0characters in\u00a0<code>letters</code>.</p> <p>Return\u00a0the smallest character in <code>letters</code> that is lexicographically greater than <code>target</code>. If such a character does not exist, return the first character in\u00a0<code>letters</code>.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0744-find-smallest-letter-greater-than-target/#clarification","title":"Clarification","text":"<ul> <li>array of letters</li> <li>non-decreasing order</li> <li>capital or small letters and how to determin orders between capital and small ones</li> <li>definition of lexicographic order? dictionary order?</li> <li>return letter or index</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0744-find-smallest-letter-greater-than-target/#assumption","title":"Assumption","text":"<ul> <li>letters and target are the same case (either uppercase or lowercase)</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0744-find-smallest-letter-greater-than-target/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0744-find-smallest-letter-greater-than-target/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since letters are sorted, we can use binary search to find the smallest letter that is greater than target.</p> PythonC++ <pre><code>class Solution:\n    def nextGreatestLetter(self, letters: List[str], target: str) -&gt; str:\n        left, right = 0, len(letters) - 1\n\n        while left &lt; right:\n            mid = (left + right) // 2\n            if target &gt;= letters[mid]:\n                left = mid + 1\n            else:\n                right = mid\n\n        if letters[left] &lt;= target:\n            return letters[0]\n        else:\n            return letters[left]\n</code></pre> <pre><code>class Solution {\npublic:\n    char nextGreatestLetter(vector&lt;char&gt;&amp; letters, char target) {\n        if (letters.empty()) return '\\0';\n\n        int left = 0;\n        int right = letters.size() - 1;\n        int mid;\n\n        while (left &lt; right)\n        {\n            mid = left + (right - left)/2;\n\n            if (target &lt; letters[mid]) right = mid;\n            else left = mid + 1;\n        }\n\n        // left == right after while loop\n        return (letters[left] &lt;= target) ? letters[0] : letters[left];\n    }\n};\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0744-find-smallest-letter-greater-than-target/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\)     Since using the binary search, the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\)     Use 3 variables for binary search.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/","title":"746. Min Cost Climbing Stairs","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 746: You are given an integer array\u00a0<code>cost</code>\u00a0where\u00a0<code>cost[i]</code>\u00a0is the cost of\u00a0<code>ith</code>\u00a0step on a staircase. Once you pay the cost, you can either climb one or two steps.</p> <p>You can either start from the step with index\u00a0<code>0</code>, or the step with index\u00a0<code>1</code>.</p> <p>Return\u00a0the minimum cost to reach the top of the floor.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#clarification","title":"Clarification","text":"<ul> <li>The top of the floor is one more step after the last step in the array.</li> <li>Each step cost differently.</li> <li>Either climb 1 or 2 steps at a time.</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#solution","title":"Solution","text":"<p>We can solve the problem using dynamic programming. The idea is to keep track of the minimum cost to reach each step and use the relationship between steps to determine the minimum cost to reach the top.</p> <ul> <li>Define state, \\(\\text{min_cost}(i)\\) the minimum cost of reaching <code>ith</code> step</li> <li> <p>Find recurrence relation. There are two ways to reach <code>ith</code> step</p> <ul> <li>climb 1 step from <code>(i-1)th</code> step, \\(\\text{min_cost}(i - 1) + \\text{cost}(i - 1)\\)</li> <li>climb 2 steps from <code>(i-2)th</code> step, \\(\\text{min_cost}(i - 2) + \\text{cost}(i - 2)\\)</li> <li>Then the recurrent relation equation is</li> </ul> \\[\\text{min_cost}(i) = \\min(\\text{min_cost}(i - 1) + \\text{cost}(i - 1), \\text{min_cost}(i - 2) + \\text{cost}(i - 2)) \\] </li> <li> <p>Base case: \\(\\text{min_cost}(0) = 0\\), \\(\\text{min_cost}(1) = 0\\) since either start from the step 0 or step 1.</p> </li> </ul> <p>Note that the top of the floor is one more step after the last step in the array.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#approach-1-iteration","title":"Approach 1: Iteration","text":"<p>We can use iterative method to implement dynamic programming solution.</p> Python <pre><code>class Solution:\n    def minCostClimbingStairs(self, cost: List[int]) -&gt; int:\n        min_prev1 = 0\n        min_prev2 = 0\n\n        for i in range(2, n + 1):\n            min_curr = min(min_prev1 + cost[i - 1], min_prev2 + cost[i - 2])\n            min_prev1, min_prev2 = min_curr, min_prev1\n\n        return min_prev1\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   We use for-loop to iterate over the array of size \\(n\\) and each iteration takes   constant time. So the total time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(1)\\)   Use two variables to store the minimum cost for the previous two steps. So the   total space complexity is \\(O(1)\\).</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#approach-2-recursion-memoization","title":"Approach 2: Recursion + Memoization","text":"<p>We can also solve this problem using recursion with memoization based on the recurrence relation. During recursion, there are many repeat computations. So we store the results in a memo dictionary.</p> python <pre><code>class Solution:\n    def minCostClimbingStairs(self, cost: List[int]) -&gt; int:\n        self.memo = {}\n        return self._min_cost(cost, len(cost))\n\n    def _min_cost(self, cost: List[int], idx: int) -&gt; int:\n        if idx &lt; 2:\n            return 0\n\n        if idx in self.memo:\n            return self.memo[idx]\n\n        min_prev1 = self._min_cost(cost, idx - 1)\n        min_prev2 = self._min_cost(cost, idx - 2)\n        min_curr = min(min_prev1 + cost[idx - 1], min_prev2 + cost[idx - 2])\n        self.memo[idx] = min_curr\n\n        return min_curr\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   Each step is visited once and each visit takes constant time. So the total time   complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>The memo dictionary takes \\(O(n)\\) space to store the results.</li> <li>The recursion stack takes \\(O(n)\\) space since the maximum depth of the recursion is \\(n\\).</li> <li>So the total space complexity is \\(O(n)\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Iteration \\(O(n)\\) \\(O(1)\\) Approach - Recursion + Memoization \\(O(n)\\) \\(O(n)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0746-min-cost-climbing-stairs/#test","title":"Test","text":"<ul> <li>Test array with 1 element</li> <li>Test array with 2 elements</li> <li>Test array with multiple elements and different costs</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc0700-0799/lc0752-open-the-lock/","title":"LC752. Open the Lock","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0752-open-the-lock/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 752: You have a lock in front of you with 4 circular wheels. Each wheel has 10 slots:\u00a0<code>'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'</code>. The wheels can rotate freely and wrap around: for example we can turn\u00a0<code>'9'</code>\u00a0to be\u00a0<code>'0'</code>, or\u00a0<code>'0'</code>\u00a0to be\u00a0<code>'9'</code>. Each move consists of turning one wheel one slot.</p> <p>The lock initially starts at\u00a0<code>'0000'</code>, a string representing the state of the 4 wheels.</p> <p>You are given a list of\u00a0<code>deadends</code>\u00a0dead ends, meaning if the lock displays any of these codes, the wheels of the lock will stop turning and you will be unable to open it.</p> <p>Given a\u00a0<code>target</code>\u00a0representing the value of the wheels that will unlock the lock, return the minimum total number of turns required to open the lock, or -1 if it is impossible.</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0752-open-the-lock/#clarification","title":"Clarification","text":"<ul> <li>Each move just turning one wheel one slot</li> <li>Could be no turns due to deadends</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0752-open-the-lock/#assumption","title":"Assumption","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0752-open-the-lock/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0752-open-the-lock/#approach-bfs","title":"Approach - BFS","text":"<p>We can consider each combination is a node of a graph, and each wheel turn is an edge connecting two nodes. The given problem can be considered as how to find minimum steps from root node to target node in a graph.</p> <p>We can use breadth-first search (BFS) method to traverse nodes level by level. Due to is level-order traversing, the first time is reaches the target, it is also the shorted path to the target.</p> <p></p> Python <pre><code>class Solution:\nSLOTS = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\nN_WHEELS = 4\nROTATE_DIRECTIONS = [-1, 1]\n\ndef neighbors(self, code: str) -&gt; str:\n    for i_wheel in range(self.N_WHEELS):\n        letter = code[i_wheel]\n        slot_index = self.SLOTS.index(letter)\n        for j_rotate in self.ROTATE_DIRECTIONS:\n            next_slot_index = (slot_index + j_rotate + len(self.SLOTS)) % len(self.SLOTS)\n            yield code[:i_wheel] + self.SLOTS[next_slot_index] + code[i_wheel+1:]\n\ndef openLock(self, deadends: List[str], target: str) -&gt; int:\n    if '0000' in deadends:\n        return - 1\n\n    n_turns = 0\n    queue = deque()\n    visited = set()\n    queue.append('0000')\n    visited.add('0000')\n\n    while queue:\n        current_level_node_count = len(queue)\n        for _ in range(current_level_node_count):\n            current_code = queue.popleft()\n            if current_code == target:\n                return n_turns\n            for neighbor_code in self.neighbors(current_code):\n                if neighbor_code not in deadends and neighbor_code not in visited:\n                    queue.append(neighbor_code)\n                    visited.add(neighbor_code)\n        n_turns += 1\n\n    return -1\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0752-open-the-lock/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^w w)\\)     In the worst case, we might iterate all \\(n^w\\) unique combinations, where \\(n = 10\\) is the number of slots for each wheel and \\(w = 4\\) is the number of wheels of the lock. For each combination, perform \\(2w\\) turns, rotating left or right (twice) for each wheel. So time complexity is \\(O(n^w 2 w)\\) = \\(O(n^w w)\\) </li> <li>Space complexity: \\(O(n^w)\\)     In the worse case, push all \\(n^w\\) unique combinations of length \\(w\\) string in the queue and the hash set. So the space complexity is \\(O(2n^w w)\\) = \\(O(n^w w)\\)</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0752-open-the-lock/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/","title":"779. K-th Symbol in Grammar","text":"","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 779: We build a table of\u00a0<code>n</code>\u00a0rows (1-indexed). We start by writing\u00a0<code>0</code>\u00a0in the\u00a0<code>1st</code>\u00a0row. Now in every subsequent row, we look at the previous row and replace each occurrence of <code>0</code>\u00a0with\u00a0<code>01</code>, and each occurrence of\u00a0<code>1</code>\u00a0with\u00a0<code>10</code>.</p> <ul> <li>For example, for\u00a0<code>n = 3</code>, the\u00a0<code>1st</code>\u00a0row is\u00a0<code>0</code>, the\u00a0<code>2nd</code>\u00a0row is\u00a0<code>01</code>, and the\u00a0<code>3rd</code> row is\u00a0<code>0110</code>.</li> </ul> <p>Given two integer\u00a0<code>n</code>\u00a0and\u00a0<code>k</code>, return the\u00a0<code>kth</code>\u00a0(1-indexed) symbol in the\u00a0<code>nth</code>\u00a0row of a table of\u00a0<code>n</code>\u00a0rows.</p>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#solution","title":"Solution","text":"","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#approach-1-recursion-based-on-binary-tree-pattern","title":"Approach 1: Recursion Based on Binary Tree Pattern","text":"<p>We can view row creation as a binary tree creation. It will generate a perfect binary tree with all levels completely filled.</p> <pre><code>Row1                          0\n                          /       \\\nRow2                     0          1\n                       /   \\      /    \\\nRow3                  0     1     1      0\n                     / \\    / \\   / \\   / \\\nRow4                0  1   1   0  1  0  0  1\n\nIndex(for Row 4)-&gt;  1  2   3   4  5  6  7  8\n</code></pre> <p>Based on explanations from @repititionismastery:</p> <ul> <li>The parent of <code>kth</code> index in <code>nth</code> row is:<ul> <li><code>k/2</code> index in the <code>(n-1)th</code> row when <code>k</code> is even.</li> <li><code>(k + 1)/2</code> index in the <code>(n-1)th</code> row when <code>k</code> is odd.</li> </ul> </li> <li>The value of <code>kth</code> index in <code>nth</code> row is:<ul> <li>flipped (reversed) value of the parent.</li> <li>same value as the parent.</li> </ul> </li> </ul> Python <pre><code>class Solution:\n    def kthGrammar(self, n: int, k: int) -&gt; int:\n        # Base case\n        if n == 1:\n            return 0\n\n        if k % 2 == 0:\n            # If k is in the 2nd half, it is the reversed value of the first half in previous row\n            return 1 - self.kthGrammar(n - 1, k // 2)\n        else:\n            return self.kthGrammar(n - 1, (k + 1) // 2)\n</code></pre>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Each recursion call will reduce \\(n\\) by 1 until reaching 1 and takes \\(O(1)\\) for   calculation. so the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\)   The recursive function calls \\(n\\) times and the function call stack takes \\(O(n)\\) space.</li> </ul>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#approach-2-recursion-based-on-observation","title":"Approach 2: Recursion Based on Observation","text":"<p>This solution is based on the idea from @Mohamed Mamdouh.</p> <pre><code>Row1: 0\nRow2: 01\nRow3: 0110\nRow4: 01101001\nRow5: 0110100110010110\n</code></pre> <pre><code>Row1: 0\nRow2: 0 | 1\nRow3: 01 | 10\nRow4: 0110 | 1001\nRow5: 01101001 | 10010110\n</code></pre> <p>Observe from rows numbers, we can find:</p> <ul> <li>Row-to-row relationship: the first half of the current row is the same as previous row.</li> <li>Within-row relationship: the 2nd half is the reverse of the 1st half (i.e., previous row from row-to-row relationship).</li> </ul> <p>Note: To flip \\(x\\) where \\(x\\) is 0 or 1, we can perform \\(x' = 1 - x\\).</p> python <pre><code>class Solution:\n    def kthGrammar(self, n: int, k: int) -&gt; int:\n        # Base case\n        if n == 1:\n            return 0\n\n        mid = (1 &lt;&lt; (n - 1)) // 2\n\n        if k &gt; mid:\n            # If k is in the 2nd half, it is the reversed value of the first half in previous row\n            return 1 - self.kthGrammar(n - 1, k - mid)\n        else:\n            # Same as the previous row\n            return self.kthGrammar(n - 1, k)\n</code></pre>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n)\\)   Each recursion call will reduce \\(n\\) by 1 until reaching 1 and takes \\(O(1)\\) for   calculation. so the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\)   The recursive function calls \\(n\\) times and the function call stack takes \\(O(n)\\) space.</li> </ul>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#approach-3-iteration-based-on-observation","title":"Approach 3: Iteration Based on Observation","text":"<p>Based on the previous observation, we can also use the iteration method to solve the problem.</p> python <pre><code>class Solution:\n    def kthGrammar(self, n: int, k: int) -&gt; int:\n        are_values_same = True  # (1)\n\n        n_total = 1 &lt;&lt; (n - 1)  # (2)\n\n        while n_total &gt; 1:\n            n_total //= 2\n\n            # If k is in the 2nd half, change it to the fist half an toggle the flag\n            if k &gt; n_total:\n                k -= n_total\n                are_values_same = not are_values_same\n\n        return 0 if are_values_same else 1\n</code></pre> <ol> <li>Initialize a flag to track if kth value is the same as the first element. By default, assume no flip.</li> <li>Number of elements in the nth row, which is \\(2^{n - 1}\\).</li> </ol>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(1)\\)   The while loop starts with \\(2^n\\) elements and each iteration reduce the number of   elements by half. So the time complexity is \\(O(\\log (2^n)) = O(n)\\).</li> <li>Space complexity: \\(O(1)\\)   Use limited variables.</li> </ul>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#approach-4-bit-count","title":"Approach 4: Bit Count","text":"<p>From previous observation, we can see that we start with \\(0\\) and flip it \\(x\\) number of times for <code>kth</code> element in the <code>nth</code> row. Then we need to determine the number of flips required.</p> <p>In previous approach, a flip happens at each subtraction. <code>k</code> is reduced until reaching 1,</p> \\[k - 2^m - 2^k - 2^j - \\cdots = 1\\] <p>Therefore, the number of flips is equal to the number of subtractions performed.</p> <p>Re-array above equation, we get \\(k - 1 = 2^m + 2^k + 2^j\\) which is the binary representation of \\(k - 1\\). Determining the number of flips becomes count number of 1-bits in the binary representation of <code>k - 1</code>.</p> python <pre><code>class Solution:\n    def kthGrammar(self, n: int, k: int) -&gt; int:\n        count = bin(k - 1).count('1')\n        return 0 if count % 2 == 0 else 1\n</code></pre>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#complexity-analysis-of-approach-4","title":"Complexity Analysis of Approach 4","text":"<ul> <li>Time complexity: \\(O(\\log k)\\) <ul> <li>Convert the number to binary takes \\(O(\\log k)\\).</li> <li>Count the 1-bits takes \\(O(\\log k)\\) for \\(\\log k\\) bits.</li> <li>The overall time complexity is \\(O(\\log k)\\).</li> </ul> </li> <li>Space complexity: \\(O(1)\\)   Only use limited variable like <code>count</code>.</li> </ul>","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Recursion on Binary Tree Pattern \\(O(n)\\) \\(O(n)\\) Approach - Recursion on Observation \\(O(n)\\) \\(O(n)\\) Approach - Iteration on Observation \\(O(n)\\) \\(O(1)\\) Approach - Bit Count \\(O(\\log k)\\) \\(O(1)\\)","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0779-k-th-symbol-in-grammar/#test","title":"Test","text":"","tags":["Recursion","Binary Tree","Bit Manipulation"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/","title":"LC787. Cheapest Flights Within K Stops","text":"","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 787: There are\u00a0<code>n</code>\u00a0cities connected by some number of flights. You are given an array <code>flights</code>\u00a0where\u00a0<code>flights[i] = [fromi, toi, pricei]</code>\u00a0indicates that there is a flight from city\u00a0<code>fromi</code>\u00a0to city\u00a0<code>toi</code>\u00a0with cost\u00a0<code>pricei</code>.</p> <p>You are also given three integers\u00a0<code>src</code>,\u00a0<code>dst</code>, and\u00a0<code>k</code>, return\u00a0the cheapest price from <code>src</code> to <code>dst</code> with at most <code>k</code> stops.\u00a0If there is no such route, return\u00a0<code>-1</code>.</p>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#clarification","title":"Clarification","text":"<ul> <li>Does <code>k</code> stops mean the number of cities between <code>src</code> and <code>dst</code>?</li> <li>Directed edge</li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#solution","title":"Solution","text":"<p>The problem can be considered as directed graph with positive weights where vertices are the cities and flights (with prices) as directed weighted edges. The problem becomes to find the shortest paths from a source city to a destination with positive weights.</p>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#approach-breadth-first-search","title":"Approach - Breadth-First Search","text":"<p>We can use breadth-first search (BFS) to explore cities level by level, where each level corresponds to the number of stops.</p> <ul> <li>Use a queue to maintain the current cost and number of stops for each path.</li> <li>Use a dictionary to track the minimum cost to reach a city within a certain number of stops to avoid unnecessary processing.</li> </ul> Tips on Calculating New Cost <ul> <li>When calculating <code>new_cost = cost + price</code>, the <code>cost</code> variable represents the cost of reaching the <code>current_city</code> during the current BFS step. This ensures that the new cost is based on the cost from the specific path that leads to <code>current_city</code>.</li> <li>When calculating <code>new_cost = min_cost[current_city] + price</code>, <code>min_cost[current_city]</code> is the globally minimum cost recorded for reaching <code>current_city</code>. This value might have been computed in a previous BFS step from a completely different path. Use it here means the cost calculation is no longer tied to the current BFS traversal path, but rather to the overall best observed so far.</li> </ul> Python <pre><code>from collections import defaultdict, deque\n\nclass Solution:\n    def findCheapestPrice(\n        self, n: int, flights: List[List[int]], src: int, dst: int, k: int\n    ) -&gt; int:\n\n        # (1)\n        adj_list = defaultdict(list)\n        for from_city, to_city, price in flights:\n            adj_list[from_city].append((to_city, price))\n\n        # (2)\n        min_cost = defaultdict(lambda: float(\"inf\"))\n        min_cost[src] = 0  # (3)\n\n        queue = deque([(src, 0, 0)])  # (4)\n\n        while queue:  # BFS traversal\n            curr_city, stops, cost = queue.popleft()\n\n            if stops &lt;= k:\n                for next_city, price in adj_list[curr_city]:\n                    new_cost = cost + price\n                    # Only consider the path if it's cheaper\n                    if new_cost &lt; min_cost[next_city]:\n                        min_cost[next_city] = new_cost\n                        queue.append((next_city, stops + 1, new_cost))\n\n        if dst in min_cost:\n            return min_cost[dst]\n        else:\n            return -1\n</code></pre> <ol> <li>Create adjacent list.</li> <li>Create the minimum cost dictionary to track the minimum cost to reach each city.</li> <li>Cost to reach source is 0.</li> <li>Store (city, stops, cost)</li> </ol>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(k V + k E)\\) <ul> <li>Build adjacent list takes \\(O(E)\\) time since going through all edges;</li> <li>For BFS traversal, there are two nested levels for iteration. The outer level is to iterate cities in the queue. All cities could be added or removed from the queue at most \\(k + 1\\) times (due to \\(k\\) stops), so at most \\(k V\\) cities in the queue. The inner level iterate neighbor cities of the current city (i.e., edges of the current city). In the worst case, it will explore neighbors of all cities \\(k + 1\\) times with total of \\(k E\\). Moreover, queue operations(enqueue and deque) take \\(O(1)\\). So the time complexity of BFS is \\(O(k V + k E)\\). The total time complexity is \\(O(E) + O(k V + k E) = O(k V + k E)\\).</li> </ul> </li> <li>Space complexity: \\(O(k V + E)\\) <ul> <li>The adjacent list takes \\(O(V + E)\\) space;</li> <li>The queue stores \\(k V\\) nodes in the worst case;</li> <li>The <code>min_cost</code> dictionary takes \\(O(V)\\) space; The total time complexity is \\(O(V + E) + O(k V) + O(V)= O(k V + E)\\).</li> </ul> </li> </ul> Detailed Time Complexity Analysis for BFS <ul> <li>Queue Operations (\\(O(k V)\\)):<ul> <li>Each city can be enqueued and dequeued at most\u00a0\\(k + 1\\)\u00a0times, where \\(k\\) is the maximum number of stops allowed.</li> <li>Since there are\u00a0\\(V\\)\u00a0cities, the total number of enqueue and dequeue operations is: \\((k + 1) V\\), which\u00a0is \\(O(k V)\\) time.</li> </ul> </li> <li>Edge Traversal (\\(O(k E)\\)):<ul> <li>For every dequeue operation of a city, its outgoing edges are processed (neighbor exploration).</li> <li>Since each city is dequeued at most\u00a0\\(k + 1\\)\u00a0times, and there are\u00a0\\(E\\)\u00a0total edges in the graph, the total number of edge considerations is: \\((k + 1) E\\), which is \\(O(k E)\\) time.</li> </ul> </li> <li>Total Time Complexity:: \\(O(k V + k E)\\).<ul> <li>This reflects the time spent on both queue operations and edge traversal.</li> </ul> </li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#approach-2-dijkstra","title":"Approach 2 - Dijkstra","text":"<p>We can use Dijkstra's algorithm to solve the shortest path problem.</p> <p>A priority queue is used to select the node that currently has the lowest price. Additionally, using an dictionary to track the minimum number of stops needed to reach each city.</p> python <pre><code>import heapq\n\nclass Solution:\n    def findCheapestPrice(self, n: int, flights: List[List[int]], src: int,\n        dst: int, k: int) -&gt; int:\n\n        # Create adjacent list\n        adj_list = defaultdict(list)\n        for from_i, to_i, price_i in flights:\n            adj_list[from_i].append((to_i, price_i))\n\n        city_stops_map = defaultdict(lambda: float(\"inf\"))\n        heap = [(0, src, 0)]  # (1)\n        while heap:\n            curr_price, curr_city, n_stops = heapq.heappop(heap)\n\n            if curr_city == dst:\n                return curr_price\n\n            if n_stops &lt;= k and n_stops &lt; city_stops_map[curr_city]:  # (2)\n                city_stops_map[curr_city] = n_stops\n                for next_city, price in adj_list[curr_city]:\n                    heapq.heappush(heap, (curr_price + price, next_city, n_stops + 1))\n\n        return -1  # (3)\n</code></pre> <ol> <li>Add <code>(cum_price, city, number of stops)</code>.</li> <li>Have to add <code>n_stops &lt; city_stops_map[curr_city]</code> to prevent exceeding time limit. The idea is that if you've already reached a city with fewer stops, revisiting it with more stops means:<ul> <li>The route is longer in terms of flights.</li> <li>The total cost cannot be cheaper because you would be adding more flight prices (positive). Note that the worst-case time complexity remains the same.</li> </ul> </li> <li>Can't reach the destination.</li> </ol>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(k E \\log (k V))\\) where \\(V\\) is the number of flights, \\(E\\) is the number of cities, and \\(k\\) is the number of stops.  <ul> <li>Build adjacent list takes \\(O(E)\\) time;</li> <li>When processing the priority queue,<ul> <li>Each node (city) can be added to the priority queue at most\u00a0\\(k + 1\\) times with at most \\((k + 1) V\\) queue operations.</li> <li>Each queue operation (push or pop from a heap) takes \\(O(\\log P)\\), where \\(P\\) is the size of the heap. The size of the heap is bounded by the number of nodes and stops, i.e., \\(P \\leq k V\\).</li> <li>So the time complexity for priority queue operation is \\(O(k V \\log(k V))\\);</li> <li>Edge relaxation takes \\(O(k E)\\) time, since there are\u00a0\\(E\\)\u00a0edges in total, each edge is relaxed at most\u00a0\\(k + 1\\) times.</li> </ul> </li> <li>The total time complexity is \\(O(E) + O(k V \\log (k V)) + O(k E)\\) \\(=\\) \\(O(k V \\log (k V)) + O(k E)\\).</li> </ul> </li> <li>Space complexity: \\(O(k V + E)\\) <ul> <li>The adjacent list stores the graph as a dictionary where each node points to a list of neighbors, which takes \\(O(V + E)\\) space;</li> <li>The priority queue is used to track the paths being explored. At any given time, the size of the priority queue depends on the number of paths being considered. In the worst case, each node can be added to the queue with \\(k + 1\\) different stop counts. So the maximum size of the queue is \\(O(k V)\\); So the total space complexity is \\(O(V + E) + O(k V) = O(k V + E)\\).</li> </ul> </li> </ul> Detailed Time Complexity Analysis of Priority Queue Operation Part <ul> <li>Priority queue operations:<ul> <li>The priority queue is used to always expand the node with the current smallest cost.</li> <li>Each node (city) can be added to the priority queue at most\u00a0\\(k + 1\\) times, where\u00a0\\(k\\)\u00a0is the maximum number of stops allowed.</li> <li>There are at most\u00a0\\(O(k V)\\)\u00a0enqueue operations because each node can be visited \\(k + 1\\) times, once for each valid stop count.</li> <li>Heap insertion and extraction take \\(O(\\log P)\\) where \\(P\\) is the size of the priority queue. In the worst case, the size of the priority queue can grow to \\(O(k V)\\). So each heap operation takes \\(O(\\log (k V))\\).</li> <li>Total time on priority queue operations: \\(O(k V \\log (k V))\\).</li> </ul> </li> <li>Edge relaxation:<ul> <li>For each node dequeued from the priority queue, all its outgoing edges are relaxed (i.e., we check if a cheaper path exists via that edge).</li> <li>Since there are\u00a0\\(E\\)\u00a0edges in total, each edge is relaxed at most\u00a0\\(k + 1\\) times (once for each valid stop count of its source node).</li> <li>Total edge relaxations: \\(O(k E)\\)</li> </ul> </li> <li>Total time complexity: \\(O(k V \\log (k V) + k E)\\), combining both priority queue operations and edge relaxations.</li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#approach-3-dynamic-programming","title":"Approach 3 - Dynamic Programming","text":"<p>The problem can also be solved using dynamic programming (DP) approach:</p> <ul> <li>State: Define <code>dp[i][j]</code> as the minimum cost to reach city <code>i</code> using at most <code>j</code> stops.</li> <li>Transition: For each flight <code>(u, v, w)</code>, update <code>dp[v][i] = min(dp[v][i], dp[u][i - 1] + w)</code>.</li> <li>Base case: <code>dp[src][0] = 0</code> and <code>dp[j][0] =</code>\\(\\infty\\) for \\(j \\neq \\text{src}\\).</li> </ul> <p>Note that to compute <code>dp[v][i]</code>, only <code>dp[u][i-1]</code> needed. So we don't need the entire DP table and just two rolling arrays: the current and the previous ones. The transition becomes <code>curr[v] = min(curr[v], prev[v] + w)</code>.</p> python <pre><code>class Solution:\n    def findCheapestPrice(self, n: int, flights: List[List[int]], src: int, dst: int,\n            k: int) -&gt; int:\n        # (1)\n        prev = [float(\"inf\")] * n\n        curr = [float(\"inf\")] * n\n\n        # Base case\n        prev[src] = 0  # (2)\n\n        # Iterate over at most k+1 stops\n        for _ in range(k + 1):\n            curr = prev[:]  # (3)\n            for u, v, w in flights:\n                if prev[u] != float(\"inf\"):  # (4)\n                    curr[v] = min(curr[v], prev[u] + w)\n            prev = curr\n\n        return curr[dst] if curr[dst] != float(\"inf\") else - 1\n</code></pre> <ol> <li>Initialize two arrays for DP:<ul> <li><code>prev</code> is minimum cost to reach city with at most <code>i - 1</code> stops;</li> <li><code>curr</code> is minimum cost to reach city with at most <code>i</code> stops.</li> </ul> </li> <li>Cost to reach <code>src</code> with 0 stops is 0.</li> <li>Start with a copy of previous results, since it will be used for <code>min</code> function later.</li> <li>Only update if city u is reachable.</li> </ol>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(k E)\\)     There are two nested for-loops:<ul> <li>the outer loop iterates \\(k + 1\\) stops;</li> <li>the inner loop iterates \\(E\\) edges. So the total time complexity is \\(O(k E)\\).</li> </ul> </li> <li>Space complexity: \\(O(V)\\)     The space used is for two arrays of size \\(V\\) (for <code>prev</code> and <code>curr</code>).</li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - BFS \\(O(k V + k E)\\) \\(O(k V + E)\\) Approach - Dijkstra \\(O(k V \\log (k V) + k E)\\) \\(O(k V + E)\\) Approach - DP \\(O(k E)\\) \\(O(V)\\) Theoretical vs. Practical Time <ul> <li>For theoretical worst-case time complexity,<ul> <li>the Dynamic Programming (DP) approach has the best worst-case time complexity;</li> <li>the BFS-based solution is comparable to DP;</li> <li>the Dijkstra's algorithm is slightly worse due to the log factor from the priority queue.</li> </ul> </li> <li>For practical applications,<ul> <li>Dijkstra and BFS are faster since they only explore reachable cities with valid paths:<ul> <li>They prioritize paths that are likely to lead to the destination or shorter path (in Dijkstra's case).</li> <li>Unreachable or irrelevant paths are not considered, reducing unnecessary work.</li> </ul> </li> <li>DP, however, computes cost for every possible path from the source to all cities for \\(k + 1\\) stops, even if those paths don't contribute to the final result.</li> </ul> </li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0787-cheapest-flights-within-k-stops/#test","title":"Test","text":"<ul> <li><code>k=0</code>: The source must directly connect to the destination.</li> <li>Disconnected graph: Return <code>\u22121</code> if the destination is unreachable.</li> <li>Multiple flights between two cities: Ensure the algorithm explores the cheapest one.</li> </ul>","tags":["Shortest Path"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/","title":"LC797. All Paths From Source to Target","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 797: Given a directed acyclic graph (DAG) of\u00a0<code>n</code>\u00a0nodes labeled from\u00a0<code>0</code>\u00a0to\u00a0<code>n - 1</code>, find all possible paths from node\u00a0<code>0</code>\u00a0to node\u00a0<code>n - 1</code>\u00a0and return them in\u00a0any order.</p> <p>The graph is given as follows:\u00a0<code>graph[i]</code>\u00a0is a list of all nodes you can visit from node\u00a0<code>i</code>\u00a0(i.e., there is a directed edge from node\u00a0<code>i</code>\u00a0to node\u00a0<code>graph[i][j]</code>).</p>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#clarification","title":"Clarification","text":"<ul> <li>Definition of directed acyclic graph (DAG)</li> <li>Find all paths from 0 to n - 1</li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#solution","title":"Solution","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#approach-dfs-with-backtracking","title":"Approach - DFS with Backtracking","text":"<p>Use DFS to traverse all nodes and save the path while traversing, If find target target, append the path results. Otherwise, backtracking the path by removing nodes.</p> <p>Since it is a Directed Acyclic Graph (DAG), no need a visited set since it won't get stuck in a loop (no cycles//loops). Actually the visited set will prevent from finding all paths. Some nodes may need to be visited multiple times when it has multiple indegree.</p> Python <pre><code>class Solution:\n    def allPathsSourceTarget(self, graph: List[List[int]]) -&gt; List[List[int]]:\n        results = []\n        path = [0]\n        self.dfs(graph, 0, path, results)\n        return results\n\n    def dfs(self, graph: List[List[int]], curr_node: int, path: List[int], results: List[List[int]]) -&gt; None:\n        if curr_node == len(graph) - 1:\n            results.append(list(path))\n        else:\n            for next_node in graph[curr_node]:\n                path.append(next_node)\n                self.dfs(graph, next_node, path, results)\n                path.pop()  # (1)\n</code></pre> <ol> <li>Backtracking by popping the last node after each recursive call to ensure the current path is restored to its previous state before exploring new branches.</li> </ol>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(2^V)\\), where \\(V\\) is the number of vertices.   In the worst case (complete binary tree), the number of paths explored by the DFS algorithm can be as large as \\(O(2^n)\\).</li> <li>Space complexity: \\(O(V)\\) <ul> <li>For recursion, the number of recursive call can go up to \\(n\\) calls in the worst case</li> <li>For the current path, it could store \\(n\\) nodes in the worst case.</li> </ul> </li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#approach2-bfs","title":"Approach2 - BFS","text":"<p>Another approach is to use BFS to traverse the node and store temporary path for each node.</p> python <pre><code>class Solution:\n    def allPathsSourceTarget(self, graph: List[List[int]]) -&gt; List[List[int]]:\n        target = len(graph) - 1\n        results = []\n        queue = deque([[0]])\n\n        while queue:\n            path = queue.popleft()\n            curr_node = path[-1]\n\n            if curr_node == target:\n                results.append(path)\n\n            for next_node in graph[curr_node]:\n                new_path = path.copy()\n                new_path.append(next_node)\n                queue.append(new_path)\n\n        return results\n</code></pre>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(2^V \\times V)\\) <ul> <li>For a graph with \\(V\\) vertices, there could be at most \\(2^{V-1}\\) possible paths.</li> <li>For each path, we need \\(O(V)\\) time to build due to copy of path</li> </ul> </li> <li>Space complexity: \\(O(2^V \\times V)\\)   The queue can contain \\(O(2^V)\\) paths and each path will take \\(O(V)\\) space.</li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - DFS \\(O(2^V)\\) \\(O(V)\\) Approach - BFS \\(O(2^V \\times V)\\) \\(O(2^V \\times V)\\)","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0700-0799/lc0797-all-paths-from-source-to-target/#test","title":"Test","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/","title":"LC802. Find Eventual Safe States","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 802: There is a directed graph of\u00a0<code>n</code>\u00a0nodes with each node labeled from\u00a0<code>0</code>\u00a0to\u00a0<code>n - 1</code>. The graph is represented by a\u00a00-indexed\u00a02D integer array\u00a0<code>graph</code>\u00a0where\u00a0<code>graph[i]</code>\u00a0is an integer array of nodes adjacent to node\u00a0<code>i</code>, meaning there is an edge from node\u00a0<code>i</code>\u00a0to each node in\u00a0<code>graph[i]</code>.</p> <p>A node is a\u00a0terminal node\u00a0if there are no outgoing edges. A node is a\u00a0safe node\u00a0if every possible path starting from that node leads to a\u00a0terminal node\u00a0(or another safe node).</p> <p>Return\u00a0an array containing all the\u00a0safe nodes\u00a0of the graph. The answer should be sorted in\u00a0ascending\u00a0order.</p>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#clarification","title":"Clarification","text":"<ul> <li>Definition of safe node</li> <li>Directed graph</li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#solution","title":"Solution","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#approach-dfs","title":"Approach - DFS","text":"<p>Similar to LC1059, we can use node-coloring variant of DFS to check each node to see whether a cycle is detected (unsafe).</p> Python <pre><code>class Solution:\n    def __init__(self):\n        self.GREY = 1\n        self.BLACK = 2\n\n    def eventualSafeNodes(self, graph: List[List[int]]) -&gt; List[int]:\n        results = []\n        n_nodes = len(graph)\n        color = [None] * n_nodes\n\n        for node in range(len(graph)):\n            if self.dfs(node, graph, color):\n                results.append(node)\n\n        return results\n\n    def dfs(self, node: int, graph: List[List[int]], color: List[int]) -&gt; bool:\n        # Return false if a cycle is detected where color is grey\n        if color[node] != None:\n            return color[node] == self.BLACK\n\n        # No outgoing links, reach the end\n        if len(graph[node]) == 0:\n            return True\n\n        # Mark as grey in process\n        color[node] = self.GREY\n\n        for next_node in graph[node]:\n            # Short circuit and return false if detected a \"False\" from any recursive call\n            if not self.dfs(next_node, graph, color):\n                return False\n\n        # Recursing process is done\n        color[node] = self.BLACK\n        return True\n</code></pre>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li> <p>Time complexity: \\(O(V + E)\\)   The total time complexity consists of:</p> <ul> <li>Iniializing <code>color</code> array takes \\(O(V)\\) time</li> <li>The <code>dfs</code> function traverse each nodes once, which takes <code>O(V)</code> time. Ofr each node, it iterates over all the outgoing edges, which takes \\(O(E)\\) time to iterate over all the edges.</li> </ul> </li> <li> <p>Space complexity: \\(O(V)\\) </p> <ul> <li>the <code>color</code> array takes \\(O(V)\\) space</li> <li>The recursion call stack used by <code>dfs</code> takes \\(O(V)\\) space in the worst case.</li> </ul> </li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#approach-2-topological-sort","title":"Approach 2 - Topological Sort","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - DFS \\(O(V + E))\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0802-find-eventual-safe-states/#test","title":"Test","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/","title":"LC841. Keys and Rooms","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 841: There are n rooms labeled from 0 to n - 1 and all the rooms are locked except for room 0. Your goal is to visit all the rooms. However, you cannot enter a locked room without having its key.</p> <p>When you visit a room, you may find a set of distinct keys in it. Each key has a number on it, denoting which room it unlocks, and you can take all of them with you to unlock the other rooms.</p> <p>Given an array rooms where rooms[i] is the set of keys that you can obtain if you visited room i, return true if you can visit all the rooms, or false otherwise.</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#clarification","title":"Clarification","text":"<ul> <li>Each room may contain 0+ keys include no key</li> <li>Room <code>0</code> is not locked</li> <li>Same key may show up in different rooms</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#approach-bfs","title":"Approach - BFS","text":"<p>We can start from room 0 as root node and use breadth-first search (BFS) to visit the rooms. When visited a room, add all keys of that room to a queue, and marked the room visited. Iterate until the queue is empty.</p> PythonPython - BFS Function <pre><code>class Solution:\ndef canVisitAllRooms(self, rooms: List[List[int]]) -&gt; bool:\n    queue = deque([0])\n    visited = set([0])\n\n    while queue:\n        i = queue.popleft()\n        for key in rooms[i]:\n            if key not in visited:\n                queue.append(key)\n                visited.add(key)\n                if len(visited) == len(rooms):  #(1)\n                    return True\n\n    return len(visited) == len(rooms)\n</code></pre> <ol> <li>Early termination.</li> </ol> <pre><code>from collections import deque\n\nclass Solution:\n    def canVisitAllRooms(self, rooms: List[List[int]]) -&gt; bool:\n        visited = self.bfs(0, rooms)\n\n        return len(visited) == len(rooms)\n\n    def bfs(self, curr: int, rooms: List[List[int]]) -&gt; Set[int]:\n        queue = deque([curr])\n        visited = set([curr])\n\n        while queue:\n            curr = queue.popleft()\n\n            for next in rooms[curr]:\n                if next not in visited:\n                    queue.append(next)\n                    visited.add(next)\n                    if len(visited) == len(rooms):\n                        return visited\n\n        return visited\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n + k)\\) where \\(n\\) is the total number of rooms and \\(k\\) is the total numbers of keys   In the worst case, visit all \\(n\\) rooms exact once. When visited a room, need to go   through all keys in the room.</li> <li>Space complexity: \\(O(n)\\)   In the worst case, add all room keys to the queue and set. The space complexity is   \\(O(n + n) = O(n)\\).</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#approach-2-dfs","title":"Approach 2 - DFS","text":"<p>We can start from room 0 as root node and use either depth-first search (DFS) to visit the rooms. During traversing, track the visited room. In the end, check whether number of visited rooms equal n</p> python <pre><code>class Solution:\n    def canVisitAllRooms(self, rooms: List[List[int]]) -&gt; bool:\n        visited = set()\n        self.dfs(0, rooms, visited)\n\n        return len(visited) == len(rooms)\n\n    def dfs(self, curr: int, rooms: List[List[int]], visited: Set[int]) -&gt; None:\n        visited.add(curr)\n\n        for next in rooms[curr]:\n            if next not in visited:\n                self.dfs(next, rooms, visited)\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n + k)\\)   It visits all \\(n\\) rooms exact once. When visited a room, need to go through all keys   in the room.</li> <li>Space complexity: \\(O(n)\\)   The space used is mainly from recursive function call stack. In the worst case, it   could go deep as \\(n-1\\).</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - BFS \\(O(n + k)\\) \\(O(n)\\) Approach - DFS \\(O(n + k)\\) \\(O(n)\\)","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0841-keys-and-rooms/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0800-0899/lc0852-peak-index-in-a-mountain-array/","title":"LC852. Peak Index in a Mountain Array","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0852-peak-index-in-a-mountain-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 852: An array\u00a0<code>arr</code>\u00a0is a\u00a0mountain\u00a0if the following properties hold:</p> <ul> <li><code>arr.length &gt;= 3</code></li> <li>There exists some\u00a0<code>i</code>\u00a0with\u00a0<code>0 &lt; i &lt; arr.length - 1</code>\u00a0such that:<ul> <li><code>arr[0] &lt; arr[1] &lt; ... &lt; arr[i - 1] &lt; arr[i]</code></li> <li><code>arr[i] &gt; arr[i + 1] &gt; ... &gt; arr[arr.length - 1]</code></li> </ul> </li> </ul> <p>Given a mountain array\u00a0<code>arr</code>, return the index\u00a0<code>i</code>\u00a0such that\u00a0<code>arr[0] &lt; arr[1] &lt; ... &lt; arr[i - 1] &lt; arr[i] &gt; arr[i + 1] &gt; ... &gt; arr[arr.length - 1]</code>.</p> <p>You must solve it in\u00a0<code>O(log(arr.length))</code>\u00a0time complexity.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0852-peak-index-in-a-mountain-array/#clarification","title":"Clarification","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0852-peak-index-in-a-mountain-array/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0852-peak-index-in-a-mountain-array/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0852-peak-index-in-a-mountain-array/#approach-binary-search","title":"Approach - Binary Search","text":"<p>We can use binary search to find the peak by checking whether <code>arr[mid] &lt; arr[mid + 1]</code>:</p> <ul> <li>true, means climbing up from left, the peak is on the right half</li> <li>false, means on the right side, peak is on the left half</li> </ul> Python <pre><code>class Solution:\n    def peakIndexInMountainArray(self, arr: List[int]) -&gt; int:\n        left, right = 0, len(arr) - 1\n\n        while left &lt; right:\n            mid = (left + right) // 2\n\n            if arr[mid] &lt; arr[mid + 1]:\n                left = mid + 1\n            else:\n                right = mid\n\n        return left\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0852-peak-index-in-a-mountain-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) Since using binary search, the time complexity is \\(O(\\log n)\\).</li> <li>Space complexity: \\(O(1)\\) Only use two index variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0852-peak-index-in-a-mountain-array/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/","title":"LC862. Shortest Subarray with Sum at Least K","text":"","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 862: Given an integer array <code>nums</code> and an integer <code>k</code>, return the length of the shortest non-empty subarray of <code>nums</code> with a sum of at least <code>k</code>. If there is no such subarray, return <code>-1</code>.</p> <p>A subarray is a contiguous part of an array.</p>","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#clarification","title":"Clarification","text":"<ul> <li>Integer array</li> <li>Includes both positive and negative numbers</li> <li>return length of the shortest subarrays with <code>sum &gt;= k</code></li> </ul>","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#assumption","title":"Assumption","text":"<ul> <li><code>long int</code> can cover the sum of subarrays</li> </ul>","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#solution","title":"Solution","text":"","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#approach-brute-force","title":"Approach - Brute Force","text":"<p>Compute sum of all possible subarrays using two nested for loops. If <code>sum &gt;= k</code>, update the minimal length of subarray.</p> PythonC++ <pre><code>class Solution:\ndef shortestSubarray(self, nums: List[int], k: int) -&gt; int:\n    sum = 0\n    count = len(nums) + 1\n\n    for i in range(len(nums)):\n        sum = 0\n        for j in range(i, len(nums)):\n            sum += nums[j]\n\n            if sum &gt;= k:\n                count = min(count, j - i + 1)\n\n    return count if count &lt; len(nums) + 1 else -1\n</code></pre> <pre><code>class Solution {\npublic:\n    int shortestSubarray(vector&lt;int&gt;&amp; nums, int k) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size n = nums.size();\n        int sum = 0; // sum between i and j;\n        int minLength = n + 1;\n        int length = 0;\n\n        for (vec_size i = 0; i &lt; n; i++) {\n            sum = 0;\n            for (vec_size j = i; j &lt; n; j ++) {\n                sum += nums[j]; \n                if (sum &gt;= k) {\n                    length = j - i + 1;\n                    if (length &lt; minLength) {\n                        minLength = length;\n                    }\n                }\n            }\n        }\n\n        return (minLength == n + 1) ? -1 : minLength;\n    }\n};\n</code></pre>","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^2)\\)     Since it use two nested for-loops to find all possible subarrays, it takes \\(O(n^2)\\) </li> <li>Space complexity: \\(O(1)\\)     Only use several local variables. </li> </ul>","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#approach-prefix-sum-deque","title":"Approach - Prefix sum + Deque","text":"<p>We can think about the problem in terms of cumulative sum, where  - <code>cusum(i)</code> is the sum of subarray from index <code>0</code> to <code>i</code>.  - <code>cusum(j) - cusum(i)</code> is the sum of subarray from index <code>i+1</code> to <code>j</code> So the problem is converted to find <code>cusum(y) - cusum(x) &gt;= k</code> for the subarray from index <code>x+1</code> to <code>y</code> (with length <code>y - (x + 1) + 1 = y - x</code>) and update the shorted length if <code>y - x</code> is smaller.</p> <p>There are two important ways to optimize the solution (@mrv2671988gives a good explanation): 1. If indices <code>x &lt; y1 &lt; y2</code> (x is the last element, \\(y_1\\) is the new element and \\(y_2\\) is the future element) and assume <code>cusum(y1) - cusum(x) &gt;= k</code>, then for any <code>y2</code> after <code>y1</code> (i.e. <code>y2 &gt; y1</code>) that satisfies <code>cusum(y2) - cusum(x) &gt;= k</code>, it will have a longer length <code>y2 - x &gt; y1 - x</code>. So no need to consider <code>x</code> for <code>y2</code> after finding the first <code>y1</code> and updating the length. <pre><code>cusum array [a1 a2 a3 a4 a5 a6 a7 a8 a9 a10 a11]\n                    x        y1          y2\n</code></pre> 2. If indices <code>x1 &lt; x2 &lt; y</code> (x_1 is the last element, x_2 is the new element, y is the future element) and assume <code>cusum(y) - cusum(x1) &gt;= k</code>  and <code>cusum(x1) &gt;= cusum(x2)</code> (i.e., negative sum of subarray from <code>x1+1</code> to <code>x2</code>), then <code>cusum(y) - cusum(x2) &gt;= cusum(y) - cusum(x1) &gt;= k</code> with shorter length <code>y - x2 &lt; y - x1</code>.  So no need to consider <code>x1</code> if there is <code>cusum(x2) &lt;= cusum(x1)</code> <pre><code>cusum array [a1 a2 a3 a4 a5 a6 a7 a8 a9 a10 a11]\n                   x1       x2          y\n</code></pre></p> <p>Based on point 2, if we use a data structure to store previous <code>cusum(x)</code>, it will be an increased order with increase index. Then we can take advantage of this property:</p> <ul> <li>Use point 1 to check whether to remove the minimum value (i.e., the first element) in the data structure. <ul> <li>If the first element (minimum value) doesn't satisfying the equation <code>cusum(y) - cusum(x) &gt;= k</code>, no need to check the rest of data</li> <li>If satisfying the equation, remove the minimum value based on point 1</li> </ul> </li> <li>Use point 2 above to determine whether to remove the last element (maximum value) in the data structure before storing the current index To effective support the operations: insert the element in the end, read/drop the element in the end, read/pop the element in the front, we use <code>deque</code> structure.</li> </ul> PythonC++ <pre><code>class Solution:\ndef shortestSubarray(self, nums: List[int], k: int) -&gt; int:\n    d = collections.deque()\n    prefix_sum = 0\n    prefix_sum_array = [0] * len(nums)\n    min_size = len(nums) + 1\n\n    for i in range(len(nums)):\n        prefix_sum += nums[i]\n        prefix_sum_array[i] = prefix_sum\n\n        if prefix_sum &gt;= k:\n            min_size = min(min_size, i + 1)\n\n        while d and (prefix_sum - prefix_sum_array[d[0]]) &gt;= k:\n            min_size = min(min_size, i - d[0])\n            d.popleft()\n\n        while d and prefix_sum &lt;= prefix_sum_array[d[-1]]:\n            d.pop()\n\n        d.append(i)\n\n    return min_size if min_size &lt; len(nums) + 1 else -1\n</code></pre> <pre><code>class Solution {\npublic:\n    int shortestSubarray(vector&lt;int&gt;&amp; nums, int k) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        vec_size n = nums.size();\n        int res = n + 1; // n+1 is impossible\n        deque&lt;vec_size&gt; d;\n\n        vector&lt;long&gt; cusum(n+1, 0);\n        for (vec_size i = 0; i &lt; n + 1; i++) {\n            if (i &gt; 0) {\n                cusum[i] = cusum[i-1] + nums[i-1];\n            }\n\n            if (cusum[i] &gt;= k) {\n                res = (i+1 &lt; res) ? i+1 : res;\n            }\n\n            while (d.size() &gt; 0 &amp;&amp; cusum[i] - cusum[d.front()] &gt;= k) {\n                res = ((i - d.front()) &lt; res) ? i - d.front() : res;\n                d.pop_front();\n            }\n\n            while (d.size() &gt; 0 &amp;&amp; cusum[i] &lt;= cusum[d.back()]) {\n                d.pop_back();\n            }\n            d.push_back(i);\n        }\n        return res &lt;= n ? res : -1;\n    }\n};\n</code></pre> <p>Potential improvements: use deque of pair to store <code>&lt;index, cusum&gt;</code> instead of just index which requires sum array.</p> PythonC++ <pre><code>class Solution:\ndef shortestSubarray(self, nums: List[int], k: int) -&gt; int:\n    d = collections.deque()\n    prefix_sum = 0\n    min_size = len(nums) + 1\n\n    for i, num in enumerate(nums):\n        prefix_sum += num\n\n        if prefix_sum &gt;= k:\n            min_size = min(min_size, i + 1)\n\n        while d and (prefix_sum - d[0][1]) &gt;= k:\n            min_size = min(min_size, i - d[0][0])\n            d.popleft()\n\n        while d and prefix_sum &lt;= d[-1][1]:\n            d.pop()\n\n        d.append([i, prefix_sum])\n\n    return min_size if min_size &lt; len(nums) + 1 else -1\n</code></pre> <pre><code>class Solution {\npublic:\n    vector&lt;int&gt;::size_type shortestSubarray(vector&lt;int&gt;&amp; nums, int k) {\n        typedef vector&lt;int&gt;::size_type vec_size;\n        deque&lt;pair&lt;vec_size, long int&gt;&gt; dq; // deque of pair &lt;index, cusum&gt;\n        long int sum = 0;\n        vec_size n = nums.size();\n        vec_size minLength = n + 1;\n        vec_size length;\n\n        for (vec_size i = 0; i &lt; n; i++) {\n            sum += nums[i];\n\n            if (sum &gt;= k) {\n                minLength = (i + 1 &lt; minLength) ? i+1 : minLength;\n            }\n\n            while (!dq.empty() &amp;&amp; (sum - (dq.front()).second &gt;= k)) {\n                length = i - (dq.front()).first; // should always &gt;= 0 no need to worry about unsigned integer overflow\n                minLength = (length &lt; minLength) ? length : minLength;\n                dq.pop_front();\n            }\n\n            while (!dq.empty() &amp;&amp; sum &lt;= (dq.back()).second) {\n                dq.pop_back();\n            }\n\n            dq.push_back({i, sum});\n        }\n        return minLength &lt;= n ? minLength : -1;\n    }\n};\n</code></pre>","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Every index will be pushed exact once and every index will be popped at most once.  </li> <li>Space complexity: \\(O(n)\\)     The <code>cusum</code> array will take \\(O(n)\\) space and the deque structure will take \\(O(n)\\) space. So the total space complexity is \\(O(n)\\).</li> </ul>","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Brute Force \\(O(n^2)\\) \\(O(1)\\) Approach - Prefix Sum + Deque \\(O(n)\\) \\(O(n)\\)","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#test","title":"Test","text":"","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#common-errors","title":"Common Errors","text":"<ul> <li>Forget to check whether queue is empty before popping elements</li> <li>Use <code>if</code> statement not <code>while</code></li> </ul>","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0862-shortest-subarray-with-sum-at-least-k/#references","title":"References","text":"","tags":["Array","Dequeue","Prefix Sum"]},{"location":"lc-solutions/lc0800-0899/lc0875-koko-eating-bananas/","title":"LC875. Koko Eating Bananas","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0875-koko-eating-bananas/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 875: Koko loves to eat bananas. There are\u00a0<code>n</code>\u00a0piles of bananas, the\u00a0<code>ith</code>\u00a0pile has\u00a0<code>piles[i]</code>\u00a0bananas. The guards have gone and will come back in\u00a0<code>h</code>\u00a0hours.</p> <p>Koko can decide her bananas-per-hour eating speed of\u00a0<code>k</code>. Each hour, she chooses some pile of bananas and eats\u00a0<code>k</code>\u00a0bananas from that pile. If the pile has less than\u00a0<code>k</code>\u00a0bananas, she eats all of them instead and will not eat any more bananas during this hour.</p> <p>Koko likes to eat slowly but still wants to finish eating all the bananas before the guards return.</p> <p>Return\u00a0the minimum integer <code>k</code> such that she can eat all the bananas within <code>h</code> hours.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0875-koko-eating-bananas/#clarification","title":"Clarification","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0875-koko-eating-bananas/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0875-koko-eating-bananas/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0875-koko-eating-bananas/#approach-binary-search","title":"Approach - Binary Search","text":"<p>The difficult part of this problem is how to convert it into classic binary search problem. Based on the problem description, we can define the search space between 1 and the max number of bananas M on a pile, <code>[1, M]</code>. Each value in the search space has a status associated with it (let <code>N</code> denotes not finish eating and <code>Y</code> denotes finish eating). Then we have <code>[N, N, \u00b7\u00b7\u00b7, N, Y, \u00b7\u00b7\u00b7,Y]</code>. For a given k,</p> <ul> <li>If Koko can finish eating, no need to check k+1, k+2,..., since Koko can finish eating with bigger numbers.</li> <li>If Koko can\u2019t finish eating, no need to check k \u2212 1, k \u2212 2, ... since Koko can NOT finish eating with smaller numbers.</li> </ul> <p>Based on this property, we can use binary search to reduce search space after each iteration until only one element left. Assume there always existing K such that Koko can finish eating within H hours. We also need to create help functions on checking whether Koko can finish eating.</p> PythonC++ <pre><code>class Solution:\n    def minEatingSpeed(self, piles: List[int], h: int) -&gt; int:\n        left, right = 1, max(piles)\n        while left &lt; right:\n            mid = (left + right) // 2\n\n            if self.canEatAll(piles, h, mid):\n                right = mid\n            else:\n                left = mid + 1\n        return left\n\n    def canEatAll(self, piles: List[int], h: int, k: int) -&gt; bool:\n        actual_hour = 0\n        for pile in piles:\n            if pile % k == 0:\n                actual_hour += pile // k\n            else:\n                actual_hour += pile // k + 1\n        return actual_hour &lt;= h\n</code></pre> <pre><code>class Solution {\npublic:\n    int minEatingSpeed(vector&lt;int&gt;&amp; piles, int H) {\n        if (piles.empty() || H &lt; piles.size()) return -1;\n\n        int left = 1; // eat at least one banana\n        int right = getMaxPile(piles);\n        int mid;\n\n        while (left &lt; right) {\n            mid = left + (right - left)/2;\n\n            if (canEatAll(piles, H, mid)) {\n                right = mid;    // continue to the left to find the smaller k since Koko wants to east as slow as possible\n            }\n            else {\n                left = mid + 1;\n            }\n        }\n\n        // left == right\n        return left;  //assumption: there will be at least one solution\n    }\n\nprivate:\n    bool canEatAll(vector&lt;int&gt;&amp; piles, int H, int mid) {\n        int hour = 0;\n\n        for (int pile:piles) {\n            hour += pile/mid + ((pile%mid == 0) ? 0 : 1); // round up\n        }\n\n        return (hour &lt;= H) ? true : false;\n    }\n\n    int getMaxPile(vector&lt;int&gt;&amp; piles) {\n        int maxPile = piles[0];\n\n        for (int pile:piles) {\n            if (pile &gt; maxPile) maxPile = pile;\n        }\n\n        return maxPile;\n    }\n};\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0875-koko-eating-bananas/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log m)\\) where \\(n\\) is the number of piles and \\(m\\) is the maximum number of bananas in a pile It takes \\(O(\\log m)\\) to find <code>k</code> in the search space <code>[1, m]</code> using binary search. For each step, it takes \\(O(n)\\) to check all piles to see whether Koko can finishing eating. Additionally, it takes \\(O(n)\\) to find the maximum number of bananas in a pile. So the total time complexity is \\(O(n \\log m) = O(n \\log m) + O(n)\\).  </li> <li>Space complexity: \\(O(1)\\) Only use several variables for binary search and computation.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0875-koko-eating-bananas/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/","title":"LC876. Middle of the Linked List","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 876: Given the\u00a0<code>head</code>\u00a0of a singly linked list, return\u00a0the middle node of the linked list.</p> <p>If there are two middle nodes, return\u00a0the second middle\u00a0node.</p>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#clarification","title":"Clarification","text":"<ul> <li>definition of middle, especially for even number of array</li> <li>return node value or node?</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#assumption","title":"Assumption","text":"<ul> <li>no loop in the linked list</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#solution","title":"Solution","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#approach-slowfast-pointers","title":"Approach - slow/fast pointers","text":"<p>Use two pointers, <code>slow</code> and <code>fast</code> pointers. Each execution, <code>slow</code> pointer moves 1 step while <code>fast</code> pointer moves 2 steps. When <code>fast</code> pointer arrives at the end, <code>slow</code> will arrive right in the middle.</p> Python <pre><code>class Solution:\n    def middleNode(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        slow = head\n        fast = head\n\n        while fast and fast.next:\n            slow = slow.next\n            fast = fast.next.next\n\n        return slow\n</code></pre>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It takes \\(n/2\\) steps to find the middle. Therefore, the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(1)\\)     It only needs two pointers to go through the list. Therefore, the space complexity is \\(O(1)\\).</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#approach-b","title":"Approach - b","text":"<p>Descriptions</p> <pre><code>source code \n</code></pre>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O()\\)     Explanation  </li> <li>Space complexity: \\(O()\\)     Explanation</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - a \\(O()\\) \\(O()\\) Approach - b \\(O()\\) \\(O()\\)","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0876-middle-of-the-linked-list/#test","title":"Test","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc0800-0899/lc0896-monotonic-array/","title":"LC896. Monotonic Array","text":"","tags":["Array"]},{"location":"lc-solutions/lc0800-0899/lc0896-monotonic-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 896: An array is\u00a0monotonic\u00a0if it is either monotone increasing or monotone decreasing.</p> <p>An array\u00a0<code>nums</code>\u00a0is monotone increasing if for all\u00a0<code>i &lt;= j</code>,\u00a0<code>nums[i] &lt;= nums[j]</code>. An array\u00a0<code>nums</code>\u00a0is monotone decreasing if for all\u00a0<code>i &lt;= j</code>,\u00a0<code>nums[i] &gt;= nums[j]</code>.</p> <p>Given an integer array\u00a0<code>nums</code>, return\u00a0<code>true</code> if the given array is monotonic, or <code>false</code> otherwise.</p>","tags":["Array"]},{"location":"lc-solutions/lc0800-0899/lc0896-monotonic-array/#clarification","title":"Clarification","text":"<ul> <li>&lt; vs &lt;= (strictly monotonic?)</li> <li>either increase or decrease</li> </ul>","tags":["Array"]},{"location":"lc-solutions/lc0800-0899/lc0896-monotonic-array/#assumption","title":"Assumption","text":"","tags":["Array"]},{"location":"lc-solutions/lc0800-0899/lc0896-monotonic-array/#solution","title":"Solution","text":"","tags":["Array"]},{"location":"lc-solutions/lc0800-0899/lc0896-monotonic-array/#approach","title":"Approach","text":"<p>Start from the basic definition where </p> <ul> <li>Monotonic increase: \\(nums[i + 1] &gt;= nums[i]\\) for all \\(i\\). For strictly monotonic, use <code>&gt;</code>.</li> <li>Monotonic decrease: \\(nums[i + 1] &lt;= nums[i]\\) for all \\(i\\). For strictly monotonic, use <code>&lt;</code>.</li> </ul> Python <pre><code>class Solution:\n    def isMonotonic(self, nums: List[int]) -&gt; bool:\n        isMonotonicIncrease = True\n        isMonotonicDecrease = True\n        for i in range(len(nums) - 1):\n            if nums[i] &gt; nums[i + 1]:\n                isMonotonicIncrease = False\n\n            if nums[i] &lt; nums[i + 1]:\n                isMonotonicDecrease = False\n\n            if not isMonotonicIncrease and not isMonotonicDecrease:\n                break\n\n        return isMonotonicIncrease or isMonotonicDecrease\n</code></pre>","tags":["Array"]},{"location":"lc-solutions/lc0800-0899/lc0896-monotonic-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     In the worst case, need to go through the whole array.</li> <li>Space complexity: \\(O(1)\\)     Use a pointer and limited local variables.</li> </ul>","tags":["Array"]},{"location":"lc-solutions/lc0800-0899/lc0896-monotonic-array/#test","title":"Test","text":"","tags":["Array"]},{"location":"lc-solutions/lc0900-0999/lc0904-fruit-into-baskets/","title":"LC904. Fruit Into Baskets","text":"","tags":["Array","Sliding Window","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0904-fruit-into-baskets/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 904: You are visiting a farm that has a single row of fruit trees arranged from left to right. The trees are represented by an integer array\u00a0<code>fruits</code>\u00a0where\u00a0<code>fruits[i]</code>\u00a0is the\u00a0type\u00a0of fruit the\u00a0<code>ith</code>\u00a0tree produces.</p> <p>You want to collect as much fruit as possible. However, the owner has some strict rules that you must follow:</p> <ul> <li>You only have\u00a0two\u00a0baskets, and each basket can only hold a\u00a0single type\u00a0of fruit. There is no limit on the amount of fruit each basket can hold.</li> <li>Starting from any tree of your choice, you must pick\u00a0exactly one fruit\u00a0from\u00a0every\u00a0tree (including the start tree) while moving to the right. The picked fruits must fit in one of your baskets.</li> <li>Once you reach a tree with fruit that cannot fit in your baskets, you must stop.</li> </ul> <p>Given the integer array\u00a0<code>fruits</code>, return\u00a0the\u00a0maximum\u00a0number of fruits you can pick.</p>","tags":["Array","Sliding Window","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0904-fruit-into-baskets/#clarification","title":"Clarification","text":"<ul> <li>only can collect two types of fruit</li> <li>pick one fruit from every tree (continuously)</li> </ul>","tags":["Array","Sliding Window","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0904-fruit-into-baskets/#assumption","title":"Assumption","text":"","tags":["Array","Sliding Window","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0904-fruit-into-baskets/#solution","title":"Solution","text":"<p>The problem can be viewed as finding out the longest length of subarrays with at most 2 different types.</p>","tags":["Array","Sliding Window","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0904-fruit-into-baskets/#approach-sliding-window-hashmap","title":"Approach - Sliding Window + Hashmap","text":"<p>The problem can be solved with sliding window and maintain a hashmap <code>count</code> to count the number of element within the window (between two pointers). For sliding window, there are two different ways:</p> <ol> <li>Expand and shrink window based on number of types (use <code>while</code> to check number of types)</li> <li>Keeps the longest window. The window doesn't shrink and expands when finding larger size (use <code>if</code> to check number of types). Refer to @lee215 solution</li> </ol> <pre><code>class Solution:\n    def totalFruit(self, fruits: List[int]) -&gt; int:\n        left = 0\n        count = {}\n        max_size = 0\n\n        for right, fruit in enumerate(fruits):\n            count[fruit] = count.get(fruit, 0) + 1\n\n            while len(count) &gt; 2 :\n                count[fruits[left]] -= 1\n                if count[fruits[left]] == 0:\n                    del count[fruits[left]]\n                left += 1\n\n            max_size = max(max_size, right - left + 1)\n\n        return max_size\n</code></pre> <pre><code>class Solution:\n    def totalFruit(self, fruits: List[int]) -&gt; int:\n        left = 0\n        count = {}\n\n        for right, fruit in enumerate(fruits):\n            count[fruit] = count.get(fruit, 0) + 1\n\n            if len(count) &gt; 2 :\n                count[fruits[left]] -= 1\n                if count[fruits[left]] == 0:\n                    del count[fruits[left]]\n                left += 1\n\n        return right - left + 1\n</code></pre> <p><code>while</code> vs. <code>if</code>:</p> <ul> <li>In terms of time complexity, <ul> <li><code>while</code> method takes \\(O(2n)\\) since in the worst case both left and right pointers move to the last element</li> <li><code>if</code> methods takes \\(O(n)\\) since just the right pointer move to the last element</li> </ul> </li> <li>In terms of space complexity, <ul> <li><code>while</code> method takes \\(O(1)\\) space, since it only stores at most three types yet </li> <li><code>if</code> method takes \\(O(n)\\) space, since it may store more than two types which can be as high as \\(n/2\\). For example, if the first half \\(n/2\\) is the same type while the 2nd half has different types with \\(n/2\\) types [1, 1, 1, 1, 1, 2, 3, 4, 5]. The hashmap with <code>if</code> method will n/2 type.</li> </ul> </li> </ul>","tags":["Array","Sliding Window","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0904-fruit-into-baskets/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Iterate through the whole array and therefore it is \\(O(n)\\).  </li> <li>Space complexity: \\(O(1)\\)     Use hashmap to store two types (when using <code>while</code> loop). It could be \\(O(m)\\) when using <code>if</code> statement.  </li> </ul>","tags":["Array","Sliding Window","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0904-fruit-into-baskets/#test","title":"Test","text":"","tags":["Array","Sliding Window","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/","title":"912. Sort an array","text":"","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 912: Given an array of integers <code>nums</code>, sort the array in ascending order and return it.</p> <p>You must solve the problem without using any built-in functions in <code>O(nlog(n))</code> time complexity and with the smallest space complexity possible.</p>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#clarification","title":"Clarification","text":"<ul> <li>Can we modify the input array?</li> </ul>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#solution","title":"Solution","text":"","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#approach-1-merge-sort-top-down","title":"Approach 1: Merge Sort (Top-Down)","text":"<p>We can use the merge sort algorithm to sort the array. The merge sort algorithm is a divide-and-conquer algorithm that divides the array into two halves, sorts each half recursively, and then merges the two sorted halves.</p> <p>In this approach, we will use top-down merge sort.</p> Python <pre><code>class Solution:\n    def sortArray(self, nums: List[int]) -&gt; List[int]:\n        nums_copy = nums[:]  # Assump the input can't be chnaged\n        aux = [0] * len(nums)  # Allocate auxiliary array for merge sort\n        self.sortSubArray(nums_copy, aux, 0, len(nums) - 1)\n        return nums_copy\n\n    def sortSubArray(self, nums: list[int], aux: list[int], lo: int, hi: int) -&gt; None:\n        # Base Case\n        if lo &gt;= hi:\n            return\n\n        mid = (lo + hi) // 2\n        self.sortSubArray(nums, aux, lo, mid)\n        self.sortSubArray(nums, aux, mid + 1, hi)\n        self.merge(nums, aux, lo, mid, hi)\n\n    def merge(self, nums: list[int], aux: list[int], lo: int, mid: int, hi: int) -&gt; None:\n        aux[lo : hi+1] = nums[lo : hi+1]  # Refresh aux (current window) with partially sorted values in nums\n\n        i, j = lo, mid + 1  # Pointers to left and right halves\n        for k in range(lo, hi + 1):\n            if i &gt; mid:  # Left half exhausted\n                nums[k] = aux[j]\n                j += 1\n            elif j &gt; hi:  # Right half exhausted\n                nums[k] = aux[i]\n                i += 1\n            elif aux[j] &lt; aux[i]:  # Right element smaller\n                nums[k] = aux[j]\n                j += 1\n            else:  # Left element smaller or equal\n                nums[k] = aux[i]\n                i += 1\n</code></pre>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li>The array is recursively split in half --&gt; \\(O(\\log n)\\) levels of recursion.</li> <li>At each level, merging multiple two halves, taking \\(O(n)\\) time across the entire level.</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Auxiliary array of size \\(n\\) is used to store the merged result.</li> <li>The space complexity of the recursive stack is \\(O(\\log n)\\) in a balanced case, but it is \\(O(n)\\) in the worst case.</li> <li>The overall space complexity is \\(O(n) + O(n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#approach-2-merge-sort-bottom-up","title":"Approach 2: Merge Sort (Bottom-Up)","text":"<p>We can also sort the array using bottom-up merge sort.</p> python <pre><code>class Solution:\n    def sortArray(self, nums: List[int]) -&gt; List[int]:\n        n = len(nums)\n        aux = [0] * n  # Auxiliary array for merging\n\n        size = 1\n        while size &lt; n:\n            for lo in range(0, n - size, size * 2):\n                mid = lo + size - 1\n                hi = min(lo + size * 2 - 1, n - 1)\n                self.merge(nums, aux, lo, mid, hi)\n            size *= 2\n\n        return nums\n\n    def merge(self, nums: list[int], aux: list[int], lo: int, mid: int, hi: int) -&gt; None:\n        # Refersh aux with partially sorted nums\n        aux[lo : hi + 1] = nums[lo : hi + 1]\n\n        i, j = lo, mid + 1\n        for k in range(lo, hi + 1):\n            if i &gt; mid:\n                nums[k] = aux[j]\n                j += 1\n            elif j &gt; hi:\n                nums[k] = aux[i]\n                i += 1\n            elif aux[j] &lt; aux[i]:\n                nums[k] = aux[j]\n                j += 1\n            else:\n                nums[k] = aux[i]\n                i += 1\n</code></pre>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li>Doubling subarray size in the main loop leads to \\(\\log n\\) levels of merging.</li> <li>At each level, all \\(n\\) elements are processed, resulting in a total of \\(O(n)\\) work per level.</li> <li>The overall time complexity is \\(O(n \\log n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\)   An auxiliary array of size \\(n\\) is used to store the merged result.</li> </ul>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#approach-3-quick-sort","title":"Approach 3: Quick Sort","text":"<p>The problem can also be solved using the quick sort algorithm. Yet, the solution fails at the test case where a very large number of same elements are present, leading to Time Limit Exceeded (TLE).</p> <p>May be use quick sort with 3 way partitioning to avoid TLE?</p> python <pre><code>class Solution:\ndef sortArray(self, nums: List[int]) -&gt; List[int]:\n    self._sort(nums, 0, len(nums) - 1)\n    return nums\n\ndef _sort(self, nums: list[int], low: int, high: int) -&gt; None:\n    if low &gt;= high:\n        return\n    # Randomize the first element\n    i_random = low + random.randint(0, len(nums)) % (high - low + 1)\n    nums[i_random], nums[low] = nums[low], nums[i_random]\n    pivot = self._partition(nums, low, high)\n    self._sort(nums, low, pivot - 1)\n    self._sort(nums, pivot + 1, high)\n\ndef _partition(self, nums: list[int], low: int, high: int) -&gt; int:\n    if low &gt;= high:\n        return -1\n    pivot = low  # Select the first element as a partition element\n    l, r = pivot + 1, high\n\n    while (l &lt;= r):\n        if nums[l] &lt; nums[pivot]:\n            l += 1\n        elif nums[r] &gt;= nums[pivot]:\n            r -= 1\n        else:\n            nums[l], nums[r] = nums[r], nums[l]\n\n    nums[pivot], nums[r] = nums[r], nums[pivot]\n\n    return r\n</code></pre>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li>The average time complexity is \\(O(n \\log n)\\).</li> <li>The worst-case time complexity is \\(O(n^2)\\), which can occur when the smallest or largest element is always chosen as the pivot.</li> </ul> </li> <li>Space complexity: \\(O(n \\log n)\\)   The space complexity is \\(O(\\log n)\\) due to the recursive stack space.</li> </ul>","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Merge Sort (Top-Down) \\(O(n \\log n)\\) \\(O(n)\\) Approach 2 - Merge Sort (Bottom-Up) \\(O(n \\log n)\\) \\(O(n)\\)","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0912-sort-an-array/#test","title":"Test","text":"","tags":["Sorting"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/","title":"LC973. K Closest Points to Origin","text":"","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 973: Given an array of\u00a0<code>points</code>\u00a0where\u00a0<code>points[i] = [xi, yi]</code>represents a point on the X-Y\u00a0plane and an integer\u00a0<code>k</code>, return the\u00a0<code>k</code>\u00a0closest points to the origin\u00a0<code>(0, 0)</code>.</p> <p>The distance between two points on the\u00a0X-Y\u00a0plane is the Euclidean distance (i.e., \\(\\sqrt{(x1 - x2)^2 + (y1 - y2)^2}\\)).</p> <p>You may return the answer in\u00a0any order. The answer is\u00a0guaranteed\u00a0to be unique\u00a0(except for the order that it is in).</p>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#clarification","title":"Clarification","text":"<ul> <li>Return the k closest points</li> <li>Euclidean distance definition</li> <li>Return the answer in any order</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#assumption","title":"Assumption","text":"<ul> <li>k &gt; 0</li> <li>No duplicate points</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#solution","title":"Solution","text":"","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#approach-heap","title":"Approach - Heap","text":"<p>We can use max heap with size k to store points with distance. When pushing points and the size &gt; k, the furthest points away from the origin are removed. In the end, only the k closest points remained.</p> Python <pre><code>import heapq\nimport math\n\nclass Solution:\n    def kClosest(self, points: List[List[int]], k: int) -&gt; List[List[int]]:\n    max_heap = []\n\n        for i in range(len(points)):\n            dist_to_origin = points[i][0] ** 2 + points[i][1] ** 2\n            heapq.heappush(\n                max_heap, (-dist_to_origin, i)\n            )  # Push negative value to achieve max heap by using min heap\n\n            if len(max_heap) &gt; k:\n                heapq.heappop(max_heap)\n\n        return [points[i] for (_, i) in max_heap]\n</code></pre> <ol> <li>Push negative value to achieve max heap by using min heap.</li> </ol>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log k)\\) <ul> <li>Iterate all \\(n\\) points. Each iteration will do at most two heap operations. The heap operation takes \\(O(\\log k)\\) time since the heap size is at most \\(k\\). So the time complexity is \\(O(n \\log k)\\).</li> <li>Return results by iterating the heap, which takes \\(O(k)\\).</li> <li>So the total time complexity is \\(O(n \\log k) + O(k) = O(n \\log k)\\).</li> </ul> </li> <li>Space complexity: \\(O(k)\\)     The heap takes \\(O(k)\\) space to store \\(k\\) elements.</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#approach-2-","title":"Approach 2 -","text":"<p>Solution</p> python <pre><code>code\n</code></pre>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Heap \\(O(n \\log k)\\) \\(O(k)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0973-k-closest-points-to-origin/#test","title":"Test","text":"","tags":["Heap","Quickselect"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/","title":"LC974. Subarray Sums Divisible by K","text":"","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 974: Given an integer array <code>nums</code> and an integer <code>k</code>, return the number of non-empty subarrays that have a sum divisible by <code>k</code>.</p> <p>A subarray is a contiguous part of an array.</p>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#clarification","title":"Clarification","text":"<ul> <li>Meaning of contiguous: not mean unbroken block of memory but more about consecutive elements (i.e., indices are adjacent and in continuous range)</li> <li>\\(0/k\\) is considered as divisible? Yes</li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#assumption","title":"Assumption","text":"<ul> <li>\\(k \\neq 0\\)</li> <li>\\(k &gt; 0\\)</li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#solution","title":"Solution","text":"","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#approach-brute-force","title":"Approach - Brute Force","text":"<p>The straightforward method is to compute sum between index <code>i</code> and <code>j</code> for any possible subarray using two for-loops. If <code>sum % k == 0</code>, increase the count. </p> <pre><code>class Solution {\npublic:\n    int subarraysDivByK(vector&lt;int&gt;&amp; nums, int k) {\n        int count = 0;\n        int sum; \n        int n = nums.size();\n\n        for (int i = 0; i &lt; n; i++) {\n            sum = 0;\n            for (int j = i; j &lt; nums.size(); j++) {\n                sum += nums[j];           \n                if (sum % k == 0) {\n                    count++;\n                }\n            }\n        }\n        return count;      \n    }\n}; \n</code></pre>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n^2)\\)     Since using two for-loops to iterate all possible subarray combinations, it takes \\(O(n^2)\\) time complexity. </li> <li>Space complexity: \\(O(1)\\)     It uses constant space complexity since just using two pointers and two variables <code>sum</code> and <code>count</code>. </li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#approach-prefix-sum-remainder","title":"Approach - Prefix Sum + Remainder","text":"<p>We can view the problem from different angle, using cumulative sum (or prefix sum). we know that <code>cusum(i) - cusum(j)</code> is the sum of subarray from index <code>i+1</code> to <code>j</code>. If the sum of the subarray is divisible by <code>k</code>, <code>cusum(i)</code> and <code>cusum(j)</code> should have the same remainder. </p> <p>Why is this true? Let's start from the basics. The quotient \\(q\\) and the remainder \\(r\\) of \\(a\\) divided by \\(n\\) satisfy the following conditions: \\(n = k q + r\\) with \\(|r| &lt; |k|\\).  For \\(sum_i = k q_i + r_i\\) and \\(sum_j = k q_j + r_j\\), \\(sum_i - sum_j = k (q_i - q_j) + (r_i - r_j)\\). if \\(sum_i - sum_j\\) is divisible by \\(k\\) (sum of subarray from <code>i+1</code> to <code>j</code> is also divisible by \\(k\\)), it means \\(r_i = r_j\\).</p> <p>So we iterate through the array and compute the cumulative sum. For any given \\(sum_i\\), we can check whether there exists \\(sum_j\\) computed previously that have the same remainder as \\(sum_i\\). Note that there may be multiple \\(sum_j\\) satisfy this condition. To effectively store previous computed \\(sum_j\\) with number of appearances and retrieve this information later, we can use </p> <ul> <li>hashmap to store <code>&lt;remainder, number of appearances&gt;</code></li> <li>vector or array to store number of appearances. Array size is \\(k\\) and index \\(0\\) to \\(k-1\\) correspond remainders.  </li> </ul> Note <p>For negative numbers, <code>n % k</code> returns signed remainder. For any negative remainder, it has an equivalent positive one. For example, \\(-1 = 0 * 4 + (-1) = -1*4 + 3\\). To handle missing count, we can convert negative remainder to the positive one by <code>+k</code>.</p> <ul> <li>Use hashmap to store remainders</li> </ul> PythonC++ <pre><code>class Solution:\ndef subarraysDivByK(self, nums: List[int], k: int) -&gt; int:\n    remainder_freq_map = {0:1} # (1)\n    count = 0\n    prefix_sum = 0\n    for num in nums:\n        prefix_sum += num\n\n        remainder = prefix_sum % k\n\n        if remainder &lt; 0:\n            remainder += k\n\n        if remainder in remainder_freq_map:\n            count += remainder_freq_map[remainder]\n            remainder_freq_map[remainder] += 1\n        else:\n            remainder_freq_map[remainder] = 1\n\n    return count\n</code></pre> <ol> <li>When <code>prefix_sum % k == 0</code>, it should count as <code>1</code>. So reminder count needs to be initialized as 1 for correct counting.</li> </ol> <pre><code>class Solution {\npublic:\n    int subarraysDivByK(vector&lt;int&gt;&amp; nums, int k) {\n        unordered_map&lt;int, int&gt; remainderCount;\n        int count = 0;\n        int sum = 0;\n        int remainder;\n\n        for (int num : nums) {\n            sum += num;\n\n            remainder = sum % k;\n            if (remainder &lt; 0) {\n                remainder += k;\n            }\n\n            if (remainder == 0) {\n                count++;\n            }\n\n            if (remainderCount.find(remainder) != remainderCount.end()) {\n                count += remainderCount[remainder];\n            }\n\n            remainderCount[remainder]++;\n\n        }\n\n        return count;\n    }\n};\n</code></pre> <ul> <li>Use vector to store remainders</li> </ul> PythonC++ <pre><code>class Solution:\ndef subarraysDivByK(self, nums: List[int], k: int) -&gt; int:\n    remainder_freq = [0] * k\n    remainder_freq[0] = 1\n    count = 0\n    prefix_sum = 0\n    for num in nums:\n        prefix_sum += num\n\n        remainder = prefix_sum % k\n\n        if remainder &lt; 0:\n            remainder += k\n\n        count += remainder_freq[remainder]\n        remainder_freq[remainder] += 1\n\n    return count\n</code></pre> <pre><code>class Solution {\npublic:\n    int subarraysDivByK(vector&lt;int&gt;&amp; nums, int k) {\n        vector&lt;int&gt; remainderArray(k, 0);\n        int count = 0;\n        int sum = 0;\n        int remainder;\n\n        for (int num : nums) {\n            sum += num;\n\n            remainder = sum % k;\n            if (remainder &lt; 0) {\n                remainder += k; // convert to negative remainder to positive ones\n            }\n\n            if (remainder == 0) {\n                count++;\n            }\n            count += remainderArray[remainder];\n            remainderArray[remainder]++;\n        }\n        return count;\n    }\n};\n</code></pre>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Since it just iterates the array once, it takes \\(O(n)\\) time complexity.</li> <li>Space complexity: \\(O(k)\\)     It needs to store remainders, which is from \\(0\\) to \\(k-1\\), at most \\(k\\).</li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Brute Force \\(O(n^2)\\) \\(O(1)\\) Approach - Prefix Sum + Remainder \\(O(n)\\) \\(O(k)\\)","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#test","title":"Test","text":"<ul> <li>Negative number</li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0974-subarray-sums-divisible-by-k/#mistakes","title":"Mistakes","text":"<ul> <li>Not initialize <code>count</code>, causing result with random number</li> </ul>","tags":["Array","Prefix Sum","Hash Table"]},{"location":"lc-solutions/lc0900-0999/lc0981-time-based-key-value-store/","title":"LC981. Time Based Key-Value Store","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0900-0999/lc0981-time-based-key-value-store/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 981: Design a time-based key-value data structure that can store multiple values for the same key at different time stamps and retrieve the key's value at a certain timestamp.</p> <p>Implement the\u00a0<code>TimeMap</code>\u00a0class:</p> <ul> <li><code>TimeMap()</code>\u00a0Initializes the object of the data structure.</li> <li><code>void set(String key, String value, int timestamp)</code>\u00a0Stores the key\u00a0<code>key</code>\u00a0with the value\u00a0<code>value</code>\u00a0at the given time\u00a0<code>timestamp</code>.</li> <li><code>String get(String key, int timestamp)</code>\u00a0Returns a value such that\u00a0<code>set</code>\u00a0was called previously, with\u00a0<code>timestamp_prev &lt;= timestamp</code>. If there are multiple such values, it returns the value associated with the largest\u00a0<code>timestamp_prev</code>. If there are no values, it returns\u00a0<code>\"\"</code>.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0900-0999/lc0981-time-based-key-value-store/#clarification","title":"Clarification","text":"<ul> <li>1 key to multiple values at different timestamps</li> <li>retrieve the key's value at a certain timestamp</li> <li>data type of timestamp, int?</li> <li>key and value contains both lower or upper case?</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0900-0999/lc0981-time-based-key-value-store/#assumption","title":"Assumption","text":"<ul> <li>timestamp is unique and increase with set function calls</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0900-0999/lc0981-time-based-key-value-store/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0900-0999/lc0981-time-based-key-value-store/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Define a map data structure and map a list of <code>[value, timestamp]</code> to a key. Since <code>timestamp</code> is increased with <code>set</code> function calls, we can use binary search to find target <code>timestamp</code> quickly.  </p> Python <pre><code>class TimeMap:\n\n    def __init__(self):\n        self.data = dict()\n\n    def set(self, key: str, value: str, timestamp: int) -&gt; None:\n        if key not in self.data:\n            self.data[key] = [[value, timestamp]]\n        else:\n            self.data[key].append([value, timestamp])\n\n    def get(self, key: str, timestamp: int) -&gt; str:\n        if key not in self.data:\n            return \"\"\n        else:\n            idx = self.find_recent_timestamp(key, timestamp)\n            if idx == -1:\n                return \"\"\n            else:\n                return self.data[key][idx][0]\n\n    def find_recent_timestamp(self, key: str, timestamp: int) -&gt; int:\n        value = self.data[key]\n        left, right = 0, len(value) - 1\n\n        while left &lt; right - 1:\n            mid = (left + right) // 2\n            if value[mid][1] == timestamp:\n                return mid\n            elif timestamp &lt; value[mid][1]:\n                right = mid - 1\n            else:\n                left = mid\n\n        if value[right][1] &lt;= timestamp:\n            return right\n        elif value[left][1] &lt;= timestamp:\n            return left\n        else:\n            return -1\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc0900-0999/lc0981-time-based-key-value-store/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: <code>set</code> is \\(O(1)\\); <code>get</code> is \\(O(\\log n_{set})\\) For <code>set</code> function, it adds the value to the end. So the time complexity is \\(O(1)\\). For <code>get</code> function, it use binary search to find target timetamp and the search space is the number of <code>set</code> function calls for each key, \\(n_{set}\\).</li> <li>Space complexity: \\(O(1)\\) Only use limited index variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc0900-0999/lc0981-time-based-key-value-store/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc0900-0999/lc0994-rotting-oranges/","title":"LC994. Rotting Oranges","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0900-0999/lc0994-rotting-oranges/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 994: You are given an \u00a0<code>m x n</code> <code>grid</code>\u00a0where each cell can have one of three values:</p> <ul> <li><code>0</code>\u00a0representing an empty cell,</li> <li><code>1</code>\u00a0representing a fresh orange, or</li> <li><code>2</code>\u00a0representing a rotten orange.</li> </ul> <p>Every minute, any fresh orange that is\u00a04-directionally adjacent\u00a0to a rotten orange becomes rotten.</p> <p>Return\u00a0the minimum number of minutes that must elapse until no cell has a fresh orange. If\u00a0this is impossible, return <code>-1</code>.</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0900-0999/lc0994-rotting-oranges/#clarification","title":"Clarification","text":"<ul> <li>4-directionally adjacent (top, bottom, left, right)</li> <li>return -1, if there is still some fresh orange left</li> <li>Is is okay to change input <code>grid</code>?</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0900-0999/lc0994-rotting-oranges/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0900-0999/lc0994-rotting-oranges/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0900-0999/lc0994-rotting-oranges/#approach-bfs","title":"Approach - BFS","text":"<p>Add ALL rotten oranges to the queue and use Breadth-First Search (BFS) to add neighbor oranges layer by layer. The number of layers added is number of minutes elapsed.</p> <p>During BFS,</p> <ul> <li>reduce fresh orange number when encounter a fresh one.</li> <li>Use <code>visited</code> to mark oranges processed instead of changing input <code>grid</code>.</li> </ul> <p>If number of fresh oranges is reduced to 0, return number of layers. Otherwise return -1.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def orangesRotting(self, grid: List[List[int]]) -&gt; int:\n        DIRECTIONS = [(0, 1), (0, -1), (-1, 0), (1, 0)]  # Up, down, left, right\n        n_rows = len(grid)\n        n_cols = len(grid[0])\n        n_fresh_oranges = 0  # number of fresh oranges\n        n_minutes = 0\n\n        queue = deque()\n        visited = set()\n\n        # Add rotten oranges to the queue\n        for i_row in range(n_rows):\n            for j_col in range(n_cols):\n                if grid[i_row][j_col] == 2:\n                    queue.append((i_row, j_col))\n                    visited.add((i_row, j_col))\n\n                if grid[i_row][j_col] == 1:\n                    n_fresh_oranges += 1\n\n        # Start from rotten oranges and traverse level by level with 4-directionally\n        # adjacent while queue and n_fresh_oranges &gt; 0:\n\n            for _ in range(len(queue)):\n                curr_row, curr_col = queue.popleft()\n                for row_delta, col_delta in DIRECTIONS:\n                    next_row, next_col = curr_row + row_delta, curr_col + col_delta\n                    if 0 &lt;= next_row &lt; n_rows and 0 &lt;= next_col &lt; n_cols \\\n                            and (next_row, next_col) not in visited \\\n                            and grid[next_row][next_col] &gt; 0:\n                        queue.append((next_row, next_col))\n                        visited.add((next_row, next_col))\n                        n_fresh_oranges -= 1\n\n            n_minutes += 1\n\n        return n_minutes if n_fresh_oranges == 0 else -1\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0900-0999/lc0994-rotting-oranges/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m \\times n)\\)   The time complexity consists of two parts:<ul> <li>Scan the grid to fill the queue initially, which takes \\(O(m \\times n)\\) time.</li> <li>Run BFS on the queue, which in the worst case would traverse all the cells exactly once and therefore takes \\(O(m \\times n)\\).    So the total time complexity is \\(O(m \\times n) + O(m \\times n) = O(m \\times n)\\).</li> </ul> </li> <li>Space complexity: \\(O(m \\times n)\\)   In the worst case, the grid is filled with rotten oranges. As a result, the queue    would be initialized with all the cells in the grid, which takes \\(O(m \\times n)\\) space.</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc0900-0999/lc0994-rotting-oranges/#test","title":"Test","text":"<ul> <li>One element not rotten, <code>[[0]]</code></li> <li>one element rotten, <code>[[2]]</code></li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/","title":"LC1004. Max Consecutive Ones III","text":"","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1004: Given a binary array <code>nums</code> and an integer <code>k</code>, return the maximum number of consecutive <code>1</code>'s in the array if you can flip at most <code>k</code> <code>0</code>'s.</p> <p>Note integer type can be rest to 0</p>","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/#similar-questions","title":"Similar Questions:","text":"<ul> <li>lc0485-max-consecutive-ones</li> <li>lc0487-max-consecutive-ones-ii</li> </ul>","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/#clarification","title":"Clarification","text":"<ul> <li>Binary tree of integer type?</li> </ul>","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/#assumption","title":"Assumption","text":"<ul> <li>Integer type can cover subarray left and right indices</li> </ul>","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/#solution","title":"Solution","text":"","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/#approach-slide-window","title":"Approach - Slide Window","text":"<p>Use a sliding window (left and right pointers) to find the longest sequence with at most k zeros: - Expand the window by moving the right pointer forward until reaching invalid window, more than <code>k</code> zeros in the current window - Shrink the window by moving the left pointer forward until having a valid window, one of fewer 0's in the current window</p> PythonPython - my solutionC++ <pre><code>class Solution: # (1)\ndef longestOnes(self, nums: List[int], k: int) -&gt; int:\n    left = 0\n\n    for right in range(len(nums)):\n        if nums[right] == 0:\n            k -= 1\n\n        if k &lt; 0:\n            if nums[left] == 0:\n                k += 1\n            left += 1 # (2)\n\n    return right - left + 1\n</code></pre> <ol> <li>This solution is proposed by lee215 and further explained well by hckrtst</li> <li>left and right move together when max window is found. The max window will be changed.</li> </ol> <pre><code>class Solution:\ndef longestOnes(self, nums: List[int], k: int) -&gt; int:\n    left = 0\n    n_zeros = 0\n    n_max_1s = 0\n\n    for right in range(len(nums)):\n        if nums[right] == 0:\n            n_zeros += 1\n\n        while n_zeros &gt; k:\n            if nums[left] == 0:\n                n_zeros -= 1\n            left += 1\n\n        n_max_1s = max(n_max_1s, right - left + 1)\n\n    return n_max_1s\n</code></pre> <pre><code>class Solution {\npublic:\n    int longestOnes(vector&lt;int&gt;&amp; nums, int k) {\n        int nOneKZero = 0;\n        int length = 0;\n        int nZeroInWindow = 0;\n        int left = 0;\n\n        for (int right = 0; right &lt; nums.size(); right++) {\n            // When expanding to right, update number of zeros in the window\n            if (nums[right] == 0) {\n                nZeroInWindow++;\n            }\n\n            // If window is invalid, shrink from left\n            while (nZeroInWindow &gt; k) {\n                if (nums[left] == 0) {\n                    nZeroInWindow--;\n                }\n                left++;\n            }\n\n            // Update length\n            length = right - left + 1;\n            nOneKZero = max(nOneKZero, length);\n        }\n        return nOneKZero;\n    }\n};\n</code></pre>","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     In the worst case, both left and right pointers iterate through the element (total twice). It is still \\(O(n)\\) time complexity.</li> <li>Space complexity: \\(O(1)\\)     Only use several local variables.</li> </ul>","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1004-max-consecutive-ones-iii/#test","title":"Test","text":"","tags":["Array","Sliding Window"]},{"location":"lc-solutions/lc1000-1099/lc1011-capacity-to-ship-packages-within-d-days/","title":"LC1011. Capacity to Ship Packages Within D Days","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1011-capacity-to-ship-packages-within-d-days/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1011: A conveyor belt has packages that must be shipped from one port to another within\u00a0<code>days</code>\u00a0days.</p> <p>The\u00a0<code>ith</code>\u00a0package on the conveyor belt has a weight of\u00a0<code>weights[i]</code>. Each day, we load the ship with packages on the conveyor belt (in the order given by\u00a0<code>weights</code>). We may not load more weight than the maximum weight capacity of the ship.</p> <p>Return the least weight capacity of the ship that will result in all the packages on the conveyor belt being shipped within\u00a0<code>days</code>days.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1011-capacity-to-ship-packages-within-d-days/#clarification","title":"Clarification","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1011-capacity-to-ship-packages-within-d-days/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1011-capacity-to-ship-packages-within-d-days/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1011-capacity-to-ship-packages-within-d-days/#approach-binary-search","title":"Approach - Binary Search","text":"<p>The problem is to find the minimum capacity of the ship so all the packages can be shipped within <code>days</code>. The search space of capacity is <code>[max(weights), sum(weights)]</code>.</p> <ul> <li>If a given capacity <code>c_k</code> meets the requirement, all capacity &gt; <code>c_k</code> also meets the requirement</li> <li>If a give capacity <code>c_k</code> doesn't meet the requirement, all capacity &lt; <code>c_k</code> can't meet the requirement</li> </ul> <p>Base on above mentioned conditions, we can use binary search to speed up the search.</p> Python <pre><code>class Solution:\n    def shipWithinDays(self, weights: List[int], days: int) -&gt; int:\n        left, right = max(weights), sum(weights)\n\n        while left &lt; right:\n            mid = (left + right) // 2\n            if self.canShipWithinDays(weights, days, mid):\n                right = mid\n            else:\n                left = mid + 1\n\n        return left\n\n    def canShipWithinDays(self, weights: List[int], days: int, capacity: int) -&gt; bool:\n        daysNeeded = 1\n        wSum = 0\n        for w in weights:\n            wSum += w\n            if wSum &gt; capacity:\n                daysNeeded += 1\n                wSum = w\n\n        return daysNeeded &lt;= days\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1011-capacity-to-ship-packages-within-d-days/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log s)\\) where \\(n\\) is the number of weights, \\(s\\) is the sum of all weights  <ul> <li>It takes \\(O(n)\\) time to iterate through <code>weights</code> to compute max weight and total weights</li> <li>During the binary search,  <ul> <li>search range is <code>[max(weights), sum(weights)]</code>. In the worst case, it is <code>sum(weights)</code>. So it takes \\(O(\\log s)\\) to do binary search.</li> <li>each step, it takes \\(O(n)\\) to check whether it is feasible</li> <li>So time complexity of whole binary search is \\(O(n \\log s)\\)</li> </ul> </li> </ul> </li> <li>Space complexity: \\(O(1)\\) Only define a few local variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1011-capacity-to-ship-packages-within-d-days/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1046-last-stone-weight/","title":"LC1046. Last Stone Weight","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1000-1099/lc1046-last-stone-weight/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1046: You are given an array of integers\u00a0<code>stones</code>\u00a0where\u00a0<code>stones[i]</code>\u00a0is the weight of the\u00a0<code>ith</code>\u00a0stone.</p> <p>We are playing a game with the stones. On each turn, we choose the heaviest two stones\u00a0and smash them together. Suppose the heaviest two stones have weights\u00a0<code>x</code>\u00a0and\u00a0<code>y</code>\u00a0with\u00a0<code>x &lt;= y</code>. The result of this smash is:</p> <ul> <li>If\u00a0<code>x == y</code>, both stones are destroyed, and</li> <li>If\u00a0<code>x != y</code>, the stone of weight\u00a0<code>x</code>\u00a0is destroyed, and the stone of weight\u00a0<code>y</code>\u00a0has new weight\u00a0<code>y - x</code>.</li> </ul> <p>At the end of the game, there is\u00a0at most one\u00a0stone left.</p> <p>Return\u00a0the weight of the last remaining stone. If there are no stones left, return\u00a0<code>0</code>.</p>","tags":["Heap"]},{"location":"lc-solutions/lc1000-1099/lc1046-last-stone-weight/#clarification","title":"Clarification","text":"<ul> <li>Choose the two heaviest stones</li> <li>Can the input be modified?</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1000-1099/lc1046-last-stone-weight/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap"]},{"location":"lc-solutions/lc1000-1099/lc1046-last-stone-weight/#solution","title":"Solution","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1000-1099/lc1046-last-stone-weight/#approach-heap","title":"Approach - Heap","text":"<p>Use Max Heap to heapify the stones array and pop up two stones at a time to smash until only one stone left:</p> <ul> <li>if two stones equal, continue</li> <li>if two stones different, push the diff to the max heap</li> </ul> <p>Return stone if max heap has one stone otherwise 0</p> Python <pre><code>import heapq\n\n\nclass Solution:\n    def lastStoneWeight(self, stones: List[int]) -&gt; int:\n        stones_negative = [-1 * w for w in stones]\n        heapq.heapify(stones_negative)  # (1)\n\n        # Smash two stones at a time until there is one or no stone left\n        while len(stones_negative) &gt; 1:\n            weight_a = heapq.heappop(stones_negative)\n            weight_b = heapq.heappop(stones_negative)\n            if weight_a != weight_b:\n                heapq.heappush(stones_negative, weight_a - weight_b)  # (2)\n\n        return -heapq.heappop(stones_negative) if len(stones_negative) &gt; 0 else 0  # (3)\n</code></pre> <ol> <li>Since python implements min heap, store negative weights to achieve max heap.</li> <li><code>weight_a - weight_b</code> is negative since <code>weight_a &lt; weight_b</code> based on sequence of popping from min heap.</li> <li>Convert the negative weight back to normal.</li> </ol>","tags":["Heap"]},{"location":"lc-solutions/lc1000-1099/lc1046-last-stone-weight/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(1)\\) <ul> <li>Heapifying the array takes \\(O(n)\\) time.</li> <li>It will iterating total \\(n\\) stones. Each iteration will perform at most 3 heap operations. The heap operation takes \\(\\log s\\) where \\(s\\) is the heap size. The heap size is reduced by one from \\(n\\) to \\(1\\) after each iteration. So the time complexity is \\(O(\\log n) + O(\\log (n - 1)) + \\cdots + O(\\log 1) \\approx O(n \\log n - n + 1) = O(n \\log n)\\).</li> <li>So the total time complexity is \\(O(n) + O(n \\log n) = O(n \\log n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>Define a new array takes \\(O(n)\\).</li> <li>The heap initially takes \\(O(n)\\) space and becomes 0 in the end.</li> <li>So the total space complexity is \\(O(n) + O(n) = O(n)\\).</li> </ul> </li> </ul> How to evaluate \\(\\log n!\\) <p>From the definition of factorial, we know \\(\\log n! = \\log (1 \\times 2 \\times \\cdots \\times n) = \\log 1 + \\log 2 + \\cdots + \\log n = \\sum_{k = 1}^n \\log k\\).</p> <p>Approximating the sum as an integral: \\(\\sum_{k = 1}^n \\log k \\approx \\int_1^n \\log x \\mathop{dx}\\)</p> <p>Computing the integral by using integration by parts: \\(\\int \\log x \\mathop{dx} = x \\log x - \\int x \\mathop{d \\log x} = x \\log x - \\int x \\frac{\\mathop{d \\ln x}}{\\ln 10} = x \\log x - \\int x \\frac{1}{x} \\frac{1}{\\ln 10} \\mathop{dx} = x \\log x - \\frac{x}{\\ln 10}\\)</p> <p>So \\(\\sum_{k = 1}^n \\log k \\approx \\int_1^n \\log x \\mathop{dx} = (n \\log n - \\frac{n}{\\ln 10}) - (1 \\log 1 - \\frac{1}{\\ln 10}) = n \\log n - \\frac{n - 1}{\\ln 10} \\approx n \\log n\\).</p>","tags":["Heap"]},{"location":"lc-solutions/lc1000-1099/lc1046-last-stone-weight/#test","title":"Test","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/","title":"LC1059. All Paths from Source Lead to Destination","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1059: Given the edges of a directed graph where edges[i] = [ai, bi] indicates there is an edge between nodes ai and bi, and two nodes source and destination of this graph, determine whether or not all paths starting from source eventually, end at destination, that is:</p> <p>At least one path exists from the source node to the destination node If a path exists from the source node to a node with no outgoing edges, then that node is equal to destination. The number of possible paths from source to destination is a finite number. Return true if and only if all roads from source lead to destination.</p>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#clarification","title":"Clarification","text":"<ul> <li>Is there a cycle in the path?</li> <li>Graph may not be connected.</li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#assumption","title":"Assumption","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#solution","title":"Solution","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#approach-dfs","title":"Approach - DFS","text":"<p>We can use depth-first search method to traverse the graph and check two conditions:</p> <ol> <li>When reaching leaf node (no neighbors), check whether it is the destination.</li> <li>Check any cycle is detected, using node-coloring variant of DFS as explained in the Introduction to Algorithms book.</li> </ol> Note <p>When traversing using DFS, assign one of the  below 3 colors to every vortex: - White, vertex is not processed yet. Initially, all vertices are white. - Grey, vertex is in processing. DFS for this vertex has started but not finished (i.e, some descendants of this vortex are not process yet) - Black, vertex and all its descendants are processed.</p> <p>How is the cycle detected? Refer to LeetCode editorial explanations. </p> <p>Why a simply visited does not work? Refer to LeetCode editorial explanations. </p> Python <pre><code>class Solution:\n    def __init__(self):\n        # No need to define white, using None instead\n        self.GREY = 1\n        self.BLACK = 2\n\n    def leadsToDestination(self, n: int, edges: List[List[int]], source: int, destination: int) -&gt; bool:\n        vertices = [[] for _ in range(n)]\n        colors = [None] * n  # None: not. visited, 1: in processed, 2: done\n\n        for edge in edges:\n            vertices[edge[0]].append(edge[1])\n\n        return self.dfs(vertices, source, destination, colors)\n\n    def dfs(self, vertices: List[List[int]], curr_node: int, destination: int, colors: List[int]) -&gt; bool:\n        # Detect a cycle\n        # If curr_node is white (not visited) or black (done), won't create a cycle\n        # If curr_node is grey (in process), but receive a incoming link from last step, it is a loop\n        if colors[curr_node] != None:\n            return colors[curr_node] == self.BLACK\n\n        # No outgoing links, reach the end\n        if len(vertices[curr_node]) == 0:\n            return curr_node == destination\n\n        # Mark as grey (in process)\n        colors[curr_node] = self.GREY\n\n        for next_node in vertices[curr_node]:\n            # Short circuit and return false if detected a \"False\" from any recursive call\n            if not self.dfs(vertices, next_node, destination, colors):\n                return False\n\n        # Recursive processing is done, mark the node as black\n        colors[curr_node] = self.BLACK\n        return True\n</code></pre>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(V + E)\\) <ul> <li>Reconstructing vertices from edges takes \\(O(V)\\)</li> <li>Use DFS with color ensures each vertex visited with limited time and takes \\(O(V)\\).</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li>The vortex list store all vertices and their associated neighbors, taking \\(O(V + E)\\).</li> <li>The color takes \\(O(V)\\) space.</li> </ul> </li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#approach2-topological-sorting","title":"Approach2 - Topological Sorting","text":"<p>Topological Sorting</p> python <pre><code>code\n</code></pre>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(1)\\)   Explanation</li> <li>Space complexity: \\(O(n)\\)   Explanation</li> </ul>","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(1)\\) \\(O(n)\\) Approach - \\(O(1)\\) \\(O(n)\\)","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1059-all-paths-from-source-lead-to-destination/#test","title":"Test","text":"","tags":["Depth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1091-shortest-path-in-binary-matrix/","title":"LC1091. Shortest Path in Binary Matrix","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1091-shortest-path-in-binary-matrix/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1091: Given an\u00a0<code>n x n</code>\u00a0binary matrix\u00a0<code>grid</code>, return\u00a0the length of the shortest\u00a0clear path\u00a0in the matrix. If there is no clear path, return\u00a0<code>-1</code>.</p> <p>A\u00a0clear path\u00a0in a binary matrix is a path from the\u00a0top-left\u00a0cell (i.e.,\u00a0<code>(0, 0)</code>) to the\u00a0bottom-right\u00a0cell (i.e.,\u00a0<code>(n - 1, n - 1)</code>) such that:</p> <ul> <li>All the visited cells of the path are\u00a0<code>0</code>.</li> <li>All the adjacent cells of the path are\u00a08-directionallyconnected (i.e., they are different and they share an edge or a corner).</li> </ul> <p>The\u00a0length of a clear path\u00a0is the number of visited cells of this path.</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1091-shortest-path-in-binary-matrix/#clarification","title":"Clarification","text":"<ul> <li>What is clear path?</li> <li>What does 8-directionally connected mean? All 8 elements surround the element are neighbors</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1091-shortest-path-in-binary-matrix/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1091-shortest-path-in-binary-matrix/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1091-shortest-path-in-binary-matrix/#approach-bfs","title":"Approach - BFS","text":"<p>Use Breadth-First Search (BFS) to traverse the nodes.</p> <ul> <li>Each node may have at most 8 neighbors. Add all its valid neighbors that are 0 and not visited.</li> <li>When finding the target, return the current path length that which is also the shorted path.</li> </ul> Python <pre><code>class Solution:\n    def shortestPathBinaryMatrix(self, grid: List[List[int]]) -&gt; int:\n        n_row = len(grid)\n        n_col = len(grid[0])\n        if grid[0][0] != 0 or grid[n_row - 1][n_col - 1] != 0:\n            return -1\n\n        DIRECTIONS = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n\n        queue = deque([(0, 0)])\n        visited = set([(0, 0)])\n        path_len = 1\n\n        while queue:\n            size = len(queue)\n            for _ in range(size):  # (1)\n                curr_row, curr_col = queue.popleft()\n                if curr_row == n_row - 1 and curr_col == n_col - 1:\n                    return path_len\n                for delta_row, delta_col in DIRECTIONS:\n                    next_row, next_col = curr_row + delta_row, curr_col + delta_col\n                    if 0 &lt;= next_row &lt; n_row and 0 &lt;= next_col &lt; n_col and grid[next_row][next_col] == 0 and (next_row, next_col) not in visited:\n                        queue.append((next_row, next_col))\n                        visited.add((next_row, next_col))\n\n            path_len += 1\n\n        return -1  # (2)\n</code></pre> <ol> <li>Explore nodes with the same path length so far.</li> <li>No path found.</li> </ol>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1091-shortest-path-in-binary-matrix/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   Processing a cell takes \\(O(1)\\) and total \\(n\\) cells are processed at most once. So the time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(\\sqrt{n})\\)   In the worst case, the queue will hold the max number of nodes with the same path length, which could be the last row and last column with total \\(2 \\times \\sqrt{n}\\) cells.</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1091-shortest-path-in-binary-matrix/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/","title":"LC1099. Two Sum Less Than K","text":"","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1099: Given an array nums of integers and integer k, return the maximum sum such that there exists i &lt; j with nums[i] + nums[j] = sum and sum &lt; k. If no i, j exist satisfying this equation, return -1.</p>","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#clarification","title":"Clarification","text":"","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#assumption","title":"Assumption","text":"","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#solution","title":"Solution","text":"","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#approach-two-pointers","title":"Approach - Two Pointers","text":"<p>Sort the array first. Then we can use two pointers, <code>left</code> pointers starts from the first element and <code>right</code> pointer starts from the last element, to go through the array.</p> <ul> <li>If <code>sum &lt; k</code>, increase the lower pointer <code>left</code></li> <li>If <code>sum &gt;= k</code>, decrease the upper pointer <code>right</code></li> </ul> <p>Continue until two pointers meet. Explore and track all possible sum that &lt; k.</p> Python <pre><code>class Solution:\n    def twoSumLessThanK(self, nums: List[int], k: int) -&gt; int:\n        nums.sort()  # Time: O(n \\logn)\n        max_sum = -1\n        left, right = 0, len(nums) - 1\n        while left &lt; right:\n            sum = nums[left] + nums[right]\n            if (sum &lt; k):\n                max_sum = max(max_sum, sum)\n                left += 1\n            else:\n                right -= 1\n        return max_sum\n</code></pre>","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) Sorting the array takes \\(O(n \\log n)\\). Tracking sum using two-pointers approach takes \\(O(n)\\). SO the total time complexity is \\(O(n \\log n)\\)</li> <li>Space complexity: \\(O(\\log n)\\)  or \\(O(n)\\) Depends on the implementation of the sorting algorithm.</li> </ul>","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Instead of using two pointers, we can iterate through each element <code>nums[i]</code> and use binary search to find the a complement value <code>nums[j] &lt; k - nums[i]</code>. </p> <p>Notice that Python <code>bisect_left</code> returns the <code>insert point</code> for the searched value, i.e., the first element &gt;= <code>k - nums[i]</code>. Since the sum &lt; k, we consider the element at <code>insert point</code> - 1.</p> Python <pre><code>class Solution:\n    def twoSumLessThanK(self, nums: List[int], k: int) -&gt; int:\n        nums.sort()\n\n        max_sum = -1\n        for left in range(len(nums)):\n            right = bisect.bisect_left(nums, k - nums[left], left + 1) - 1\n            if right &gt; left:\n                max_sum = max(max_sum, nums[left] + nums[right])\n\n        return max_sum\n</code></pre>","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) Sorting takes \\(O(n \\log n)\\) and iterate with binary search takes \\(O(n \\log n)\\).</li> <li>Space complexity: \\(O(\\log n)\\) or \\(O(n)\\) Depend on the implementation of the sorting algorithm.</li> </ul>","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Two Pointers \\(O(n \\log n)\\) \\(O(\\log)\\) or \\(O(n)\\) Approach - Binary Search \\(O(n \\log n)\\) \\(O(\\log)\\) or \\(O(n)\\)","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1000-1099/lc1099-two-sum-less-than-k/#test","title":"Test","text":"","tags":["Sorting","Two Pointers","Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1101-the-earliest-moment-when-everyone-become-friends/","title":"LC1101. The Earliest Moment When Everyone Become Friends","text":"","tags":["Union Find"]},{"location":"lc-solutions/lc1100-1199/lc1101-the-earliest-moment-when-everyone-become-friends/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1101: There are n people in a social group labeled from\u00a0<code>0</code>\u00a0to\u00a0<code>n - 1</code>. You are given an array <code>logs</code>where\u00a0<code>logs[i] = [timestampi, xi, yi]</code>\u00a0indicates that\u00a0<code>xi</code>\u00a0and\u00a0<code>yi</code>\u00a0will be friends at the time\u00a0<code>timestampi</code>.</p> <p>Friendship is\u00a0symmetric. That means if\u00a0<code>a</code>\u00a0is friends with\u00a0<code>b</code>, then\u00a0<code>b</code>\u00a0is friends with\u00a0<code>a</code>. Also, person\u00a0<code>a</code>\u00a0is acquainted with a person\u00a0<code>b</code>\u00a0if\u00a0<code>a</code>\u00a0is friends with\u00a0<code>b</code>, or\u00a0<code>a</code>\u00a0is a friend of someone acquainted with\u00a0<code>b</code>.</p> <p>Return\u00a0the earliest time for which every person became acquainted with every other person. If there is no such earliest time, return\u00a0<code>-1</code>.</p>","tags":["Union Find"]},{"location":"lc-solutions/lc1100-1199/lc1101-the-earliest-moment-when-everyone-become-friends/#clarification","title":"Clarification","text":"<ul> <li>Friendship is symmetric (undirected graph?).</li> <li>Clarifications on acquainted, does long friendship link count for acquainted? 0 - 1 - 2 - 3 - 4 are in single link friendship. Are 0 and 4 acquainted?</li> </ul>","tags":["Union Find"]},{"location":"lc-solutions/lc1100-1199/lc1101-the-earliest-moment-when-everyone-become-friends/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Union Find"]},{"location":"lc-solutions/lc1100-1199/lc1101-the-earliest-moment-when-everyone-become-friends/#solution","title":"Solution","text":"","tags":["Union Find"]},{"location":"lc-solutions/lc1100-1199/lc1101-the-earliest-moment-when-everyone-become-friends/#approach-union-find","title":"Approach - Union Find","text":"<p>First, sort the log by time stamp. Then use union find to union two people based on the log. When comes downs to the single connected component the first time, the time stamp is the earliest time everyone become friends.</p> Python <pre><code>from operator import itemgetter\n\nclass UnionFind:\n    def __init__(self, n):\n        self.root = [i for i in range(n)]\n        self.rank = [0] * n\n        self.group_count = n\n\n    def find(self, x):\n        if x == self.root[x]:\n            return x\n\n        self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x, y):\n        root_x = self.find(x)\n        root_y = self.find(y)\n\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = self.root[root_x]\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = self.root[root_y]\n            else:\n                self.root[root_y] = self.root[root_x]\n                self.rank[root_x] += 1\n            self.group_count -= 1\n\n\nclass Solution:\n    def earliestAcq(self, logs: List[List[int]], n: int) -&gt; int:\n        logs_sorted = sorted(logs, key=itemgetter(0))  # (1)\n\n        uf = UnionFind(n)\n\n        for time_stamp, friend_a, friend_b in logs_sorted:\n            uf.union(friend_a, friend_b)\n\n            if uf.group_count == 1:  # (2)\n                return time_stamp\n\n        return -1  # (3)\n</code></pre> <ol> <li>Sort the events in chronological order in order to find the earliest moment. We can also sort in-place if the input is allowed to change.</li> <li>Return the moment when all individuals are all connected. This is earliest moment.</li> <li>Not everyone connected.</li> </ol>","tags":["Union Find"]},{"location":"lc-solutions/lc1100-1199/lc1101-the-earliest-moment-when-everyone-become-friends/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li> <p>Time complexity: \\(O(m \\log m + n)\\) where \\(n\\) is number of people and \\(m\\) is the number of logs  </p> <ul> <li>First, Sort the logs (Python uses Timsort) takes \\(O(m \\log m\\)) time.</li> <li>Then, creating a union-find data structure takes \\(O(n)\\) time to initialize <code>root</code> and <code>rank</code> arrays.</li> <li>Then iterate through the \\(m\\) sorted logs. At each iteration, it invokes the <code>union</code> function with amortized time complexity of \\(O(\\alpha(n))\\). So all iterations take \\(O(m \\alpha(n))\\). So the total time complexity is \\(O(m \\log m) + O(n) + O(m \\alpha(n))\\) = \\(O(m \\log m + n + m \\alpha(n)) \\approx O(m \\log m + n)\\). The inverse Ackermann function \\(\\alpha(n)\\) grows extremely slowly, almost constant for practical values.</li> </ul> </li> <li> <p>Space complexity: \\(O(n + m)\\) </p> <ul> <li>The space complexity of union-find data structure takes \\(O(n)\\) due to <code>root</code> and <code>rank</code> arrays.</li> <li>The space complexity of the sorting algorithm depends on the implementation. Python uses Timsort, which takes \\(O(m)\\). In Java, the space complexity is \\(O(\\log m)\\). So the total time complexity is \\(O(n) + O(m) = O(n + m)\\)</li> </ul> </li> </ul>","tags":["Union Find"]},{"location":"lc-solutions/lc1100-1199/lc1101-the-earliest-moment-when-everyone-become-friends/#test","title":"Test","text":"<ul> <li><code>n = 1</code>, return 0 since a person is connected to himself.</li> <li>log doesn't connect all nodes.</li> </ul>","tags":["Union Find"]},{"location":"lc-solutions/lc1100-1199/lc1129-shortest-path-with-alternating-colors/","title":"LC1129. Shortest Path with Alternating Colors","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1100-1199/lc1129-shortest-path-with-alternating-colors/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1129: You are given an integer\u00a0<code>n</code>, the number of nodes in a directed graph where the nodes are labeled from\u00a0<code>0</code>\u00a0to\u00a0<code>n - 1</code>. Each edge is red or blue in this graph, and there could be self-edges and parallel edges.</p> <p>You are given two arrays\u00a0<code>redEdges</code>\u00a0and\u00a0<code>blueEdges</code>\u00a0where:</p> <ul> <li><code>redEdges[i] = [ai, bi]</code>\u00a0indicates that there is a directed red edge from node\u00a0<code>ai</code>\u00a0to node\u00a0<code>bi</code>in the graph, and</li> <li><code>blueEdges[j] = [uj, vj]</code>\u00a0indicates that there is a directed blue edge from node\u00a0<code>uj</code>\u00a0to node\u00a0<code>vj</code>\u00a0in the graph.</li> </ul> <p>Return an array\u00a0<code>answer</code>\u00a0of length\u00a0<code>n</code>, where each\u00a0<code>answer[x]</code>\u00a0is the length of the shortest path from node\u00a0<code>0</code>\u00a0to node\u00a0<code>x</code>\u00a0such that the edge colors alternate along the path, or\u00a0<code>-1</code>\u00a0if such a path does not exist.</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1100-1199/lc1129-shortest-path-with-alternating-colors/#clarification","title":"Clarification","text":"<ul> <li>Directed graph with self-edges and parallel edges</li> <li>Shortest path from 0 to x with alternating color on edges</li> <li>redEdges and blueEdges mapped to nodes? ith edge corresponding to ith node?</li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1100-1199/lc1129-shortest-path-with-alternating-colors/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1100-1199/lc1129-shortest-path-with-alternating-colors/#solution","title":"Solution","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1100-1199/lc1129-shortest-path-with-alternating-colors/#approach-bfs","title":"Approach - BFS","text":"<p>Do a breadth-first search, where the \"nodes\" are actually (Node, color of last edge taken). Use <code>visited</code> to track node with the last edge color.</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def __init__(self):\n        self.RED = 0\n        self.BLUE = 1\n\n    def shortestAlternatingPaths(self, n: int, redEdges: List[List[int]], blueEdges: List[List[int]]) -&gt; List[int]:\n        answer = [-1] * n\n        queue = deque([(0, -1)])  # Add (node, last_edge_color) pair, node 0, with no last edge color (-1)\n        visited = set([(0, -1)])\n\n        # Convert edge list with different colors to one node adjacent list with color\n        adj_list = [[] for _ in range(n)]\n        for edge in redEdges:\n            adj_list[edge[0]].append((edge[1], self.RED))\n\n        for edge in blueEdges:\n            adj_list[edge[0]].append((edge[1], self.BLUE))\n\n        path_len = 0\n        while queue:\n            size = len(queue)\n\n            for _ in range(size):\n                node, last_edge_color = queue.popleft()\n                if answer[node] == -1:\n                    answer[node] = path_len\n\n                for next_node_edge_color in adj_list[node]:\n                    if next_node_edge_color[1] != last_edge_color and next_node_edge_color not in visited:\n                        queue.append(next_node_edge_color)\n                        visited.add(next_node_edge_color)\n\n            path_len += 1\n\n        return answer\n</code></pre>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1100-1199/lc1129-shortest-path-with-alternating-colors/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n + e)\\) where \\(n\\) is number of nodes and \\(e\\) is number of edges   The total time complexity consists of:<ul> <li>Converting edges to node adjacent list takes \\(O(e)\\)</li> <li>For BFS, each queue operation takes \\(O(1)\\) time and each node will be visited at most twice (one for blue edge and one for red edge), which takes \\(O(n)\\). For each node, it will go through all edges, both blue and red ones, which takes total \\(O(e)\\). So the time complexity for BFS is \\(O(n + e)\\)</li> </ul> </li> <li>Space complexity: \\(O(n + e)\\) <ul> <li>Build the adjacent list takes \\(O(e)\\) space.</li> <li>The BFS queue takes \\(O(2 \\times 2 \\times n) = O(n)\\). Each node is added at most twice in the form of two integers tuple <code>(node, edge color)</code>.</li> <li>The answer takes \\(O(n)\\) space.</li> <li>The visited takes \\(O(2 \\times 2 \\times n) = O(n)\\) since each node can be visited at most twice (blue and red edges) in the form of two integer tuple <code>(node, edge color)</code>.</li> </ul> </li> </ul>","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1100-1199/lc1129-shortest-path-with-alternating-colors/#test","title":"Test","text":"","tags":["Breadth-First Search"]},{"location":"lc-solutions/lc1100-1199/lc1136-parallel-courses/","title":"LC1136. Parallel Courses","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc1100-1199/lc1136-parallel-courses/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1136: You are given an integer\u00a0<code>n</code>, which indicates that there are\u00a0<code>n</code>\u00a0courses labeled from <code>1</code>\u00a0to\u00a0<code>n</code>. You are also given an array\u00a0<code>relations</code>\u00a0where <code>relations[i] = [prevCoursei, nextCoursei]</code>, representing a prerequisite relationship between course\u00a0<code>prevCoursei</code>\u00a0and course\u00a0<code>nextCoursei</code>: course\u00a0<code>prevCoursei</code>\u00a0has to be taken before course\u00a0<code>nextCoursei</code>.</p> <p>In one semester, you can take\u00a0any number\u00a0of courses as long as you have taken all the prerequisites in the\u00a0previoussemester for the courses you are taking.</p> <p>Return\u00a0the\u00a0minimum\u00a0number of semesters needed to take all courses. If there is no way to take all the courses, return\u00a0<code>-1</code>.</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc1100-1199/lc1136-parallel-courses/#clarification","title":"Clarification","text":"<ul> <li>directed edge from prevCourse to nextCourse</li> <li>index from 1 to n (not 0 to n - 1)</li> <li>takey any number of courses in one semester as long as no prerequisites needed</li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc1100-1199/lc1136-parallel-courses/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Topological Sort"]},{"location":"lc-solutions/lc1100-1199/lc1136-parallel-courses/#solution","title":"Solution","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc1100-1199/lc1136-parallel-courses/#approach-topological-sort","title":"Approach - Topological Sort","text":"<p>This problem is similar to course schedule II problem and can be solved using topological sort. It needs to count number of levels. Each level is for the courses with the same in-degrees. The number of levels indicate the number of semesters.</p> Python <pre><code>from collections import defaultdict, deque\n\n\nclass Solution:\n    def minimumSemesters(self, n: int, relations: List[List[int]]) -&gt; int:\n        # Build adjacent list and compute in degrees from relations.\n        adj_list = defaultdict(list)\n        in_degrees = {i: 0 for i in range(1, n + 1)}  # (1)\n        for prev_course, next_course in relations:\n            if next_course not in adj_list[prev_course]:  # Handle duplicated relations.\n                adj_list[prev_course].append(next_course)  # Directed edge.\n                in_degrees[next_course] += 1\n\n        # Find nodes with zero in-degree\n        zero_in_degree_list = [i for i in range(1, n + 1) if in_degrees[i] == 0]\n        zero_in_degree_queue = deque(zero_in_degree_list)\n\n        # Perform topological sort\n        n_levels = 0\n        n_processed = 0\n        while zero_in_degree_queue:\n            size = len(zero_in_degree_queue)\n            n_processed += size\n            for i in range(size):\n                curr_node = zero_in_degree_queue.popleft()\n                for next_node in adj_list[curr_node]:\n                    in_degrees[next_node] -= 1\n                    if in_degrees[next_node] == 0:\n                        zero_in_degree_queue.append(next_node)\n\n            n_levels += 1\n\n        return n_levels if n_processed == n else -1\n</code></pre> <ol> <li>Use dict comprehension instead of defaultdict since all nodes need to have in-degree.</li> </ol>","tags":["Topological Sort"]},{"location":"lc-solutions/lc1100-1199/lc1136-parallel-courses/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(V + E)\\) where \\(V\\) is number of courses and \\(E\\) is number of relations.<ul> <li>Initialize in_degree dictionary takes \\(O(V)\\) for all \\(V\\) courses.</li> <li>Build adjacent lis takes \\(O(E)\\) time since goes through all relations.</li> <li>Find zero in-degree queue takes \\(O(V)\\) since goes trough all nodes and check in-degree.</li> <li>Queue operations will process all nodes exact once, taking \\(O(V)\\) time.</li> <li>Neighbor explorations of all nodes take \\(O(E)\\) time.</li> <li>So the total time complexity is \\(O(V) + O(E) + O(V) + O(V) + O(E) = O(V + E)\\).</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\).<ul> <li>Adjacent list takes \\(O(V + E)\\) space store all nodes and their edges.</li> <li>In-degree dictionary take \\(O(V)\\) space since store in-degrees for all nodes.</li> <li>Queue may hold all nodes in the worst case, taking \\(O(V)\\).</li> <li>So the total space complexity is \\(O(V + E) + O(V) + O(V) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Topological Sort"]},{"location":"lc-solutions/lc1100-1199/lc1136-parallel-courses/#test","title":"Test","text":"","tags":["Topological Sort"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/","title":"1137. N-th Tribonacci Number","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1137: The Tribonacci sequence Tn is defined as follows:</p> <p>T0 = 0, T1 = 1, T2 = 1, and Tn+3 = Tn + Tn+1 + Tn+2 for n &gt;= 0.</p> <p>Given n, return the value of Tn.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#clarification","title":"Clarification","text":"<ul> <li>Definition of Tribonacci number</li> <li>n &gt;= 0</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#solution","title":"Solution","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#approach-1-iteration","title":"Approach 1: Iteration","text":"<p>The problem can be solved using iteration. The idea is to keep track of the previous three numbers and update them based on the Tribonacci sequence definition.</p> Python <pre><code>class Solution:\n    def tribonacci(self, n: int) -&gt; int:\n        # Base case\n        if n == 0:\n            return 0\n\n        if 0 &lt; n &lt;= 2:\n            return 1\n\n        prev1, prev2, prev3 = 1, 1, 0\n\n        for i in range(3, n + 1):\n            curr = prev1 + prev2 + prev3\n            prev1, prev2, prev3 = curr, prev1, prev2\n\n        return prev1\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n)\\)   The iteration loop iterates over the range from 3 to n+1, which takes \\(O(n)\\) time.</li> <li>Space complexity: \\(O(1)\\)   Only use 4 local variables, so the space complexity is \\(O(1)\\).</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#approach-2-matrix-exponentiation","title":"Approach 2: Matrix Exponentiation","text":"<p>The Tribonacci sequence equation can be converted into a matrix equation:</p> \\[\\underbrace{\\begin{bmatrix} t_{n-2} \\\\ t_{n-1} \\\\ t_{n} \\\\ \\end{bmatrix}}_{T_n} = \\underbrace{\\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 \\\\ \\end{bmatrix}}_{M} \\underbrace{\\begin{bmatrix} t_{n-3} \\\\ t_{n-2} \\\\ t_{n-1} \\\\ \\end{bmatrix}}_{T_{n-1}}\\] <p>Then we can calculate \\(T_n\\) using \\(T_n = M T_{n-1} = M^2 T_{n-2} = \\cdots = M^{n - 2} T_2\\), where \\(T_2 = [t_0, t_1, t_2] = [0, 1, 1]^\\top\\) (i.e., \\(n = 3\\)). It comes down to compute \\(M^n\\). We can use matrix exponential technique to compute \\(M^n\\) in \\(O(\\log n)\\) time. The idea is similar to 50. Power(x, n).</p> python <pre><code>class Solution:\n    def tribonacci(self, n: int) -&gt; int:\n        # Base case\n        if n == 0:\n            return 0\n\n        if 0 &lt; n &lt;=2:\n            return 1\n\n        fib_matrix = np.array([[0, 1, 0], [0, 0, 1], [1, 1, 1]])\n        init_vec = np.array([[0], [1], [1]])\n        fib_matrix_pow = self.fastPow(fib_matrix, n - 2)\n        nth_vec = fib_matrix_pow @ init_vec  # T_n = M^n T_0\n\n        return nth_vec.item((-1, 0))\n\n    def fastPow(self, matrix: npt.NDArray, pow: int) -&gt; npt.NDArray:\n        if pow == 1:\n            return matrix\n\n        res = np.identity(3, dtype=np.uint64)\n\n        while pow &gt; 0:\n            # Handle odd number of pow\n            if pow &amp; 1:\n                res @= matrix\n                pow -= 1\n            matrix @= matrix\n            pow = pow // 2\n\n        return res\n\n    def fastPowRecursion(self, matrix: npt.NDArray, pow: int) -&gt; npt.NDArray:\n        if pow == 1:\n            return matrix\n\n        half = self.fastPow(matrix, pow // 2)\n        res = half @ half  # matrix multiplication\n\n        # Handle odd number of pow\n        if pow &amp; 1:\n            res = res @ matrix\n\n        return res\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(3^3 \\log n)\\)<ul> <li>The matrix exponentiation (<code>fastPow</code> method) takes \\(\\log n\\) steps. Each step conducts matrix multiplication, which takes \\(O(m^3)\\) time, where \\(m = 3\\) for \\(3 \\times 3\\) matrices.</li> <li>So the total time complexity is \\(O(3^3 \\log n)\\).</li> </ul> </li> <li>Space complexity: \\(O(1)\\) using iterative fast power or \\(O(log n)\\) using recursive fast power<ul> <li><code>fastPow</code> takes \\(O(1)\\) space if using iteration method and takes $O(\\log n) space if using recursion method due to recursion stack.</li> <li>local variables for matrices and vector take \\(O(1)\\) space</li> <li>so the total space complexity is \\(O(1)\\) if using iterative fast power and $ \\log n$ if using recursive fast power.</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#approach-3-recursion-memoization","title":"Approach 3: Recursion + Memoization","text":"<p>The problem can also be solved using recursion based on recurrence relation from Tribonacci equation. We will use memoization to store repeated calculations.</p> python <pre><code>class Solution:\n    def __init__(self):\n        self.cache = {}\n\n    def tribonacci(self, n: int) -&gt; int:\n        # Base case\n        if n == 0:\n            return 0\n        if 0 &lt; n &lt;= 2:\n            return 1\n\n        if n in self.cache:\n            return self.cache[n]\n\n        self.cache[n] = self.tribonacci(n - 1) + self.tribonacci(n - 2) + self.tribonacci(n - 3)\n        return self.cache[n]\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n)\\)   Recursively call the function for each number from 0 to n just once and each call   takes \\(O(1)\\) time. So the total time complexity is \\(O(n)\\).</li> <li>Space complexity: \\(O(n)\\) <ul> <li>The cache dictionary stores at most \\(n - 2\\) results.</li> <li>The recursion stack takes \\(O(n)\\) space since the depth could be \\(n\\).</li> <li>So the total space complexity is \\(O(n)\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Iteration \\(O(n)\\) \\(O(1)\\) Approach 2 - Matrix exponential \\(O(\\log n)\\) \\(O(1)\\) Approach 3 - Recursion + Memoization \\(O(n)\\) \\(O(n)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1137-n-th-tribonacci-number/#test","title":"Test","text":"<ul> <li>Test n &lt;= 2</li> <li>Test n &gt; 2</li> <li>Tes very large n to check the time complexity</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/","title":"---","text":"<p>tags:     - Dynamic Programming</p>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#1143-longest-common-subsequence","title":"1143. Longest Common Subsequence","text":""},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1143: Given two strings\u00a0<code>text1</code>\u00a0and\u00a0<code>text2</code>, return\u00a0the length of their longest common subsequence.\u00a0If there is no\u00a0common subsequence, return\u00a0<code>0</code>.</p> <p>A\u00a0subsequence\u00a0of a string is a new string generated from the original string with some characters (can be none) deleted without changing the relative order of the remaining characters.</p> <ul> <li>For example,\u00a0<code>\"ace\"</code>\u00a0is a subsequence of\u00a0<code>\"abcde\"</code>.</li> </ul> <p>A\u00a0common subsequence\u00a0of two strings is a subsequence that is common to both strings.</p>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#clarification","title":"Clarification","text":"<ul> <li>A subsequence is a sequence that appears in the same relative order, but not necessarily contiguous.</li> </ul>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#assumption","title":"Assumption","text":"<p>-</p>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#solution","title":"Solution","text":"<p>This problem can be solved using dynamic programming:</p> <ol> <li>Define the State: Let <code>dp(i, j)</code> be the length of the longest common subsequence of <code>text1[0:i + 1]</code> (from index <code>0</code> to <code>i</code>) and <code>text2[0:j + 1]</code> (from index <code>0</code> to <code>j</code>).</li> <li>State Transition:<ul> <li>If the last characters of both substrings are equal (<code>text1[i] == text2[j]</code>), then:    <code>dp(i, j) = dp(i-1, j-1) + 1</code>.</li> <li>If they are not equal, then: <code>dp(i, j) = max(dp(i-1, j), dp(i, j-1))</code></li> </ul> </li> <li>Base Case: If either string is empty, the longest common subsequence is <code>0</code>.</li> </ol> <p>Note that <code>dp(i, j)</code> can also be defined as the length of the longest common subsequence of <code>text1[i:]</code> (from index <code>i</code> to end) and <code>text2[j:]</code> (from index <code>j</code> to end).</p>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#approach-1-dynamic-programming-top-down-with-memoization","title":"Approach 1: Dynamic Programming (Top-Down with Memoization)","text":"<p>The first approach uses a top-down dynamic programming technique with memoization to find the longest common subsequence. The function <code>dp</code> is defined recursively, and the results are cached to avoid redundant calculations.</p> Python <pre><code>class Solution:\n    def longestCommonSubsequence(self, text1: str, text2: str) -&gt; int:\n        self.cache = {}\n        return self.dp(text1, text2, len(text1) - 1, len(text2) - 1)\n\n    def dp(self, text1: str, text2: str, i: int, j: int) -&gt; int:\n        # Base case\n        if i &lt; 0 or j &lt; 0:\n            return 0\n\n        # Return cached result if exists\n        if (i, j) in self.cache:\n            return self.cache[(i, j)]\n\n        # Recursively update the current result based on previous ones\n        if text1[i] == text2[j]:\n            self.cache[(i, j)] = self.dp(text1, text2, i - 1, j - 1) + 1\n        else:\n            self.cache[(i, j)] = max(self.dp(text1, text2, i - 1, j), self.dp(text1, text2, i, j - 1))\n\n        return self.cache[(i, j)]\n</code></pre>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m n)\\) where <code>m</code> and <code>n</code> are the lengths of <code>text1</code> and <code>text2</code>, respectively   The algorithm explores all possible pairs of indices <code>(i, j)</code> for the two strings   with \\(0 \\leq i &lt; m\\) and \\(0 \\leq j &lt; n\\), leading to a time complexity of \\(O(m n)\\).</li> <li>Space complexity: \\(O(m n)\\) <ul> <li>Memoization cache stores up to \\(m n\\) entries.</li> <li>The recursion stack can go up to a depth of \\(O(m + n)\\) where no characters match and it alternately advance <code>i</code> or <code>j</code> one at a time.</li> <li>Thus, the overall space complexity is \\(O(m n) + O(m + n) = O(m n)\\).</li> </ul> </li> </ul>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#approach-2-dynamic-programming-bottom-up-with-tabulation","title":"Approach 2: Dynamic Programming (Bottom-Up with Tabulation)","text":"<p>The second approach uses a bottom-up dynamic programming technique with tabulation to find the longest common subsequence. It builds a 2D grid <code>dp_grid</code> where <code>dp_grid[i][j]</code> represents the length of the longest common subsequence of <code>text1[0:i + 1]</code> and <code>text2[0:j + 1]</code>. The grid is filled iteratively, starting from the last row and last column (the smallest problem), and moving towards the first row and first column (the largest problem).</p> <p>To facilitate calculation, we add an extra row and column to the grid, initialized to <code>0</code>, which allows us to handle the base case where one of the strings is empty.</p> <p>LeetCode Tutorial on Longest Common Subsequence has a good illustration of the bottom-up approach.</p> <p>To optimize space, we can use two 1D arrays instead of a 2D grid. The previous row is stored in <code>prev_row</code>, and the current row is stored in <code>curr_row</code>. After processing each row, the <code>prev_row</code> is updated to <code>curr_row</code>, and the process continues until the first row is reached.</p> pythonpython - grid <pre><code>class Solution:\n    def longestCommonSubsequence(self, text1: str, text2: str) -&gt; int:\n        # Swap text1 and text2 if text2 is longer to optimize space (smaller arrays)\n        if len(text2) &gt; len(text1):\n            text1, text2 = text2, text1\n\n        n_row, n_col = len(text1), len(text2)\n        dp_grid = [[0] * (n_col + 1) for _ in range(n_row + 1)]  # Initialize n_row x n_col grid with 0s\n\n        # Iterate by rows and then columns, starting from the last row and last column\n        prev_row = [0] * (n_col + 1)\n        for i_row in range(n_row - 1, -1, -1):\n            curr_row = [0] * (n_col + 1)\n            for i_col in range(n_col - 1, -1, -1):\n                if text1[i_row] == text2[i_col]:\n                    curr_row[i_col] = 1 + prev_row[i_col + 1]\n                else:\n                    curr_row[i_col] = max(curr_row[i_col + 1], prev_row[i_col])\n            prev_row = curr_row\n\n        return prev_row[0]\n</code></pre> <pre><code>class Solution:\n    def longestCommonSubsequence(self, text1: str, text2: str) -&gt; int:\n        n_row, n_col = len(text1), len(text2)\n        dp_grid = [[0] * (n_col + 1) for _ in range(n_row + 1)]  # Initialize n_row x n_col grid with 0s\n\n        # Iterate by rows and then columns, starting from the last row and last column\n        for i_row in range(n_row - 1, -1, -1):\n            for i_col in range(n_col - 1, -1, -1):\n                if text1[i_row] == text2[i_col]:\n                    dp_grid[i_row][i_col] = 1 + dp_grid[i_row + 1][i_col + 1]\n                else:\n                    dp_grid[i_row][i_col] = max(dp_grid[i_row + 1][i_col], dp_grid[i_row][i_col + 1])\n\n        return dp_grid[0][0]\n</code></pre>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(m n)\\)   The algorithm use two nested loops to iterate through the characters of <code>text1</code> and <code>text2</code>,   leading to a time complexity of \\(O(m n)\\) where <code>m</code> and <code>n</code> are the lengths of <code>text1</code>   and <code>text2</code>, respectively.</li> <li>Space complexity: \\(O(min(m, n))\\)     The space complexity is reduced to \\(O(min(m, n))\\) by using two 1D arrays instead of a     2D grid. The size of the arrays is the smaller of the two strings.</li> </ul>"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - DP (Top-Down) \\(O(m n)\\) \\(O(m n)\\) Approach 2 - DP (Bottom-Up) \\(O(m n)\\) \\(O(min(m, n))\\)"},{"location":"lc-solutions/lc1100-1199/lc1143-longest-common-subsequence/#test","title":"Test","text":"<ul> <li>Test normal cases</li> <li>Test edge cases with one or both strings empty</li> <li>Test cases with no common subsequence</li> <li>Test cases with all characters matching</li> </ul>"},{"location":"lc-solutions/lc1100-1199/lc1146-snapshot-array/","title":"LC1146. Snapshot Array","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1146-snapshot-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1146: Implement a SnapshotArray that supports the following interface:</p> <ul> <li><code>SnapshotArray(int length)</code>\u00a0initializes an array-like data structure with the given length.\u00a0Initially, each element equals 0.</li> <li><code>void set(index, val)</code>\u00a0sets the element at the given\u00a0<code>index</code>\u00a0to be equal to\u00a0<code>val</code>.</li> <li><code>int snap()</code>\u00a0takes a snapshot of the array and returns the\u00a0<code>snap_id</code>: the total number of times we called\u00a0<code>snap()</code>\u00a0minus\u00a0<code>1</code>.</li> <li><code>int get(index, snap_id)</code>\u00a0returns the value at the given\u00a0<code>index</code>, at the time we took the snapshot with the given\u00a0<code>snap_id</code></li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1146-snapshot-array/#clarification","title":"Clarification","text":"<ul> <li>initial value 0</li> <li>How large it will be? \\(5 \\times 10^4\\)</li> <li>Index out of range detection?</li> <li>Snap Id doesn't exist?</li> <li>What does snapshot mean? Store the current array somewhere to retrieve later?</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1146-snapshot-array/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1146-snapshot-array/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1146-snapshot-array/#approach-binary-search","title":"Approach - Binary Search","text":"<p>First, we need to define a data structure to store the snapshots. We use a list of lists. Each index has its own list of <code>[snap_id, val]</code> which will only be updated when <code>set</code> function is called with unique <code>snap_id</code> value. If there are multiple <code>set</code> calls with the same <code>snap_id</code>, the <code>val</code> is updated with the recent value.</p> <p>Then, when <code>get</code> value for a given <code>index</code> and <code>snap_id</code>. We will get the list of <code>[snap_id, val]</code> for the given <code>index</code>. Since the <code>snap_id</code> is sorted with increasing and unique values, we can use binary search to find the target snap_id and retrieve the <code>val</code>.</p> <p></p> Python <pre><code>class SnapshotArray:\n\n    def __init__(self, length: int):\n        self.array_snapshot = [[[0, 0]] for _ in range(length)]\n        self.snap_id = 0\n\n    def set(self, index: int, val: int) -&gt; None:\n        if self.array_snapshot[index][-1][0] == self.snap_id:\n            self.array_snapshot[index][-1][1] = val  # (1)\n        else:\n            self.array_snapshot[index].append([self.snap_id, val])\n\n    def snap(self) -&gt; int:\n        self.snap_id += 1\n        return self.snap_id - 1\n\n    def get(self, index: int, snap_id: int) -&gt; int:\n        array = self.array_snapshot[index]\n\n        idx_snap = -1\n        left, right = 0, len(array) - 1\n        while left &lt;= right:\n            mid = (left + right) // 2\n            if snap_id &gt;= array[mid][0]:\n                idx_snap = mid\n                left = mid + 1  # (2)\n            else:\n                right = mid - 1\n\n        if idx_snap == -1:\n            return 0\n        else:\n            return self.array_snapshot[index][idx_snap][1]\n</code></pre> <ol> <li>Override previous value if set called for the same snap id</li> <li>Since <code>idx_snap</code> stores the <code>mid</code>, the potential solution, we can use <code>+ 1</code></li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1146-snapshot-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity:  <ul> <li>Constructor: \\(O(n)\\) due to initialization, where \\(n\\) is the length array.  </li> <li>Set, snap: \\(O(1)\\) </li> <li>Get: \\(O(\\log n_{set})\\) where \\(n_{set}\\) is the number of <code>set</code> function calls. Since using binary search, it takes at most \\(\\log n_{set}\\) steps.</li> </ul> </li> <li>Space complexity: \\(O(n_{set})\\)     The snapshot array size is increased with number of <code>set</code> function calls.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1146-snapshot-array/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1100-1199/lc1167-minimum-cost-to-connect-sticks/","title":"LC1167. Minimum Cost to Connect Sticks","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1100-1199/lc1167-minimum-cost-to-connect-sticks/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1167: You have some number of sticks with positive integer lengths. These lengths are given as an array\u00a0<code>sticks</code>, where\u00a0<code>sticks[i]</code>\u00a0is the length of the\u00a0<code>ith</code>\u00a0stick.</p> <p>You can connect any two sticks of lengths\u00a0<code>x</code>\u00a0and\u00a0<code>y</code>\u00a0into one stick\u00a0by paying a cost of <code>x + y</code>. You must connect\u00a0all the sticks until there is only one stick remaining.</p> <p>Return\u00a0the minimum cost of connecting all the given sticks into one stick in this way.</p>","tags":["Heap"]},{"location":"lc-solutions/lc1100-1199/lc1167-minimum-cost-to-connect-sticks/#clarification","title":"Clarification","text":"<ul> <li>Connect any two sticks. Two sticks are connected become a new one.</li> <li>Connect all sticks include the new ones connected in previous steps</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1100-1199/lc1167-minimum-cost-to-connect-sticks/#assumption","title":"Assumption","text":"<ul> <li>The input can be modified.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1100-1199/lc1167-minimum-cost-to-connect-sticks/#solution","title":"Solution","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1100-1199/lc1167-minimum-cost-to-connect-sticks/#approach-heap","title":"Approach - Heap","text":"<p>We can use min heap to store sticks. Always pick two of the smallest sticks to connect and put the new one back to the heap. Continue doing this until only one stick left.</p> Why Pick Two of the Smallest Sticks? <p>Let's start with a simple example of 4 sticks \\(\\text{sticks} = [a_1,\\, a_2,\\, a_3,\\, a_4]\\) and go through it by its original order:</p> <ol> <li>After first merge, \\(\\text{sticks} = [(a_1 + a_2),\\, a_3,\\, a_4]\\), \\(\\text{cost} = (a_1 + a_2)\\).</li> <li>After 2nd merge, \\(\\text{sticks} = [(a_1 + a_2 + a_3),\\, a_4]\\), \\(\\text{cost} = (a_1 + a_2) + (a_1 + a_2 + a_3)\\).</li> <li>Finally, \\(\\text{sticks} = [(a_1 + a_2 + a_3 + a_4)]\\), \\(\\text{cost} = (a_1 + a_2) + (a_1 + a_2 + a_3) + (a_1 + a_2 + a_3 + a_4)\\).</li> </ol> <p>The final cost can be re-written as: \\(\\text{cost} = 3 a_1 + 3 a_2 + 2 a_3 + a_4\\). From the final cost, the sticks which are connected first appear more times in the final cost. Therefore, it is optimal to pick smaller sticks first to get the smallest cost.</p> Python <pre><code>import heapq\n\nclass Solution:\n    def connectSticks(self, sticks: List[int]) -&gt; int:\n        min_cost = 0\n        heapq.heapify(sticks)\n        # Connect two sticks using min heap\n        while len(sticks) &gt; 1:\n            cost = heapq.heappop(sticks) + heapq.heappop(sticks)\n            heapq.heappush(sticks, cost)\n            min_cost += cost\n\n        return min_cost\n</code></pre>","tags":["Heap"]},{"location":"lc-solutions/lc1100-1199/lc1167-minimum-cost-to-connect-sticks/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li><code>heapify</code> the array takes \\(O(n)\\) time.</li> <li>Iterate the array \\(n\\) times and each iteration takes 3 heap operations. Each heap operation takes \\(O(\\log s)\\), where \\(s\\) is the heap size, decreasing from \\(n\\), \\(n - 1\\), \\(\\cdots\\), \\(1\\) after each iteration. So the time complexity to iterate heap is \\(O(\\log n) + O(\\log (n - 1)) + \\cdots + O(log 2) \\approx O(n \\log n)\\).</li> <li>So the total time complexity is \\(O(n) + O(n \\log n) = O(n \\log n)\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\)     The heap stores \\(n\\) elements.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1100-1199/lc1167-minimum-cost-to-connect-sticks/#test","title":"Test","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/","title":"LC1168. Optimize Water Distribution in a Village","text":"","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1168: There are\u00a0<code>n</code>\u00a0houses in a village. We want to supply water for all the houses by building wells and laying pipes.</p> <p>For each house\u00a0<code>i</code>, we can either build a well inside it directly with cost <code>wells[i - 1]</code>\u00a0(note the\u00a0<code>-1</code>\u00a0due to\u00a00-indexing), or pipe in water from another well to it. The costs to lay pipes between houses are given by the array\u00a0<code>pipes</code>\u00a0where each <code>pipes[j] = [house1j, house2j, costj]</code>\u00a0represents the cost to connect\u00a0<code>house1j</code>\u00a0and <code>house2j</code>\u00a0together using a pipe. Connections are bidirectional, and there could be multiple valid connections between the same two houses with different costs.</p> <p>Return\u00a0the minimum total cost to supply water to all houses.</p>","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#clarification","title":"Clarification","text":"<ul> <li>Supply water for all the houses --&gt; fully connected</li> <li>Either build a well or connect it with pipes</li> <li>Connections are bidirectional</li> <li>House index starts from 1</li> </ul>","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#solution","title":"Solution","text":"<p>The problem can be viewed as a weighted undirected graph. Each house represents a vertex and each pipe with cost represents the edge between two houses with weight.</p> <p>The challenging part is how to handle multiple wells with costs associated with houses. The solution is to add one virtual vertex to represent the well and add edges between the well and houses. The weight of the edge is the cost of building a well at the corresponding house.</p> <p>For the input <code>Input: n = 3, wells = [1,2,2], pipes = [[1,2,1],[2,3,1]]</code>, we can create the following graph with the virtual vertex <code>0</code> represents the well.</p> <pre><code>graph LR\n    well(((\"0\")))\n    house1((\"1\"))\n    house2((\"2\"))\n    house3((\"3\"))\n    well -. \"1\" .- house1\n    well -. \"2\" .- house2\n    well -. \"2\" .- house3\n    house1 -- \"1\" --- house2\n    house2 -- \"1\" --- house3</code></pre> <p>The problem of finding the minimal total cost to supply water to all houses is transformed into find a subset of edges that connect all vertices with minimum total weight, i.e., finding a minimum spanning tree.</p>","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#approach-1-kruskals-algorithm-with-union-find","title":"Approach 1 - Kruskal's Algorithm with Union Find","text":"<p>To solve the minimum spanning tree problem, we can use classical Kruskal's algorithm with union-find structure. The algorithm can be implemented with the following two steps:</p> <ol> <li>First, sort all the edges based on their costs, including the additional edges added between the virtual vertex (a well) and houses.</li> <li>Then iterate through the sorted edges. If both vertices belong to different groups using Union Find data structure, add the edge to the minimum spanning tree list and increase the total cost.</li> </ol> Python <pre><code>from operator import itemgetter\n\nclass UnionFind:\n    def __init__(self, size: int) -&gt; None:\n        self.root = [i for i in range(size)]\n        self.rank = [0] * size\n\n    def find(self, x: int) -&gt; int:\n        if x != self.root[x]:\n            self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x: int, y: int) -&gt; bool:  # (1)\n        root_x = self.find(x)\n        root_y = self.find(y)\n\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = root_x\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = root_y\n            else:\n                self.root[root_y] = root_x\n                self.rank[root_x] += 1\n\n    def connected(self, x: int, y: int) -&gt; bool:\n        return self.find(x) == self.find(y)\n\nclass Solution:\n    def minCostToSupplyWater(self, n: int, wells: List[int], pipes: List[List[int]]) -&gt; int:\n        ordered_edges = []\n\n        for index, cost in enumerate(wells):  # (2)\n            ordered_edges.append((0, index + 1, cost))\n\n        ordered_edges.extend(pipes) # (3)\n\n        ordered_edges.sort(key=itemgetter(2))  # (4)\n\n        # (5)\n        uf = UnionFind(n + 1)  # (6)\n        total_cost = 0\n        n_edges_mst = 0\n        for house_1, house_2, cost in ordered_edges:\n            if not uf.connected(house_1, house_2):\n                uf.union(house_1, house_2):\n                total_cost += cost\n                n_edges_mst += 1\n\n            if n_edges_mst &gt;= n:\n                break\n\n        return total_cost\n</code></pre> <ol> <li>Return a flag to indicate whether the joining actually happens within the function. Otherwise, need to add an additional function to check <code>find(a) == find(b)</code>.</li> <li>Add edges between a well (the virtual vertex with index of 0) and houses. The weight of the edge is the cost of building the well.</li> <li>Add the edges from pipes.</li> <li>Sort all edges by their weights.</li> <li>Iterate through the ordered edges and find minimum spanning tree.</li> <li><code>+1</code> for the well (a virtual node).</li> </ol>","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O((V + E) \\log (V + E))\\) where \\(V\\) is the number of houses (vertices) and \\(E\\) is the number of pipes (edges)  <ul> <li>Adding edges between a well and houses takes \\(O(V)\\) iterations;</li> <li>Adding edges from pipes takes \\(O(E)\\) iterations;</li> <li>Sorting \\(V + E\\) edges takes \\(O((V + E) \\log (V + E))\\);</li> <li>Create union find structure takes \\(O(V)\\) time;</li> <li>Go through all edges take \\(O(V + E)\\) iterations and each iteration takes \\(O(\\alpha(V)\\) time. So the overall iteration time is \\(O((V + E) \\alpha(V))\\); So the total time complexity is \\(O(V) + O(E) + O((V + E) \\log (V + E)) + O(V) + O((V + E) \\alpha(V))\\), which can be simplified as \\(O((V + E) (\\log (V + E) + \\alpha(V))) = O((V + E) \\log (V + E))\\).</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li>The order edges list stores \\(V + E\\) edges, taking \\(O(V + E)\\) space;</li> <li>The union-find data structure takes \\(O(V)\\) space to store <code>root</code> and <code>rank</code>;</li> <li>The sorting algorithm in Python (Timsort) takes \\(O(V + E)\\); So the overall space complexity is \\(O(V + E) + O(V) + O(V + E) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#approach-2-prims-algorithm","title":"Approach 2 - Prim's Algorithm","text":"<p>We can also use Prim's algorithm to find the minimum spanning tree.</p> python <pre><code>import heapq\nfrom collections import defaultdict\n\nclass Solution:\n    def minCostToSupplyWater(self, n: int, wells: List[int], pipes: List[List[int]]) -&gt; int:\n        edges = defaultdict(list)\n        for i in range(1, n + 1):\n            edges[0].append((wells[i - 1], i))\n            edges[i].append((wells[i - 1], 0))\n        for house1, house2, cost in pipes:\n            edges[house1].append((cost, house2))\n            edges[house2].append((cost, house1))\n\n        pq = [(0, 0)]  # (cost, index)\n        nodes_in_mst = set()\n        total_cost = 0\n        while pq:\n            curr_cost, curr_id = heapq.heappop(pq)\n            if curr_id in nodes_in_mst:\n                continue\n\n            total_cost += curr_cost\n            nodes_in_mst.add(curr_id)\n\n            if len(nodes_in_mst) == n + 1:\n                break\n\n            for next_cost, next_id in edges[curr_id]:\n                if next_id not in nodes_in_mst:\n                    heapq.heappush(pq, (next_cost, next_id))\n\n        return total_cost\n</code></pre>","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O((V + E) \\log (V + E))\\) where \\(V\\) is the number of nodes and \\(E\\) is the number of pipes.  <ul> <li>Adding edges between a well and houses takes \\(O(V)\\) time;</li> <li>Adding edges from pipes takes \\(O(E)\\) time;</li> <li>In the worst case, the algorithm goes through all edges, \\(O(V + E)\\),including new edges to the virtual node. Each iteration, pop node from heap or push node to queue takes \\(O(\\log (V + E))\\). So the time is \\(O((V + E) \\log (V + E))\\). So the total time complexity is \\(O(V) + O(E) + O((V + E) \\log (V + E))\\) = \\(O((V + E) \\log (V + E))\\).</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li>Edges take \\(O(V + E)\\) space for both vertices and edges;</li> <li>The set takes \\(O(V)\\) space in the worst case;</li> <li>In the worst case, the heap stores all combined edges, \\(V + E\\). So the overall space complexity is \\(O(V + E) + O(V) + O(V + E) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Kruskal's Algorithm \\(O((V + E) \\log (V + E))\\) \\(O(V + E)\\) Approach 2 - Prim's Algorithm \\(O((V + E) \\log (V + E))\\) \\(O(V + E)\\)","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1100-1199/lc1168-optimize-water-distribution-in-a-village/#test","title":"Test","text":"","tags":["Union Find","Minimum Spanning Tree"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/","title":"LC1202. Smallest String With Swaps","text":"","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1202: You are given a string\u00a0<code>s</code>, and an array of pairs of indices in the string\u00a0<code>pairs</code>\u00a0where <code>pairs[i] =\u00a0[a, b]</code>\u00a0indicates 2 indices(0-indexed) of the string.</p> <p>You can\u00a0swap the characters at any pair of indices in the given\u00a0<code>pairs</code> any number of times.</p> <p>Return the\u00a0lexicographically smallest string that\u00a0<code>s</code>\u00a0can be changed to after using the swaps.</p>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#clarification","title":"Clarification","text":"<ul> <li>pairs: pair of indices in the string</li> <li>0-indexed</li> <li>mixed case or just lower case?</li> <li>lexicographically smallest</li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#solution","title":"Solution","text":"<p>The problem can be viewed as a graph problem. Each index is a vertex and each given pair is a undirected edge between the vertices. An edge implies that we can travel from one vertex to another (i.e., swap them in the context of this problem).</p> Tip <p>Since characters in the <code>pairs</code> can be swapped any number of times, letters in a connected component can be rearranged in any order. For example, for <code>(a, b)</code> and <code>(b, c)</code> pairs, we can swap <code>a</code> and <code>c</code> by swapping <code>a</code> with <code>b</code> and then with <code>c</code>.</p>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#approach-1-bfsdfs","title":"Approach 1 - BFS/DFS","text":"<p>Starting from the first letter, use breadth-first search (BFS) or depth-first search (DFS) to find the connected components in the graph. Then sort the characters in each connected component in ascending order and put in sorted indices. Continue the process to re-order letters in the rest of indices.</p> Python - DFSPython - BFS <pre><code>from collections import queue, defaultdict\n\n\nclass Solution:\n    def smallestStringWithSwaps(self, s: str, pairs: List[List[int]]) -&gt; str:\n        n = len(s)\n        # Convert edges to adjacent list of vertices\n        adj_list = defaultdict(list)\n        for i, j in pairs:\n            adj_list[i].append(j)\n            adj_list[j].append(i)  # (1)\n\n        visited = set()\n        s_smallest_list = ['' for _ in range(n)]\n        for i in range(n):  # (2)\n            if i in visited:\n                continue\n\n            indices = []\n            self.dfs(i, adj_list, visited, indices)\n            letters = [s[i] for i in indices]\n\n            # (3)\n            indices.sort()\n            letters.sort()\n\n            for i, ch in zip(indices, letters):\n                s_smallest_list[i] = ch\n\n        return ''.join(s_smallest_list)\n\n    def dfs(\n        self,\n        index: int,\n        adj_list: dict[int, list],\n        visited: set[int],\n        indices: list[int],\n    ) -&gt; None:\n        visited.add(index)\n        indices.append(index)\n\n        for neighbor in adj_list[index]:\n            if neighbor not in visited:\n                self.dfs(neighbor, adj_list, visited, indices)\n</code></pre> <ol> <li>Undirected edge so add both directions.</li> <li>Go through each index and find connected components.</li> <li>Letters in a connected component can be swapped with any others. sort them for the lexicographically order</li> </ol> <pre><code>from collections import queue, defaultdict\n\n\nclass Solution:\n    def smallestStringWithSwaps(self, s: str, pairs: List[List[int]]) -&gt; str:\n        n = len(s)\n        # Convert edges to adjacent list of vertices\n        adj_list = defaultdict(list)\n        for i, j in pairs:\n            adj_list[i].append(j)\n            adj_list[j].append(i)  # (1)\n\n        visited = set()\n        s_smallest_list = [\"\"] * n\n        for i in range(n):  # (2)\n            if i in visited:\n                continue\n\n            indices = []\n            self.dfs(i, adj_list, visited, indices)\n            letters = [s[idx] for idx in indices]\n\n            # (3)\n            letters.sort()\n            indices.sort()\n\n            for i, ch in zip(indices, letters):\n                s_smallest_list[i] = ch\n\n        return ''.join(s_smallest_list)\n\n    def bfs(\n        self,\n        index: int,\n        adj_list: dict[int, list],\n        visited: set[int],\n        indices: list[int],\n    ) -&gt; None:\n        visited.add(index)\n        queue = deque([index])\n\n        # Travel the adjacent indices\n        while queue:\n            curr_index = queue.popleft()\n            indices.append(curr_index)\n            for neighbor in adj_list[curr_index]:\n                if neighbor not in visited:\n                    queue.append(neighbor)\n                    visited.add(neighbor)\n</code></pre> <ol> <li>Undirected edge so add both directions.</li> <li>Go through each index and find connected components.</li> <li>Letters in a connected component can be swapped with any others. sort them for the lexicographically order</li> </ol>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(E + V \\log V)\\) where \\(V\\) is the number of vertices (i.e., the length of the string) and \\(E\\) is the number of edges (the number of pairs).  <ul> <li>Building the adjacent list will take \\(O(E)\\) operation. Each operation takes \\(O(1)\\) time to insert elements into the adjacent list;</li> <li>During the DFS/BFS traversal, each vertex will only be visited once and iterate over the edge list of each vertex. Each edge is also iterated once. So it takes \\(O(V + E)\\);</li> <li>Converting <code>indices</code> to <code>letters</code> takes \\(O(V)\\);</li> <li>Sorting the list of <code>letters</code> and <code>indices</code> take \\(O(V \\log V)\\);</li> <li>Update the smallest string list takes \\(O(V)\\);</li> <li>Convert list of letters to string takes \\(O(V)\\); So the total time complexity is \\(O(V) + O(E) + O(V + E) + O(V) + O(V \\log V) + O(V) + O(V)\\), which is \\(O(E) + O(V \\log V) = O(E + V \\log V)\\).</li> </ul> </li> <li>Space complexity: \\(O(E + V)\\) <ul> <li>Building the adjacent list takes \\(O(E)\\) space;</li> <li>Tracking the visited vertices takes \\(O(V)\\) in the worst case;</li> <li>For traversal, the run time stack of DFS or the queue of BFS will use \\(O(V)\\) space in the worst case;</li> <li>Sorting in Python (timsort) takes \\(O(V)\\) space in the worst case;</li> <li>The smallest string list takes \\(O(V)\\) space So the total space is \\(O(E) + O(V) + O(V) + O(V) + O(V) = O(V + E)\\).</li> </ul> </li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#approach-2-union-find","title":"Approach 2 - Union Find","text":"<p>Similarly, we can use union-find to find all connected components by union <code>pairs</code>. Then, put indices and letters of different parents (connected components) in separate list. For each connected components, sort indices and letters and put them in the smallest string.</p> python <pre><code>class UnionFind:\n    def __init__(self, n):\n        self.parent = [i for i in range(n)]\n        self.rank = [0] * n\n\n    def find(self, x):\n        if x != self.parent[x]:\n            self.parent[x] = self.find(self.parent[x])\n        return self.parent[x]\n\n    def union(self, x, y):\n        parent_x = self.find(x)\n        parent_y = self.find(y)\n\n        if parent_x != parent_y:\n            if self.rank[x] &gt; self.rank[y]:\n                self.parent[parent_y] = parent_x\n            elif self.rank[x] &lt; self.rank[y]:\n                self.parent[parent_x] = parent_y\n            else:\n                self.parent[parent_y] = parent_x\n                self.rank[parent_x] += 1\n\n\nclass Solution:\n    def smallestStringWithSwaps(self, s: str, pairs: List[List[int]]) -&gt; str:\n        n = len(s)\n        uf = UnionFind(n)\n\n        # Use union-find to union pairs for connected component\n        for a, b in pairs:\n            uf.union(a, b)\n\n        # Group indices by connected components\n        groups = defaultdict(lambda: ([], []))\n        for i, ch in enumerate(s):\n            parent = uf.find(i)\n            groups[parent][0].append(i)\n            groups[parent][1].append(ch)\n\n        # Sorting within each group and combine for smallest string\n        res = [\"\"] * n\n        for ids, chars in groups.values():\n            ids.sort()\n            chars.sort()\n            for ch, i in zip(chars, ids):\n                res[i] = ch\n\n        return \"\".join(res)\n</code></pre>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O((E + V) \\alpha(V) + V \\log V)\\) <ul> <li><code>union-find</code> takes \\(O(V)\\) time to initialize;</li> <li>When union pairs, it goes through \\(E\\) pairs and each operation takes \\(O(\\alpha(V))\\) time. The time complexity is \\(O(E \\alpha(V))\\);</li> <li>For grouping by connected components, it takes \\(O(V)\\) operations and each operation takes \\(O(\\alpha(V))\\) to <code>find</code> and \\(O(1)\\) to insert;</li> <li>Sorting takes \\(O(V \\log V)\\) in the worst case;</li> <li>Insert into result and combine into string takes \\(O(V)\\) So the total time complexity is \\(O(V) + O(E \\alpha(V)) + O(V \\alpha(V)) + O(V \\log V) + O(V)\\), which is \\(O((E + V) \\alpha(V) + V \\log V)\\).</li> </ul> </li> <li>Space complexity: \\(O(V)\\) <ul> <li><code>union-find</code> takes \\(O(V)\\) space to store parent and rank;</li> <li><code>groups</code> takes \\(O(V)\\) store indices and letters;</li> <li>sorting in Python (timsoret) takes \\(O(V)\\) space in the worst case;</li> <li>find result takes \\(O(V)\\) space So the total time complexity is \\(O(V) + O(V) + O(V) = O(V)\\)</li> </ul> </li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - \\(O(E + V \\log V)\\) \\(O(V + E)\\) Approach 2 - Union Find \\(O((E + V) \\alpha(V) + V \\log V)\\) \\(O(V)\\)","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1202-smallest-string-with-swaps/#test","title":"Test","text":"<ul> <li>No Pairs: If <code>pairs</code> is empty, return the string as is.</li> <li>Isolated Characters: Characters not in any pairs remain unchanged.</li> <li>Multiple Components: Ensure each connected component is handled independently.</li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1200-1299/lc1231-divide-chocolate/","title":"LC1231. Divide Chocolate","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1231-divide-chocolate/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1231: You have one chocolate bar that consists of some chunks. Each chunk has its own sweetness given by the array\u00a0<code>sweetness</code>.</p> <p>You want to share the chocolate with your\u00a0<code>k</code>\u00a0friends so you start cutting the chocolate bar into\u00a0<code>k + 1</code>\u00a0pieces using\u00a0<code>k</code>\u00a0cuts, each piece consists of some\u00a0consecutive\u00a0chunks.</p> <p>Being generous, you will eat the piece with the\u00a0minimum total sweetness\u00a0and give the other pieces to your friends.</p> <p>Find the\u00a0maximum total sweetness\u00a0of the\u00a0piece you can get by cutting the chocolate bar optimally.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1231-divide-chocolate/#clarification","title":"Clarification","text":"<ul> <li>Sweetness is random or sorted?</li> <li><code>k</code> cuts -&gt; <code>k + 1</code> pieces, one for you, and the other k for friends</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1231-divide-chocolate/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1231-divide-chocolate/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1231-divide-chocolate/#approach-binary-search","title":"Approach - Binary Search","text":"<p>We always receive the piece with the minimum total sweetness. THe problem is to maximize the sweetness of the piece that we take (Note: it is still minimum sweetness compared to other pieces to our friends.).</p> <p>Re-phrase in mathematical terms: the chocolate bar is represented by a non-zero integer array and the sum of a contiguous subarray stands for the sweetness of a piece. The task is to find the maximum possible minimum sum of all subarrays after dividing the array into <code>k + 1</code> contiguous subarrays with <code>k</code> cuts.</p> <p>Similar to the idea used in LC410 split array largest sum, we can search for minimum sweetness to cut chocolate bar. For a given minimum sweetness,</p> <ul> <li>If number of pieces <code>&gt;= k + 1</code>, increase the minimum sweetness</li> <li>Otherwise, some friends can't get a piece of chocolate, need to decrease the minimum sweetness</li> </ul> <p>Based on above mentioned properties, we can use binary search to find the minimum sweetness.</p> Python <pre><code>class Solution:\n    def maximizeSweetness(self, sweetness: List[int], k: int) -&gt; int:\n        ans = -1\n        low, high = min(sweetness), sum(sweetness) // (k + 1)  # (1)\n\n        while low &lt; high:\n            mid = (low + high + 1) // 2  # (2)\n            if self.canBeDivided(sweetness, k, mid):\n                low = mid\n            else:\n                high = mid - 1\n        return high\n\n    def canBeDivided(self, sweetness: List[int], k: int, target: int):\n        count, curr_sum = 0, 0\n        for value in sweetness:\n            curr_sum += value\n            if curr_sum &gt;= target:\n                count += 1\n                curr_sum = 0  # (3)\n        return count &gt; k\n</code></pre> <ol> <li>The upper bound is <code>sum(sweetness) // (k + 1)</code>. If not, any value, <code>x &gt; sum(sweetness) // (k + 1)</code>, will lead to <code>x * (k + 1) &gt; sum(sweetness)</code>.</li> <li>Due to <code>low = mid</code> and <code>high = mid - 1</code> conditions. If <code>low = mid + 1</code> and <code>high = mid</code>, use <code>mid = (low + high) // 2</code></li> <li>Reset to 0 since the piece is cut and start a new piece</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1231-divide-chocolate/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log (s/(k + 1)))\\) where \\(n\\) is the number of chunks and \\(s\\) is the total sweetness. The binary search space is <code>s / (k + 1)</code>, it takes \\(O(\\log s/(k+1))\\) by using binary search. For each iteration of binary search, we need to traverse the whole chocolate bar, which takes \\(O(n)\\) time.</li> <li>Space complexity: \\(O(1)\\) Use limited variables. </li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1231-divide-chocolate/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/","title":"1232 Check if it is a straight line","text":"<p>tags:     - Array     - Math     - Geometry</p>"},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/#lc1232-check-if-it-is-a-straight-line","title":"LC1232. Check If It Is a Straight Line","text":""},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1232: You are given an array\u00a0<code>coordinates</code>,\u00a0<code>coordinates[i] = [x, y]</code>, where\u00a0<code>[x, y]</code>\u00a0represents the coordinate of a point. Check if these points\u00a0make a straight line in the XY plane.</p>"},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/#clarification","title":"Clarification","text":"<ul> <li>Any duplicates</li> <li>Integer or float point</li> </ul>"},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/#assumption","title":"Assumption","text":""},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/#solution","title":"Solution","text":""},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/#approach-math","title":"Approach - Math","text":"<p>To check if points make a straight line, we can go through points by pair and check whether they have the same slope. For any 2 points \\((x_0, y_0)\\) and \\((x_1, y_1)\\) and any given 3rd point \\((x, y)\\), if they are in a straight line, the slopes between points are equal:</p> \\[ (y - y_1) / (x - x_1) = (y_1 - y_0) / (x_1 - x_0) \\tag{1.1}\\] <p>In order to avoid being divided by 0, change the above equation to the multiplication form:</p> \\[ (y - y_1) (x_1 - x_0) = (x - x_1) (y_1 - y_0) \\] Python <pre><code>class Solution:\n    def checkStraightLine(self, coordinates: List[List[int]]) -&gt; bool:\n        n_points = len(coordinates)\n\n        if n_points == 1:\n            return False\n\n        if n_points == 2:\n            return True\n\n        (x0, y0), (x1, y1) = coordinates[:2]\n\n        for i in range(2, len(coordinates)):\n            (x, y) = coordinates[i]\n            if (x1 - x0) * (y - y1) != (y1 - y0) * (x - x1):\n                return False\n\n        return True\n</code></pre>"},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Need to to go through all points and check slope.</li> <li>Space complexity: \\(O(1)\\)     Use limited local variables. </li> </ul>"},{"location":"lc-solutions/lc1200-1299/lc1232-check-if-it-is-a-straight-line/#test","title":"Test","text":""},{"location":"lc-solutions/lc1200-1299/lc1235-maximum-profit-in-job-scheduling/","title":"LC1235. Maximum Profit in Job Scheduling","text":"","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1235-maximum-profit-in-job-scheduling/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1235: We have\u00a0<code>n</code>\u00a0jobs, where every job is scheduled to be done from\u00a0<code>startTime[i]</code>\u00a0to\u00a0<code>endTime[i]</code>, obtaining a profit of\u00a0<code>profit[i]</code>.</p> <p>You're given the\u00a0<code>startTime</code>,\u00a0<code>endTime</code>\u00a0and\u00a0<code>profit</code>\u00a0arrays, return the maximum profit you can take such that there are no two jobs in the subset with overlapping time range.</p> <p>If you choose a job that ends at time\u00a0<code>X</code>\u00a0you will be able to start another job that starts at time\u00a0<code>X</code>.</p>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1235-maximum-profit-in-job-scheduling/#clarification","title":"Clarification","text":"","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1235-maximum-profit-in-job-scheduling/#assumption","title":"Assumption","text":"","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1235-maximum-profit-in-job-scheduling/#solution","title":"Solution","text":"","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1235-maximum-profit-in-job-scheduling/#approach-dynamic-programming-binary-search","title":"Approach - Dynamic Programming + Binary Search","text":"<p>First, sort the job by <code>endTime</code>. Then solve it using dynamic programming, where <code>dp[endTime] = profit</code> is the profit within the <code>endTime</code>, induction rule is - Don't do the job, profit won't be changed. - Do this job, binary search in the dp to find the largest profit before start time <code>s</code>, <code>dp[endTimeBeforeStart]</code>. Then <code>dp[endTime] = max(dp[prevEndTime], dp[endTimeBeforeStart]</code>.</p> <p>The base case is <code>dp[0] = 0</code> as we make 0 profit at <code>time = 0</code>.</p> Python <pre><code>class Solution:\n    def jobScheduling(self, startTime: List[int], endTime: List[int], profit: List[int]) -&gt; int:\n        jobs = sorted(zip(startTime, endTime, profit), key=lambda v: v[1])  # sorted by endTime\n        dp = [[0, 0]]\n        for s, e, p in jobs:\n            i = bisect.bisect(dp, [s + 1]) - 1  # (1)\n            if dp[i][1] + p &gt; dp[-1][1]:\n                dp.append([e, dp[i][1] + p])\n        return dp[-1][1]\n</code></pre> <ol> <li><code>s+1</code> for search dp[i][0] &gt;= s + 1, <code>-1</code> from search result to return <code>dp[i][0] &lt;= s</code></li> </ol>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1235-maximum-profit-in-job-scheduling/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) The sorting takes \\(O(n \\log n)\\) and binary search of each job takes another \\(O(n \\log n)\\).</li> <li>Space complexity: \\(O(n)\\) The sorting takes \\(O(n)\\) and <code>dp</code> also takes \\(O(n)\\).</li> </ul>","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1235-maximum-profit-in-job-scheduling/#test","title":"Test","text":"","tags":["Dynamic Programming","Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1283-find-the-smallest-divisor-given-a-threshold/","title":"LC1283. Find the Smallest Divisor Given a Threshold","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1283-find-the-smallest-divisor-given-a-threshold/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1283: Given an array of integers\u00a0<code>nums</code>\u00a0and an integer\u00a0<code>threshold</code>, we will choose a positive integer\u00a0<code>divisor</code>, divide all the array by it, and sum the division's result. Find the\u00a0smallest <code>divisor</code>\u00a0such that the result mentioned above is less than or equal to\u00a0<code>threshold</code>.</p> <p>Each result of the division is rounded to the nearest integer greater than or equal to that element. (For example:\u00a0<code>7/3 = 3</code>\u00a0and\u00a0<code>10/2 = 5</code>).</p> <p>The test cases are generated so\u00a0that there will be an answer.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1283-find-the-smallest-divisor-given-a-threshold/#clarification","title":"Clarification","text":"<ul> <li>samllest divisor</li> <li>nearest integer greater than or equal to that element</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1283-find-the-smallest-divisor-given-a-threshold/#assumption","title":"Assumption","text":"<ul> <li>Positive numbers</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1283-find-the-smallest-divisor-given-a-threshold/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1283-find-the-smallest-divisor-given-a-threshold/#approach-binary-search","title":"Approach - Binary Search","text":"<p>If increasing divisor, sum of division decreases. We can use binary search to quickly find the divisor.</p> <ul> <li>If sum of division &gt; threshold, it is true for all divisor &lt; current divisor. So increase divisor to search the right part of the current divisor</li> <li>Otherwise, reduce divisor and search the left part of the current divisor</li> </ul> Note <p>For integer ceiling division, we can simply add <code>division - 1</code> to the numerator, i.e., <code>(num + division - 1) // division</code>.</p> Python <pre><code>class Solution:\n    def smallestDivisor(self, nums: List[int], threshold: int) -&gt; int:\n        left, right = 1, max(nums)\n\n        while left &lt; right:\n            mid = (left + right) // 2\n            division_sum = self.sumOfDivision(nums, mid)\n            if division_sum &lt;= threshold:\n                right = mid\n            else:\n                left = mid + 1\n\n        return left\n\n    def sumOfDivision(self, nums: List[int], division: int) -&gt; int:\n        division_sum = 0\n        for num in nums:\n            division_sum += (num + division - 1) // division\n\n        return division_sum\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1283-find-the-smallest-divisor-given-a-threshold/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log m)\\), where \\(n\\) is the number of elements and \\(m\\) is the maximum element of the array  <ul> <li>Every time reduce the search space of possible divisors by half, \\(m \\rightarrow m/2 \\rightarrow m/4 \\rightarrow \\cdots \\rightarrow 1\\). The are \\(\\log m\\) iterations.</li> <li>For each divisor, we iterate on the whole array to find the sum of division, which takes \\(O(n)\\) time</li> <li>Thus, for \\(\\log m\\) divisors, overall it takes \\(O(n \\log m)\\) time</li> </ul> </li> <li>Space complexity: \\(O(1)\\) Only several variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1200-1299/lc1283-find-the-smallest-divisor-given-a-threshold/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/","title":"1335. Minimum Difficulty Of A Job Schedule","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1335: You want to schedule a list of jobs in\u00a0<code>d</code>\u00a0days. Jobs are dependent (i.e To work on the <code>ith</code>\u00a0job, you have to finish all the jobs\u00a0<code>j</code>\u00a0where\u00a0<code>0 &lt;= j &lt; i</code>).</p> <p>You have to finish\u00a0at least\u00a0one task every day. The difficulty of a job schedule is the sum of difficulties of each day of the\u00a0<code>d</code>\u00a0days. The difficulty of a day is the maximum difficulty of a job done on that day.</p> <p>You are given an integer array\u00a0<code>jobDifficulty</code>\u00a0and an integer\u00a0<code>d</code>. The difficulty of the\u00a0<code>ith</code>\u00a0job is\u00a0<code>jobDifficulty[i]</code>.</p> <p>Return\u00a0the minimum difficulty of a job schedule. If you cannot find a schedule for the jobs return\u00a0<code>-1</code>.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#solution","title":"Solution","text":"<p>The problem can be solved using dynamic programming by defining:</p> <ul> <li>State: <code>min_diff(i, d)</code> represents the minimum difficulty of scheduling when starting at the <code>i</code>th job with <code>d</code> days left.</li> <li>State transition: For starting job <code>i</code>, we can choose to end the current day at job <code>j</code> (where <code>j</code> is between <code>i + 1</code> and the last possible job for the current day, <code>n - d + 1</code>), and the difficulty for that day would be the maximum job difficulty from job <code>i</code> to job <code>j</code>. So the state transition can be expressed as:</li> </ul> \\[\\text{min_diff}(i, d) = \\min_{j=i+1}^{n-d+1} \\left( \\text{min_diff}(j+1, d-1) + \\max(\\text{jobDifficulty}[i:j]) \\right)\\] <ul> <li> <p>Base case: When there is only one day left (<code>d == 1</code>), the difficulty is simply the maximum job difficulty from job <code>i</code> to the end of the list: \\(\\text{min_diff}(i, 1) = \\max(\\text{jobDifficulty}[i:])\\)</p> </li> <li> <p>Edge case: If there are fewer jobs than days, return <code>-1</code> since it's impossible to schedule.</p> </li> </ul> <pre><code>graph TD\n    min_diff_0_3(\"min_diff(0, 3)\") --- min_diff_1_2(\"min_diff(1, 2)\")\n    min_diff_0_3 --- min_diff_2_2(\"min_diff(2, 2)\")\n    min_diff_0_3 --- min_diff_3_2(\"min_diff(3, 2)\")\n    min_diff_0_3 --- min_diff_4_2(\"min_diff(4, 2)\")\n    min_diff_1_2 --- min_diff_2_1(\"min_diff(2, 1)\")\n    min_diff_1_2 --- min_diff_3_1(\"min_diff(3, 1)\")\n    min_diff_1_2 --- min_diff_4_1(\"min_diff(4, 1)\")\n    min_diff_1_2 --- min_diff_5_1(\"min_diff(5, 1)\")</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#approach-1-top-down-dynamic-programming","title":"Approach 1: Top-Down Dynamic Programming","text":"<p>Based on the state and state transition defined above, we can implement a top-down dynamic programming solution using memoization to avoid redundant calculations.</p> PythonPython - LRU Cache <pre><code>class Solution:\n  def minDifficulty(self, jobDifficulty: List[int], d: int) -&gt; int:\n      n = len(jobDifficulty)\n\n      # Edge case: make sure there is at least one job per day\n      if n &lt; d:\n          return -1\n\n      self.memo = {}\n\n      return self._min_diff(jobDifficulty, 0, d)\n\n  def _min_diff(self, jobDifficulty: List[int], i: int, days_remaining: int) -&gt; int:\n      # Return cached results if exist\n      if (i, days_remaining) in self.memo:\n          return self.memo[(i, days_remaining)]\n\n      # Base case: finish all remaining jobs in the last day\n      if days_remaining == 1:\n          self.memo[(i, days_remaining)] = max(jobDifficulty[i:])\n          return self.memo[(i, days_remaining)]\n\n      n = len(jobDifficulty)\n      min_total = float('inf')\n      daily_max_job_diff = 0  # the maximum difficulty of today\n\n      # Iterate through possible starting index for the next day\n      # and ensure there is at least one job for each remaining day.\n      for j in range(i, n - days_remaining + 1):\n          daily_max_job_diff = max(daily_max_job_diff, jobDifficulty[j])\n          total = daily_max_job_diff + self._min_diff(jobDifficulty, j + 1, days_remaining - 1)\n          min_total = min(min_total, total)\n\n      self.memo[(i, days_remaining)] = int(min_total)\n      return int(min_total)\n</code></pre> <pre><code>from functools import lru_cache\n\nclass Solution:\n    def minDifficulty(self, jobDifficulty: List[int], d: int) -&gt; int:\n        n = len(jobDifficulty)\n\n        # Edge case: make sure there is at least one job per day\n        if n &lt; d:\n            return -1\n\n        return self._min_diff(tuple(jobDifficulty), 0, d)  # (1)\n\n    @lru_cache(None)\n    def _min_diff(self, jobDifficulty: tuple, i: int, days_remaining: int) -&gt; int:\n        # Base case: finish all remaining jobs in the last day\n        if days_remaining == 1:\n            return max(jobDifficulty[i:])\n\n        n = len(jobDifficulty)\n        min_total = float('inf')\n        daily_max_job_diff = 0  # the maximum difficulty of today\n\n        # Iterate through possible starting index for the next day\n        # and ensure there is at least one job for each remaining day.\n        for j in range(i, n - days_remaining + 1):\n            daily_max_job_diff = max(daily_max_job_diff, jobDifficulty[j])\n            total = daily_max_job_diff + self._min_diff(jobDifficulty, j + 1, days_remaining - 1)\n            min_total = min(min_total, total)\n\n        return int(min_total)\n</code></pre> <ol> <li><code>jobDifficulty</code> is passed as a <code>tuple</code> into <code>_min_diff()</code> so it's hashable and usable with <code>@lru_cache</code></li> </ol>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n^2 \\cdot d)\\) where \\(n\\) is the number of jobs and \\(d\\) is the number of days.<ul> <li>Number of unique states: \\(O(n \\cdot d)\\). For state \\((i, d)\\),<ul> <li>\\(i\\): job index, from \\(0\\) to \\(n-1\\), which is \\(O(n)\\)</li> <li>\\(d\\): remaining days, from \\(1\\) to \\(d\\), which is \\(O(d)\\)</li> </ul> </li> <li>Each state takes \\(O(n)\\) time to compute the minimum difficulty for the remaining jobs</li> <li>Total time complexity: \\(O(n \\cdot d) \\cdot O(n) = O(n^2 \\cdot d)\\)</li> </ul> </li> <li>Space complexity: \\(O(n \\cdot d)\\) <ul> <li>The memoization dictionary stores results for each unique state \\((i, d)\\), which has \\(O(n \\cdot d)\\) entries. So as the LRU cache.</li> <li>The recursion call stack can go up to \\(O(d)\\) deep.</li> <li>So the total space complexity is \\(O(n \\cdot d) + O(d) = O(n \\cdot d)\\).</li> </ul> </li> </ul> Refined analysis of unique states <p>The valid unique states \\((i, d)\\) are those where \\(n - i \\geq d \\rightarrow i \\leq n - d\\). So we can sum over valid \\(i\\) values for each \\(d\\):</p> \\[\\sum_{k=1}^d (n - k + 1) = d \\cdot n - \\frac{d(d-1)}{2}\\] <p>This is \\(O(n \\cdot d - d^2)\\) with the upper bound of \\(O(n \\cdot d)\\).</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#approach-2-bottom-up-1d-dynamic-programming","title":"Approach 2: Bottom-Up 1D Dynamic Programming","text":"<p>We can also implement a bottom-up dynamic programming solution by iteratively filling a DP table based on the state transition defined above. Since the state only depends on the previous day's results, we can optimize the space complexity to \\(O(n)\\) by using a single array to store the minimum difficulty for the next day.</p> python <pre><code>class Solution:\n  def minDifficulty(self, jobDifficulty: List[int], d: int) -&gt; int:\n      n = len(jobDifficulty)\n      min_diff_prev_day = [float('inf')] * n + [0]\n      for days_remaining in range(1, d + 1):\n          min_diff_curr_day = [float('inf')] * n + [0]\n          for i in range(n - days_remaining + 1):\n              daily_max_job_diff = 0\n              for j in range(i + 1, n - days_remaining + 2):\n                  daily_max_job_diff = max(daily_max_job_diff, jobDifficulty[j - 1])\n                  min_diff_curr_day[i] = min(min_diff_curr_day[i], daily_max_job_diff + min_diff_prev_day[j])\n          min_diff_prev_day = min_diff_curr_day\n\n      return min_diff_prev_day[0] if min_diff_prev_day[0] &lt; float('inf') else -1\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n^2 \\cdot d)\\) <ul> <li>Similar to Approach 1, we have \\(O(n \\cdot d)\\) unique states.</li> <li>Each state takes \\(O(n)\\) time to compute the minimum difficulty for the remaining jobs.</li> <li>Total time complexity: \\(O(n \\cdot d) \\cdot O(n) = O(n^2 \\cdot d)\\)</li> </ul> </li> <li>Space complexity: \\(O(n)\\) <ul> <li>We only use two arrays of size \\(n\\) to store the minimum difficulty for the current and previous days, so the space complexity is \\(O(n)\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Top-Down \\(O(n^2 \\cdot d)\\) \\(O(n \\cdot d)\\) Approach - Bottom-Up \\(O(n^2 \\cdot d)\\) \\(O(n)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1335-minimum-difficulty-of-a-job-schedule/#test","title":"Test","text":"<ul> <li>Test \\(n\\) &lt; \\(d\\) (impossible to schedule)</li> <li>Test \\(n\\) = \\(d\\) (each job on a separate day)</li> <li>Test \\(n\\) &gt; \\(d\\) (multiple jobs on some days)</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/","title":"LC1337. The K Weakest Rows in a Matrix","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1337: You are given an\u00a0<code>m x n</code>\u00a0binary matrix\u00a0<code>mat</code>\u00a0of\u00a0<code>1</code>'s (representing soldiers) and\u00a0<code>0</code>'s (representing civilians). The soldiers are positioned\u00a0in front\u00a0of the civilians. That is, all the\u00a0<code>1</code>'s will appear to the\u00a0left\u00a0of all the\u00a0<code>0</code>'s in each row.</p> <p>A row\u00a0<code>i</code>\u00a0is\u00a0weaker\u00a0than a row\u00a0<code>j</code>\u00a0if one of the following is true:</p> <ul> <li>The number of soldiers in row\u00a0<code>i</code>\u00a0is less than the number of soldiers in row\u00a0<code>j</code>.</li> <li>Both rows have the same number of soldiers and\u00a0<code>i &lt; j</code>.</li> </ul> <p>Return\u00a0the indices of the <code>k</code> weakest\u00a0rows in the matrix ordered from weakest to strongest.</p>","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#clarification","title":"Clarification","text":"<ul> <li>Binary matrix</li> <li>All the 1's appear to the left of all the 0's (how to use it?)</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#solution","title":"Solution","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#approach-heap","title":"Approach - Heap","text":"<p>The problem can be solved using max queue to store top k weakest rows. The priority are determined by two numbers <code>(number of soldiers, row_id)</code>. Note that when using <code>tuple</code> in python <code>heapq</code>, it will compare the first elements of tuples. If they are equal, it will compare the second elements to break the tie. If the comparison is customized, we can create a class with <code>__lt__</code> method.</p> <pre><code>class Item:\n    def __init__(self, value, row_id):\n        self.value = value\n        self.row_id = row_id\n\n    def __lt__(self, other):\n        # Compare by value first, then by row id if values are equal\n        return (self.value, self.row_id) &lt; (other.value, other.row_id)\n</code></pre> Python <pre><code>import heapq\n\nclass Solution:\n    def kWeakestRows(self, mat: List[List[int]], k: int) -&gt; List[int]:\n        max_heap = []\n        for i_row, row in enumerate(mat):\n            n_soldiers = row.count(1)  # (1)\n            heapq.heappush(max_heap, Item(-n_soldiers, -i_row))  # (2)\n            if len(max_heap) &gt; k:\n                heapq.heappop(max_heap)\n\n        # Essentially, pop items from \"max heap\".\n        # (3)\n        indices = [-heapq.heappop(max_heap)[1] for i in range(len(max_heap))]\n        return indices[::-1]  # (4)\n</code></pre> <ol> <li>Could use binary search to find the index of first <code>0</code> and the count is <code>index + 1</code> based on \"all the\u00a0<code>1</code>'s will appear to the\u00a0left\u00a0of all the\u00a0<code>0</code>'s in each row\".</li> <li>Store negative numbers to achieve max heap.</li> <li>Pop negative numbers from small to large (i.e., positive numbers from high to low).</li> <li>Reverse the order since it is sorted from largest to smallest.</li> </ol>","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m n + m\\log k)\\) or \\(O(m \\log n + m \\log k)\\)<ul> <li>Iterate all \\(m\\) rows. Each iteration will<ul> <li>count number of <code>1</code>s which takes \\(O(n)\\). This could be reduced to \\(O(\\log n)\\) if using binary search.</li> <li>conduct at most two heap operations which takes \\(O(\\log k)\\) sine the heap size is maintained at \\(k\\).</li> <li>So iterating all rows take \\(O(m n + m \\log k)\\) or \\(O(m \\log n + m \\log k)\\) using binary search.</li> </ul> </li> <li>Popping all items from the heap takes \\(O(k)\\).</li> <li>Reversing the final result of \\(k\\) items takes \\(O(k)\\).</li> <li>So the total time complexity is \\(O(m n + m \\log k) + O(k) + O(k) = O(m n + m \\log k)\\) or \\(O(m \\log n + m \\log k)\\) using binary search.</li> </ul> </li> <li>Space complexity: \\(O(k)\\)     The heap size is \\(k\\), taking \\(O(k)\\) space. The final result list takes \\(O(k)\\) space.     So the total space complexity is \\(O(k)\\).</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#approach-2-vertical-iteration","title":"Approach 2 - Vertical Iteration","text":"<p>Instead of going through row by row, we can scan column by column to find the k weakest rows. This method takes advantage of \"all the\u00a0<code>1</code>'s will appear to the\u00a0left\u00a0of all the\u00a0<code>0</code>'s in each row\". It doesn't need to calculate weakest condition. Instead, it finds the first 0s for each columns. The order of 0s found is the order of k weakest rows.</p> python <pre><code>class Solution:\n    def kWeakestRows(self, mat: List[List[int]], k: int) -&gt; List[int]:\n        n_rows, n_cols = len(mat), len(mat[0])\n\n        k_weakest_rows = []\n        # Scan matrix column by column\n        for i_col in range(n_cols):\n            for j_row in range(n_rows):\n                if len(k_weakest_rows) == k:\n                    return k_weakest_rows\n                # (1)\n                if mat[j_row][i_col] == 0 and (\n                    i_col == 0 or mat[j_row][i_col - 1] == 1\n                ):\n                    k_weakest_rows.append(j_row)\n\n        # (2)\n        i_row = 0\n        while len(k_weakest_rows) &lt; k:\n            # (3)\n            if mat[i_row][-1] == 1:\n                k_weakest_rows.append(i_row)\n            i_row += 1\n\n        return k_weakest_rows\n</code></pre> <ol> <li>Check whether it is the first 0 in the corresponding row, i.e., left is 1 and current is 0, <code>[..., 1, 1, 0, 0, ...]</code>.</li> <li>Edge cases: number of rows with 0s &lt; k, indicating some of the first k weakest rows are entirely 1s.</li> <li>If last element in the row is 1, indicating the whole row is 1s, which is not included yet.</li> </ol>","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(m n)\\) <ul> <li>Scanning matrix column by column to find k first 0s, taking \\(O(m n)\\) time.</li> <li>For edge cases, it takes at most \\(O(k)\\) iterations to find the rest of weakest rows.</li> <li>So the total time complexity is \\(O(m n)\\).</li> </ul> </li> <li>Space complexity: \\(O(k)\\)     The final result list store \\(k\\) indices.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Heap \\(O(m \\log n + m \\log k)\\) \\(O(k)\\) Approach 2 - Vertical Iteration \\(O(m n)\\) \\(O(k)\\)","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1337-the-k-weakest-rows-in-a-matrix/#test","title":"Test","text":"<ul> <li>All rows have the same number of soldiers\u00a0\u2192 Return the first\u00a0<code>k</code>\u00a0rows by index. -\u00a0Rows with only 0s\u00a0\u2192 Weakest rows should be the ones with all 0s. -\u00a0Rows with all 1s\u00a0\u2192 Strongest rows should be last. -\u00a0Large matrix\u00a0(m,n&gt;1000)(m,n&gt;1000)\u00a0\u2192 Binary search + heap is best.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/","title":"LC1351. Count Negative Numbers in a Sorted Matrix","text":"","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1351: Given a\u00a0<code>m x n</code>\u00a0matrix\u00a0<code>grid</code>\u00a0which is sorted in non-increasing order both row-wise and column-wise, return\u00a0the number of\u00a0negativenumbers in <code>grid</code>.</p> <p>Example 1:</p> <p>Input: grid = [[4,3,2,-1],[3,2,1,-1],[1,1,-1,-2],[-1,-1,-2,-3]] Output: 8 Explanation: There are 8 negatives number in the matrix.  </p>","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#clarification","title":"Clarification","text":"<ul> <li>matrix</li> <li>What does it mean sorted? non-increasing in row-wise and column-wise?</li> <li>return # of negative numbers</li> <li>go through examples</li> </ul>","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#assumption","title":"Assumption","text":"","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#solution","title":"Solution","text":"","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since the matrix is sorted, we can go through each row and use modified binary search to find the first negative number. On that row, all numbers on the right of the negative number all also negative. The we can count negative numbers row by row.</p> Python <pre><code>class Solution:\n    def countNegatives(self, grid: List[List[int]]) -&gt; int:\n        m, n = len(grid), len(grid[0])\n\n        num_negative = 0\n        for i_row in range(m):\n            row_value = grid[i_row]\n\n            left = 0\n            right = n - 1\n            while left &lt; right:\n                mid = (left + right) // 2\n                if row_value[mid] &lt; 0:\n                    right = mid\n                else:\n                    left = mid + 1\n\n            if row_value[left] &lt; 0:\n                num_negative += n - left\n\n        return num_negative\n</code></pre>","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(m \\log n)\\)     In the worst case, for each row, it takes at most \\(\\log n\\) steps to find the first negative number using binary search and we need to do it for \\(m\\) rows. So the time complexity is \\(O(m \\log n)\\)</li> <li>Space complexity: \\(O(1)\\)     Only use several variables for searching.</li> </ul>","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#approach-stairs","title":"Approach - Stairs","text":"<p>If replacing positive numbers or 0 with <code>+</code> sign and negative numbers with <code>-</code>sign, the problem can be viewed as climb up or go down stairs. The <code>-</code> form the stairs.  <pre><code>[ + + + -\n  + + + -\n  + + - -\n  - - - - ]\n</code></pre> This idea is inspired by @rock's solution</p> <p>Since the matrix is sorted in non-increasing order both row-wise and column-wise, there are some interesting properties:</p> <ol> <li>Along a row, all numbers on the right of a negative number are negative. (non-increasing row-wise)</li> <li>Along a column, all numbers below a negative number are negative. (non-increasing column-wise)</li> <li> <p>For the first negative on a row, we can divide a matrix by 4 quadrants with this negative number at the corner of each quadrant:</p> <ol> <li>The top left quadrant only contains positive numbers (except the negative number at the corner)  </li> <li>The top right quadrant may contain either positive or negative numbers  </li> <li>The bottom left quadrant may contain either positive or negative numbers  </li> <li>The bottom right quadrant only contains negative numbers  </li> </ol> </li> </ol> <p>If climbing up stairs, only need to search the top right quadrant (3b). If going down stairs, only need to search the bottom left quadrant (3c).</p> Python <pre><code>class Solution:\n    def countNegatives(self, grid: List[List[int]]) -&gt; int:\n        m, n = len(grid), len(grid[0])\n        n_negative = 0\n\n        # Start from the bottom left number and step up\n        i_row, i_col = m - 1, 0\n        while i_row &gt;= 0 and i_col &lt; n:\n            if grid[i_row][i_col] &gt;= 0:\n                i_col += 1  # (1)\n            else:\n                n_negative += n - i_col  #(2)\n                i_row -= 1  # (3)\n\n        return n_negative\n</code></pre> <ol> <li>Always move right since no negative value on the left. Refer to property 3b</li> <li>Count the rest of negative numbers. Refer to property 1</li> <li>Step up</li> </ol>","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(m + n)\\)     In the worst case, climbing up stairs from bottom to top takes at most \\(m + n\\) steps.  </li> <li>Space complexity: \\(O(1)\\)     Only use two variables for indexing.</li> </ul>","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Binary Search \\(O(m \\log n)\\) \\(O(1)\\) Approach - Stairs \\(O(m + n)\\) \\(O(1)\\) <p>Is \\(O(m \\log n)\\) better than \\(O(m + n)\\)?</p> <ul> <li>For general cases where \\(m\\) and \\(n\\) are in the same magnitude (e.g., \\(n = c \\times m\\) where \\(c &gt; 1\\) is a constant), \\(O(m + n)\\) is better. \\(O(m + n) = O((c + 1) \\times m) = O(m) &lt; O(m \\log(cm)) = O(m (\\log c + \\log m)) = O(m \\log m)\\) </li> <li>For rare cases where \\(n &gt;&gt; m\\) (e.g. \\(n = m^2\\)), \\(O(m \\log n)\\) is better. \\(O(m \\log n) = O(m \\log(m^2)) = O(2m \\log m) = O(m \\log m) &lt; O(m^2) = O(m + m^2) = O(m + n)\\).</li> </ul>","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1300-1399/lc1351-count-negative-numbers-in-a-sorted-matrix/#test","title":"Test","text":"","tags":["Binary Search","Matrix"]},{"location":"lc-solutions/lc1400-1499/lc1498-number-of-subsequences-that-satisfy-the-given-sum-condition/","title":"LC1498. Number of Subsequences That Satisfy the Given Sum Condition","text":"","tags":["Two Pointers","Sorting"]},{"location":"lc-solutions/lc1400-1499/lc1498-number-of-subsequences-that-satisfy-the-given-sum-condition/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1498: You are given an array of integers\u00a0<code>nums</code>\u00a0and an integer\u00a0<code>target</code>.</p> <p>Return\u00a0the number of\u00a0non-empty\u00a0subsequences of <code>nums</code> such that the sum of the minimum and maximum element on it is less or equal to <code>target</code>. Since the answer may be too large, return it\u00a0modulo <code>109 + 7</code>.</p>","tags":["Two Pointers","Sorting"]},{"location":"lc-solutions/lc1400-1499/lc1498-number-of-subsequences-that-satisfy-the-given-sum-condition/#clarification","title":"Clarification","text":"<ul> <li>unsorted array</li> <li>find subsequences with min + max &lt;= target</li> </ul>","tags":["Two Pointers","Sorting"]},{"location":"lc-solutions/lc1400-1499/lc1498-number-of-subsequences-that-satisfy-the-given-sum-condition/#assumption","title":"Assumption","text":"","tags":["Two Pointers","Sorting"]},{"location":"lc-solutions/lc1400-1499/lc1498-number-of-subsequences-that-satisfy-the-given-sum-condition/#solution","title":"Solution","text":"","tags":["Two Pointers","Sorting"]},{"location":"lc-solutions/lc1400-1499/lc1498-number-of-subsequences-that-satisfy-the-given-sum-condition/#approach-sort-two-pointers","title":"Approach - Sort + Two Pointers","text":"<p>Sorted array first and use two pointers:</p> <ul> <li>i, the index of minimum</li> <li>j, the index of maximum, j &gt;= i</li> </ul> <p>One starts from the beginning and the other starts from the end to find the first subsequence that satisfy <code>nums[i] + nums[j] &lt;= target</code>. Then the number of sub sequences starting from <code>i</code> and before <code>j</code> that satisfy the condition is \\(2^{j - i}\\). The number at index <code>i</code> is always included since <code>i + 1</code> will be considered when increasing <code>i</code> later. There are remaining <code>j - i</code> items to select from. Each item has two options: selected or not selected. So there are total \\(2^{j - i}\\) options. </p> <p>Takes sequence <code>[3, 5, 6]</code> with target <code>9</code> as an example.  <pre><code>[3  5  6]\n 3  x  x  -&gt;  3\n 3  x  \u2713  -&gt;  3, 6\n 3  \u2713  x  -&gt;  3, 5\n 3  \u2713  \u2713  -&gt;  3, 5, 6\n</code></pre></p> Python <pre><code>class Solution:\n    def numSubseq(self, nums: List[int], target: int) -&gt; int:\n        nums.sort()\n        count = 0\n        mod = 10**9 + 7\n\n        idx_min, idx_max = 0, len(nums) - 1\n        while idx_min &lt;= idx_max:\n            if nums[idx_min] + nums[idx_max] &lt;= target:\n                count += pow(2, idx_max - idx_min, mod)\n                idx_min += 1\n            else:\n                idx_max -= 1\n\n        return count % mod\n</code></pre>","tags":["Two Pointers","Sorting"]},{"location":"lc-solutions/lc1400-1499/lc1498-number-of-subsequences-that-satisfy-the-given-sum-condition/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) The sort function takes \\(O(n \\log n)\\) time, the while loop takes \\(n\\) steps to go through all indices and each step may take \\(O(1)\\) or \\(O(\\log(\\text{idx_max} - \\text{idx_min}))\\) for calling <code>pow</code> function.</li> <li>Space complexity: \\(O(1)\\) Since using in-place sort and two index variables, the time complexity is \\(O(1)\\).</li> </ul>","tags":["Two Pointers","Sorting"]},{"location":"lc-solutions/lc1500-1599/lc1533-find-the-index-of-the-large-integer/","title":"LC1533. Find the Index of the Large Integer","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1533-find-the-index-of-the-large-integer/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1533: We have an integer array\u00a0<code>arr</code>, where all the integers in\u00a0<code>arr</code>\u00a0are equal except for one integer which is\u00a0larger\u00a0than the rest of the integers. You will not be given direct access to the array, instead, you will have an\u00a0API <code>ArrayReader</code>\u00a0which have the following functions:</p> <ul> <li><code>int compareSub(int l, int r, int x, int y)</code>: where\u00a0<code>0 &lt;= l, r, x, y &lt; ArrayReader.length()</code>,\u00a0<code>l &lt;= r and</code> <code>x &lt;= y</code>. The function compares the sum of sub-array\u00a0<code>arr[l..r]</code>\u00a0with the sum of the sub-array\u00a0<code>arr[x..y]</code>\u00a0and returns:<ul> <li>1\u00a0if\u00a0<code>arr[l]+arr[l+1]+...+arr[r] &gt; arr[x]+arr[x+1]+...+arr[y]</code>.</li> <li>0\u00a0if\u00a0<code>arr[l]+arr[l+1]+...+arr[r] == arr[x]+arr[x+1]+...+arr[y]</code>.</li> <li>-1\u00a0if\u00a0<code>arr[l]+arr[l+1]+...+arr[r] &lt; arr[x]+arr[x+1]+...+arr[y]</code>.</li> </ul> </li> <li><code>int length()</code>: Returns the size of the array.</li> </ul> <p>You are allowed to call\u00a0<code>compareSub()</code> 20 times\u00a0at most. You can assume both functions work in\u00a0<code>O(1)</code>\u00a0time.</p> <p>Return\u00a0the index of the array\u00a0<code>arr</code>\u00a0which has the largest integer.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1533-find-the-index-of-the-large-integer/#clarification","title":"Clarification","text":"<ul> <li>arr: one integer is larger and the rest are equal</li> <li>API function return 1, 0, or -1</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1533-find-the-index-of-the-large-integer/#assumption","title":"Assumption","text":"<p>-The larger number always exist</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1533-find-the-index-of-the-large-integer/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1533-find-the-index-of-the-large-integer/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Put the array into two halves with the same size. if both halves contain the same elements, the sum of the two halves will be the same. If one half contains the larger value, the sum of that half will be larger. So we can use binary search to compare left half and right half:</p> <ul> <li>If <code>left half &gt; right half</code>, skip right half and search the left half</li> <li>If <code>left half &lt; right half</code>, skip left half and search the right half</li> <li>if <code>left half == right half</code>,  the larger element is at <code>left + half_length * 2</code> when comparing <code>[left, left + half_length - 1]</code> and <code>[left + half_length, left + half_length * 2 - 1]</code>. This only happens for subarray with odd number of elements.</li> </ul> Python <pre><code>class Solution:\n    def getIndex(self, reader: 'ArrayReader') -&gt; int:\n        left, right = 0, reader.length() - 1\n\n        while left &lt; right:\n            h = (right - left + 1) // 2\n            status = reader.compareSub(left, left + h - 1, left + h, left + h * 2 - 1)\n            if status == 0:\n                return left + h * 2\n            elif status == -1:\n                left = left + h\n            else:\n                right = left + h - 1\n\n        return left\n</code></pre>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1533-find-the-index-of-the-large-integer/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log n)\\) After each iteration, the search space is reduced by half by using binary search. </li> <li>Space complexity: \\(O(1)\\) Only using a few variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1533-find-the-index-of-the-large-integer/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1539-kth-missing-positive-number/","title":"LC1539. Kth Missing Positive Number","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1539-kth-missing-positive-number/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1539: Given an array\u00a0<code>arr</code>\u00a0of positive integers sorted in a\u00a0strictly increasing order, and an integer\u00a0<code>k</code>.</p> <p>Return\u00a0the <code>kth</code> positive\u00a0integer that is\u00a0missing\u00a0from this array.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1539-kth-missing-positive-number/#clarification","title":"Clarification","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1539-kth-missing-positive-number/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1539-kth-missing-positive-number/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1539-kth-missing-positive-number/#approach-binary-search","title":"Approach - Binary Search","text":"<p>The array <code>arr</code> can be transformed into a missing positive array, <code>arr_miss</code> with conversion <code>arr[i] - (i + 1)</code>. For example, <pre><code>index, i:  0  1  2  3\narr:      [1  3  4  6]\narr_miss: [0  1  1  2]\n</code></pre> <code>arr_miss[i]</code> represents how many missing positive so far at index <code>i</code>. So the question can be solved by the following two steps:</p> <ol> <li>Find the smallest index, <code>idx</code>, of <code>arr_miss</code> such that <code>arr_miss[idx] &gt;= k</code></li> <li>Obtain the <code>kth</code> missing positive integer</li> </ol> <p>For step 1, we can use binary search to find the index. </p> <p>For step 2, <code>idx + k</code> is the <code>kth</code> positive integer.  <pre><code>arr_miss[idx] + idx + 1 == arr[idx], not missing\narr_miss[idx] + idx, is the arr_miss[idx]th missing integer\nk + idx, is the kth missing integer\n</code></pre> Or another way to think about, the result is</p> \\[\\underbrace{arr[idx - 1]}_{\\text{largest non-missing number} &lt; \\text{kth missing number}} + \\underbrace{k - arr\\_miss[idx - 1]}_{\\text{offset, how far from kth missing number}} = arr[idx - 1] + k - (arr[idx - 1] - idx) = idx + k\\] Python <pre><code>class Solution:\n    def findKthPositive(self, arr: List[int], k: int) -&gt; int:\n        left, right = 0, len(arr)  # (1)\n\n        while left &lt; right:\n            mid = (left + right) // 2\n\n            if arr[mid] - (mid + 1) &lt; k:\n                left = mid + 1\n            else:\n                right = mid\n\n        return left + k\n</code></pre> <ol> <li>Need to cover the case where all missing numbers from arr &lt; k. <code>len(arr) - 1</code> doesn't work</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1539-kth-missing-positive-number/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log)\\) Use binary search to find the index</li> <li>Space complexity: \\(O(1)\\) Use limited variables</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1539-kth-missing-positive-number/#test","title":"Test","text":"<ul> <li>Array missing numbers &lt; \\(k\\)</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/","title":"LC1584. Min Cost to Connect All Points","text":"","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1584: You are given an array\u00a0<code>points</code>\u00a0representing integer coordinates of some points on a 2D-plane, where\u00a0<code>points[i] = [xi, yi]</code>.</p> <p>The cost of connecting two points\u00a0<code>[xi, yi]</code>\u00a0and\u00a0<code>[xj, yj]</code>\u00a0is the manhattan distance\u00a0between them:\u00a0<code>|xi - xj| + |yi - yj|</code>, where\u00a0<code>|val|</code>\u00a0denotes the absolute value of\u00a0<code>val</code>.</p> <p>Return\u00a0the minimum cost to make all points connected.\u00a0All points are connected if there is\u00a0exactly one\u00a0simple path between any two points.</p>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#clarification","title":"Clarification","text":"<ul> <li>array of points, each point is [xi, yi]</li> <li>the cost of the edge is the manhattan distance between two points</li> <li>minimum cost to connect all points</li> </ul>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#solution","title":"Solution","text":"<p>The problem can be transformed into minimum spanning tree (MST) problem. Then we can use classical Kruskal's or Prim's algorithm to find the MST.</p> <p>Tip: We can use input array indices to represent the nodes.</p>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#approach-kruskals-algorithm","title":"Approach - Kruskal's Algorithm","text":"<p>Follow the Krusal's algorithm to find the minimum spanning tree by sorting edges by the cost. Regarding sorting, we can either use normal sorting or priority queue.</p> Python - sort tuplePython - sort classPython - heapq class <pre><code>from operator import itemgetter\n\n\nclass UnionFind:\n    def __init__(self, n: int) -&gt; None:\n        self.root = [i for i in range(n)]\n        self.rank = [0] * n\n\n    def find(self, x: int) -&gt; int:\n        if x != self.root[x]:\n            self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x: int, y: int) -&gt; bool:\n        root_x = self.find(x)\n        root_y = self.find(y)\n\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = root_x\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = root_y\n            else:\n                self.root[root_y] = root_x\n                self.rank[root_x] += 1\n\n            return True\n        else:\n            return False\n\n\nclass Solution:\n    def minCostConnectPoints(self, points: List[List[int]]) -&gt; int:\n        n_points = len(points)\n\n        edges = []\n        for i in range(n_points):  # O(n^2)\n            for j in range(i + 1, n_points):\n                xi, yi = points[i]\n                xj, yj = points[j]\n                dist = abs(xi - xj) + abs(yi - yj)\n                edges.append((i, j, dist))\n\n        edges.sort(key=itemgetter(2))\n\n        total_cost = 0\n        n_edges = 0\n        uf = UnionFind(n_points)\n        for i_point, j_point, cost in edges:  # O(n \\alpha(n))\n            if uf.union(i_point, j_point):  # O(\\alpha(n))\n                total_cost += cost\n                n_edges += 1\n                if n_edges == n_points - 1:\n                    break\n\n        return total_cost\n</code></pre> <pre><code>from operator import attrgetter\n\n\nclass UnionFind:\n    def __init__(self, n: int) -&gt; None:\n        self.root = [i for i in range(n)]\n        self.rank = [0] * n\n\n    def find(self, x: int) -&gt; int:\n        if x != self.root[x]:\n            self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x: int, y: int) -&gt; bool:\n        root_x = self.find(x)\n        root_y = self.find(y)\n\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = root_x\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = root_y\n            else:\n                self.root[root_y] = root_x\n                self.rank[root_x] += 1\n\n    def connected(self, x: int, y: int) -&gt; bool:\n        return self.find(x) == self.find(y)\n\nclass Edge:\n    def __init__(self, point1: int, point2: int, cost: int) -&gt; None:\n        self.point1 = point1\n        self.point2 = point2\n        self.cost = cost\n\n    def __lt__(self, other) -&gt; bool:\n        return self.cost &lt; other.cost\n\n\nclass Solution:\n    def minCostConnectPoints(self, points: List[List[int]]) -&gt; int:\n        n_points = len(points)\n\n        edges = []\n        for i in range(n_points):  # O(n^2)\n            xi, yi = points[i]\n            for j in range(i + 1, n_points):\n                xj, yj = points[j]\n                dist = abs(xi - xj) + abs(yi - yj)\n                edge = Edge(i, j, dist)\n                edges.append(edge)\n\n        # Sort edges\n        edges.sort(key=attrgetter('cost'))  # (1)\n\n        total_cost = 0\n        n_edges = 0\n        uf = UnionFind(n_points)\n        for edge in edges:  # O(n \\alpha(n))\n            if not uf.connected(edge.point1, edge.point2):\n                uf.union(edge.point1, edge.point2)  # O(\\alpha(n))\n                total_cost += edge.cost\n                n_edges += 1\n\n            if n_edges == n_points - 1:\n                break\n\n        return total_cost\n</code></pre> <ol> <li>Add key to speed up sorting, which is still slower than sorting list of tuples</li> </ol> <pre><code>import heapq\n\n\nclass UnionFind:\n    def __init__(self, n: int) -&gt; None:\n        self.root = [i for i in range(n)]\n        self.rank = [0] * n\n\n    def find(self, x: int) -&gt; int:\n        if x != self.root[x]:\n            self.root[x] = self.find(self.root[x])\n        return self.root[x]\n\n    def union(self, x: int, y: int) -&gt; bool:\n        root_x = self.find(x)\n        root_y = self.find(y)\n\n        if root_x != root_y:\n            if self.rank[root_x] &gt; self.rank[root_y]:\n                self.root[root_y] = root_x\n            elif self.rank[root_x] &lt; self.rank[root_y]:\n                self.root[root_x] = root_y\n            else:\n                self.root[root_y] = root_x\n                self.rank[root_x] += 1\n\n    def connected(self, x: int, y: int) -&gt; bool:\n        return self.find(x) == self.find(y)\n\n\nclass Edge:\n    def __init__(self, point1: int, point2: int, cost: int) -&gt; None:\n        self.point1 = point1\n        self.point2 = point2\n        self.cost = cost\n\n    def __lt__(self, other):\n        return self.cost &lt; other.cost\n\n\nclass Solution:\n    def minCostConnectPoints(self, points: List[List[int]]) -&gt; int:\n        n_points = len(points)\n        pq = []\n\n        for i in range(n_points):  # (1)\n            xi, yi = points[i]\n            for j in range(i + 1, n_points):\n                xj, yj = points[j]\n                dist = abs(xi - xj) + abs(yi - yj)\n                edge = Edge(i, j, dist)\n                # heapq.heappush(pq, edge)  # push and sort in the same time O(\\log E)\n                pq.append(edge)\n\n        # Convert pq into a heap. O(E).\n        heapq.heapify(pq)\n\n        total_cost = 0\n        n_edges = 0\n        uf = UnionFind(n_points)\n        while pq:\n            edge = heapq.heappop(pq)\n            if not uf.connected(edge.point1, edge.point2):\n                uf.union(edge.point1, edge.point2)\n                total_cost += edge.cost\n                n_edges += 1\n                if n_edges == n_points - 1:\n                    break\n\n        return total_cost\n</code></pre> <ol> <li>\\(O(E)\\) without <code>heappush</code>, \\(O(E \\log E)\\) with <code>heappush</code>.</li> </ol>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n^2 \\log n)\\) where \\(n\\) represents the number of points.  <ul> <li>Go through all edges, \\(n (n - 1) / 2 \\approx n^2 / 2\\),among points to compute cost.</li> <li>Sorting all edges takes \\(O(n^2 \\log (n^2)) = O(n^2 2 \\log(n)) = O(n^2 \\log(n))\\) from <code>timsort</code> in Python. </li> <li>To find minimum spanning tree, adding points and check points connectivity using union-find takes \\(O(\\alpha(n))\\) and in the worst case may need to go through all \\(n^2\\) edges. So it takes \\(O(n^2 \\alpha(n))\\). In total, it takes \\(O(n^2) + O(n^2 \\log n) + O(n^2 \\alpha(n)) = O(n^2 \\log (n))\\).</li> </ul> </li> <li>Space complexity: \\(O(n^2)\\) <ul> <li>Store cost for each edge takes \\(O(n^2)\\) space.</li> <li>Sorting edges takes \\(O(n^2)\\) space from <code>timsort</code> in Python.</li> <li>Union find structure takes \\(O(n)\\) space to store points (2 points per edge) In total, it takes \\(O(n^2 + n^2 + n) = O(n^2)\\) space.</li> </ul> </li> </ul>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#approach-2-prims-algorithm-min-heap","title":"Approach 2 - Prim's Algorithm (Min Heap)","text":"<p>We can also use Prim's algorithm to solve the minimum spanning tree problem. We use min-heap data structure to track the lowest-weighted edge, <code>(weight, next_point)</code>.</p> <p>Note that we don't need to include the <code>curr_point</code> like this <code>(weight, curr_point, next_point)</code>. We just need to find the lowest weight edge and associated next point. The current point is already evaluated, either in the minimum spanning tree or may form a cycle.</p> python - min heap <pre><code>import heapq\n\n\nclass Solution:\n    def minCostConnectPoints(self, points: List[List[int]]) -&gt; int:\n        n_points = len(points)\n        points_in_mst = set()  # track points which are in minimum spanning tree (MST)\n        min_heap = [(0, 0)]  # Min-heap to store minimum weight edge at top\n\n        total_cost = 0\n        n_edges_used = 0\n\n        while n_edges_used &lt; n_points:\n            cost, curr_point = heapq.heappop(min_heap)\n\n            # Discard the point if already in MST (prevent cycle)\n            if curr_point in points_in_mst:\n                continue\n\n            points_in_mst.add(curr_point)\n            total_cost += cost\n            n_edges_used += 1\n\n            for next_point in range(n_points):\n                # Add (edge weight, next_point) from the curr_point\n                if next_point not in points_in_mst:\n                    next_cost = abs(\n                        points[curr_point][0] - points[next_point][0]\n                    ) + abs(points[curr_point][1] - points[next_point][1])\n                    heapq.heappush(min_heap, (next_cost, next_point))\n\n        return total_cost\n</code></pre>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<p>Min heap method:</p> <ul> <li>Time complexity: \\(O(n^2 \\log (n))\\)   In the worst case, we push/pop \\(n (n - 1) / 2 \\approx n^2 / 2\\) edges. Each push/pop   operation takes \\(O(\\log (n^2 / 2) = 2 \\log(n)\\)So the overall time complexity is   \\(O(n^2 \\log (n))\\)</li> <li>Space complexity: \\(O(n^2)\\) <ul> <li>In the worst case, the min heap stores all \\(n^2 / 2\\) edges.</li> <li>The <code>set</code> to track points in the minimum spanning tree stores \\(n\\) points. So the overall space complexity is \\(O(n^2) + O(n) = O(n^2)\\).</li> </ul> </li> </ul>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#approach-3-prims-algorithm-optimized","title":"Approach 3 - Prim's ALgorithm (Optimized)","text":"<p>Instead of using min-heap, we will optimize the Prim's algorithm by using one <code>min_dist</code> array. <code>min_dist[i]</code> stores the weight of the smallest weighted edge to reach the ith node from any node in the current tree.</p> <p>We will iterate over the <code>min_dist</code> array and greedily pick the node that is not in the MST and has the smallest edge weight. Then update the value in <code>min_dist</code>.</p> python <pre><code>class Solution:\n    def minCostConnectPoints(self, points: List[List[int]]) -&gt; int:\n        n_points = len(points)\n        points_in_mst = set()  # track points which are in minimum spanning tree (MST)\n        total_cost = 0\n        min_dist = [math.inf] * n_points\n        min_dist[0] = 0\n\n        while len(points_in_mst) &lt; n_points:\n            curr_min_edge = math.inf\n            curr_point = -1\n\n            # Pick least weight node which is not in MST\n            for node in range(n_points):\n                if node not in points_in_mst and curr_min_edge &gt; min_dist[node]:\n                    curr_min_edge = min_dist[node]\n                    curr_point = node\n\n            points_in_mst.add(curr_point)\n            total_cost += curr_min_edge\n\n            for next_point in range(n_points):\n                # Add (edge weight, next_point) from the curr_point\n                if next_point not in points_in_mst:\n                    next_cost = abs(\n                        points[curr_point][0] - points[next_point][0]\n                    ) + abs(points[curr_point][1] - points[next_point][1])\n                    if min_dist[next_point] &gt; next_cost:\n                        min_dist[next_point] = next_cost\n\n        return total_cost\n</code></pre>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(n^2)\\) <ul> <li>Initialize <code>min_dist</code> takes \\(O(n)\\).</li> <li>The outer while loop takes \\(O(n)\\) iteration<ul> <li>The inner for-loop to pick the least weight takes \\(O(n)\\).</li> <li>Another inner for-loop takes \\(O(n)\\).</li> <li>So the while loop with two inner for-loops take \\(O(n) \\times (O(n) + O(n)) = O(n^2)\\) time.</li> </ul> </li> </ul> </li> <li>Space complexity: \\(O(n)\\)<ul> <li><code>points_in_mist</code> takes \\(O(n)\\) space.</li> <li><code>min_dist</code> takes \\(O(n)\\) space.</li> <li>So the total space complexity is \\(O(n + n) = O(n)\\).</li> </ul> </li> </ul>","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Kruskal \\(O(n^2 \\log (n))\\) \\(O(n^2)\\) Approach 2A - Prim - Min Heap \\(O(n^2 \\log (n))\\) \\(O(n^2)\\) Approach 2A - Prim - Optimized \\(O(n^2)\\) \\(O(n)\\)","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1500-1599/lc1584-min-cost-to-connect-all-points/#test","title":"Test","text":"","tags":["Minimum Spanning Tree","Union Find"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/","title":"LC1631. Path With Minimum Effort","text":"","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1631: You are a hiker preparing for an upcoming hike. You are given\u00a0<code>heights</code>, a 2D array of size <code>rows x columns</code>, where\u00a0<code>heights[row][col]</code>\u00a0represents the height of cell\u00a0<code>(row, col)</code>. You are situated in the top-left cell,\u00a0<code>(0, 0)</code>, and you hope to travel to the bottom-right cell,\u00a0<code>(rows-1, columns-1)</code>\u00a0(i.e.,\u00a00-indexed). You can move\u00a0up, down,\u00a0left, or\u00a0right, and you wish to find a route that requires the minimum effort.</p> <p>A route's\u00a0effort\u00a0is the\u00a0maximum absolute difference\u00a0in heights between two consecutive cells of the route.</p> <p>Return\u00a0the minimum\u00a0effort\u00a0required to travel from the top-left cell to the bottom-right cell.</p>","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#clarification","title":"Clarification","text":"","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#assumption","title":"Assumption","text":"","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#solution","title":"Solution","text":"","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#approach-shortest-path-faster-algorithm","title":"Approach - Shortest Path Faster Algorithm","text":"<p>Use a queue to track the path with effort. Use breadth-first search to search cells, which allow visiting cells multiple times. We will update the minimum effort between <code>(0, 0)</code> and any node <code>(i, j)</code> during the search. We will add the cell to the queue if it has less effort.</p> Python <pre><code>from collections import deque, defaultdict\n\nclass Solution:\n    def minimumEffortPath(self, heights: List[List[int]]) -&gt; int:\n        DIRECTIONS = ((-1, 0), (1, 0), (0, -1), (0, 1))  # (1)\n        n_rows, n_cols = len(heights), len(heights[0])\n        min_effort = defaultdict(lambda: float(\"inf\"))  # (2)\n        queue = deque([(0, 0, 0)])  # (row, col, effort)\n        min_effort[(0, 0)] = 0\n\n        while queue:\n            curr_row, curr_col, effort = queue.popleft()\n            for delta_row, delta_col in DIRECTIONS:\n                next_row, next_col = curr_row + delta_row, curr_col + delta_col\n                if 0 &lt;= next_row &lt; n_rows and 0 &lt;= next_col &lt; n_cols:\n                    abs_diff = abs(heights[next_row][next_col] - heights[curr_row][curr_col])\n                    new_effort = max(abs_diff, effort)\n                    if new_effort &lt; min_effort[(next_row, next_col)]:\n                        queue.append((next_row, next_col, new_effort))\n                        min_effort[(next_row, next_col)] = new_effort\n\n        return min_effort[(n_rows - 1, n_cols - 1)]\n</code></pre> <ol> <li>up, down, left, right.</li> <li>dictionary[cell] = minimum effort on the path from (0, 0) and the current cell.</li> </ol>","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m n)\\) <ul> <li>For queue operation, each node will be added to the queue at most \\(4\\) times (4 move directions in the 2D array). There will be at most \\(4 m n\\) queue operations. Each queue operation (enqueue or dequeue) takes \\(O(1)\\). So the queue operation takes \\(O(m n)\\).</li> <li>For neighboring exploration, each node will explore \\(4\\) neighbors. For at most \\(4 m n\\) nodes, the total neighboring explorations is \\(16 m n\\). So neighboring exploration takes \\(O(m n)\\). So the total time complexity is \\(O(m n) + O(m n) = O(m n)\\).</li> </ul> </li> <li>Space complexity: \\(O(m n)\\) <ul> <li>The <code>min_effort</code> dictionary takes \\(O(m n)\\) space for total \\(m n\\) cells.</li> <li>The <code>queue</code> takes \\(O(m n)\\) space since \\(m n\\) cells can be added at most 4 times. So the total space complexity is \\(O(m n) + O(m n) = O(m n)\\).</li> </ul> </li> </ul>","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#approach-2-dijkstra","title":"Approach 2 - Dijkstra","text":"<p>This problem can also use Dijkstra's algorithm to find the minimum effort (i.e., shortest path).</p> Python <pre><code>import heapq\nimport math\nfrom collections import defaultdict\n\nclass Solution:\n    def minimumEffortPath(self, heights: List[List[int]]) -&gt; int:\n        DIRECTIONS = ((-1, 0), (1, 0), (0, -1), (0, 1))  # (1)\n        n_rows, n_cols = len(heights), len(heights[0])\n        min_effort = defaultdict(lambda: math.inf)  # (2)\n        pq = [(0, 0, 0)]  # (3)\n\n        while pq:\n            effort, curr_row, curr_col = heapq.heappop(pq)  # (4)\n            if (curr_row, curr_col) not in min_effort:\n                min_effort[(curr_row, curr_col)] = effort\n\n                for delta_row, delta_col in DIRECTIONS:\n                    next_row, next_col = curr_row + delta_row, curr_col + delta_col\n                    if 0 &lt;= next_row &lt; n_rows and 0 &lt;= next_col &lt; n_cols:\n                        abs_diff = abs(heights[next_row][next_col] - heights[curr_row][curr_col])\n                        new_effort = max(abs_diff, effort)\n                        heapq.heappush(pq, (new_effort, next_row, next_col))\n\n        return min_effort[(n_rows - 1, n_cols - 1)]\n</code></pre> <ol> <li>up, down, left, right.</li> <li>dictionary[(row, col)] = minimum effort on the path from (0, 0) and the current cell.</li> <li>(effort, row, col)</li> <li>The priority queue returns the minimum item based on the first element of the tuple (effort).</li> </ol>","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li> <p>Time complexity: \\(O(m n \\log (m n))\\) where \\(m\\) is number of rows and \\(n\\) is number of columns.  </p> <ul> <li>Each node (cell) can be added to the priority queue at most 1 time with at most \\(m n\\) queue operations.</li> <li>Each queue operation (push or pop from a heap) takes \\(O(\\log s)\\), which \\(s\\) is the size of the heap. The size of the heap is bounded by the number of nodes, i.e., \\(s \\leq m n\\). So the queue operation time complexity is \\(O(\\log (m n))\\). So the total time complexity is \\(O(m n \\log (m n))\\).</li> </ul> </li> <li> <p>Space complexity: \\(O(m n)\\)     The heap size may contains at most \\(m n\\) nodes and <code>min_effort</code> dictionary takes     \\(O(m n)\\) space. So the total is \\(O(m n) + O(m n) = O(m n)\\).</p> </li> </ul>","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#approach-3-binary-search-bfs","title":"Approach 3 - Binary Search + BFS","text":"<p>Use binary search to find a minimum <code>effort</code> between \\(0\\) and \\(10^6\\) (given constraint) such that there exists a route with maximum absolute difference &lt;= <code>effort</code>. For each <code>effort</code>, we can search the route by using either Breadth First Search (BFS) or Depth First Search (DFS).</p> Python <pre><code>class Solution:\n    def minimumEffortPath(self, heights: List[List[int]]) -&gt; int:\n        low, high = 0, 10**6\n        while low &lt; high:\n            effort = (low + high) // 2\n            if self.isPath(heights, effort):\n                high = effort\n            else:\n                low = effort + 1\n        return low\n\n    def isPath(self, heights: List[List[int]], effort: int) -&gt; bool:\n        n_row, n_col = len(heights), len(heights[0])\n        seen, dq = {(0, 0)}, deque([(0, 0)])\n        while dq:\n            x, y = dq.popleft()\n            if (x, y) == (n_row - 1, n_col - 1):\n                return True\n\n            for r, c in (x, y + 1), (x, y - 1), (x + 1, y), (x - 1, y):\n                if 0 &lt;= r and r &lt; n_row and 0 &lt;= c and c &lt; n_col\n                        and abs(heights[r][c] - heights[x][y]) &lt;= effort\n                        and (r, c) not in seen:\n                    seen.add((r, c))\n                    dq.append((r, c))\n        return False\n</code></pre>","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li> <p>Time complexity: \\(O(m n)\\) where \\(m\\) is the number of rows, \\(n\\) is the number of columns We do binary search to calculate the <code>effort</code> and then do BFS on the matrix for each of these values.</p> <ul> <li>Binary search: the search space is \\([0, 10^6]\\). So the time complexity is \\(O(\\log 10^6)\\)</li> <li>BFS: the time complexity of the BFS for vertices \\(V\\) and edges \\(E\\) is \\(O(V + E)\\). In the matrix with size \\((m, n)\\), there are \\(m \\times n\\) vertices and \\(m \\times n\\) edges. So the time complexity would be \\(O(mn + mn) = O(mn)\\). The total time complexity is \\(O(\\log 10^6 * (mn))\\) which is equivalent to \\(O(mn)\\).</li> </ul> </li> <li> <p>Space complexity: \\(O(m n)\\) As we use a queue and seen dictionary of potential max size \\(mn\\).</p> </li> </ul>","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - SPFA \\(O(m n)\\) \\(O(m n)\\) Approach - Dijkstra \\(O(m n \\log(m n))\\) \\(O(m n)\\) Approach - Binary Search \\(O(m n)\\) \\(O(m n)\\)","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1631-path-with-minimum-effort/#test","title":"Test","text":"<ul> <li>Single cell grid (<code>heights = [[x]]</code>): Effort = 0.</li> <li>Large grid with identical heights (<code>heights[i][j] = c</code>): Effort = 0.</li> <li>Tall grid or wide grid with significant height differences.</li> </ul>","tags":["Shortest Path","Breadth-First Search","Binary Search"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/","title":"LC1642. Furthest Building You Can Reach","text":"","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1642: You are given an integer array\u00a0<code>heights</code>\u00a0representing the heights of buildings, some <code>bricks</code>, and some\u00a0<code>ladders</code>.</p> <p>You start your journey from building\u00a0<code>0</code>\u00a0and move to the next building by possibly using bricks or ladders.</p> <p>While moving from building\u00a0<code>i</code>\u00a0to building\u00a0<code>i+1</code>\u00a0(0-indexed),</p> <ul> <li>If the current building's height is\u00a0greater than or equal\u00a0to the next building's height, you do\u00a0not\u00a0need a ladder or bricks.</li> <li>If the current building's height is\u00a0less than\u00a0the next building's height, you can either use\u00a0one ladder\u00a0or\u00a0<code>(h[i+1] - h[i])</code> bricks.</li> </ul> <p>Return the furthest building index (0-indexed) you can reach if you use the given ladders and bricks optimally.</p>","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#clarification","title":"Clarification","text":"<ul> <li>integer array is 0-indexed</li> <li>use either 1 ladder or (h[i+1] - h[i]) bricks</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#solution","title":"Solution","text":"<p>The best strategy is to use the ladder for the longest climbs and the bricks for the shortest climbs.</p>","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#approach-max-heap","title":"Approach - Max Heap","text":"<p>We can always use bricks first. If running out of bricks, replace the longest climb with a ladder. We can use max heap to track number of climbs needed for each step and return the max climb if needed.</p> Python <pre><code>import heapq\n\nclass Solution:\n    def furthestBuilding(self, heights: List[int], bricks: int, ladders: int) -&gt; int:\n        max_heap = []\n        for i in range(0, len(heights) - 1):\n            climb = heights[i + 1] - heights[i]\n\n            # Jump down or walk flat, no need a ladder or bricks\n            if climb &lt;= 0:\n                continue\n\n            # Use bricks for this climb and always push it to the max heap\n            heapq.heappush(max_heap, -climb)  # (1)\n            bricks -= climb\n\n            # If used all the bricks and ladders, return the current index\n            if bricks &lt; 0 and ladders == 0:\n                return i  # (2)\n\n            # Run out of bricks. Replace the largest bricks in previous steps with a ladder\n            if bricks &lt; 0:\n                bricks += -heapq.heappop(max_heap)\n                ladders -= 1\n\n        # Have enough bricks and ladders to reach the end\n        return len(heights) - 1\n</code></pre> <ol> <li>Push negative value to use a min heap as a max heap.</li> <li><code>i</code> is the current building, <code>i + 1</code> is the next building to climb but failed.</li> </ol>","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li>Iterate all \\(n\\) heights and each iteration has at most 2 heap operations. Each heap operation takes \\(O(\\log s)\\) time with heap size \\(s\\). In the worst case, the heap size increases from 1 to \\(n\\) after each iteration. The time complexity is \\(O(\\log 1) + O(\\log 2) + \\cdots + O(\\log n) \\approx n \\log n\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\)     In the worst case, the heap stores \\(n - 1\\) climbs.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#approach-2-min-heap","title":"Approach 2 - Min Heap","text":"<p>Similarly, we can always use a ladder first. If ladder is used up, we will use bricks to cover the minimum climb in previous steps and reclaim a ladder. Continue until no more ladders and bricks not able to cover the next climb. We can use min heap to track the number of climbs per step and return the minimum climb if needed.</p> python <pre><code>import heapq\n\n\nclass Solution:\n    def furthestBuilding(self, heights: List[int], bricks: int, ladders: int) -&gt; int:\n        min_heap = []\n\n        for i in range(len(heights) - 1):\n            diff = heights[i + 1] - heights[i]\n\n            # Jump down or flat, continue\n            if diff &lt;= 0:\n                continue\n\n            # Use ladders first\n            heapq.heappush(min_heap, diff)\n            ladders -= 1\n            if ladders &gt;= 0:\n                continue\n\n            # Use up ladders and try to use bricks for min climb\n            bricks -= heapq.heappop(min_heap)\n            if bricks &lt; 0:\n                return i\n            else:\n                ladders += 1\n\n        # Finish all climbs\n        return len(heights) - 1\n</code></pre>","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(n \\log n)\\) <ul> <li>Iterate all \\(n\\) heights and each iteration has at most 2 heap operations. Each heap operation takes \\(O(\\log s)\\) time with heap size \\(s\\). In the worst case, the heap size increases from 1 to \\(n\\) after each iteration. The time complexity is \\(O(\\log 1) + O(\\log 2) + \\cdots + O(\\log n) \\approx n \\log n\\).</li> </ul> </li> <li>Space complexity: \\(O(n)\\)     In the worst case, the heap stores \\(n - 1\\) climbs.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Max Heap \\(O(n \\log n)\\) \\(O(n)\\) Approach - Min Heap \\(O(n \\log n)\\) \\(O(n)\\)","tags":["Heap"]},{"location":"lc-solutions/lc1600-1699/lc1642-furthest-building-you-can-reach/#test","title":"Test","text":"<ul> <li>All buildings are the same height\u00a0\u2192 No bricks or ladders needed.</li> <li>Enough bricks to reach the last building\u00a0\u2192 Ladders may not be used.</li> <li>Large jumps appear early\u00a0\u2192 Ladders should be prioritized.</li> </ul>","tags":["Heap"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/","title":"LC1721. Swapping Nodes in a Linked List","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1721: You are given the\u00a0<code>head</code>\u00a0of a linked list, and an integer\u00a0<code>k</code>.</p> <p>Return\u00a0the head of the linked list after\u00a0swapping\u00a0the values of the <code>kth</code> node from the beginning and the <code>kth</code> node from the end (the list is\u00a01-indexed).</p>","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#clarification","title":"Clarification","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#assumption","title":"Assumption","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#solution","title":"Solution","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#approach-two-pointers","title":"Approach - Two Pointers","text":"<p>Use two pointers <code>p_1</code> and <code>p_k</code> starting from head to </p> <ul> <li>Find the k-th node from the front by moving <code>p_k</code> pointer k steps</li> <li>Find the k-th last element by moving both <code>p_1</code> and <code>p_k</code> together until <code>p_k</code> reaches the end. Note that <code>p_1</code> and <code>p_1</code> maintains the same distance <code>k</code> nodes.</li> </ul> Python <pre><code>class Solution:\n    def swapNodes(self, head: Optional[ListNode], k: int) -&gt; Optional[ListNode]:\n        p_1, p_k = head, head\n\n        for _ in range(1, k):\n            p_k = p_k.next\n\n        node_k_begin = p_k\n\n        while p_k.next:\n            p_1 = p_1.next\n            p_k = p_k.next\n\n        node_k_end = p_1\n\n        node_k_begin.val, node_k_end.val = node_k_end.val, node_k_begin.val\n\n        return head\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Go through the whole linked list once</li> <li>Space complexity: \\(O(1)\\)     Only use two pointers</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#approach-stack","title":"Approach - Stack","text":"<p>Use stack to  - store nodes and find the k-th node from the front - pop nodes and find the k-th last element</p> Python <pre><code>from collections import deque\n\nclass Solution:\n    def swapNodes(self, head: Optional[ListNode], k: int) -&gt; Optional[ListNode]:\n        stack = deque()\n        i = 1\n        current = head\n\n        while current:\n            stack.append(current)\n            if i == k:\n                node_k_begin = current\n            current = current.next\n            i += 1\n\n        i = 1\n        while stack:\n            current = stack.pop()\n            if i == k:\n                node_k_end = current\n                break\n            i += 1\n\n        stack.clear()\n\n        temp = node_k_begin.val\n        node_k_begin.val = node_k_end.val\n        node_k_end.val = temp\n\n        return head\n</code></pre>","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#complexity-analysis_1","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     Go through the whole linke list once. </li> <li>Space complexity: \\(O(n)\\)     Store the whole linked list in stack.</li> </ul>","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - Two Pointers \\(O(n)\\) \\(O(1)\\) Approach - Stack \\(O(n)\\) \\(O(n)\\)","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1721-swapping-nodes-in-a-linked-list/#test","title":"Test","text":"","tags":["Linked List"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/","title":"1770. Maximum Score From Performing Multiplication Operations","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1770: You are given two\u00a00-indexed\u00a0integer arrays\u00a0<code>nums</code>\u00a0and\u00a0<code>multipliers</code>\u00a0of size\u00a0<code>n</code>\u00a0and <code>m</code>\u00a0respectively, where\u00a0<code>n &gt;= m</code>.</p> <p>You begin with a score of\u00a0<code>0</code>. You want to perform\u00a0exactly <code>m</code>\u00a0operations. On the <code>ith</code>\u00a0operation (0-indexed) you will:</p> <ul> <li>Choose one integer\u00a0<code>x</code>\u00a0from\u00a0either the start or the end\u00a0of the array\u00a0<code>nums</code>.</li> <li>Add\u00a0<code>multipliers[i] * x</code>\u00a0to your score.<ul> <li>Note that\u00a0<code>multipliers[0]</code>\u00a0corresponds to the first operation,\u00a0<code>multipliers[1]</code>\u00a0to the second operation, and so on.</li> </ul> </li> <li>Remove\u00a0<code>x</code>\u00a0from\u00a0<code>nums</code>.</li> </ul> <p>Return\u00a0the\u00a0maximum\u00a0score after performing <code>m</code> operations.</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#clarification","title":"Clarification","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#solution","title":"Solution","text":"","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#approach-1-dynamic-programming-top-down-with-memoization","title":"Approach 1: Dynamic Programming (Top-Down with Memoization)","text":"<p>The problem can be solved using dynamic programming.</p> <ul> <li>State: <code>dp(op, left, right)</code>, the maximum score after performing <code>op</code> operations with   <code>left</code> and <code>right</code> as the left and right indices of the remaining numbers in <code>nums</code>.</li> <li>Recurrence relation: for each state, we have two options:<ul> <li>Select left:, the score is <code>dp(op + 1, left + 1, right) + nums[left] * multipliers[op]</code></li> <li>Select right: the score is <code>dp(op + 1, left, right - 1) + nums[right] * multipliers[op]</code> Select maximum of results obtained by selecting from left and right: <code>max(dp(op + 1, left + 1, right) + nums[left] * multipliers[op], dp(op + 1, left, right - 1) + nums[right] * multipliers[op])</code></li> </ul> </li> <li>Base case: If <code>op</code> is equal to <code>m</code>, return <code>0</code> since we have performed all operations.</li> </ul> <p>Note that the state can be reduced to <code>dp(op, left)</code> since <code>right</code> can be inferred as <code>len(nums) - 1 - (op - left)</code>. If we have completed <code>op</code> operations and the left pointer is at <code>left</code>, it means there are <code>op - left</code> operations from the right side, and thus the right pointer can be calculated as <code>len(nums) - 1 - (op - left)</code>.</p> Python <pre><code>class Solution:\n    def maximumScore(self, nums: List[int], multipliers: List[int]) -&gt; int:\n        self.memo = {}\n        return self.dp(nums, multipliers, 0, 0, len(nums) - 1)\n\n    def dp(self, nums: List[int], multipliers: List[int], op: int, left: int, right: int) -&gt; int:\n        # Base case:\n        if op == len(multipliers) or left &gt; right:\n            return 0\n\n        # Return previously computed result\n        if (op, left, right) in self.memo:\n            return self.memo[(op, left, right)]\n\n        # Recursively computed scores by selecting left and right\n        left_score = self.dp(nums, multipliers, op + 1, left + 1, right) + nums[left] * multipliers[op]\n        right_score = self.dp(nums, multipliers, op + 1, left, right - 1) + nums[right] * multipliers[op]\n        max_score = max(left_score, right_score)\n        self.memo[(op, left, right)] = max_score\n\n        return max_score\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li>Time complexity: \\(O(m^2)\\) <ul> <li>Each call is uniquely determined by <code>(op, left)</code> (right can be inferred from <code>op</code>   and <code>left</code>) where:<ul> <li>\\(0 \\leq \\text{op} \\leq \\text{m}\\)</li> <li>\\(0 \\leq \\text{left} \\leq \\text{op}\\) (because we can't select more than <code>op</code> numbers from the left) So the total number of unique states is \\(\\sum_{i=0}^m i = \\fract{m^2}{2}\\).</li> </ul> </li> <li>Each state takes \\(O(1)\\) time to compute (just max of two recursive calls + multiplication).</li> <li>So the total time complexity is \\(O(m^2)\\).</li> </ul> </li> <li>Space complexity: \\(O(m^2)\\) <ul> <li>The memoization dictionary stores up to \\(O(m^2)\\) results.</li> <li>The recursion call stack can go up to \\(O(m)\\) deep, calling all operations.</li> <li>So the total space complexity is \\(O(m^2) + O(m) = O(m^2)\\).</li> </ul> </li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#approach-2-dynamic-programming-bottom-up","title":"Approach 2: Dynamic Programming (Bottom-Up)","text":"<p>The problem can also be solved using dynamic programming in a bottom-up manner. We can use a 2D array <code>dp</code> where <code>dp[op][left]</code> represents the maximum score after performing <code>op</code> operations with the left pointer at <code>left</code>. The right pointer can be inferred as <code>right = len(nums) - 1 - (op - left)</code>. We can fill the <code>dp</code> array in reverse order, starting from the last operation and working our way to the first operation.</p> python <pre><code>class Solution:\n    def maximumScore(self, nums: List[int], multipliers: List[int]) -&gt; int:\n        n_ops = len(multipliers)\n        n_num = len(nums)\n\n        dp = [[0] * (n_ops + 1) for _ in range(n_ops + 1)]\n\n        for op in range(n_ops - 1, -1, -1):\n            for left in range(op, -1, -1):\n                right = n_num - 1 - (op - left)\n                dp[op][left] = max(\n                    multipliers[op] * nums[left] + dp[op + 1][left + 1],\n                    multipliers[op] * nums[right] + dp[op + 1][left],\n                )\n\n        return dp[0][0]\n</code></pre> <p>With space optimization, we can reduce the space complexity by changing the 2D DP array to 2 1D DP array to only 1 1D DP array.</p> <pre><code>flowchart LR\n    A(2D DP Array) --&gt; B[Two 1D DP Arrays] --&gt; C[Single 1D DP Array]</code></pre> <p>The space complexity can be reduced to \\(O(m)\\) by using a single array <code>dp</code> of size <code>n_ops + 1</code> to store the maximum scores for each operation. The <code>dp</code> array is updated in reverse order to ensure that the values from the previous operation are used correctly in the current operation.</p> python <pre><code>class Solution:\n    def maximumScore(self, nums: List[int], multipliers: List[int]) -&gt; int:\n        n_ops = len(multipliers)\n        n_num = len(nums)\n\n        dp = [0] * (n_ops + 1)\n\n        for op in range(n_ops - 1, -1, -1):\n            for left in range(0, op + 1, 1):\n                right = n_num - 1 - (op - left)\n                dp[left] = max(\n                    multipliers[op] * nums[left] + dp[left + 1],\n                    multipliers[op] * nums[right] + dp[left],\n                )\n\n        return dp[0]\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(m^2)\\) <ul> <li>The outer loop iterates <code>m</code> times (for each operation).</li> <li>The inner loop iterates up to <code>m</code> times (for each possible left index).</li> <li>Each iteration takes \\(O(1)\\) time to compute the maximum score.</li> <li>So the total time complexity is \\(O(m^2)\\).</li> </ul> </li> <li>Space complexity: \\(O(m)\\)   The optimized <code>dp</code> array is of size <code>m + 1</code>, so the space complexity is \\(O(m)\\).</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#approach-3-tree-traversal","title":"Approach 3: Tree Traversal","text":"<p>The problem can be viewed as a binary tree where each node represents a state of the problem. The root node represents the initial state with zero score, and each level of the tree represents a multiplication operation. The left child of a node represents choosing the first number in <code>nums</code>, while the right child represents choosing the last number in <code>nums</code>. The leaf nodes represent the final scores after all operations have been performed.</p> <p>So we can traverse the tree and find the maximum score.</p> <p>Optimization: consider as a graph, starting from the root node (with all <code>nums</code>) and branching to left node (choosing the first number in <code>nums</code>) and right node (choosing the last number in <code>nums</code>). The edge connects nodes from (i-1)th level to the ith level is the multiplication. Then it becomes finding the path with the maximum score.</p> python <pre><code>from collections import deque\n\nclass Solution:\n    def maximumScore(self, nums: List[int], multipliers: List[int]) -&gt; int:\n        return self.bfs(nums, multipliers)\n\n    def bfs(self, nums: list[int], multipliers: list[int]) -&gt; int:\n        n_operations = len(multipliers)\n        max_score = 0\n        level = 0\n        queue = deque([(0, 0, len(nums) - 1)])  # (score, begin index, end index), indices are for subsets of nums\n\n        while queue:\n            size = len(queue)\n\n            for _ in range(size):\n                score, idx_begin, idx_end = queue.popleft()\n\n                # Check whether finish all operations\n                if level == n_operations:\n                    max_score = max(max_score, score)\n                    continue\n\n                queue.append((score + nums[idx_begin] * multipliers[level], idx_begin + 1, idx_end))  # Choose from the start\n                queue.append((score + nums[idx_end] * multipliers[level], idx_begin, idx_end - 1))  # Choose from the end\n\n            level += 1\n\n        return max_score\n</code></pre>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#complexity-analysis-of-approach-3","title":"Complexity Analysis of Approach 3","text":"<ul> <li>Time complexity: \\(O(2^m)\\)   Explore all possible combinations of <code>nums</code> and <code>multipliers</code> in a tree-like structure.<ul> <li>Each node in the tree represents a state of the problem, and the number of nodes is \\(O(2^m)\\) where \\(m\\) is the number of operations.</li> <li>The maximum depth of the tree is \\(O(m)\\), where \\(m\\) is the number of operations.</li> <li>Each node takes \\(O(1)\\) time to process.</li> <li>The total time complexity is \\(O(2^m)\\).</li> </ul> </li> <li>Space complexity: \\(O(2^m)\\)   The queue stores the states of the nodes at each level of the tree. The maximum number   of nodes happening at the last level (<code>m</code>th level) is \\(O(2^m)\\).</li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach 1 - Dynamic Programming (Top-Down) \\(O(m^2)\\) \\(O(m^2)\\) Approach 2 - Dynamic Programming (Bottom-Up) \\(O(m^2)\\) \\(O(m)\\) Approach 3 - Tree Traversal \\(O(2^m)\\) \\(O(2^m)\\)","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1700-1799/lc1770-maximum-score-from-performing-multiplication-operations/#test","title":"Test","text":"<ul> <li>Test normal cases</li> <li>Test edge cases like empty <code>nums</code> or <code>multipliers</code></li> <li>Test cases where <code>n</code> is equal to <code>m</code></li> </ul>","tags":["Dynamic Programming"]},{"location":"lc-solutions/lc1800-1899/lc1802-maximum-value-at-a-given-index-in-a-bounded-array/","title":"LC1802. Maximum Value at a Given Index in a Bounded Array","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1802-maximum-value-at-a-given-index-in-a-bounded-array/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1802: You are given three positive integers:\u00a0<code>n</code>,\u00a0<code>index</code>, and\u00a0<code>maxSum</code>. You want to construct an array\u00a0<code>nums</code>\u00a0(0-indexed)\u00a0that satisfies the following conditions:</p> <ul> <li><code>nums.length == n</code></li> <li><code>nums[i]</code>\u00a0is a\u00a0positive\u00a0integer where\u00a0<code>0 &lt;= i &lt; n</code>.</li> <li><code>abs(nums[i] - nums[i+1]) &lt;= 1</code>\u00a0where\u00a0<code>0 &lt;= i &lt; n-1</code>.</li> <li>The sum of all the elements of\u00a0<code>nums</code>\u00a0does not exceed\u00a0<code>maxSum</code>.</li> <li><code>nums[index]</code>\u00a0is\u00a0maximized.</li> </ul> <p>Return\u00a0<code>nums[index]</code> of the constructed array.</p> <p>Note that\u00a0<code>abs(x)</code>\u00a0equals\u00a0<code>x</code>\u00a0if\u00a0<code>x &gt;= 0</code>, and\u00a0<code>-x</code>\u00a0otherwise.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1802-maximum-value-at-a-given-index-in-a-bounded-array/#clarification","title":"Clarification","text":"<ul> <li>Allow duplicates</li> <li>Positive integer</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1802-maximum-value-at-a-given-index-in-a-bounded-array/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1802-maximum-value-at-a-given-index-in-a-bounded-array/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1802-maximum-value-at-a-given-index-in-a-bounded-array/#approach-binary-search","title":"Approach - Binary Search","text":"<p>To maximize <code>nums[index]</code>, it should be a peak of the array. The array will look like this with positive integers:</p> \\[ \\begin{matrix} \\text{index:} &amp; 0 &amp; 1 &amp; \\cdots &amp; i - d &amp; \\cdots &amp; i - 2 &amp; i - 1 &amp; i &amp; i + 1 &amp; i + 2 &amp; \\cdots &amp; i + d &amp; \\cdots &amp; n - 2 &amp; n -1 \\\\ \\text{value:} &amp; 1 &amp; 1 &amp; \\cdots &amp; m - d &amp; \\cdots &amp; m - 2 &amp; m - 1 &amp; m &amp; m - 1 &amp; m - 2 &amp; \\cdots &amp; m - d &amp; \\cdots &amp; 1 &amp; 1 \\end{matrix} \\] <p>Note that:</p> <ul> <li>The optimized solution is always reduced by the largest step <code>1</code> from the max value <code>m</code> until down to 1 due to positive integer requirement. If any two values are equal, we can always move <code>1</code> to the max value to make it higher.</li> <li>Depends on what the max value <code>m</code> and index <code>i</code> are. The value at index <code>0</code> could be either <code>m - i</code> or <code>1</code> and the right value at index <code>n - 1</code> could be either <code>m - (n - 1 - index)</code> or <code>1</code>.  </li> <li>Since numbers must be positive, we need at least <code>n</code> ones to populate the array. The array becomes</li> </ul> \\[ \\begin{matrix} \\text{index:} &amp; 0 &amp; 0 &amp; \\cdots &amp; i - d &amp; \\cdots &amp; i - 2 &amp; i - 1 &amp; i &amp; i + 1 &amp; i + 2 &amp; \\cdots &amp; i + d &amp; \\cdots &amp; n - 2 &amp; n -1 \\\\ \\text{value:} &amp; 0 &amp; 0 &amp; \\cdots &amp; m - d &amp; \\cdots &amp; m - 2 &amp; m - 1 &amp; m &amp; m - 1 &amp; m - 2 &amp; \\cdots &amp; m - d &amp; \\cdots &amp; 0 &amp; 0 \\end{matrix} \\] <p>To compute the sum of above array, we can divide it into two subarrays (left and right containing <code>m</code>): <code>[left, left + 1, ..., m - 1, m]</code> and <code>[m, m - 1, ..., right + 1, right]</code> and compute the sum of subarrays. </p> <p>The sum of <code>[left, left + 1, ..., m - 1, m]</code> or <code>[0, 0, 0 (left), 1, ..., m - 1, m]</code> is <code>(m + left) * (m - left + 1) / 2</code>.</p> <p>Essentially we are trying to find the max value <code>m</code> such that <code>sum(array) &lt;= maxSum</code>.</p> <ul> <li>If <code>sum(array) &lt;= maxSum</code>, <code>m</code> is the potential of the max value and we can further search some values &gt;= <code>m</code></li> <li>Otherwise, <code>m</code> is too large, we need to search smaller ones. Based on this, we can use binary search to find the max value <code>m</code>. </li> </ul> <p>@lee215 gives an elegant solution.</p> Python <pre><code>class Solution:\n    def maxValue(self, n: int, index: int, maxSum: int) -&gt; int:\n        maxSum -= n  # (1)\n        left, right = 0, maxSum\n        while left &lt; right:\n            mid = (left + right + 1) // 2\n            if self.getSum(n, index, mid) &lt;= maxSum:\n                left = mid\n            else:\n                right = mid - 1\n        return left + 1  # (2)\n\n    def getSum(self, n: int, index: int, valueMax: int) -&gt; int:\n        valueLeft = max(valueMax - index, 0)\n        res = (valueMax + valueLeft) * (valueMax - valueLeft + 1) / 2\n        valueRight = max(valueMax - (n - 1 - index), 0)\n        res += (valueMax + valueRight) * (valueMax - valueRight + 1) / 2\n        return res - valueMax  # (3)\n</code></pre> <ol> <li>All number are positive, assign 1 to each element</li> <li>+1 since reducing 1 from each position at the 1st line of the code</li> <li><code>valueMax</code> is added twice and needs to remove one</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1802-maximum-value-at-a-given-index-in-a-bounded-array/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(\\log \\text{maxSum})\\) It takes \\(O(\\log \\text{maxSum})\\) steps to search the max value. For <code>getSum</code> function, it takes \\(O(1)\\) to compute. </li> <li>Space complexity: \\(O(1)\\) Only use limited variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1802-maximum-value-at-a-given-index-in-a-bounded-array/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1870-minimum-speed-to-arrive-on-time/","title":"LC1870. Minimum Speed to Arrive on Time","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1870-minimum-speed-to-arrive-on-time/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1870: You are given a floating-point number\u00a0<code>hour</code>, representing the amount of time you have to reach the office. To commute to the office, you must take\u00a0<code>n</code>\u00a0trains in sequential order. You are also given an integer array\u00a0<code>dist</code>\u00a0of length\u00a0<code>n</code>, where\u00a0<code>dist[i]</code>describes the distance (in kilometers) of the\u00a0<code>ith</code>\u00a0train ride.</p> <p>Each train can only depart at an integer hour, so you may need to wait in between each train ride.</p> <ul> <li>For example, if the\u00a0<code>1st</code>\u00a0train ride takes\u00a0<code>1.5</code>\u00a0hours, you must wait for an additional\u00a0<code>0.5</code>\u00a0hours before you can depart on the\u00a0<code>2nd</code>\u00a0train ride at the 2 hour mark.</li> </ul> <p>Return\u00a0the\u00a0minimum positive integer\u00a0speed\u00a0(in kilometers per hour)\u00a0that all the trains must travel at for you to reach the office on time, or <code>-1</code> if it is impossible to be on time.</p> <p>Tests are generated such that the answer will not exceed\u00a0<code>107</code>\u00a0and\u00a0<code>hour</code>\u00a0will have\u00a0at most two digits after the decimal point.</p>","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1870-minimum-speed-to-arrive-on-time/#clarification","title":"Clarification","text":"<ul> <li><code>hour</code>: floating-point</li> <li>integer <code>dist</code></li> <li>return minimum positive integer speed</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1870-minimum-speed-to-arrive-on-time/#assumption","title":"Assumption","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1870-minimum-speed-to-arrive-on-time/#solution","title":"Solution","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1870-minimum-speed-to-arrive-on-time/#approach-binary-search","title":"Approach - Binary Search","text":"<p>Since each train will depart at an integer hour, when computing actual hours, for all the rides except the last one, the time of train ride need to round off to the next integer (<code>ceil</code>). The last ride can end at a decimal with a float value. </p> <ul> <li>If speed <code>s</code> meets the time requirement, no need to search speed &gt; <code>s</code> since they all will meet the requirement</li> <li>Otherwise, no need to search speed &lt; <code>s</code>, since they won't meet the requirement either.</li> </ul> <p>Based on these properties, we can use binary search to speed up searching. </p> Python <pre><code>class Solution:\n    def minSpeedOnTime(self, dist: List[int], hour: float) -&gt; int:\n        ans = -1\n        minSpeed, maxSpeed = 1, 10**7\n\n        while minSpeed &lt;= maxSpeed:\n            midSpeed = (minSpeed + maxSpeed) // 2\n            if self.canReachInTime(dist, hour, midSpeed):\n                ans = midSpeed\n                maxSpeed = midSpeed - 1  # (1)\n            else:\n                minSpeed = midSpeed + 1\n\n        return ans\n\n    def canReachInTime(self, dist: List[int], hour: float, speed: int) -&gt; bool:\n        hour_actual = 0\n        for idx in range(len(dist) - 1):\n            hour_actual += (dist[idx] + speed - 1) // speed  # (2)\n\n        hour_actual += dist[-1] / speed  # (3)\n        return hour_actual &lt;= hour\n</code></pre> <ol> <li>Can use <code>-1</code> since the answer is stored in the step above. If no <code>ans = midSpeed</code>, can't add <code>-1</code></li> <li>Integer hour with ceiling calculation since each train departs at an integer hour</li> <li>Last one is floating calculation</li> </ol>","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1870-minimum-speed-to-arrive-on-time/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n \\log k)\\) where \\(n\\) is the number of rides and \\(k\\) is the size of the search space, i.e., \\(10^7\\). After each iteration, the search space, \\(k\\) (\\(10^7\\)), is reduced by half. Within each iteration, it needs to go through the array to find the ride time, which takes \\(O(n)\\) time. Therefore, the total time complexity is \\(O(n \\log k)\\).   </li> <li>Space complexity: \\(O(1)\\) No extra space is required other that limited number of variables.</li> </ul>","tags":["Binary Search"]},{"location":"lc-solutions/lc1800-1899/lc1870-minimum-speed-to-arrive-on-time/#test","title":"Test","text":"","tags":["Binary Search"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/","title":"LC1973. Find if Path Exists in Graph","text":"","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 1973: There is a\u00a0bi-directional\u00a0graph with\u00a0<code>n</code>\u00a0vertices, where each vertex is labeled from\u00a0<code>0</code>\u00a0to\u00a0<code>n - 1</code>\u00a0(inclusive). The edges in the graph are represented as a 2D integer array\u00a0<code>edges</code>, where each\u00a0<code>edges[i] = [ui, vi]</code>\u00a0denotes a bi-directional edge between vertex\u00a0<code>ui</code>\u00a0and vertex\u00a0<code>vi</code>. Every vertex pair is connected by\u00a0at most one\u00a0edge, and no vertex has an edge to itself.</p> <p>You want to determine if there is a\u00a0valid path\u00a0that exists from vertex\u00a0<code>source</code>\u00a0to vertex\u00a0<code>destination</code>.</p> <p>Given\u00a0<code>edges</code>\u00a0and the integers\u00a0<code>n</code>,\u00a0<code>source</code>, and\u00a0<code>destination</code>, return\u00a0<code>true</code> if there is a\u00a0valid path\u00a0from <code>source</code> to <code>destination</code>, or <code>false</code> otherwise__.</p>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#clarification","title":"Clarification","text":"<ul> <li>bi-directional and no self-loop</li> <li>at most 1 edge between vertices</li> <li>can source and destination be the same?</li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#assumption","title":"Assumption","text":"<p>-</p>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#solution","title":"Solution","text":"<p>Go through edges and construct vortex matrix and then use either BFS or DFS to check if path exists</p>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#approach-bfs","title":"Approach - BFS","text":"Python <pre><code>class Solution:\n    def validPath(self, n: int, edges: List[List[int]], source: int, destination: int) -&gt; bool:\n        vertices = [[] for _ in range(n)]\n        for edge in edges:  # (1)\n            vertices[edge[0]].append(edge[1])\n            vertices[edge[1]].append(edge[0])\n\n        queue = deque([source])\n        visited = set([source])\n        while queue:\n            curr_node = queue.popleft()\n            if curr_node == destination:  # (2)\n                return True\n            for next_node in vertices[curr_node]:\n                if next_node not in visited:\n                    queue.append(next_node)\n                    visited.add(next_node)\n\n        return False\n</code></pre> <ol> <li>Add both edges since it is a bi-directed graph.  Each node may add duplicate values, which will be handled by visited later.</li> <li>Can handle normal cases and special case where source and destination are the same node</li> </ol>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#complexity-analysis-of-approach-1","title":"Complexity Analysis of Approach 1","text":"<ul> <li> <p>Time complexity: \\(O(V + E)\\)   The time complexity consists of:</p> <ul> <li>Build vertices matrix by visiting all <code>E</code> edges, which takes \\(O(E)\\) </li> <li>In BFS, each vertex is only visited once, it takes \\(O(V)\\) to traverse all nodes. </li> </ul> </li> <li> <p>Space complexity: \\(O(V + E)\\)   The space used consists of:</p> <ul> <li>Use a list to store all edges, which take \\(O(2 \\times E) = O(E)\\) space  </li> <li>Use <code>visited</code> to track visited nodes, which takes \\(O(V)\\) in the worst case</li> <li>Use <code>queue</code> to traverse nodes, which takes \\(O(V)\\) in the worst case</li> </ul> </li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#approach-2-dfs","title":"Approach 2 - DFS","text":"python <pre><code>class Solution:\ndef validPath(self, n: int, edges: List[List[int]], source: int, destination: int) -&gt; bool:\n    vertices = [[] for _ in range(n)]\n    for edge in edges:\n        # Undirected graph and it's okay to add redundant nodes\n        # Since we will use visited to check later\n        vertices[edge[0]].append(edge[1])\n        vertices[edge[1]].append(edge[0])\n\n    visited = set()\n    return self.dfs(vertices, visited, source, destination)\n\n\ndef dfs(self, vertices: List[List[int]], visited: Set[int], curr_node: int, destination: int) -&gt; bool:\n    if curr_node == destination:\n            return True\n\n    if curr_node not in visited:\n        visited.add(curr_node)\n        for next_node in vertices[curr_node]:\n            if self.dfs(vertices, visited, next_node, destination):\n                return True\n    return False\n</code></pre>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#complexity-analysis-of-approach-2","title":"Complexity Analysis of Approach 2","text":"<ul> <li>Time complexity: \\(O(V + E)\\) where \\(V\\) and \\(E\\) are the number of vertices and edges.  <ul> <li>For building <code>vertices</code> matrix of all <code>E</code> edges, it takes \\(O(E)\\).</li> <li>Each node is only visited once by using DFS with visited, it takes \\(O(V)\\) to traverse all nodes.</li> </ul> </li> <li>Space complexity: \\(O(V + E)\\) <ul> <li>Use a list of list to store two nodes per edge for all edges, it takes \\(O(2 \\times E) = O(E)\\).</li> <li>Use <code>set</code> to track the visited nodes, it may add all \\(V\\) nodes and use \\(O(V)\\) space in the worst case.</li> <li>The recursive function uses function call call stack, uses \\(O(V)\\) space in the worst case.</li> </ul> </li> </ul>","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#approach-3-union-find","title":"Approach 3 - Union Find","text":"","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#comparison-of-different-approaches","title":"Comparison of Different Approaches","text":"<p>The table below summarize the time complexity and space complexity of different approaches:</p> Approach Time Complexity Space Complexity Approach - BFS \\(O(V + E)\\) \\(O(V + E)\\) Approach - DFS \\(O(V + E)\\) \\(O(V + E)\\)","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc1900-1999/lc1971-find-if-path-exists-in-graph/#test","title":"Test","text":"","tags":["Breadth-First Search","Depth-First Search","Union Find"]},{"location":"lc-solutions/lc2000-2099/lc2095-delete-the-middle-node-of-a-linked-list/","title":"LC2095. Delete the Middle Node of a Linked List","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc2000-2099/lc2095-delete-the-middle-node-of-a-linked-list/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 2095: You are given the\u00a0<code>head</code>\u00a0of a linked list.\u00a0Delete\u00a0the\u00a0middle node, and return\u00a0the <code>head</code> of the modified linked list.</p> <p>The\u00a0middle node\u00a0of a linked list of size\u00a0<code>n</code>\u00a0is the\u00a0<code>\u230an / 2\u230bth</code>node from the\u00a0start\u00a0using\u00a00-based indexing, where\u00a0<code>\u230ax\u230b</code>denotes the largest integer less than or equal to\u00a0<code>x</code>.</p> <ul> <li>For\u00a0<code>n</code>\u00a0=\u00a0<code>1</code>,\u00a0<code>2</code>,\u00a0<code>3</code>,\u00a0<code>4</code>, and\u00a0<code>5</code>, the middle nodes are\u00a0<code>0</code>,\u00a0<code>1</code>,\u00a0<code>1</code>,\u00a0<code>2</code>, and\u00a0<code>2</code>, respectively.</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc2000-2099/lc2095-delete-the-middle-node-of-a-linked-list/#clarification","title":"Clarification","text":"<ul> <li>know the head and delete the middle</li> <li>definition of the middle</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc2000-2099/lc2095-delete-the-middle-node-of-a-linked-list/#assumption","title":"Assumption","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc2000-2099/lc2095-delete-the-middle-node-of-a-linked-list/#solution","title":"Solution","text":"","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc2000-2099/lc2095-delete-the-middle-node-of-a-linked-list/#approach-slowfast-pointers","title":"Approach - Slow/fast pointers","text":"<p>Use slow and fast pointers to find the middle. The fast pointer move as twice faster as the slow pointer. Let fast pointer goes first, when it reaches the end. The slower pointer's next node is the middle specified by the condition.</p> Note <p>If both fast and slow pointers starts from the same node, when fast pointers reaches the end, the slow pointer is the middle node. </p> Python <pre><code>class Solution:\n    def deleteMiddle(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:\n        if head is None or head.next is None:\n            return None\n\n        slow = head\n        fast = head.next.next # (1)\n\n        while fast and fast.next:\n            fast = fast.next.next\n            slow = slow.next\n\n        slow.next = slow.next.next\n        return head\n</code></pre> <ol> <li>The fast pointer moves early. So the slow pointer will stays at the node before the middle one when fast reaches the end.</li> </ol>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc2000-2099/lc2095-delete-the-middle-node-of-a-linked-list/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O(n)\\)     It takes \\(n/2\\) steps to go through the linked list and 1 step to remove the node. So the time complexity is \\(O(n)\\).  </li> <li>Space complexity: \\(O(1)\\)     Just use two pointers to iterate through the list.</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc2000-2099/lc2095-delete-the-middle-node-of-a-linked-list/#test","title":"Test","text":"<ul> <li>Test empty node</li> <li>Test list with just one node</li> </ul>","tags":["Linked List","Slow/Fast Pointers"]},{"location":"lc-solutions/lc2000-2099/lc2300-successful-pairs-of-spells-and-portions/","title":"LC2300. Successful Pairs of Spells and Potions","text":"","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc2000-2099/lc2300-successful-pairs-of-spells-and-portions/#problem-description","title":"Problem Description","text":"<p>LeetCode Problem 2300: You are given two positive integer arrays\u00a0<code>spells</code>\u00a0and\u00a0<code>potions</code>, of length\u00a0<code>n</code>\u00a0and\u00a0<code>m</code>\u00a0respectively, where\u00a0<code>spells[i]</code>\u00a0represents the strength of the\u00a0<code>ith</code>\u00a0spell and\u00a0<code>potions[j]</code>\u00a0represents the strength of the\u00a0<code>jth</code>\u00a0potion.</p> <p>You are also given an integer\u00a0<code>success</code>. A spell and potion pair is considered\u00a0successful\u00a0if the\u00a0product\u00a0of their strengths is\u00a0at least<code>success</code>.</p> <p>Return\u00a0an integer array <code>pairs</code> of length <code>n</code> where <code>pairs[i]</code> is the number of\u00a0potions\u00a0that will form a successful pair with the <code>ith</code> spell.</p>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc2000-2099/lc2300-successful-pairs-of-spells-and-portions/#clarification","title":"Clarification","text":"<ul> <li>two positive integer arrays with different size</li> <li>spells[i] * potions[j] &gt;=  success (int)</li> <li>return pairs array</li> <li>sorted or unsorted</li> </ul>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc2000-2099/lc2300-successful-pairs-of-spells-and-portions/#assumption","title":"Assumption","text":"<ul> <li>n &gt;= 1 and m &gt;= 1</li> </ul>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc2000-2099/lc2300-successful-pairs-of-spells-and-portions/#solution","title":"Solution","text":"","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc2000-2099/lc2300-successful-pairs-of-spells-and-portions/#approach-sorting-binary-search","title":"Approach - Sorting + Binary Search","text":"<p>Sort <code>portions</code> array and use binary search to find the first <code>portion[j]</code> meet the success condition for <code>spell[i]</code>. Then the rest of portions (j+1, j+2, ..., m-1) will also meet the success condition. The total number for <code>spell[i]</code> is <code>m - j</code>. </p> PythonPython - Simplified <pre><code>class Solution:\n    def successfulPairs(self, spells: List[int], potions: List[int], success: int) -&gt; List[int]:\n        n, m = len(spells), len(potions)\n        potions.sort()\n        pairs = [0] * n\n\n        for i in range(len(spells)):\n            left, right = 0, m - 1\n            while left &lt; right:\n                mid = (left + right) // 2\n                if potions[mid] * spells[i] &gt;= success:\n                    right = mid\n                else:\n                    left = mid + 1\n\n            if potions[left] * spells[i] &gt;= success:\n                pairs[i] = m - left\n            else:\n                pairs[i] = m - left - 1\n\n        return pairs\n</code></pre> <pre><code>class Solution:\n    def successfulPairs(self, spells: List[int], potions: List[int], success: int) -&gt; List[int]:\n        potions.sort()\n        return [len(potions) - bisect_left(potions, (success + a - 1) // a) for a in spells] # (1)\n</code></pre> <ol> <li><code>(success + a - 1) // a</code> is the ceiling value of <code>success / spells[i]</code></li> </ol>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc2000-2099/lc2300-successful-pairs-of-spells-and-portions/#complexity-analysis","title":"Complexity Analysis","text":"<ul> <li>Time complexity: \\(O((n + m) \\log m)\\) The sort takes \\(O(m \\log m)\\) and find all pairs with binary search takes \\(O(n \\log m)\\)</li> <li>Space complexity: \\(O(n)\\) Return array of pairs with size n</li> </ul>","tags":["Binary Search","Sorting"]},{"location":"lc-solutions/lc2000-2099/lc2300-successful-pairs-of-spells-and-portions/#test","title":"Test","text":"","tags":["Binary Search","Sorting"]}]}